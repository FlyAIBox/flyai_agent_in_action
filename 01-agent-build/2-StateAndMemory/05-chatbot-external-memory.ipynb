{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(flyai_agent_in_action)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(flyai_agent_in_action)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU ä¿¡æ¯     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 2015.36 GB (Available: 1867.67 GB)                                    |\n",
      "| GPU ä¿¡æ¯     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA ä¿¡æ¯    | 12.6                                                                  |\n",
      "| Python ç‰ˆæœ¬  | 3.12.11                                                               |\n",
      "| Conda ç‰ˆæœ¬   | conda 25.7.0                                                          |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 2014.78 GB, Used: 651.70 GB, Free: 1260.66 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c7afe-1037-41ab-98e4-494692e47402",
   "metadata": {
    "id": "af6c7afe-1037-41ab-98e4-494692e47402"
   },
   "source": [
    "# èŠå¤©æœºå™¨äººï¼šæ¶ˆæ¯æ‘˜è¦ä¸å¤–éƒ¨æ•°æ®åº“å†…å­˜\n",
    "\n",
    "## è¯¾ç¨‹å›é¡¾\n",
    "\n",
    "åœ¨å‰é¢çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº†å¦‚ä½•è‡ªå®šä¹‰å›¾çŠ¶æ€æ¨¡å¼å’ŒçŠ¶æ€å½’çº¦å™¨ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¹Ÿå±•ç¤ºäº†ä¸€äº›ä¿®å‰ªæˆ–è¿‡æ»¤å›¾ä¸­æ¶ˆæ¯çš„æŠ€å·§ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨è¿™äº›æ¦‚å¿µæ„å»ºäº†ä¸€ä¸ªå…·æœ‰å†…å­˜çš„èŠå¤©æœºå™¨äººï¼Œå®ƒèƒ½å¤Ÿç”Ÿæˆå¯¹è¯çš„è¿è¡Œæ‘˜è¦ã€‚\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›èŠå¤©æœºå™¨äººæ‹¥æœ‰å¯ä»¥æ— é™æœŸæŒä¹…åŒ–çš„å†…å­˜å‘¢ï¼Ÿ\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›æ›´é«˜çº§çš„æ£€æŸ¥ç‚¹å™¨ï¼Œå®ƒä»¬æ”¯æŒå¤–éƒ¨æ•°æ®åº“ã€‚\n",
    "\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ [SQLiteä½œä¸ºæ£€æŸ¥ç‚¹å™¨](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer)ï¼Œä½†å…¶ä»–æ£€æŸ¥ç‚¹å™¨ï¼ˆå¦‚ [Postgres](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)ï¼‰ä¹Ÿæ˜¯å¯ç”¨çš„ï¼\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯æ£€æŸ¥ç‚¹å™¨ï¼ˆCheckpointerï¼‰ï¼Ÿ\n",
    "æ£€æŸ¥ç‚¹å™¨æ˜¯LangGraphä¸­ç”¨äºä¿å­˜å’Œæ¢å¤å›¾æ‰§è¡ŒçŠ¶æ€çš„ç»„ä»¶ã€‚å®ƒå…è®¸ï¼š\n",
    "- **çŠ¶æ€æŒä¹…åŒ–**ï¼šå°†å¯¹è¯çŠ¶æ€ä¿å­˜åˆ°å¤–éƒ¨å­˜å‚¨\n",
    "- **ä¼šè¯æ¢å¤**ï¼šåœ¨åº”ç”¨é‡å¯åæ¢å¤ä¹‹å‰çš„å¯¹è¯\n",
    "- **å¤šçº¿ç¨‹æ”¯æŒ**ï¼šæ”¯æŒå¤šä¸ªå¹¶å‘å¯¹è¯ä¼šè¯\n",
    "- **å†å²è¿½è¸ª**ï¼šè®°å½•å®Œæ•´çš„æ‰§è¡Œå†å²\n",
    "\n",
    "### ä¸ºä»€ä¹ˆéœ€è¦å¤–éƒ¨æ•°æ®åº“ï¼Ÿ\n",
    "- **å†…å­˜é™åˆ¶**ï¼šPythonè¿›ç¨‹é‡å¯åï¼Œå†…å­˜ä¸­çš„çŠ¶æ€ä¼šä¸¢å¤±\n",
    "- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒå¤šä¸ªç”¨æˆ·åŒæ—¶ä½¿ç”¨\n",
    "- **å¯é æ€§**ï¼šæ•°æ®æŒä¹…åŒ–ï¼Œä¸ä¼šå› ç³»ç»Ÿæ•…éšœä¸¢å¤±\n",
    "- **ç”Ÿäº§ç¯å¢ƒ**ï¼šæ»¡è¶³ç”Ÿäº§ç¯å¢ƒçš„æ•°æ®å­˜å‚¨éœ€æ±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ed78d9-6ca2-45ac-96a9-52e341ec519d",
   "metadata": {
    "id": "85ed78d9-6ca2-45ac-96a9-52e341ec519d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# è¿™ä¸ªå‘½ä»¤ä¼šå®‰è£…LangGraphçš„SQLiteæ£€æŸ¥ç‚¹å™¨å’Œå…¶ä»–æ ¸å¿ƒä¾èµ–\n",
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langgraph-checkpoint-sqlite langchain_core langgraph langchain_openai\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7 langgraph-checkpoint-sqlite==2.0.11\n",
    "# ä¾èµ–åŒ…è¯´æ˜ï¼š\n",
    "# - langgraph-checkpoint-sqlite: SQLiteæ£€æŸ¥ç‚¹å™¨ï¼Œç”¨äºæŒä¹…åŒ–çŠ¶æ€\n",
    "# - langchain_core: LangChainæ ¸å¿ƒåŠŸèƒ½\n",
    "# - langgraph: LangGraphå›¾æ‰§è¡Œæ¡†æ¶\n",
    "# - langchain_openai: OpenAIæ¨¡å‹é›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e10c4d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e10c4d4",
    "outputId": "0920788f-41e4-4957-941e-beafe979ce12"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# ç¯å¢ƒå˜é‡é…ç½®\n",
    "# è®¾ç½®OpenAI APIå¯†é’¥ï¼Œè¿™æ˜¯ä½¿ç”¨OpenAIæ¨¡å‹æ‰€å¿…éœ€çš„\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# è®¾ç½®OpenAI APIå¯†é’¥\n",
    "# æ‚¨éœ€è¦ä» https://platform.openai.com/api-keys è·å–APIå¯†é’¥\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d25c0-e9b5-4854-bf07-3cc3ff07122e",
   "metadata": {
    "id": "b40d25c0-e9b5-4854-bf07-3cc3ff07122e"
   },
   "source": [
    "## SQLite æ•°æ®åº“ä»‹ç»\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ [SqliteSaveræ£€æŸ¥ç‚¹å™¨](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer) ä½œä¸ºèµ·ç‚¹ã€‚\n",
    "\n",
    "SQLiteæ˜¯ä¸€ä¸ª[å°å·§ã€å¿«é€Ÿã€é«˜åº¦æµè¡Œ](https://x.com/karpathy/status/1819490455664685297)çš„SQLæ•°æ®åº“ã€‚\n",
    "\n",
    "### SQLiteçš„ä¼˜åŠ¿\n",
    "- **è½»é‡çº§**ï¼šæ— éœ€å•ç‹¬çš„æ•°æ®åº“æœåŠ¡å™¨\n",
    "- **é›¶é…ç½®**ï¼šå¼€ç®±å³ç”¨\n",
    "- **è·¨å¹³å°**ï¼šæ”¯æŒæ‰€æœ‰ä¸»æµæ“ä½œç³»ç»Ÿ\n",
    "- **ACIDå…¼å®¹**ï¼šæ”¯æŒäº‹åŠ¡å¤„ç†\n",
    "- **åµŒå…¥å¼**ï¼šå¯ä»¥ç›´æ¥åµŒå…¥åˆ°åº”ç”¨ç¨‹åºä¸­\n",
    "\n",
    "å¦‚æœæˆ‘ä»¬æä¾› `\":memory:\"` å‚æ•°ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªå†…å­˜ä¸­çš„SQLiteæ•°æ®åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae15402-17ae-4e89-8ecf-4c89e08b22fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fae15402-17ae-4e89-8ecf-4c89e08b22fe",
    "outputId": "56f9d78d-4b40-488c-8736-ec4821045f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²åˆ›å»ºå†…å­˜SQLiteæ•°æ®åº“è¿æ¥\n",
      "ğŸ“ æ³¨æ„ï¼šå†…å­˜æ•°æ®åº“åœ¨ç¨‹åºç»“æŸåä¼šä¸¢å¤±æ•°æ®\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºSQLiteæ•°æ®åº“è¿æ¥\n",
    "import sqlite3\n",
    "\n",
    "# åˆ›å»ºå†…å­˜æ•°æ®åº“è¿æ¥\n",
    "# \":memory:\" è¡¨ç¤ºåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å†…å­˜æ•°æ®åº“\n",
    "# check_same_thread=False å…è®¸å¤šçº¿ç¨‹è®¿é—®ï¼ˆLangGraphéœ€è¦ï¼‰\n",
    "conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "\n",
    "print(\"âœ… å·²åˆ›å»ºå†…å­˜SQLiteæ•°æ®åº“è¿æ¥\")\n",
    "print(\"ğŸ“ æ³¨æ„ï¼šå†…å­˜æ•°æ®åº“åœ¨ç¨‹åºç»“æŸåä¼šä¸¢å¤±æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf53ec-6d4a-42ce-8183-344795eed403",
   "metadata": {
    "id": "c2bf53ec-6d4a-42ce-8183-344795eed403"
   },
   "source": [
    "ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æä¾›ä¸€ä¸ªæ•°æ®åº“è·¯å¾„ï¼Œå®ƒå°±ä¼šä¸ºæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–çš„æ•°æ®åº“æ–‡ä»¶ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58339167-920c-4994-a0a7-0a9c5d4f7cf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58339167-920c-4994-a0a7-0a9c5d4f7cf7",
    "outputId": "c4ce1a90-942f-4ace-a60a-339f23ac5500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²è¿æ¥åˆ°æŒä¹…åŒ–SQLiteæ•°æ®åº“\n",
      "ğŸ“ æ•°æ®åº“æ–‡ä»¶ä½ç½®: state_db/example.db\n",
      "ğŸ’¾ æ•°æ®å°†æŒä¹…åŒ–ä¿å­˜åˆ°ç£ç›˜\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæŒä¹…åŒ–æ•°æ®åº“\n",
    "# è®¾ç½®æ•°æ®åº“æ–‡ä»¶è·¯å¾„\n",
    "db_path = \"state_db/example.db\"\n",
    "\n",
    "# è¿æ¥åˆ°æŒä¹…åŒ–æ•°æ®åº“æ–‡ä»¶\n",
    "# è¿™ä¸ªæ•°æ®åº“æ–‡ä»¶ä¼šä¿å­˜åœ¨ç£ç›˜ä¸Šï¼Œç¨‹åºé‡å¯åæ•°æ®ä¸ä¼šä¸¢å¤±\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "print(\"âœ… å·²è¿æ¥åˆ°æŒä¹…åŒ–SQLiteæ•°æ®åº“\")\n",
    "print(f\"ğŸ“ æ•°æ®åº“æ–‡ä»¶ä½ç½®: {db_path}\")\n",
    "print(\"ğŸ’¾ æ•°æ®å°†æŒä¹…åŒ–ä¿å­˜åˆ°ç£ç›˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7736b6-a750-48f8-a838-8e7616b12250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c7736b6-a750-48f8-a838-8e7616b12250",
    "outputId": "f337a1cd-3122-4447-c95d-dadd357ea6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²åˆ›å»ºSQLiteæ£€æŸ¥ç‚¹å™¨\n",
      "ğŸ”§ æ£€æŸ¥ç‚¹å™¨å°†ç®¡ç†å¯¹è¯çŠ¶æ€çš„æŒä¹…åŒ–\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºSQLiteæ£€æŸ¥ç‚¹å™¨\n",
    "# è¿™æ˜¯LangGraphä¸­ç”¨äºæŒä¹…åŒ–çŠ¶æ€çš„ç»„ä»¶\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# ä½¿ç”¨SQLiteè¿æ¥åˆ›å»ºæ£€æŸ¥ç‚¹å™¨\n",
    "# è¿™ä¸ªæ£€æŸ¥ç‚¹å™¨å°†è´Ÿè´£ä¿å­˜å’Œæ¢å¤å›¾çš„çŠ¶æ€\n",
    "memory = SqliteSaver(conn)\n",
    "\n",
    "print(\"âœ… å·²åˆ›å»ºSQLiteæ£€æŸ¥ç‚¹å™¨\")\n",
    "print(\"ğŸ”§ æ£€æŸ¥ç‚¹å™¨å°†ç®¡ç†å¯¹è¯çŠ¶æ€çš„æŒä¹…åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cb629-213f-4b87-965e-19b812c42da1",
   "metadata": {
    "id": "9d8cb629-213f-4b87-965e-19b812c42da1"
   },
   "source": [
    "ç°åœ¨è®©æˆ‘ä»¬é‡æ–°å®šä¹‰æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººã€‚\n",
    "\n",
    "## èŠå¤©æœºå™¨äººæ¶æ„è®¾è®¡\n",
    "\n",
    "æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå…·æœ‰ä»¥ä¸‹åŠŸèƒ½çš„æ™ºèƒ½èŠå¤©æœºå™¨äººï¼š\n",
    "\n",
    "### æ ¸å¿ƒåŠŸèƒ½\n",
    "1. **å¯¹è¯ç®¡ç†**ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤\n",
    "2. **æ¶ˆæ¯æ‘˜è¦**ï¼šå½“å¯¹è¯è¿‡é•¿æ—¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦\n",
    "3. **çŠ¶æ€æŒä¹…åŒ–**ï¼šä½¿ç”¨SQLiteä¿å­˜å¯¹è¯å†å²\n",
    "4. **æ™ºèƒ½è·¯ç”±**ï¼šæ ¹æ®å¯¹è¯é•¿åº¦å†³å®šæ˜¯å¦è¿›è¡Œæ‘˜è¦\n",
    "\n",
    "### çŠ¶æ€è®¾è®¡\n",
    "- **messages**ï¼šå­˜å‚¨å¯¹è¯æ¶ˆæ¯åˆ—è¡¨\n",
    "- **summary**ï¼šå­˜å‚¨å¯¹è¯æ‘˜è¦\n",
    "- **è‡ªåŠ¨æ‘˜è¦è§¦å‘**ï¼šå½“æ¶ˆæ¯æ•°é‡è¶…è¿‡6æ¡æ—¶è§¦å‘æ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc414e29-2078-41a0-887c-af1a6a3d72c0",
   "metadata": {
    "id": "dc414e29-2078-41a0-887c-af1a6a3d72c0"
   },
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# åˆå§‹åŒ–OpenAIæ¨¡å‹\n",
    "# ä½¿ç”¨GPT-4oæ¨¡å‹ï¼Œtemperature=0ç¡®ä¿è¾“å‡ºç¨³å®šä¸€è‡´\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# å®šä¹‰çŠ¶æ€ç±»\n",
    "# ç»§æ‰¿MessagesStateï¼Œæ·»åŠ summaryå­—æ®µç”¨äºå­˜å‚¨å¯¹è¯æ‘˜è¦\n",
    "class State(MessagesState):\n",
    "    \"\"\"èŠå¤©æœºå™¨äººçŠ¶æ€ç±»\"\"\"\n",
    "    summary: str  # å­˜å‚¨å¯¹è¯æ‘˜è¦\n",
    "\n",
    "def call_model(state: State):\n",
    "    \"\"\"\n",
    "    è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›å¤\n",
    "\n",
    "    Args:\n",
    "        state: å½“å‰å¯¹è¯çŠ¶æ€\n",
    "\n",
    "    Returns:\n",
    "        dict: åŒ…å«AIå›å¤çš„çŠ¶æ€æ›´æ–°\n",
    "    \"\"\"\n",
    "    # è·å–ç°æœ‰æ‘˜è¦ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # å¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œå°†å…¶æ·»åŠ åˆ°ç³»ç»Ÿæ¶ˆæ¯ä¸­\n",
    "    if summary:\n",
    "        # åˆ›å»ºåŒ…å«æ‘˜è¦çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "        system_message = f\"æ­¤å‰å¯¹è¯çš„æ‘˜è¦ï¼š{summary}\"\n",
    "        # å°†ç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨å¼€å¤´\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ¶ˆæ¯\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›å¤\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \"\"\"\n",
    "    å¯¹å¯¹è¯è¿›è¡Œæ‘˜è¦å¤„ç†\n",
    "\n",
    "    å½“å¯¹è¯æ¶ˆæ¯è¿‡å¤šæ—¶ï¼Œç”Ÿæˆæ‘˜è¦å¹¶åˆ é™¤æ—§æ¶ˆæ¯\n",
    "\n",
    "    Args:\n",
    "        state: å½“å‰å¯¹è¯çŠ¶æ€\n",
    "\n",
    "    Returns:\n",
    "        dict: åŒ…å«æ–°æ‘˜è¦å’Œåˆ é™¤æ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°\n",
    "    \"\"\"\n",
    "    # è·å–ç°æœ‰æ‘˜è¦\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "      # å¦‚æœæ‘˜è¦å·²å­˜åœ¨ï¼Œåˆ™æ‰©å±•ç°æœ‰æ‘˜è¦\n",
    "      summary_message = (\n",
    "          f\"ç›®å‰ä¸ºæ­¢çš„å¯¹è¯æ‘˜è¦ï¼š{summary}\\n\\n\"\n",
    "          \"è¯·ç»“åˆä¸Šæ–¹çš„æ–°æ¶ˆæ¯ï¼Œæ‰©å±•ç°æœ‰æ‘˜è¦ï¼š\"\n",
    "      )\n",
    "\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰ç°æœ‰æ‘˜è¦ï¼Œåˆ™åˆ›å»ºæ–°æ‘˜è¦\n",
    "        summary_message = \"è¯·å¯¹ä¸Šæ–¹çš„å¯¹è¯åˆ›å»ºæ‘˜è¦ï¼š\"\n",
    "\n",
    "    # å°†æ‘˜è¦æç¤ºæ·»åŠ åˆ°æ¶ˆæ¯å†å²ä¸­\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # åˆ é™¤é™¤æœ€è¿‘2æ¡æ¶ˆæ¯å¤–çš„æ‰€æœ‰æ¶ˆæ¯\n",
    "    # ä½¿ç”¨RemoveMessageæ¥æ ‡è®°è¦åˆ é™¤çš„æ¶ˆæ¯\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \"\"\"\n",
    "    å†³å®šä¸‹ä¸€æ­¥æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹\n",
    "\n",
    "    æ ¹æ®å¯¹è¯é•¿åº¦å†³å®šæ˜¯ç»§ç»­å¯¹è¯è¿˜æ˜¯è¿›è¡Œæ‘˜è¦\n",
    "\n",
    "    Args:\n",
    "        state: å½“å‰å¯¹è¯çŠ¶æ€\n",
    "\n",
    "    Returns:\n",
    "        str: ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹åç§°æˆ–END\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # å¦‚æœæ¶ˆæ¯è¶…è¿‡6æ¡ï¼Œåˆ™è¿›è¡Œæ‘˜è¦\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # å¦åˆ™ç»“æŸå¯¹è¯\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c13c0b-a383-4f73-9cc1-63f0eed8f190",
   "metadata": {
    "id": "41c13c0b-a383-4f73-9cc1-63f0eed8f190"
   },
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨SQLiteæ£€æŸ¥ç‚¹å™¨é‡æ–°ç¼–è¯‘å›¾ã€‚\n",
    "\n",
    "## å›¾æ„å»ºè¿‡ç¨‹\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåŒ…å«ä»¥ä¸‹ç»„ä»¶çš„LangGraphï¼š\n",
    "\n",
    "### èŠ‚ç‚¹ï¼ˆNodesï¼‰\n",
    "1. **conversation**ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”ŸæˆAIå›å¤\n",
    "2. **summarize_conversation**ï¼šå½“å¯¹è¯è¿‡é•¿æ—¶ç”Ÿæˆæ‘˜è¦\n",
    "\n",
    "### è¾¹ï¼ˆEdgesï¼‰\n",
    "1. **START â†’ conversation**ï¼šä»å¼€å§‹èŠ‚ç‚¹åˆ°å¯¹è¯èŠ‚ç‚¹\n",
    "2. **conversation â†’ should_continue**ï¼šæ¡ä»¶è¾¹ï¼Œå†³å®šä¸‹ä¸€æ­¥\n",
    "3. **summarize_conversation â†’ END**ï¼šæ‘˜è¦å®Œæˆåç»“æŸ\n",
    "\n",
    "### æ£€æŸ¥ç‚¹å™¨é›†æˆ\n",
    "- ä½¿ç”¨SQLiteæ£€æŸ¥ç‚¹å™¨å®ç°çŠ¶æ€æŒä¹…åŒ–\n",
    "- æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘è®¿é—®\n",
    "- è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤å¯¹è¯çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e867fd95-91eb-4ce1-82fc-bb72d611a96d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "e867fd95-91eb-4ce1-82fc-bb72d611a96d",
    "outputId": "9d4ed258-a4cb-426e-dad7-9f7512a2365b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ èŠå¤©æœºå™¨äººå›¾ç»“æ„å·²æ„å»ºå®Œæˆ\n",
      "ğŸ“Š ä¸‹å›¾æ˜¾ç¤ºäº†èŠ‚ç‚¹å’Œè¾¹çš„è¿æ¥å…³ç³»\n",
      "å›¾å¯è§†åŒ–ï¼š\n",
      "âŒ Pyppeteer æ¸²æŸ“å¤±è´¥: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n",
      "\n",
      "ğŸ“ å›¾ç»“æ„ï¼ˆMermaid æ–‡æœ¬æ ¼å¼ï¼‰ï¼š\n",
      "==================================================\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__(<p>__start__</p>)\n",
      "\tconversation(conversation)\n",
      "\tsummarize_conversation(summarize_conversation)\n",
      "\t__end__(<p>__end__</p>)\n",
      "\t__start__ --> conversation;\n",
      "\tconversation --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ”— å›¾ç»“æ„ä¿¡æ¯ï¼š\n",
      "èŠ‚ç‚¹: ['__start__', 'conversation', 'summarize_conversation', '__end__']\n",
      "è¾¹: [Edge(source='__start__', target='conversation', data=None, conditional=False), Edge(source='conversation', target='__end__', data=None, conditional=False)]\n",
      "\n",
      "ğŸ’¡ æ‰‹åŠ¨æ¸²æŸ“è¯´æ˜ï¼š\n",
      "1. å¤åˆ¶ä¸Šé¢çš„ Mermaid æ–‡æœ¬\n",
      "2. è®¿é—® https://mermaid.live/\n",
      "3. ç²˜è´´æ–‡æœ¬åˆ°ç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å›¾å½¢\n",
      "4. æˆ–è€…ä½¿ç”¨æ”¯æŒ Mermaid çš„ Markdown ç¼–è¾‘å™¨\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºLangGraph\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# åˆ›å»ºçŠ¶æ€å›¾\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "# conversationèŠ‚ç‚¹ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”ŸæˆAIå›å¤\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "# summarize_conversationèŠ‚ç‚¹ï¼šç”Ÿæˆå¯¹è¯æ‘˜è¦\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "# ä»å¼€å§‹èŠ‚ç‚¹åˆ°å¯¹è¯èŠ‚ç‚¹\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "# æ¡ä»¶è¾¹ï¼šæ ¹æ®å¯¹è¯é•¿åº¦å†³å®šä¸‹ä¸€æ­¥\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "# æ‘˜è¦å®Œæˆåç»“æŸ\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾å¹¶é›†æˆSQLiteæ£€æŸ¥ç‚¹å™¨\n",
    "# checkpointerå‚æ•°å¯ç”¨çŠ¶æ€æŒä¹…åŒ–\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# æ˜¾ç¤ºå›¾çš„Mermaidå¯è§†åŒ–\n",
    "print(\"ğŸ¯ èŠå¤©æœºå™¨äººå›¾ç»“æ„å·²æ„å»ºå®Œæˆ\")\n",
    "print(\"ğŸ“Š ä¸‹å›¾æ˜¾ç¤ºäº†èŠ‚ç‚¹å’Œè¾¹çš„è¿æ¥å…³ç³»\")\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# å±•ç¤ºå›¾ç»“æ„\n",
    "# å›¾å¯è§†åŒ–\n",
    "print(\"å›¾å¯è§†åŒ–ï¼š\")\n",
    "\n",
    "# æ–¹æ¡ˆ1ï¼šå°è¯•ä½¿ç”¨ Pyppeteer æœ¬åœ°æ¸²æŸ“ï¼ˆæ¨èï¼‰\n",
    "try:\n",
    "    # å¯è§†åŒ–ï¼šé€šè¿‡ Mermaid æ¸²æŸ“å›¾ç»“æ„\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"âœ… å›¾æ¸²æŸ“æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Pyppeteer æ¸²æŸ“å¤±è´¥: {e}\")\n",
    "    \n",
    "    # æ–¹æ¡ˆ2ï¼šæ˜¾ç¤º Mermaid æ–‡æœ¬æ ¼å¼\n",
    "    print(\"\\nğŸ“ å›¾ç»“æ„ï¼ˆMermaid æ–‡æœ¬æ ¼å¼ï¼‰ï¼š\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æ–¹æ¡ˆ3ï¼šæ˜¾ç¤ºå›¾çš„èŠ‚ç‚¹å’Œè¾¹ä¿¡æ¯\n",
    "    print(\"\\nğŸ”— å›¾ç»“æ„ä¿¡æ¯ï¼š\")\n",
    "    print(\"èŠ‚ç‚¹:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"è¾¹:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # æ–¹æ¡ˆ4ï¼šæä¾›æ‰‹åŠ¨æ¸²æŸ“è¯´æ˜\n",
    "    print(\"\\nğŸ’¡ æ‰‹åŠ¨æ¸²æŸ“è¯´æ˜ï¼š\")\n",
    "    print(\"1. å¤åˆ¶ä¸Šé¢çš„ Mermaid æ–‡æœ¬\")\n",
    "    print(\"2. è®¿é—® https://mermaid.live/\")\n",
    "    print(\"3. ç²˜è´´æ–‡æœ¬åˆ°ç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å›¾å½¢\")\n",
    "    print(\"4. æˆ–è€…ä½¿ç”¨æ”¯æŒ Mermaid çš„ Markdown ç¼–è¾‘å™¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769db99-3938-45e6-a594-56beb18d6c45",
   "metadata": {
    "id": "8769db99-3938-45e6-a594-56beb18d6c45"
   },
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å¤šæ¬¡è°ƒç”¨å›¾æ¥æµ‹è¯•èŠå¤©æœºå™¨äººçš„åŠŸèƒ½ã€‚\n",
    "\n",
    "## æµ‹è¯•èŠå¤©æœºå™¨äºº\n",
    "\n",
    "æˆ‘ä»¬å°†è¿›è¡Œä»¥ä¸‹æµ‹è¯•ï¼š\n",
    "\n",
    "### æµ‹è¯•åœºæ™¯\n",
    "1. **è‡ªæˆ‘ä»‹ç»**ï¼šç”¨æˆ·ä»‹ç»è‡ªå·±çš„åå­—\n",
    "2. **è®°å¿†æµ‹è¯•**ï¼šè¯¢é—®ç”¨æˆ·åå­—ï¼Œæµ‹è¯•AIçš„è®°å¿†èƒ½åŠ›\n",
    "3. **å…´è¶£åˆ†äº«**ï¼šç”¨æˆ·åˆ†äº«å…´è¶£çˆ±å¥½\n",
    "4. **çŠ¶æ€æŒä¹…åŒ–**ï¼šéªŒè¯çŠ¶æ€æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“\n",
    "\n",
    "### é…ç½®è¯´æ˜\n",
    "- **thread_id**ï¼šç”¨äºæ ‡è¯†ä¸åŒçš„å¯¹è¯ä¼šè¯\n",
    "- **config**ï¼šåŒ…å«çº¿ç¨‹IDçš„é…ç½®å¯¹è±¡\n",
    "- **æŒä¹…åŒ–**ï¼šæ¯æ¬¡è°ƒç”¨éƒ½ä¼šè‡ªåŠ¨ä¿å­˜çŠ¶æ€åˆ°SQLiteæ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4094a0-d240-4be8-903a-7d9f605bdc5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f4094a0-d240-4be8-903a-7d9f605bdc5c",
    "outputId": "94f9bc30-fbcd-44ee-b81a-4c626f4fb4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹èŠå¤©æœºå™¨äººæµ‹è¯•\n",
      "==================================================\n",
      "\n",
      "ğŸ“ æµ‹è¯•1ï¼šç”¨æˆ·è‡ªæˆ‘ä»‹ç»\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼ŒLanceï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ã€‚ä½ å–œæ¬¢æ—§é‡‘å±±49äººé˜Ÿï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­èŠèŠä»–ä»¬ï¼Œæˆ–è€…ä½ æœ‰å…¶ä»–æ„Ÿå…´è¶£çš„è¯é¢˜å—ï¼Ÿ\n",
      "\n",
      "ğŸ§  æµ‹è¯•2ï¼šAIè®°å¿†æµ‹è¯•\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å«Lanceã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "ğŸ¯ æµ‹è¯•3ï¼šç”¨æˆ·åˆ†äº«å…´è¶£\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yo-Yo Maæ˜¯ä¸€ä½éå¸¸æ°å‡ºçš„å¤§æç´æ¼”å¥å®¶ï¼Œä»–çš„éŸ³ä¹æ·±å—è®¸å¤šäººå–œçˆ±ã€‚ä»–çš„æ¼”å¥é£æ ¼ä¼˜é›…è€Œå¯Œæœ‰æƒ…æ„Ÿï¼Œèƒ½å¤Ÿè§¦åŠ¨äººå¿ƒã€‚ä½ æœ‰ç‰¹åˆ«å–œæ¬¢çš„Yo-Yo Maçš„ä½œå“æˆ–ä¸“è¾‘å—ï¼Ÿæˆ–è€…ä½ å¯¹å¤å…¸éŸ³ä¹è¿˜æœ‰å…¶ä»–æ–¹é¢çš„å…´è¶£ï¼Ÿ\n",
      "\n",
      "âœ… èŠå¤©æœºå™¨äººæµ‹è¯•å®Œæˆ\n",
      "ğŸ’¾ æ‰€æœ‰å¯¹è¯çŠ¶æ€å·²ä¿å­˜åˆ°SQLiteæ•°æ®åº“\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºå¯¹è¯çº¿ç¨‹é…ç½®\n",
    "# thread_idç”¨äºæ ‡è¯†ä¸åŒçš„å¯¹è¯ä¼šè¯ï¼Œç›¸åŒIDçš„å¯¹è¯ä¼šå…±äº«çŠ¶æ€\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹èŠå¤©æœºå™¨äººæµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æµ‹è¯•1ï¼šç”¨æˆ·è‡ªæˆ‘ä»‹ç»\n",
    "print(\"\\nğŸ“ æµ‹è¯•1ï¼šç”¨æˆ·è‡ªæˆ‘ä»‹ç»\")\n",
    "input_message = HumanMessage(content=\"ä½ å¥½ï¼æˆ‘æ˜¯Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# æµ‹è¯•2ï¼šAIè®°å¿†æµ‹è¯•\n",
    "print(\"\\nğŸ§  æµ‹è¯•2ï¼šAIè®°å¿†æµ‹è¯•\")\n",
    "input_message = HumanMessage(content=\"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# æµ‹è¯•3ï¼šç”¨æˆ·åˆ†äº«å…´è¶£\n",
    "print(\"\\nğŸ¯ æµ‹è¯•3ï¼šç”¨æˆ·åˆ†äº«å…´è¶£\")\n",
    "input_message = HumanMessage(content=\"æˆ‘å–œæ¬¢YoYoMAçš„å¤å…¸éŸ³ä¹\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\nâœ… èŠå¤©æœºå™¨äººæµ‹è¯•å®Œæˆ\")\n",
    "print(\"ğŸ’¾ æ‰€æœ‰å¯¹è¯çŠ¶æ€å·²ä¿å­˜åˆ°SQLiteæ•°æ®åº“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3e842-4497-45e2-a924-69672a9bcb33",
   "metadata": {
    "id": "c0f3e842-4497-45e2-a924-69672a9bcb33"
   },
   "source": [
    "è®©æˆ‘ä»¬ç¡®è®¤çŠ¶æ€å·²æ­£ç¡®ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“ã€‚\n",
    "\n",
    "## çŠ¶æ€æŒä¹…åŒ–éªŒè¯\n",
    "\n",
    "æˆ‘ä»¬å°†æ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "### çŠ¶æ€æ£€æŸ¥é¡¹ç›®\n",
    "1. **æ¶ˆæ¯å†å²**ï¼šéªŒè¯æ‰€æœ‰å¯¹è¯æ¶ˆæ¯æ˜¯å¦ä¿å­˜\n",
    "2. **æ‘˜è¦ä¿¡æ¯**ï¼šæ£€æŸ¥å¯¹è¯æ‘˜è¦æ˜¯å¦æ­£ç¡®ç”Ÿæˆ\n",
    "3. **å…ƒæ•°æ®**ï¼šæŸ¥çœ‹æ‰§è¡Œæ­¥éª¤å’Œé…ç½®ä¿¡æ¯\n",
    "4. **æ—¶é—´æˆ³**ï¼šç¡®è®¤çŠ¶æ€ä¿å­˜æ—¶é—´\n",
    "\n",
    "### çŠ¶æ€ç»“æ„è¯´æ˜\n",
    "- **values**ï¼šåŒ…å«å®é™…çš„çŠ¶æ€æ•°æ®ï¼ˆæ¶ˆæ¯å’Œæ‘˜è¦ï¼‰\n",
    "- **next**ï¼šä¸‹ä¸€æ­¥è¦æ‰§è¡Œçš„èŠ‚ç‚¹\n",
    "- **config**ï¼šé…ç½®ä¿¡æ¯ï¼ŒåŒ…æ‹¬çº¿ç¨‹IDå’Œæ£€æŸ¥ç‚¹ID\n",
    "- **metadata**ï¼šæ‰§è¡Œå…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ­¥éª¤æ•°å’Œçˆ¶èŠ‚ç‚¹ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ab158a-5a82-417a-8841-730a4cc18ea7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2ab158a-5a82-417a-8841-730a4cc18ea7",
    "outputId": "6e9803ce-656c-425e-ad73-0dd5f09bdf10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€æŸ¥ä¿å­˜çš„å¯¹è¯çŠ¶æ€\n",
      "==================================================\n",
      "ğŸ“Š çŠ¶æ€æ¦‚è§ˆ:\n",
      "  - æ¶ˆæ¯æ•°é‡: 6\n",
      "  - æ˜¯å¦æœ‰æ‘˜è¦: æ˜¯\n",
      "  - æ‰§è¡Œæ­¥éª¤: 27\n",
      "  - åˆ›å»ºæ—¶é—´: 2025-09-30T03:13:25.513351+00:00\n",
      "\n",
      "ğŸ’¬ æ¶ˆæ¯å†å²:\n",
      "  1. ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼æˆ‘æ˜¯Lance\n",
      "  2. ğŸ¤– AI: ä½ å¥½ï¼ŒLanceï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ã€‚ä½ å–œæ¬¢æ—§é‡‘å±±49äººé˜Ÿï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­èŠèŠä»–ä»¬ï¼Œæˆ–è€…ä½ æœ‰å…¶ä»–æ„Ÿå…´è¶£çš„...\n",
      "  3. ğŸ‘¤ ç”¨æˆ·: æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\n",
      "  4. ğŸ¤– AI: ä½ å«Lanceã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "  5. ğŸ‘¤ ç”¨æˆ·: æˆ‘å–œæ¬¢YoYoMAçš„å¤å…¸éŸ³ä¹\n",
      "  6. ğŸ¤– AI: Yo-Yo Maæ˜¯ä¸€ä½éå¸¸æ°å‡ºçš„å¤§æç´æ¼”å¥å®¶ï¼Œä»–çš„éŸ³ä¹æ·±å—è®¸å¤šäººå–œçˆ±ã€‚ä»–çš„æ¼”å¥é£æ ¼ä¼˜é›…è€Œå¯Œæœ‰æƒ…æ„Ÿï¼Œèƒ½...\n",
      "\n",
      "ğŸ“ å¯¹è¯æ‘˜è¦:\n",
      "  Lanceç”¨ä¸­æ–‡å†æ¬¡ä»‹ç»äº†è‡ªå·±ï¼Œå¹¶è¡¨è¾¾äº†å¯¹æ—§é‡‘å±±49äººé˜Ÿçš„å–œçˆ±ã€‚AIåŠ©æ‰‹ç”¨ä¸­æ–‡å›åº”ï¼Œè¡¨ç¤ºå¾ˆé«˜å…´å†æ¬¡è§åˆ°Lanceï¼Œå¹¶æåˆ°å¯ä»¥ç»§ç»­è®¨è®º49äººé˜Ÿæˆ–å…¶ä»–æ„Ÿå…´è¶£çš„è¯é¢˜ã€‚æ•´ä¸ªå¯¹è¯ç®€çŸ­ä¸”æœ‰äº›é‡å¤ï¼ŒLanceå¤šæ¬¡ä»‹...\n",
      "\n",
      "âœ… çŠ¶æ€æŒä¹…åŒ–éªŒè¯å®Œæˆ\n",
      "ğŸ’¾ çŠ¶æ€å·²æˆåŠŸä¿å­˜åˆ°SQLiteæ•°æ®åº“\n"
     ]
    }
   ],
   "source": [
    "# è·å–å½“å‰å¯¹è¯çŠ¶æ€\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "\n",
    "print(\"ğŸ” æ£€æŸ¥ä¿å­˜çš„å¯¹è¯çŠ¶æ€\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯\n",
    "print(f\"ğŸ“Š çŠ¶æ€æ¦‚è§ˆ:\")\n",
    "print(f\"  - æ¶ˆæ¯æ•°é‡: {len(graph_state.values['messages'])}\")\n",
    "print(f\"  - æ˜¯å¦æœ‰æ‘˜è¦: {'æ˜¯' if graph_state.values.get('summary') else 'å¦'}\")\n",
    "print(f\"  - æ‰§è¡Œæ­¥éª¤: {graph_state.metadata.get('step', 'N/A')}\")\n",
    "print(f\"  - åˆ›å»ºæ—¶é—´: {graph_state.created_at}\")\n",
    "\n",
    "print(f\"\\nğŸ’¬ æ¶ˆæ¯å†å²:\")\n",
    "for i, msg in enumerate(graph_state.values['messages'], 1):\n",
    "    msg_type = \"ğŸ‘¤ ç”¨æˆ·\" if hasattr(msg, 'content') and isinstance(msg, HumanMessage) else \"ğŸ¤– AI\"\n",
    "    print(f\"  {i}. {msg_type}: {msg.content[:50]}{'...' if len(msg.content) > 50 else ''}\")\n",
    "\n",
    "if graph_state.values.get('summary'):\n",
    "    print(f\"\\nğŸ“ å¯¹è¯æ‘˜è¦:\")\n",
    "    print(f\"  {graph_state.values['summary'][:100]}{'...' if len(graph_state.values['summary']) > 100 else ''}\")\n",
    "\n",
    "print(f\"\\nâœ… çŠ¶æ€æŒä¹…åŒ–éªŒè¯å®Œæˆ\")\n",
    "print(f\"ğŸ’¾ çŠ¶æ€å·²æˆåŠŸä¿å­˜åˆ°SQLiteæ•°æ®åº“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21152d-ed9c-408d-b7d5-f634c9ce81e2",
   "metadata": {
    "id": "1e21152d-ed9c-408d-b7d5-f634c9ce81e2"
   },
   "source": [
    "### çŠ¶æ€æŒä¹…åŒ–éªŒè¯\n",
    "\n",
    "ä½¿ç”¨SQLiteç­‰æ•°æ®åº“æ„å‘³ç€çŠ¶æ€æ˜¯æŒä¹…åŒ–çš„ï¼\n",
    "\n",
    "## æŒä¹…åŒ–çš„ä¼˜åŠ¿\n",
    "\n",
    "### æ•°æ®æŒä¹…æ€§\n",
    "- **ç¨‹åºé‡å¯**ï¼šå³ä½¿é‡å¯Pythonå†…æ ¸ï¼Œæ•°æ®ä»ç„¶ä¿å­˜\n",
    "- **ä¼šè¯æ¢å¤**ï¼šå¯ä»¥æ¢å¤ä¹‹å‰çš„å¯¹è¯çŠ¶æ€\n",
    "- **å¤šå®ä¾‹æ”¯æŒ**ï¼šå¤šä¸ªåº”ç”¨å®ä¾‹å¯ä»¥å…±äº«åŒä¸€æ•°æ®åº“\n",
    "\n",
    "### å®é™…åº”ç”¨åœºæ™¯\n",
    "1. **Webåº”ç”¨**ï¼šç”¨æˆ·å…³é—­æµè§ˆå™¨åé‡æ–°æ‰“å¼€ï¼Œå¯¹è¯ç»§ç»­\n",
    "2. **APIæœåŠ¡**ï¼šæœåŠ¡é‡å¯åï¼Œç”¨æˆ·ä¼šè¯ä¸ä¼šä¸¢å¤±\n",
    "3. **å¤šç”¨æˆ·ç³»ç»Ÿ**ï¼šä¸åŒç”¨æˆ·æ‹¥æœ‰ç‹¬ç«‹çš„å¯¹è¯çº¿ç¨‹\n",
    "4. **æ•°æ®åˆ†æ**ï¼šå¯ä»¥åˆ†æå†å²å¯¹è¯æ•°æ®\n",
    "\n",
    "## æµ‹è¯•æŒä¹…åŒ–åŠŸèƒ½\n",
    "\n",
    "è®©æˆ‘ä»¬éªŒè¯çŠ¶æ€ç¡®å®è¢«æŒä¹…åŒ–ä¿å­˜äº†ã€‚å³ä½¿é‡æ–°è·å–çŠ¶æ€ï¼Œæ•°æ®ä»ç„¶å­˜åœ¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a44dc5-be04-45fa-a6fc-27b0f8ee4678",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9a44dc5-be04-45fa-a6fc-27b0f8ee4678",
    "outputId": "09f0a6ba-bea1-4991-dd7d-68a0ac771fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ é‡æ–°è·å–çŠ¶æ€ï¼ŒéªŒè¯æŒä¹…åŒ–\n",
      "==================================================\n",
      "ğŸ“Š çŠ¶æ€æ¢å¤éªŒè¯:\n",
      "  - æ¶ˆæ¯æ•°é‡: 6\n",
      "  - æ˜¯å¦æœ‰æ‘˜è¦: æ˜¯\n",
      "  - çŠ¶æ€å®Œæ•´æ€§: âœ… å®Œæ•´\n",
      "\n",
      "ğŸ’¾ æŒä¹…åŒ–çŠ¶æ€:\n",
      "  - æ•°æ®åº“æ–‡ä»¶: state_db/example.db\n",
      "  - çº¿ç¨‹ID: 1\n",
      "  - æ£€æŸ¥ç‚¹ID: N/A\n",
      "\n",
      "ğŸ‰ æŒä¹…åŒ–éªŒè¯æˆåŠŸï¼\n",
      "âœ¨ çŠ¶æ€å·²æˆåŠŸä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼Œå¯ä»¥è·¨ä¼šè¯æ¢å¤\n"
     ]
    }
   ],
   "source": [
    "# é‡æ–°è·å–çŠ¶æ€ï¼ŒéªŒè¯æŒä¹…åŒ–\n",
    "# å³ä½¿é‡æ–°åˆ›å»ºé…ç½®å¯¹è±¡ï¼ŒçŠ¶æ€ä»ç„¶å¯ä»¥ä»æ•°æ®åº“æ¢å¤\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "\n",
    "print(\"ğŸ”„ é‡æ–°è·å–çŠ¶æ€ï¼ŒéªŒè¯æŒä¹…åŒ–\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# éªŒè¯çŠ¶æ€æ˜¯å¦å®Œæ•´æ¢å¤\n",
    "print(f\"ğŸ“Š çŠ¶æ€æ¢å¤éªŒè¯:\")\n",
    "print(f\"  - æ¶ˆæ¯æ•°é‡: {len(graph_state.values['messages'])}\")\n",
    "print(f\"  - æ˜¯å¦æœ‰æ‘˜è¦: {'æ˜¯' if graph_state.values.get('summary') else 'å¦'}\")\n",
    "print(f\"  - çŠ¶æ€å®Œæ•´æ€§: {'âœ… å®Œæ•´' if graph_state.values else 'âŒ ä¸å®Œæ•´'}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ æŒä¹…åŒ–çŠ¶æ€:\")\n",
    "print(f\"  - æ•°æ®åº“æ–‡ä»¶: {db_path}\")\n",
    "print(f\"  - çº¿ç¨‹ID: {config['configurable']['thread_id']}\")\n",
    "print(f\"  - æ£€æŸ¥ç‚¹ID: {graph_state.config.get('checkpoint_id', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ æŒä¹…åŒ–éªŒè¯æˆåŠŸï¼\")\n",
    "print(f\"âœ¨ çŠ¶æ€å·²æˆåŠŸä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼Œå¯ä»¥è·¨ä¼šè¯æ¢å¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b89d33",
   "metadata": {
    "id": "53b89d33"
   },
   "source": [
    "## å­¦ä¹ æ€»ç»“\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç»æˆåŠŸå­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“å®ç°èŠå¤©æœºå™¨äººçš„æŒä¹…åŒ–å†…å­˜ã€‚\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "#### 1. æ£€æŸ¥ç‚¹å™¨ï¼ˆCheckpointerï¼‰\n",
    "- **ä½œç”¨**ï¼šç®¡ç†å›¾çŠ¶æ€çš„ä¿å­˜å’Œæ¢å¤\n",
    "- **ç±»å‹**ï¼šå†…å­˜æ£€æŸ¥ç‚¹å™¨ vs æ•°æ®åº“æ£€æŸ¥ç‚¹å™¨\n",
    "- **ä¼˜åŠ¿**ï¼šæ”¯æŒçŠ¶æ€æŒä¹…åŒ–ã€å¤šçº¿ç¨‹è®¿é—®ã€ä¼šè¯æ¢å¤\n",
    "\n",
    "#### 2. SQLiteæ•°æ®åº“\n",
    "- **ç‰¹ç‚¹**ï¼šè½»é‡çº§ã€é›¶é…ç½®ã€è·¨å¹³å°\n",
    "- **åº”ç”¨**ï¼šé€‚åˆä¸­å°å‹åº”ç”¨çš„æŒä¹…åŒ–å­˜å‚¨\n",
    "- **é›†æˆ**ï¼šä¸LangGraphæ— ç¼é›†æˆ\n",
    "\n",
    "#### 3. çŠ¶æ€ç®¡ç†\n",
    "- **æ¶ˆæ¯å†å²**ï¼šå­˜å‚¨å®Œæ•´çš„å¯¹è¯è®°å½•\n",
    "- **æ‘˜è¦æœºåˆ¶**ï¼šè‡ªåŠ¨ç”Ÿæˆå¯¹è¯æ‘˜è¦ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´\n",
    "- **æ™ºèƒ½è·¯ç”±**ï¼šæ ¹æ®å¯¹è¯é•¿åº¦å†³å®šæ˜¯å¦è¿›è¡Œæ‘˜è¦\n",
    "\n",
    "#### 4. å›¾æ¶æ„è®¾è®¡\n",
    "- **èŠ‚ç‚¹**ï¼šconversationï¼ˆå¯¹è¯ï¼‰ã€summarize_conversationï¼ˆæ‘˜è¦ï¼‰\n",
    "- **è¾¹**ï¼šæ¡ä»¶è¾¹å®ç°æ™ºèƒ½è·¯ç”±\n",
    "- **çŠ¶æ€**ï¼šç»§æ‰¿MessagesStateï¼Œæ·»åŠ summaryå­—æ®µ\n",
    "\n",
    "### ğŸ› ï¸ å®è·µæŠ€èƒ½\n",
    "\n",
    "#### ä»£ç å®ç°\n",
    "- âœ… åˆ›å»ºSQLiteæ•°æ®åº“è¿æ¥\n",
    "- âœ… é…ç½®æ£€æŸ¥ç‚¹å™¨\n",
    "- âœ… è®¾è®¡çŠ¶æ€ç±»\n",
    "- âœ… å®ç°èŠ‚ç‚¹å‡½æ•°\n",
    "- âœ… æ„å»ºæ¡ä»¶è¾¹\n",
    "- âœ… ç¼–è¯‘å›¾å¹¶é›†æˆæ£€æŸ¥ç‚¹å™¨\n",
    "\n",
    "#### æµ‹è¯•éªŒè¯\n",
    "- âœ… å¤šè½®å¯¹è¯æµ‹è¯•\n",
    "- âœ… çŠ¶æ€æŒä¹…åŒ–éªŒè¯\n",
    "- âœ… è®°å¿†èƒ½åŠ›æµ‹è¯•\n",
    "- âœ… æ‘˜è¦åŠŸèƒ½æµ‹è¯•\n",
    "\n",
    "### ğŸš€ è¿›é˜¶å­¦ä¹ \n",
    "\n",
    "#### ä¸‹ä¸€æ­¥å»ºè®®\n",
    "1. **æ¢ç´¢å…¶ä»–æ•°æ®åº“**ï¼šå°è¯•PostgreSQLæ£€æŸ¥ç‚¹å™¨\n",
    "2. **ä¼˜åŒ–æ‘˜è¦ç­–ç•¥**ï¼šè°ƒæ•´æ‘˜è¦è§¦å‘æ¡ä»¶å’Œç­–ç•¥\n",
    "3. **æ·»åŠ æ›´å¤šåŠŸèƒ½**ï¼šç”¨æˆ·è®¤è¯ã€å¤šè¯­è¨€æ”¯æŒç­‰\n",
    "4. **æ€§èƒ½ä¼˜åŒ–**ï¼šæ•°æ®åº“ç´¢å¼•ã€è¿æ¥æ± ç­‰\n",
    "\n",
    "#### ç›¸å…³èµ„æº\n",
    "- [LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)\n",
    "- [SQLiteæ£€æŸ¥ç‚¹å™¨æ–‡æ¡£](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer)\n",
    "- [PostgreSQLæ£€æŸ¥ç‚¹å™¨](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)\n",
    "- [LangGraph StudioæŒ‡å—](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)\n",
    "\n",
    "### ğŸ’¡ å…³é”®æ”¶è·\n",
    "\n",
    "1. **æŒä¹…åŒ–çš„é‡è¦æ€§**ï¼šç”Ÿäº§ç¯å¢ƒå¿…é¡»è€ƒè™‘æ•°æ®æŒä¹…åŒ–\n",
    "2. **çŠ¶æ€ç®¡ç†**ï¼šåˆç†è®¾è®¡çŠ¶æ€ç»“æ„ï¼Œå¹³è¡¡æ€§èƒ½å’ŒåŠŸèƒ½\n",
    "3. **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†å¤æ‚åŠŸèƒ½åˆ†è§£ä¸ºç‹¬ç«‹çš„èŠ‚ç‚¹\n",
    "4. **æµ‹è¯•é©±åŠ¨**ï¼šé€šè¿‡æµ‹è¯•éªŒè¯åŠŸèƒ½çš„æ­£ç¡®æ€§\n",
    "\n",
    "### ğŸ‰ æ­å–œå®Œæˆï¼\n",
    "\n",
    "æ‚¨å·²ç»æŒæ¡äº†LangGraphä¸­å¤–éƒ¨æ•°æ®åº“é›†æˆçš„æ ¸å¿ƒæŠ€èƒ½ã€‚è¿™äº›çŸ¥è¯†å°†å¸®åŠ©æ‚¨æ„å»ºæ›´åŠ å¥å£®å’Œå¯æ‰©å±•çš„AIåº”ç”¨ã€‚\n",
    "\n",
    "ç»§ç»­æ¢ç´¢ä¸‹ä¸€ä¸ªæ¨¡å—ï¼Œå­¦ä¹ æ›´å¤šé«˜çº§åŠŸèƒ½ï¼\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
