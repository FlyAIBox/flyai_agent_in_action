{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {},
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n\n#### æ¦‚è¿°\n\næœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n\n- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n\n#### é…ç½®\n\n- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(flyai_agent_in_action)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n\n# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\neval \"$(conda shell.bash hook)\"\nconda activate flyai_agent_in_action\n\necho \"=========================================\"\necho \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\necho \"=========================================\"\n\n# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\nCURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n\nif [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\"\n    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n    echo \"\"\n    echo \"ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\"\n    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\"\nelse\n    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n    echo \"\"\n    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(flyai_agent_in_action)'ã€‚\"\n    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n    echo \"\"\n    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n    echo \"\"\n    echo \"%%script bash\"\n    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n    echo \"conda activate flyai_agent_in_action\"\nfi\n\necho \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/langchain-academy/blob/fly101/module-2/chatbot-summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {
    "id": "b651ead9-5504-45ee-938d-f91ac78dddd1"
   },
   "source": [
    "# å¸¦æ¶ˆæ¯æ‘˜è¦åŠŸèƒ½çš„èŠå¤©æœºå™¨äºº\n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬å·²ç»å­¦ä¹ äº†å¦‚ä½•è‡ªå®šä¹‰å›¾çŠ¶æ€æ¨¡å¼ï¼ˆgraph state schemaï¼‰å’ŒçŠ¶æ€å½’çº¦å™¨ï¼ˆreducerï¼‰ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¹Ÿå±•ç¤ºäº†å¤šç§åœ¨å›¾çŠ¶æ€ä¸­ä¿®å‰ªæˆ–è¿‡æ»¤æ¶ˆæ¯çš„æ–¹æ³•ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ›´è¿›ä¸€æ­¥ï¼\n",
    "\n",
    "ä¸ä»…ä»…æ˜¯ä¿®å‰ªæˆ–è¿‡æ»¤æ¶ˆæ¯ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥ç”Ÿæˆå¯¹è¯çš„æŒç»­æ‘˜è¦ã€‚\n",
    "\n",
    "è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿä¿ç•™å®Œæ•´å¯¹è¯çš„å‹ç¼©è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç®€å•åœ°é€šè¿‡ä¿®å‰ªæˆ–è¿‡æ»¤æ¥åˆ é™¤å®ƒä»¬ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†æŠŠè¿™ç§æ‘˜è¦åŠŸèƒ½æ•´åˆåˆ°ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººä¸­ã€‚\n",
    "\n",
    "å¹¶ä¸”æˆ‘ä»¬å°†ä¸ºè¿™ä¸ªèŠå¤©æœºå™¨äººé…å¤‡è®°å¿†åŠŸèƒ½ï¼Œæ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„å¯¹è¯ï¼Œè€Œä¸ä¼šäº§ç”Ÿé«˜æ˜‚çš„tokenæˆæœ¬æˆ–å»¶è¿Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {
    "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d"
   },
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# ä½¿ç”¨ %%capture æ¥éšè—å®‰è£…è¿‡ç¨‹çš„è¾“å‡ºä¿¡æ¯\n",
    "%%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_core langgraph langchain_openai\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09201a62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09201a62",
    "outputId": "181fdbf3-2fa5-42a5-d4de-ec9ab8e0a9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    è®¾ç½®ç¯å¢ƒå˜é‡çš„è¾…åŠ©å‡½æ•°\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œåˆ™æç¤ºç”¨æˆ·è¾“å…¥\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# è®¾ç½® OpenAI API å¯†é’¥\n",
    "# è¿™æ˜¯ä½¿ç”¨ OpenAI æ¨¡å‹æ‰€å¿…éœ€çš„\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {
    "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd"
   },
   "source": [
    "æˆ‘ä»¬å°†ä½¿ç”¨ [LangSmith](https://docs.smith.langchain.com/) è¿›è¡Œ[è¿½è¸ª](https://docs.smith.langchain.com/concepts/tracing)ã€‚\n",
    "\n",
    "LangSmith æ˜¯ LangChain æä¾›çš„è°ƒè¯•å’Œç›‘æ§å·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬ï¼š\n",
    "- è¿½è¸ª LLM è°ƒç”¨é“¾\n",
    "- ç›‘æ§æ€§èƒ½å’Œæˆæœ¬\n",
    "- è°ƒè¯•å¯¹è¯æµç¨‹\n",
    "- åˆ†ææ¨¡å‹è¡Œä¸º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464856d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "464856d4",
    "outputId": "02083c1b-58d2-4ecf-9bfd-d176c5ed864a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½® LangSmith ç›¸å…³ç¯å¢ƒå˜é‡\n",
    "# LangSmith ç”¨äºè¿½è¸ªå’Œè°ƒè¯• LangChain åº”ç”¨\n",
    "_set_env(\"LANGSMITH_API_KEY\")  # LangSmith API å¯†é’¥\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # å¯ç”¨è¿½è¸ªåŠŸèƒ½\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"FlyAIBox\"  # è®¾ç½®é¡¹ç›®åç§°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {
    "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åˆå§‹åŒ– OpenAI èŠå¤©æ¨¡å‹\n",
    "# gpt-4o: ä½¿ç”¨ GPT-4 Omni æ¨¡å‹ï¼Œè¿™æ˜¯ OpenAI æœ€æ–°çš„å¤šæ¨¡æ€æ¨¡å‹\n",
    "# temperature=0: è®¾ç½®æ¸©åº¦ä¸º 0ï¼Œä½¿æ¨¡å‹è¾“å‡ºæ›´åŠ ç¡®å®šæ€§å’Œä¸€è‡´\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {
    "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b"
   },
   "source": [
    "æˆ‘ä»¬å°†ä½¿ç”¨ `MessagesState`ï¼Œå°±åƒä¹‹å‰ä¸€æ ·ã€‚\n",
    "\n",
    "é™¤äº†å†…ç½®çš„ `messages` é”®ä¹‹å¤–ï¼Œæˆ‘ä»¬ç°åœ¨è¿˜å°†åŒ…å«ä¸€ä¸ªè‡ªå®šä¹‰é”®ï¼ˆ`summary`ï¼‰ã€‚\n",
    "\n",
    "**çŠ¶æ€è®¾è®¡è¯´æ˜ï¼š**\n",
    "- `messages`: å­˜å‚¨å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨\n",
    "- `summary`: å­˜å‚¨å¯¹è¯çš„æ‘˜è¦ä¿¡æ¯ï¼Œç”¨äºå‹ç¼©é•¿å¯¹è¯å†å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {
    "id": "948e60f0-5c76-4235-b40e-cf523205d40e"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    \"\"\"\n",
    "    è‡ªå®šä¹‰çŠ¶æ€ç±»ï¼Œç»§æ‰¿è‡ª MessagesState\n",
    "\n",
    "    ç»§æ‰¿çš„åŠŸèƒ½ï¼š\n",
    "    - messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†å²\n",
    "\n",
    "    æ–°å¢åŠŸèƒ½ï¼š\n",
    "    - summary: å­—ç¬¦ä¸²ç±»å‹ï¼Œç”¨äºå­˜å‚¨å¯¹è¯æ‘˜è¦\n",
    "    \"\"\"\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {
    "id": "6855ea31-5cc1-4277-a189-0b72459f67ec"
   },
   "source": [
    "æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹æ¥è°ƒç”¨æˆ‘ä»¬çš„ LLMï¼Œå¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œåˆ™å°†å…¶èå…¥åˆ°æç¤ºä¸­ã€‚\n",
    "\n",
    "**èŠ‚ç‚¹åŠŸèƒ½è¯´æ˜ï¼š**\n",
    "- æ£€æŸ¥çŠ¶æ€ä¸­æ˜¯å¦å­˜åœ¨æ‘˜è¦\n",
    "- å¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œå°†å…¶ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸­\n",
    "- è°ƒç”¨ LLM ç”Ÿæˆå›å¤\n",
    "- è¿”å› AI çš„å›å¤æ¶ˆæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {
    "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "def call_model(state: State):\n",
    "    \"\"\"\n",
    "    è°ƒç”¨ LLM æ¨¡å‹ç”Ÿæˆå›å¤çš„èŠ‚ç‚¹å‡½æ•°\n",
    "\n",
    "    å‚æ•°:\n",
    "        state (State): å½“å‰å›¾çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å’Œæ‘˜è¦ä¿¡æ¯\n",
    "\n",
    "    è¿”å›:\n",
    "        dict: åŒ…å« AI å›å¤æ¶ˆæ¯çš„å­—å…¸\n",
    "\n",
    "    åŠŸèƒ½è¯´æ˜:\n",
    "        1. æ£€æŸ¥çŠ¶æ€ä¸­æ˜¯å¦å­˜åœ¨å¯¹è¯æ‘˜è¦\n",
    "        2. å¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œå°†å…¶ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸Šä¸‹æ–‡ä¸­\n",
    "        3. è°ƒç”¨ LLM æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "        4. è¿”å›åŒ…å« AI å›å¤çš„çŠ¶æ€æ›´æ–°\n",
    "    \"\"\"\n",
    "\n",
    "    # è·å–æ‘˜è¦ä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # å¦‚æœå­˜åœ¨æ‘˜è¦ï¼Œå°†å…¶èå…¥åˆ°æç¤ºä¸­\n",
    "    if summary:\n",
    "        # åˆ›å»ºåŒ…å«æ‘˜è¦çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "        # è¿™æœ‰åŠ©äº LLM ç†è§£ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡\n",
    "        # system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        system_message = f\"æ­¤å‰å¯¹è¯çš„æ‘˜è¦ï¼š{summary}\"\n",
    "\n",
    "        # å°†ç³»ç»Ÿæ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´\n",
    "        # ç³»ç»Ÿæ¶ˆæ¯é€šå¸¸ç”¨äºæä¾›ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»¤\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ¶ˆæ¯\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # è°ƒç”¨ LLM æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # è¿”å›åŒ…å«æ–°æ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {
    "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450"
   },
   "source": [
    "æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹æ¥ç”Ÿæˆæ‘˜è¦ã€‚\n",
    "\n",
    "**æ‘˜è¦èŠ‚ç‚¹åŠŸèƒ½ï¼š**\n",
    "- åˆ†æå½“å‰å¯¹è¯å†å²\n",
    "- ä½¿ç”¨ LLM ç”Ÿæˆå¯¹è¯æ‘˜è¦\n",
    "- æ¸…ç†æ—§æ¶ˆæ¯ï¼Œåªä¿ç•™æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯\n",
    "- æ›´æ–°çŠ¶æ€ä¸­çš„æ‘˜è¦ä¿¡æ¯\n",
    "\n",
    "**æ³¨æ„ï¼š** è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ `RemoveMessage` åœ¨ç”Ÿæˆæ‘˜è¦åè¿‡æ»¤æˆ‘ä»¬çš„çŠ¶æ€ï¼Œè¿™æ ·å¯ä»¥ï¼š\n",
    "- å‡å°‘å†…å­˜å ç”¨\n",
    "- é™ä½åç»­è°ƒç”¨çš„ token æˆæœ¬\n",
    "- ä¿æŒå¯¹è¯çš„è¿ç»­æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {
    "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e"
   },
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå¯¹è¯æ‘˜è¦çš„èŠ‚ç‚¹å‡½æ•°\n",
    "\n",
    "    å‚æ•°:\n",
    "        state (State): å½“å‰å›¾çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å’Œæ‘˜è¦ä¿¡æ¯\n",
    "\n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æ–°æ‘˜è¦å’Œæ¶ˆæ¯åˆ é™¤æŒ‡ä»¤çš„å­—å…¸\n",
    "\n",
    "    åŠŸèƒ½è¯´æ˜:\n",
    "        1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æ‘˜è¦\n",
    "        2. æ ¹æ®æƒ…å†µåˆ›å»ºä¸åŒçš„æ‘˜è¦æç¤º\n",
    "        3. è°ƒç”¨ LLM ç”Ÿæˆæˆ–æ›´æ–°æ‘˜è¦\n",
    "        4. åˆ é™¤æ—§æ¶ˆæ¯ï¼Œåªä¿ç•™æœ€è¿‘çš„ 2 æ¡æ¶ˆæ¯\n",
    "        5. æ›´æ–°çŠ¶æ€ä¸­çš„æ‘˜è¦ä¿¡æ¯\n",
    "    \"\"\"\n",
    "\n",
    "    # é¦–å…ˆè·å–ä»»ä½•ç°æœ‰çš„æ‘˜è¦\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # åˆ›å»ºæ‘˜è¦æç¤º\n",
    "    # if summary:\n",
    "    #     # å¦‚æœæ‘˜è¦å·²å­˜åœ¨ï¼Œåˆ™æ‰©å±•ç°æœ‰æ‘˜è¦\n",
    "    #     summary_message = (\n",
    "    #         f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "    #         \"Extend the summary by taking into account the new messages above:\"\n",
    "    #     )\n",
    "\n",
    "    # else:\n",
    "    #     # å¦‚æœæ²¡æœ‰ç°æœ‰æ‘˜è¦ï¼Œåˆ™åˆ›å»ºæ–°æ‘˜è¦\n",
    "    #     summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    if summary:\n",
    "      # å¦‚æœæ‘˜è¦å·²å­˜åœ¨ï¼Œåˆ™æ‰©å±•ç°æœ‰æ‘˜è¦\n",
    "      summary_message = (\n",
    "          f\"ç›®å‰ä¸ºæ­¢çš„å¯¹è¯æ‘˜è¦ï¼š{summary}\\n\\n\"\n",
    "          \"è¯·ç»“åˆä¸Šæ–¹çš„æ–°æ¶ˆæ¯ï¼Œæ‰©å±•ç°æœ‰æ‘˜è¦ï¼š\"\n",
    "      )\n",
    "\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰ç°æœ‰æ‘˜è¦ï¼Œåˆ™åˆ›å»ºæ–°æ‘˜è¦\n",
    "        summary_message = \"è¯·å¯¹ä¸Šæ–¹çš„å¯¹è¯åˆ›å»ºæ‘˜è¦ï¼š\"\n",
    "\n",
    "    # å°†æ‘˜è¦æç¤ºæ·»åŠ åˆ°æ¶ˆæ¯å†å²ä¸­\n",
    "    # è¿™æ · LLM å¯ä»¥åŸºäºå®Œæ•´çš„å¯¹è¯å†å²ç”Ÿæˆæ‘˜è¦\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "\n",
    "    # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # åˆ é™¤é™¤æœ€è¿‘ 2 æ¡æ¶ˆæ¯å¤–çš„æ‰€æœ‰æ¶ˆæ¯\n",
    "    # è¿™æ ·å¯ä»¥å‡å°‘å†…å­˜å ç”¨å’Œ token æˆæœ¬\n",
    "    # RemoveMessage ç”¨äºæ ‡è®°æ¶ˆæ¯ä¸ºåˆ é™¤çŠ¶æ€\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    # è¿”å›æ–°çš„æ‘˜è¦å’Œæ¶ˆæ¯åˆ é™¤æŒ‡ä»¤\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {
    "id": "f982993e-f4be-4ff7-9a38-886f75398b3d"
   },
   "source": [
    "æˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªæ¡ä»¶è¾¹æ¥å†³å®šæ˜¯å¦åŸºäºå¯¹è¯é•¿åº¦ç”Ÿæˆæ‘˜è¦ã€‚\n",
    "\n",
    "**æ¡ä»¶è¾¹çš„ä½œç”¨ï¼š**\n",
    "- ç›‘æ§å¯¹è¯ä¸­çš„æ¶ˆæ¯æ•°é‡\n",
    "- å½“æ¶ˆæ¯æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œè§¦å‘æ‘˜è¦ç”Ÿæˆ\n",
    "- å¦åˆ™ç›´æ¥ç»“æŸå¯¹è¯\n",
    "- è¿™æ ·å¯ä»¥å¹³è¡¡å¯¹è¯è´¨é‡å’Œæ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {
    "id": "b507665d-7f5d-442a-b498-218c94c5dd8b"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from typing_extensions import Literal\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"\n",
    "    å†³å®šæ˜¯å¦ç»§ç»­å¯¹è¯æˆ–ç”Ÿæˆæ‘˜è¦çš„æ¡ä»¶å‡½æ•°\n",
    "\n",
    "    å‚æ•°:\n",
    "        state (State): å½“å‰å›¾çŠ¶æ€\n",
    "\n",
    "    è¿”å›:\n",
    "        Literal: ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹åç§°æˆ– END\n",
    "\n",
    "    åŠŸèƒ½è¯´æ˜:\n",
    "        æ ¹æ®å¯¹è¯ä¸­çš„æ¶ˆæ¯æ•°é‡å†³å®šä¸‹ä¸€æ­¥æ“ä½œï¼š\n",
    "        - å¦‚æœæ¶ˆæ¯æ•°é‡ > 6ï¼Œåˆ™ç”Ÿæˆæ‘˜è¦\n",
    "        - å¦åˆ™ç›´æ¥ç»“æŸå¯¹è¯\n",
    "\n",
    "    è®¾è®¡ç†å¿µ:\n",
    "        è¿™ä¸ªé˜ˆå€¼å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼š\n",
    "        - è¾ƒå°çš„é˜ˆå€¼ï¼šæ›´é¢‘ç¹çš„æ‘˜è¦ï¼Œä½†å¯èƒ½ä¸¢å¤±ç»†èŠ‚\n",
    "        - è¾ƒå¤§çš„é˜ˆå€¼ï¼šä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡ï¼Œä½†å¯èƒ½å¢åŠ æˆæœ¬\n",
    "    \"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # å¦‚æœæ¶ˆæ¯æ•°é‡è¶…è¿‡ 6 æ¡ï¼Œåˆ™ç”Ÿæˆå¯¹è¯æ‘˜è¦\n",
    "    # è¿™ä¸ªé˜ˆå€¼å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # å¦åˆ™ç›´æ¥ç»“æŸå¯¹è¯\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {
    "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd"
   },
   "source": [
    "## æ·»åŠ è®°å¿†åŠŸèƒ½\n",
    "\n",
    "å›é¡¾ä¸€ä¸‹ï¼Œ[çŠ¶æ€åœ¨å•æ¬¡å›¾æ‰§è¡Œä¸­æ˜¯ç¬æ€çš„](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)ã€‚\n",
    "\n",
    "è¿™é™åˆ¶äº†æˆ‘ä»¬åœ¨ä¸­æ–­æƒ…å†µä¸‹è¿›è¡Œå¤šè½®å¯¹è¯çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "æ­£å¦‚åœ¨æ¨¡å— 1 æœ«å°¾ä»‹ç»çš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[æŒä¹…åŒ–](https://langchain-ai.github.io/langgraph/how-tos/persistence/)æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼\n",
    "\n",
    "**LangGraph æŒä¹…åŒ–æœºåˆ¶ï¼š**\n",
    "- LangGraph å¯ä»¥ä½¿ç”¨æ£€æŸ¥ç‚¹å™¨ï¼ˆcheckpointerï¼‰åœ¨æ¯ä¸€æ­¥åè‡ªåŠ¨ä¿å­˜å›¾çŠ¶æ€\n",
    "- è¿™ä¸ªå†…ç½®çš„æŒä¹…åŒ–å±‚ä¸ºæˆ‘ä»¬æä¾›äº†è®°å¿†åŠŸèƒ½\n",
    "- å…è®¸ LangGraph ä»æœ€åä¸€æ¬¡çŠ¶æ€æ›´æ–°å¤„ç»§ç»­æ‰§è¡Œ\n",
    "\n",
    "**MemorySaver ä»‹ç»ï¼š**\n",
    "- æˆ‘ä»¬ä¹‹å‰å±•ç¤ºçš„æœ€å®¹æ˜“ä½¿ç”¨çš„æ£€æŸ¥ç‚¹å™¨ä¹‹ä¸€æ˜¯ `MemorySaver`\n",
    "- å®ƒæ˜¯ä¸€ä¸ªç”¨äºå›¾çŠ¶æ€çš„å†…å­˜é”®å€¼å­˜å‚¨\n",
    "- æˆ‘ä»¬åªéœ€è¦åœ¨ç¼–è¯‘å›¾æ—¶æ·»åŠ æ£€æŸ¥ç‚¹å™¨ï¼Œå›¾å°±å…·æœ‰äº†è®°å¿†åŠŸèƒ½ï¼\n",
    "\n",
    "**è®°å¿†åŠŸèƒ½çš„å¥½å¤„ï¼š**\n",
    "- æ”¯æŒé•¿æ—¶é—´è¿è¡Œçš„å¯¹è¯\n",
    "- å¯ä»¥åœ¨ä¸­æ–­åæ¢å¤å¯¹è¯\n",
    "- ä¿æŒå¯¹è¯çš„è¿ç»­æ€§å’Œä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
    "outputId": "47e6692c-8686-4f20-939d-ad595e76a491"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ–°çš„å›¾å·¥ä½œæµ\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "# conversation: å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤çš„èŠ‚ç‚¹\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "# summarize_conversation: ç”Ÿæˆå¯¹è¯æ‘˜è¦çš„èŠ‚ç‚¹\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# è®¾ç½®å›¾çš„è¿æ¥å…³ç³»\n",
    "# è®¾ç½®å…¥å£ç‚¹ä¸º conversation èŠ‚ç‚¹\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "# æ·»åŠ æ¡ä»¶è¾¹ï¼šæ ¹æ®æ¶ˆæ¯æ•°é‡å†³å®šæ˜¯å¦ç”Ÿæˆæ‘˜è¦\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "# æ‘˜è¦ç”Ÿæˆå®Œæˆåç›´æ¥ç»“æŸ\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾å¹¶æ·»åŠ è®°å¿†åŠŸèƒ½\n",
    "memory = MemorySaver()  # åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹å™¨\n",
    "graph = workflow.compile(checkpointer=memory)  # ç¼–è¯‘å›¾å¹¶å¯ç”¨æŒä¹…åŒ–\n",
    "\n",
    "# æ˜¾ç¤ºå›¾çš„æµç¨‹å›¾\n",
    "# è¿™æœ‰åŠ©äºç†è§£æ•´ä¸ªå¯¹è¯æµç¨‹\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {
    "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9"
   },
   "source": [
    "## çº¿ç¨‹ï¼ˆThreadsï¼‰\n",
    "\n",
    "æ£€æŸ¥ç‚¹å™¨åœ¨æ¯ä¸€æ­¥éƒ½å°†çŠ¶æ€ä¿å­˜ä¸ºæ£€æŸ¥ç‚¹ã€‚\n",
    "\n",
    "è¿™äº›ä¿å­˜çš„æ£€æŸ¥ç‚¹å¯ä»¥åˆ†ç»„åˆ°ä¸€ä¸ªå¯¹è¯çš„`çº¿ç¨‹`ä¸­ã€‚\n",
    "\n",
    "**çº¿ç¨‹æ¦‚å¿µç±»æ¯”ï¼š**\n",
    "- æƒ³è±¡ Slack ä½œä¸ºç±»æ¯”ï¼šä¸åŒçš„é¢‘é“æ‰¿è½½ä¸åŒçš„å¯¹è¯\n",
    "- çº¿ç¨‹å°±åƒ Slack é¢‘é“ï¼Œæ•è·åˆ†ç»„çš„çŠ¶æ€é›†åˆï¼ˆä¾‹å¦‚å¯¹è¯ï¼‰\n",
    "\n",
    "**çº¿ç¨‹çš„ä½œç”¨ï¼š**\n",
    "- éš”ç¦»ä¸åŒçš„å¯¹è¯ä¼šè¯\n",
    "- å…è®¸åŒæ—¶è¿›è¡Œå¤šä¸ªç‹¬ç«‹çš„å¯¹è¯\n",
    "- æ¯ä¸ªçº¿ç¨‹ç»´æŠ¤è‡ªå·±çš„çŠ¶æ€å’Œè®°å¿†\n",
    "\n",
    "**é…ç½®çº¿ç¨‹ï¼š**\n",
    "- ä½¿ç”¨ `configurable` å‚æ•°è®¾ç½®çº¿ç¨‹ ID\n",
    "- ä¸åŒçš„çº¿ç¨‹ ID å¯¹åº”ä¸åŒçš„å¯¹è¯ä¼šè¯\n",
    "- è¿™æ ·å¯ä»¥åœ¨åŒä¸€ä¸ªå›¾ä¸­ç®¡ç†å¤šä¸ªç‹¬ç«‹çš„å¯¹è¯\n",
    "\n",
    "![çŠ¶æ€å›¾](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
    "outputId": "184c1386-bed2-453e-a56a-0a82841e1200"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=0f6681b8-8a9c-48e7-adc4-568f01165179; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=1144f291-f0c8-4dde-867a-126b834c03ff; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=45bfc5ab-ce15-48e4-9471-725df12f20e3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¬¬ä¸€è½®å¯¹è¯ ===\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼ŒLanceï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "=== ç¬¬äºŒè½®å¯¹è¯ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: user-defined usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=45bfc5ab-ce15-48e4-9471-725df12f20e3; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=4befc9ad-0283-4843-9401-4186fa78fa89; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=4befc9ad-0283-4843-9401-4186fa78fa89; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=1144f291-f0c8-4dde-867a-126b834c03ff; trace=0f6681b8-8a9c-48e7-adc4-568f01165179,id=0f6681b8-8a9c-48e7-adc4-568f01165179; trace=799e270f-1684-47b6-beb5-7760b8445836,id=799e270f-1684-47b6-beb5-7760b8445836; trace=799e270f-1684-47b6-beb5-7760b8445836,id=189bba46-2290-4f0f-8864-248672114216; trace=799e270f-1684-47b6-beb5-7760b8445836,id=664d0deb-dbb4-43f2-9a6a-f30e5e582b9e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å‘Šè¯‰æˆ‘ä½ å«Lanceã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "=== ç¬¬ä¸‰è½®å¯¹è¯ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: user-defined usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=799e270f-1684-47b6-beb5-7760b8445836,id=664d0deb-dbb4-43f2-9a6a-f30e5e582b9e; trace=799e270f-1684-47b6-beb5-7760b8445836,id=9dcc090f-7c9e-4e38-a40b-54545a6f10f0; trace=799e270f-1684-47b6-beb5-7760b8445836,id=9dcc090f-7c9e-4e38-a40b-54545a6f10f0; trace=799e270f-1684-47b6-beb5-7760b8445836,id=189bba46-2290-4f0f-8864-248672114216; trace=799e270f-1684-47b6-beb5-7760b8445836,id=799e270f-1684-47b6-beb5-7760b8445836; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=4d599692-dd6e-496a-9dbd-85eb57dc928d; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=d51a7315-216e-4cfa-aa8b-87c699aa4788; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=711bff83-f8da-4ac7-9f2a-6208d258907a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yo-Yo Maæ˜¯ä¸€ä½éå¸¸æ°å‡ºçš„å¤å…¸å¤§æç´å®¶ï¼Œä»–çš„éŸ³ä¹ä½œå“æ·±å—è®¸å¤šäººå–œçˆ±ã€‚ä»–ä»¥å…¶ä¸°å¯Œçš„æƒ…æ„Ÿè¡¨è¾¾å’Œç²¾æ¹›çš„æŠ€è‰ºè€Œé—»åã€‚ä½ æœ‰ç‰¹åˆ«å–œæ¬¢ä»–çš„å“ªä¸€éƒ¨ä½œå“æˆ–ä¸“è¾‘å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªå¯¹è¯çº¿ç¨‹\n",
    "# çº¿ç¨‹ ID ç”¨äºåŒºåˆ†ä¸åŒçš„å¯¹è¯ä¼šè¯\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# å¼€å§‹å¯¹è¯ - ç¬¬ä¸€è½®\n",
    "print(\"=== ç¬¬ä¸€è½®å¯¹è¯ ===\")\n",
    "input_message = HumanMessage(content=\"ä½ å¥½ï¼æˆ‘æ˜¯Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ç»§ç»­å¯¹è¯ - ç¬¬äºŒè½®\n",
    "print(\"\\n=== ç¬¬äºŒè½®å¯¹è¯ ===\")\n",
    "input_message = HumanMessage(content=\"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ç»§ç»­å¯¹è¯ - ç¬¬ä¸‰è½®\n",
    "print(\"\\n=== ç¬¬ä¸‰è½®å¯¹è¯ ===\")\n",
    "input_message = HumanMessage(content=\"æˆ‘å–œæ¬¢YoYoMAçš„å¤å…¸éŸ³ä¹\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# æ³¨æ„ï¼šç”±äºæˆ‘ä»¬ä½¿ç”¨äº†ç›¸åŒçš„ configï¼ˆç›¸åŒçš„çº¿ç¨‹ IDï¼‰ï¼Œ\n",
    "# èŠå¤©æœºå™¨äººå¯ä»¥è®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {
    "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2"
   },
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰ç”ŸæˆçŠ¶æ€æ‘˜è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä»ç„¶æœ‰ â‰¤ 6 æ¡æ¶ˆæ¯ã€‚\n",
    "\n",
    "è¿™æ˜¯åœ¨ `should_continue` å‡½æ•°ä¸­è®¾ç½®çš„ã€‚\n",
    "\n",
    "```python\n",
    "# å¦‚æœæ¶ˆæ¯æ•°é‡è¶…è¿‡ 6 æ¡ï¼Œåˆ™ç”Ÿæˆå¯¹è¯æ‘˜è¦\n",
    "if len(messages) > 6:\n",
    "    return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "**å½“å‰çŠ¶æ€åˆ†æï¼š**\n",
    "- ç›®å‰æœ‰ 6 æ¡æ¶ˆæ¯ï¼ˆ3 è½®å¯¹è¯ï¼Œæ¯è½® 2 æ¡æ¶ˆæ¯ï¼‰\n",
    "- è¿˜æ²¡æœ‰è¾¾åˆ°è§¦å‘æ‘˜è¦çš„é˜ˆå€¼ï¼ˆ> 6ï¼‰\n",
    "- å› æ­¤å¯¹è¯ç›´æ¥ç»“æŸï¼Œæ²¡æœ‰ç”Ÿæˆæ‘˜è¦\n",
    "\n",
    "**çº¿ç¨‹çš„ä½œç”¨ï¼š**\n",
    "- ç”±äºæˆ‘ä»¬ä½¿ç”¨äº†çº¿ç¨‹ï¼Œå¯ä»¥ç»§ç»­å¯¹è¯\n",
    "- æ¯æ¬¡è°ƒç”¨éƒ½ä¼šä»ä¸Šæ¬¡çš„çŠ¶æ€ç»§ç»­\n",
    "- è¿™å±•ç¤ºäº†è®°å¿†åŠŸèƒ½çš„é‡è¦æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
    "outputId": "138d7ee8-9f26-4e81-d71d-ff29296ac79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰æ‘˜è¦: 'åœ¨è¿™æ®µå¯¹è¯ä¸­ï¼Œç”¨æˆ·è‡ªæˆ‘ä»‹ç»ä¸ºLanceï¼Œå¹¶è¡¨ç¤ºå–œæ¬¢Yo-Yo Maçš„å¤å…¸éŸ³ä¹å’Œä¹’ä¹“çƒè¿åŠ¨å‘˜å­™é¢–èã€‚ç”¨æˆ·æåˆ°å­™é¢–èæ˜¯å¦æ˜¯ä¹’ä¹“çƒå¥³å•ä¸–ç•Œç¬¬ä¸€ï¼Œå¹¶å¯¹å¥¹çš„è¡¨ç°è¡¨ç¤ºè®¤å¯ã€‚'\n",
      "è¯´æ˜: ç”±äºæ¶ˆæ¯æ•°é‡ â‰¤ 6ï¼Œè¿˜æ²¡æœ‰ç”Ÿæˆæ‘˜è¦\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥å½“å‰çº¿ç¨‹çš„çŠ¶æ€æ‘˜è¦\n",
    "# ç”±äºæ¶ˆæ¯æ•°é‡è¿˜æ²¡æœ‰è¶…è¿‡é˜ˆå€¼ï¼Œæ‘˜è¦åº”è¯¥ä¸ºç©º\n",
    "current_summary = graph.get_state(config).values.get(\"summary\", \"\")\n",
    "print(f\"å½“å‰æ‘˜è¦: '{current_summary}'\")\n",
    "print(\"è¯´æ˜: ç”±äºæ¶ˆæ¯æ•°é‡ â‰¤ 6ï¼Œè¿˜æ²¡æœ‰ç”Ÿæˆæ‘˜è¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {
    "id": "068a93e9-f716-4980-8edf-94115017d865"
   },
   "source": [
    "å¸¦æœ‰çº¿ç¨‹ ID çš„ `config` å…è®¸æˆ‘ä»¬ä»ä¹‹å‰è®°å½•çš„çŠ¶æ€ç»§ç»­ï¼\n",
    "\n",
    "**çº¿ç¨‹è®°å¿†åŠŸèƒ½æ¼”ç¤ºï¼š**\n",
    "- æ¯æ¬¡è°ƒç”¨ `graph.invoke()` æ—¶éƒ½ä½¿ç”¨ç›¸åŒçš„ `config`\n",
    "- è¿™ç¡®ä¿äº†å¯¹è¯çš„è¿ç»­æ€§å’Œä¸Šä¸‹æ–‡ä¿æŒ\n",
    "- èŠå¤©æœºå™¨äººèƒ½å¤Ÿè®°ä½ä¹‹å‰çš„æ‰€æœ‰å¯¹è¯å†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
    "outputId": "d48baf28-45b8-491a-8dc4-458982a5f08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¬¬å››è½®å¯¹è¯ï¼ˆè§¦å‘æ‘˜è¦ï¼‰ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: user-defined usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=711bff83-f8da-4ac7-9f2a-6208d258907a; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=13b12a6c-3b7a-4ec5-b717-2a09cdb4824a; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=13b12a6c-3b7a-4ec5-b717-2a09cdb4824a; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=d51a7315-216e-4cfa-aa8b-87c699aa4788; trace=4d599692-dd6e-496a-9dbd-85eb57dc928d,id=4d599692-dd6e-496a-9dbd-85eb57dc928d; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=43c4901b-e921-483a-8945-6afa9f7a9881; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=7a86b03e-bb64-4cfc-bc9b-a822eb3debe0; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=79feaaa0-295e-49df-a148-c059954740c9\n",
      "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: user-defined usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=79feaaa0-295e-49df-a148-c059954740c9; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=51c36359-94d2-4d65-9f66-7c16206574c5; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=51c36359-94d2-4d65-9f66-7c16206574c5; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=7a86b03e-bb64-4cfc-bc9b-a822eb3debe0; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=752d19e3-4fd7-4554-8691-03cae7b7246e; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=4bc42940-0d84-4791-8584-a41ccc88c3ee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å­™é¢–èæ˜¯ä¸€ä½éå¸¸ä¼˜ç§€çš„ä¹’ä¹“çƒè¿åŠ¨å‘˜ï¼Œå¥¹åœ¨å›½é™…æ¯”èµ›ä¸­å–å¾—äº†è®¸å¤šä¼˜å¼‚çš„æˆç»©ã€‚ä¸è¿‡ï¼Œä¹’ä¹“çƒä¸–ç•Œæ’åä¼šæ ¹æ®é€‰æ‰‹åœ¨å„é¡¹èµ›äº‹ä¸­çš„è¡¨ç°è¿›è¡ŒåŠ¨æ€è°ƒæ•´ï¼Œå› æ­¤å¥¹æ˜¯å¦æ˜¯å½“å‰çš„ä¸–ç•Œç¬¬ä¸€éœ€è¦æŸ¥çœ‹æœ€æ–°çš„æ’åæ›´æ–°ã€‚æ— è®ºå¦‚ä½•ï¼Œå¥¹çš„å®åŠ›å’Œè¡¨ç°éƒ½å¾—åˆ°äº†å¹¿æ³›çš„è®¤å¯ã€‚ä½ å–œæ¬¢å¥¹çš„æ¯”èµ›é£æ ¼å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# ç»§ç»­å¯¹è¯ - ç¬¬å››è½®ï¼ˆè¿™å°†è§¦å‘æ‘˜è¦ç”Ÿæˆï¼‰\n",
    "print(\"=== ç¬¬å››è½®å¯¹è¯ï¼ˆè§¦å‘æ‘˜è¦ï¼‰ ===\")\n",
    "input_message = (HumanMessage(content=\"æˆ‘å–œæ¬¢å­™é¢–èï¼Œå¥¹ä¸æ˜¯ä¹’ä¹“çƒå¥³å•ä¸–ç•Œç¬¬ä¸€å—ï¼Ÿ\"))\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# æ³¨æ„ï¼šè¿™ä¸€è½®å¯¹è¯åï¼Œæ¶ˆæ¯æ•°é‡å°†è¶…è¿‡ 6 æ¡\n",
    "# ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆå¯¹è¯æ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
    "outputId": "851714ce-7f06-468b-e438-0c6a86ddb51a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç”Ÿæˆçš„å¯¹è¯æ‘˜è¦ ===\n",
      "æ‘˜è¦å†…å®¹: åœ¨è¿™æ®µå¯¹è¯ä¸­ï¼Œç”¨æˆ·è‡ªæˆ‘ä»‹ç»ä¸ºLanceï¼Œå¹¶è¡¨ç¤ºå–œæ¬¢Yo-Yo Maçš„å¤å…¸éŸ³ä¹å’Œä¹’ä¹“çƒè¿åŠ¨å‘˜å­™é¢–èã€‚ç”¨æˆ·æåˆ°å­™é¢–èæ˜¯å¦æ˜¯ä¹’ä¹“çƒå¥³å•ä¸–ç•Œç¬¬ä¸€ï¼Œå¹¶å¯¹å¥¹çš„è¡¨ç°è¡¨ç¤ºè®¤å¯ã€‚\n",
      "\n",
      "=== æ‘˜è¦åŠŸèƒ½è¯´æ˜ ===\n",
      "1. ç³»ç»Ÿè‡ªåŠ¨åˆ†æäº†æ•´ä¸ªå¯¹è¯å†å²\n",
      "2. ç”Ÿæˆäº†åŒ…å«å…³é”®ä¿¡æ¯çš„æ‘˜è¦\n",
      "3. æ—§æ¶ˆæ¯è¢«æ¸…ç†ï¼Œåªä¿ç•™æœ€è¿‘çš„ 2 æ¡\n",
      "4. æ‘˜è¦å°†åœ¨åç»­å¯¹è¯ä¸­æä¾›ä¸Šä¸‹æ–‡\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥æ‘˜è¦ç”Ÿæˆåçš„çŠ¶æ€\n",
    "# ç°åœ¨åº”è¯¥æœ‰äº†å¯¹è¯æ‘˜è¦\n",
    "final_summary = graph.get_state(config).values.get(\"summary\", \"\")\n",
    "print(\"=== ç”Ÿæˆçš„å¯¹è¯æ‘˜è¦ ===\")\n",
    "print(f\"æ‘˜è¦å†…å®¹: {final_summary}\")\n",
    "print(\"\\n=== æ‘˜è¦åŠŸèƒ½è¯´æ˜ ===\")\n",
    "print(\"1. ç³»ç»Ÿè‡ªåŠ¨åˆ†æäº†æ•´ä¸ªå¯¹è¯å†å²\")\n",
    "print(\"2. ç”Ÿæˆäº†åŒ…å«å…³é”®ä¿¡æ¯çš„æ‘˜è¦\")\n",
    "print(\"3. æ—§æ¶ˆæ¯è¢«æ¸…ç†ï¼Œåªä¿ç•™æœ€è¿‘çš„ 2 æ¡\")\n",
    "print(\"4. æ‘˜è¦å°†åœ¨åç»­å¯¹è¯ä¸­æä¾›ä¸Šä¸‹æ–‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {
    "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e"
   },
   "source": [
    "## LangSmith è¿½è¸ª\n",
    "\n",
    "è®©æˆ‘ä»¬æŸ¥çœ‹è¿½è¸ªä¿¡æ¯ï¼\n",
    "\n",
    "**LangSmith è¿½è¸ªåŠŸèƒ½ï¼š**\n",
    "- å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„å¯¹è¯æµç¨‹\n",
    "- ç›‘æ§æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæƒ…å†µ\n",
    "- åˆ†æ LLM è°ƒç”¨çš„æ€§èƒ½å’Œæˆæœ¬\n",
    "- è°ƒè¯•å¯¹è¯é€»è¾‘å’ŒçŠ¶æ€å˜åŒ–\n",
    "\n",
    "**å¦‚ä½•æŸ¥çœ‹è¿½è¸ªï¼š**\n",
    "1. è®¿é—® LangSmith ç½‘ç«™\n",
    "2. ç™»å½•æ‚¨çš„è´¦æˆ·\n",
    "3. æŸ¥çœ‹ \"FlyAIBox\" é¡¹ç›®\n",
    "4. æ‰¾åˆ°æœ€æ–°çš„è¿½è¸ªè®°å½•\n",
    "5. åˆ†æå¯¹è¯æµç¨‹å’Œæ€§èƒ½æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e1501",
   "metadata": {
    "id": "c62e1501"
   },
   "source": [
    "## ç³»ç»Ÿæ¶æ„æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒç»„ä»¶\n",
    "\n",
    "1. **çŠ¶æ€ç®¡ç† (State)**\n",
    "   - `MessagesState`: åŸºç¡€æ¶ˆæ¯çŠ¶æ€\n",
    "   - `summary`: è‡ªå®šä¹‰æ‘˜è¦å­—æ®µ\n",
    "   - æ”¯æŒæ¶ˆæ¯çš„å¢åˆ æ”¹æŸ¥\n",
    "\n",
    "2. **èŠ‚ç‚¹åŠŸèƒ½ (Nodes)**\n",
    "   - `call_model`: è°ƒç”¨ LLM ç”Ÿæˆå›å¤\n",
    "   - `summarize_conversation`: ç”Ÿæˆå¯¹è¯æ‘˜è¦\n",
    "   - `should_continue`: æ¡ä»¶åˆ¤æ–­é€»è¾‘\n",
    "\n",
    "3. **è®°å¿†ç³»ç»Ÿ (Memory)**\n",
    "   - `MemorySaver`: å†…å­˜æ£€æŸ¥ç‚¹å™¨\n",
    "   - çº¿ç¨‹éš”ç¦»: æ”¯æŒå¤šå¯¹è¯å¹¶è¡Œ\n",
    "   - çŠ¶æ€æŒä¹…åŒ–: æ”¯æŒä¸­æ–­æ¢å¤\n",
    "\n",
    "### å·¥ä½œæµç¨‹\n",
    "\n",
    "```\n",
    "ç”¨æˆ·è¾“å…¥ â†’ call_model â†’ should_continue â†’\n",
    "    â†“                    â†“\n",
    "   ç»“æŸ               summarize_conversation â†’ ç»“æŸ\n",
    "```\n",
    "\n",
    "### å…³é”®ç‰¹æ€§\n",
    "\n",
    "- **æ™ºèƒ½æ‘˜è¦**: è‡ªåŠ¨å‹ç¼©é•¿å¯¹è¯å†å²\n",
    "- **è®°å¿†ä¿æŒ**: æ”¯æŒé•¿æ—¶é—´å¯¹è¯\n",
    "- **æˆæœ¬ä¼˜åŒ–**: å‡å°‘ token ä½¿ç”¨é‡\n",
    "- **çŠ¶æ€ç®¡ç†**: çµæ´»çš„çŠ¶æ€æ›´æ–°æœºåˆ¶\n",
    "\n",
    "### é€‚ç”¨åœºæ™¯\n",
    "\n",
    "- å®¢æœèŠå¤©æœºå™¨äºº\n",
    "- ä¸ªäººåŠ©æ‰‹åº”ç”¨\n",
    "- æ•™è‚²å¯¹è¯ç³»ç»Ÿ\n",
    "- æŠ€æœ¯æ”¯æŒå·¥å…·\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39bd23a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39bd23a4",
    "outputId": "9e47ee8e-577a-4569-d5c6-24ef80e9a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åˆ›å»ºæ–°å¯¹è¯çº¿ç¨‹æ¼”ç¤º ===\n",
      "æ–°çº¿ç¨‹ä¸­çš„å¯¹è¯ï¼š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Too many requests: tenant exceeded usage limits: user-defined usage limit monthly_traces of 10 exceeded. Check LangSmith usage configuration settings\"}\\n')trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=4bc42940-0d84-4791-8584-a41ccc88c3ee; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=752d19e3-4fd7-4554-8691-03cae7b7246e; trace=43c4901b-e921-483a-8945-6afa9f7a9881,id=43c4901b-e921-483a-8945-6afa9f7a9881; trace=f9568fda-d71b-4c4b-9c05-7932e606a54a,id=f9568fda-d71b-4c4b-9c05-7932e606a54a; trace=f9568fda-d71b-4c4b-9c05-7932e606a54a,id=61b00404-5712-44eb-bdcf-0e5ad14b1e6b; trace=f9568fda-d71b-4c4b-9c05-7932e606a54a,id=26d4170c-5b6f-4796-b365-35979b9fa13f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼æ¬¢è¿ä½ ï¼å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–è€…éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥ä¸ºä½ åšçš„å—ï¼Ÿ\n",
      "\n",
      "=== çº¿ç¨‹éš”ç¦»è¯´æ˜ ===\n",
      "1. çº¿ç¨‹ 1 å’Œçº¿ç¨‹ 2 æ˜¯å®Œå…¨ç‹¬ç«‹çš„å¯¹è¯\n",
      "2. æ¯ä¸ªçº¿ç¨‹ç»´æŠ¤è‡ªå·±çš„çŠ¶æ€å’Œè®°å¿†\n",
      "3. å¯ä»¥åœ¨åŒä¸€ä¸ªå›¾ä¸­åŒæ—¶ç®¡ç†å¤šä¸ªå¯¹è¯\n",
      "4. è¿™ç±»ä¼¼äº Slack ä¸­çš„ä¸åŒé¢‘é“\n"
     ]
    }
   ],
   "source": [
    "# æ¼”ç¤ºå¦‚ä½•åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹\n",
    "print(\"=== åˆ›å»ºæ–°å¯¹è¯çº¿ç¨‹æ¼”ç¤º ===\")\n",
    "\n",
    "# åˆ›å»ºæ–°çš„çº¿ç¨‹é…ç½®\n",
    "new_config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# åœ¨æ–°çº¿ç¨‹ä¸­å¼€å§‹å¯¹è¯\n",
    "print(\"æ–°çº¿ç¨‹ä¸­çš„å¯¹è¯ï¼š\")\n",
    "input_message = HumanMessage(content=\"ä½ å¥½ï¼Œæˆ‘æ˜¯æ–°ç”¨æˆ·\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, new_config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\n=== çº¿ç¨‹éš”ç¦»è¯´æ˜ ===\")\n",
    "print(\"1. çº¿ç¨‹ 1 å’Œçº¿ç¨‹ 2 æ˜¯å®Œå…¨ç‹¬ç«‹çš„å¯¹è¯\")\n",
    "print(\"2. æ¯ä¸ªçº¿ç¨‹ç»´æŠ¤è‡ªå·±çš„çŠ¶æ€å’Œè®°å¿†\")\n",
    "print(\"3. å¯ä»¥åœ¨åŒä¸€ä¸ªå›¾ä¸­åŒæ—¶ç®¡ç†å¤šä¸ªå¯¹è¯\")\n",
    "print(\"4. è¿™ç±»ä¼¼äº Slack ä¸­çš„ä¸åŒé¢‘é“\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}