{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 🔧 环境配置和检查\n",
    "\n",
    "#### 概述\n",
    "\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助您：\n",
    "\n",
    "- 使用统一的conda环境：激活统一的学习环境\n",
    "- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n",
    "- 加速模型下载：设置HuggingFace镜像代理\n",
    "- 检查系统配置：检查硬件和软件配置\n",
    "\n",
    "#### 配置\n",
    "\n",
    "- **所需环境及其依赖已经部署好**\n",
    "- 在`Notebook`右上角选择`jupyter内核`为`python(flyai_agent_in_action)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\n",
      "=========================================\n",
      "✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\n",
      "✅ 正在使用的环境路径: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\n",
      "   如果需要后续单元格也使用此环境，请执行以下操作:\n",
      "   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. 激活 conda 环境 (仅对当前单元格有效)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. 检查当前激活的环境\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\"\n",
    "    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\"\n",
    "    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n",
    "    echo \"   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\"\n",
    "else\n",
    "    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(flyai_agent_in_action)'。\"\n",
    "    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n",
    "    echo \"\"\n",
    "    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# 必须在每个单元格都执行\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### 环境信息\n",
      "| 项目         | 信息                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| 操作系统     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU 信息     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| 内存信息     | 2015.36 GB (Available: 1868.14 GB)                                    |\n",
      "| GPU 信息     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA 信息    | 12.6                                                                  |\n",
      "| Python 版本  | 3.12.11                                                               |\n",
      "| Conda 版本   | conda 25.7.0                                                          |\n",
      "| 物理磁盘空间 | Total: 2014.78 GB, Used: 788.88 GB, Free: 1123.48 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助您：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {
    "id": "147e576c"
   },
   "source": [
    "# 图状态编辑与人工反馈\n",
    "\n",
    "\n",
    "## 本教程简介\n",
    "\n",
    "本教程将向您展示如何在LangGraph中编辑图状态并集成人工反馈。这是构建人机协作AI系统的关键技术，让人类可以在AI执行过程中进行干预和指导。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {
    "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b"
   },
   "source": [
    "# 编辑图状态\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们之前讨论了人机协作（human-in-the-loop）的动机：\n",
    "\n",
    "**(1) 审批（Approval）** - 我们可以中断智能体，向用户展示状态，并允许用户接受某个操作\n",
    "\n",
    "**(2) 调试（Debugging）** - 我们可以回滚图来重现或避免问题\n",
    "\n",
    "**(3) 编辑（Editing）** - 您可以修改状态\n",
    "\n",
    "我们展示了断点如何支持用户审批，但还不知道如何在图被中断后修改图状态！\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "现在，让我们展示如何直接编辑图状态并插入人工反馈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {
    "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装必要的依赖包\n",
    "# 这些包是构建LangGraph应用的核心组件\n",
    "%pip install --quiet langgraph==0.6.7 langchain_openai==0.3.32 langgraph_sdk==0.2.6 langgraph-prebuilt==0.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5948594",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5948594",
    "outputId": "90174103-6cdd-4be5-a4c9-7c84d2b01331"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n",
      "OPENAI_BASE_URL:  ········\n"
     ]
    }
   ],
   "source": [
    "# 设置环境变量\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"安全地设置环境变量，如果不存在则提示用户输入\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# 设置OpenAI API密钥，这是使用OpenAI模型所必需的\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {
    "id": "65a8df1f-a76a-4803-a532-ea9802106ac8"
   },
   "source": [
    "## 编辑状态\n",
    "\n",
    "之前，我们介绍了断点（breakpoints）。\n",
    "\n",
    "我们使用断点来中断图，并在执行下一个节点之前等待用户审批。\n",
    "\n",
    "但**断点也是[修改图状态的机会](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)。**\n",
    "\n",
    "让我们在`assistant`节点之前设置一个断点来构建我们的智能体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {
    "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4"
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 定义数学运算工具函数\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"乘法运算：计算两个整数的乘积\n",
    "\n",
    "    Args:\n",
    "        a: 第一个整数\n",
    "        b: 第二个整数\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"加法运算：计算两个整数的和\n",
    "\n",
    "    Args:\n",
    "        a: 第一个整数\n",
    "        b: 第二个整数\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"除法运算：计算两个整数的商\n",
    "\n",
    "    Args:\n",
    "        a: 被除数\n",
    "        b: 除数\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "# 将工具函数组合成工具列表\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# 初始化OpenAI聊天模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 将工具绑定到语言模型，使模型能够调用这些工具\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
    "outputId": "b0a5516f-31c0-495d-d439-caf0e80e825b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图可视化：\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 图渲染成功！\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 定义系统消息，指导AI助手的行为\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# 定义助手节点函数\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"助手节点：使用语言模型处理消息并可能调用工具\n",
    "\n",
    "    Args:\n",
    "        state: 包含消息列表的图状态\n",
    "\n",
    "    Returns:\n",
    "        包含AI响应的新状态更新\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# 创建状态图构建器\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 定义节点：这些节点执行具体的工作\n",
    "builder.add_node(\"assistant\", assistant)  # AI助手节点\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # 工具执行节点\n",
    "\n",
    "# 定义边：这些边决定控制流程\n",
    "builder.add_edge(START, \"assistant\")  # 从开始到助手\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # 如果助手的最新消息是工具调用 -> tools_condition 路由到工具节点\n",
    "    # 如果助手的最新消息不是工具调用 -> tools_condition 路由到结束\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # 从工具回到助手\n",
    "\n",
    "# 创建内存检查点保存器，用于保存图状态\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译图，在assistant节点之前设置中断点\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# 展示图结构\n",
    "# 图可视化\n",
    "print(\"图可视化：\")\n",
    "\n",
    "# 方案1：尝试使用 Pyppeteer 本地渲染（推荐）\n",
    "try:\n",
    "    # 可视化：通过 Mermaid 渲染图结构\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"✅ 图渲染成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Pyppeteer 渲染失败: {e}\")\n",
    "    \n",
    "    # 方案2：显示 Mermaid 文本格式\n",
    "    print(\"\\n📝 图结构（Mermaid 文本格式）：\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 方案3：显示图的节点和边信息\n",
    "    print(\"\\n🔗 图结构信息：\")\n",
    "    print(\"节点:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"边:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # 方案4：提供手动渲染说明\n",
    "    print(\"\\n💡 手动渲染说明：\")\n",
    "    print(\"1. 复制上面的 Mermaid 文本\")\n",
    "    print(\"2. 访问 https://mermaid.live/\")\n",
    "    print(\"3. 粘贴文本到编辑器中查看图形\")\n",
    "    print(\"4. 或者使用支持 Mermaid 的 Markdown 编辑器\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {
    "id": "92a47fd5-1f60-41dc-9206-698ed8ece530"
   },
   "source": [
    "让我们运行图！\n",
    "\n",
    "我们可以看到图在聊天模型响应之前被中断了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
    "outputId": "7736c7bb-0693-433a-99c8-9a04c1458e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# 定义初始输入：用户要求进行数学运算\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# 创建线程配置，用于跟踪对话状态\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 运行图直到第一个中断点\n",
    "# 由于设置了interrupt_before=[\"assistant\"]，图会在assistant节点执行前停止\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
    "outputId": "d898817a-3556-4785-c4e3-2fc1cc4a1229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='5855f46d-72f2-4621-baed-5207ca104cf3')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0bd4-1899-69ce-8000-9d9ccadd2f6f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-04T00:58:35.728523+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0bd4-1897-6d45-bfff-f841e432f415'}}, tasks=(PregelTask(id='40606bf0-e3f4-76d4-31c5-4cba86eb22f6', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取当前图状态，查看中断时的状态信息\n",
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {
    "id": "36ef63a1-2ab8-416d-babf-d35054e294f0"
   },
   "source": [
    "现在，我们可以直接应用状态更新。\n",
    "\n",
    "记住，对`messages`键的更新将使用`add_messages`归约器：\n",
    "\n",
    "* 如果我们想要覆盖现有消息，可以提供消息的`id`。\n",
    "* 如果我们只是想要追加到消息列表中，那么可以传递一个没有指定`id`的消息，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
    "outputId": "1ea55096-4c34-41bd-8f31-6795d6cef635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a0bd4-18c2-676d-8001-bd9461ac7b7b'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新图状态：添加新的人类消息\n",
    "# 这里我们添加一条新消息来修改用户的原始请求\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {
    "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829"
   },
   "source": [
    "让我们看一下结果。\n",
    "\n",
    "我们使用新消息调用了`update_state`。\n",
    "\n",
    "`add_messages`归约器将其追加到我们的状态键`messages`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
    "outputId": "29f6863a-e7ed-492a-8754-ad65919747d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "# 获取更新后的状态并显示所有消息\n",
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {
    "id": "e4041959-cc3a-4168-8cf7-06d1711921d8"
   },
   "source": [
    "现在，让我们继续执行我们的智能体，只需传递`None`并允许它从当前状态继续。\n",
    "\n",
    "我们发出当前状态，然后继续执行剩余的节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
    "outputId": "ee0bd980-4ec0-49d3-e382-a65aa66b03d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_wpeAjQLX5n7nXgvolexlwRVS)\n",
      " Call ID: call_wpeAjQLX5n7nXgvolexlwRVS\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 继续执行图，从当前中断点开始\n",
    "# 传递None表示从当前状态继续，而不是重新开始\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {
    "id": "b18dc1ca"
   },
   "source": [
    "现在，我们又回到了`assistant`节点，它设置了我们的`breakpoint`。\n",
    "\n",
    "我们可以再次传递`None`来继续执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5952731-0170-4589-a399-ee787df35400",
    "outputId": "2f880747-c7b3-41d7-f6e1-165ab9ca18f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 and 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "# 继续执行图，完成剩余的计算\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
