{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### üîß ÁéØÂ¢ÉÈÖçÁΩÆÂíåÊ£ÄÊü•\n",
    "\n",
    "#### Ê¶ÇËø∞\n",
    "\n",
    "Êú¨ÊïôÁ®ãÈúÄË¶ÅÁâπÂÆöÁöÑÁéØÂ¢ÉÈÖçÁΩÆ‰ª•Á°Æ‰øùÊúÄ‰Ω≥Â≠¶‰π†‰ΩìÈ™å„ÄÇ‰ª•‰∏ãÈÖçÁΩÆÂ∞ÜÂ∏ÆÂä©ÊÇ®Ôºö\n",
    "\n",
    "- ‰ΩøÁî®Áªü‰∏ÄÁöÑcondaÁéØÂ¢ÉÔºöÊøÄÊ¥ªÁªü‰∏ÄÁöÑÂ≠¶‰π†ÁéØÂ¢É\n",
    "- ÈÄöËøáÂõΩÂÜÖÈïúÂÉèÊ∫êÂø´ÈÄüÂÆâË£Ö‰æùËµñÔºöÈÖçÁΩÆpip‰ΩøÁî®Ê∏ÖÂçéÈïúÂÉèÊ∫ê\n",
    "- Âä†ÈÄüÊ®°Âûã‰∏ãËΩΩÔºöËÆæÁΩÆHuggingFaceÈïúÂÉè‰ª£ÁêÜ\n",
    "- Ê£ÄÊü•Á≥ªÁªüÈÖçÁΩÆÔºöÊ£ÄÊü•Á°¨‰ª∂ÂíåËΩØ‰ª∂ÈÖçÁΩÆ\n",
    "\n",
    "#### ÈÖçÁΩÆ\n",
    "\n",
    "- **ÊâÄÈúÄÁéØÂ¢ÉÂèäÂÖ∂‰æùËµñÂ∑≤ÁªèÈÉ®ÁΩ≤Â•Ω**\n",
    "- Âú®`Notebook`Âè≥‰∏äËßíÈÄâÊã©`jupyterÂÜÖÊ†∏`‰∏∫`python(flyai_agent_in_action)`ÔºåÂç≥ÂèØÊâßË°å‰∏ãÊñπ‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\n",
      "=========================================\n",
      "‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ flyai_agent_in_action ÁéØÂ¢É„ÄÇ\n",
      "‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑ Python ÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî® Notebook ÂΩìÂâçÈÄâÊã©ÁöÑ Jupyter ÂÜÖÊ†∏„ÄÇ\n",
      "   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\n",
      "   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(flyai_agent_in_action)'„ÄÇ\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. ÊøÄÊ¥ª conda ÁéØÂ¢É (‰ªÖÂØπÂΩìÂâçÂçïÂÖÉÊ†ºÊúâÊïà)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. Ê£ÄÊü•ÂΩìÂâçÊøÄÊ¥ªÁöÑÁéØÂ¢É\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ flyai_agent_in_action ÁéØÂ¢É„ÄÇ\"\n",
    "    echo \"‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑ Python ÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî® Notebook ÂΩìÂâçÈÄâÊã©ÁöÑ Jupyter ÂÜÖÊ†∏„ÄÇ\"\n",
    "    echo \"   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\"\n",
    "    echo \"   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(flyai_agent_in_action)'„ÄÇ\"\n",
    "else\n",
    "    echo \"‚ùå ÊøÄÊ¥ªÂ§±Ë¥•ÊàñÁéØÂ¢ÉÂêçÁß∞‰∏çÂåπÈÖç„ÄÇÂΩìÂâçÁéØÂ¢É: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"‚ö†Ô∏è ‰∏•ÈáçÊèêÁ§∫: Âª∫ËÆÆÂ∞Ü Notebook ÁöÑ Jupyter **ÂÜÖÊ†∏ (Kernel)** ÂàáÊç¢‰∏∫ 'python(flyai_agent_in_action)'„ÄÇ\"\n",
    "    echo \"   (ÈÄöÂ∏∏‰Ωç‰∫é Notebook Âè≥‰∏äËßíÊàñ 'ÂÜÖÊ†∏' ËèúÂçï‰∏≠)\"\n",
    "    echo \"\"\n",
    "    echo \"üìö Â§áÁî®ÊñπÊ≥ï (‰∏çÊé®Ëçê): Â¶ÇÊûúÊó†Ê≥ïÂàáÊç¢ÂÜÖÊ†∏ÔºåÂàôÂøÖÈ°ªÂú®**ÊØè‰∏™**‰ª£Á†ÅÂçïÂÖÉÊ†ºÁöÑÂ§¥ÈÉ®ÈáçÂ§ç‰ª•‰∏ãÂëΩ‰ª§:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# ÂøÖÈ°ªÂú®ÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩÊâßË°å\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. ËÆæÁΩÆpip ‰∏∫Ê∏ÖÂçéÊ∫ê\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. ËÆæÁΩÆHuggingFace‰ª£ÁêÜ\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# È™åËØÅÔºö‰ΩøÁî®shellÂëΩ‰ª§Ê£ÄÊü•\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ÁéØÂ¢É‰ø°ÊÅØ\n",
      "| È°πÁõÆ         | ‰ø°ÊÅØ                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| Êìç‰ΩúÁ≥ªÁªü     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU ‰ø°ÊÅØ     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| ÂÜÖÂ≠ò‰ø°ÊÅØ     | 2015.36 GB (Available: 1868.14 GB)                                    |\n",
      "| GPU ‰ø°ÊÅØ     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA ‰ø°ÊÅØ    | 12.6                                                                  |\n",
      "| Python ÁâàÊú¨  | 3.12.11                                                               |\n",
      "| Conda ÁâàÊú¨   | conda 25.7.0                                                          |\n",
      "| Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥ | Total: 2014.78 GB, Used: 788.88 GB, Free: 1123.48 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# üîç ÁéØÂ¢É‰ø°ÊÅØÊ£ÄÊü•ËÑöÊú¨\n",
    "#\n",
    "# Êú¨ËÑöÊú¨ÁöÑ‰ΩúÁî®Ôºö\n",
    "# 1. ÂÆâË£Ö pandas Â∫ìÁî®‰∫éÊï∞ÊçÆË°®Ê†ºÂ±ïÁ§∫\n",
    "# 2. Ê£ÄÊü•Á≥ªÁªüÁöÑÂêÑÈ°πÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "# 3. ÁîüÊàêËØ¶ÁªÜÁöÑÁéØÂ¢ÉÊä•ÂëäË°®Ê†º\n",
    "#\n",
    "# ÂØπ‰∫éÂàùÂ≠¶ËÄÖÊù•ËØ¥ÔºåËøô‰∏™Ê≠•È™§Â∏ÆÂä©ÊÇ®Ôºö\n",
    "# - ‰∫ÜËß£ÂΩìÂâçËøêË°åÁéØÂ¢ÉÁöÑÁ°¨‰ª∂ÈÖçÁΩÆ\n",
    "# - Á°ÆËÆ§ÊòØÂê¶Êª°Ë∂≥Ê®°ÂûãËøêË°åÁöÑÊúÄ‰ΩéË¶ÅÊ±Ç\n",
    "# - Â≠¶‰π†Â¶Ç‰ΩïÈÄöËøá‰ª£Á†ÅËé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "\n",
    "# ÂÆâË£Ö pandas Â∫ì - Áî®‰∫éÂàõÂª∫ÂíåÂ±ïÁ§∫Êï∞ÊçÆË°®Ê†º\n",
    "# pandas ÊòØ Python ‰∏≠ÊúÄÊµÅË°åÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂíåÂàÜÊûêÂ∫ì\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # ÂØºÂÖ• platform Ê®°Âùó‰ª•Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "import os # ÂØºÂÖ• os Ê®°Âùó‰ª•‰∏éÊìç‰ΩúÁ≥ªÁªü‰∫§‰∫í\n",
    "import subprocess # ÂØºÂÖ• subprocess Ê®°Âùó‰ª•ËøêË°åÂ§ñÈÉ®ÂëΩ‰ª§\n",
    "import pandas as pd # ÂØºÂÖ• pandas Ê®°ÂùóÔºåÈÄöÂ∏∏Áî®‰∫éÊï∞ÊçÆÂ§ÑÁêÜÔºåËøôÈáåÁî®‰∫éÂàõÂª∫Ë°®Ê†º\n",
    "import shutil # ÂØºÂÖ• shutil Ê®°Âùó‰ª•Ëé∑ÂèñÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ CPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨Ê†∏ÂøÉÊï∞Èáè\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # ÂàùÂßãÂåñ CPU ‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # Â¶ÇÊûúÊòØ Windows Á≥ªÁªü\n",
    "        cpu_info = platform.processor() # ‰ΩøÁî® platform.processor() Ëé∑Âèñ CPU ‰ø°ÊÅØ\n",
    "        try:\n",
    "            # Ëé∑Âèñ Windows ‰∏äÁöÑÊ†∏ÂøÉÊï∞Èáè (ÈúÄË¶Å WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # Â¶ÇÊûú WMI ‰∏çÂèØÁî®ÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # Êõ¥Êñ∞ PATH ÁéØÂ¢ÉÂèòÈáè\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/cpuinfo Êñá‰ª∂Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # Êü•Êâæ‰ª• 'model name'ÂºÄÂ§¥ÁöÑË°å\n",
    "                        if not cpu_info: # Âè™Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™ model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # Êü•Êâæ‰ª• 'cpu cores' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # Êü•Êâæ‰ª• 'processor' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # ËøîÂõû CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "\n",
    "\n",
    "# Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # ÂàùÂßãÂåñÂÜÖÂ≠ò‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    if platform.system() == \"Windows\":\n",
    "        # Âú® Windows ‰∏ä‰∏çÂÆπÊòìÈÄöËøáÊ†áÂáÜÂ∫ìËé∑ÂèñÔºåÈúÄË¶ÅÂ§ñÈÉ®Â∫ìÊàñ PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # ËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞è\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # ËøêË°å sysctl ÂëΩ‰ª§\n",
    "        stdout, stderr = process.communicate() # Ëé∑ÂèñÊ†áÂáÜËæìÂá∫ÂíåÊ†áÂáÜÈîôËØØ\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # Ëß£ÊûêËæìÂá∫ÔºåËé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞èÔºàÂ≠óËäÇÔºâ\n",
    "        mem_gb = mem_bytes / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/meminfo Êñá‰ª∂Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # Êü•Êâæ‰ª• 'MemTotal' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÊÄªÂÜÖÂ≠òÔºàKBÔºâ\n",
    "                    elif line.startswith('MemAvailable'): # Êü•Êâæ‰ª• 'MemAvailable' ÂºÄÂ§¥ÁöÑË°å\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÂèØÁî®ÂÜÖÂ≠òÔºàKBÔºâ\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # ËΩ¨Êç¢‰∏∫ GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫ÊÄªÂÜÖÂ≠ò\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # Ê∑ªÂä†ÂèØÁî®ÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "    return mem_info # ËøîÂõûÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ GPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨ÊòæÂ≠ò\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvidia-smi Ëé∑Âèñ NVIDIA GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # Ëß£ÊûêËæìÂá∫ÔºåËé∑Âèñ GPU ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # Ê†ºÂºèÂåñ GPU ‰ø°ÊÅØ\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # ËøîÂõû GPU ‰ø°ÊÅØÊàñÊèêÁ§∫‰ø°ÊÅØ\n",
    "        else:\n",
    "             # Â∞ùËØï‰ΩøÁî® lshw Ëé∑ÂèñÂÖ∂‰ªñ GPU ‰ø°ÊÅØ (ÈúÄË¶ÅÂÆâË£Ö lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "                     # ÁÆÄÂçïËß£ÊûêËæìÂá∫‰∏≠ÁöÑ product ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # Ê∑ªÂä†ÊúÄÂêé‰∏Ä‰∏™ GPU ÁöÑ‰ø°ÊÅØ\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # Â¶ÇÊûúÊâæÂà∞ GPU ‰ΩÜ‰ø°ÊÅØÊó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # Â¶ÇÊûú‰∏§‰∏™ÂëΩ‰ª§ÈÉΩÊâæ‰∏çÂà∞ GPUÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ lshw ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvidia-smi ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# Ëé∑Âèñ CUDA ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvcc --version Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # Êü•ÊâæÂåÖÂê´ 'release' ÁöÑË°å\n",
    "                    return line.split('release ')[1].split(',')[0] # Ëß£ÊûêË°åÔºåÊèêÂèñÁâàÊú¨Âè∑\n",
    "        return \"CUDA not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ CUDA ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvcc ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ Python ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_python_version():\n",
    "    return platform.python_version() # Ëé∑Âèñ Python ÁâàÊú¨\n",
    "\n",
    "# Ëé∑Âèñ Conda ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® conda --version Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            return result.stdout.strip() # ËøîÂõû Conda ÁâàÊú¨\n",
    "        return \"Conda not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ Conda ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ conda ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # Ëé∑ÂèñÊ†πÁõÆÂΩïÁöÑÁ£ÅÁõò‰ΩøÁî®ÊÉÖÂÜµ\n",
    "        total_gb = total / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        used_gb = used / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        free_gb = free / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # Â¶ÇÊûúËé∑Âèñ‰ø°ÊÅØÂá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁéØÂ¢É‰ø°ÊÅØ\n",
    "os_name = platform.system() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÂêçÁß∞\n",
    "os_version = platform.release() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÁâàÊú¨\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # Âú® Linux ‰∏äÂ∞ùËØïËé∑ÂèñÂèëË°åÁâàÂíåÁâàÊú¨\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # Êü•ÊâæÂåÖÂê´ 'Description:' ÁöÑË°å\n",
    "                    os_version = line.split('Description:')[1].strip() # ÊèêÂèñÊèèËø∞‰ø°ÊÅØ‰Ωú‰∏∫ÁâàÊú¨\n",
    "                    break # ÊâæÂà∞ÂêéÈÄÄÂá∫Âæ™ÁéØ\n",
    "                elif 'Release:' in line: # Êü•ÊâæÂåÖÂê´ 'Release:' ÁöÑË°å\n",
    "                     os_version = line.split('Release:')[1].strip() # ÊèêÂèñÁâàÊú¨Âè∑\n",
    "                     # Â∞ùËØïËé∑Âèñ codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # Â∞Ü codename Ê∑ªÂä†Âà∞ÁâàÊú¨‰ø°ÊÅØ‰∏≠\n",
    "                     except:\n",
    "                         pass # Â¶ÇÊûúËé∑Âèñ codename Â§±Ë¥•ÂàôÂøΩÁï•\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release ÂèØËÉΩÊú™ÂÆâË£ÖÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ÁªÑÂêàÂÆåÊï¥ÁöÑÊìç‰ΩúÁ≥ªÁªü‰ø°ÊÅØ\n",
    "cpu_info = get_cpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "memory_info = get_memory_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "gpu_info = get_gpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "cuda_version = get_cuda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "python_version = get_python_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Python ÁâàÊú¨\n",
    "conda_version = get_conda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "disk_info = get_disk_space() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# ÂàõÂª∫Áî®‰∫éÂ≠òÂÇ®Êï∞ÊçÆÁöÑÂ≠óÂÖ∏\n",
    "env_data = {\n",
    "    \"È°πÁõÆ\": [ # È°πÁõÆÂêçÁß∞ÂàóË°®\n",
    "        \"Êìç‰ΩúÁ≥ªÁªü\",\n",
    "        \"CPU ‰ø°ÊÅØ\",\n",
    "        \"ÂÜÖÂ≠ò‰ø°ÊÅØ\",\n",
    "        \"GPU ‰ø°ÊÅØ\",\n",
    "        \"CUDA ‰ø°ÊÅØ\",\n",
    "        \"Python ÁâàÊú¨\",\n",
    "        \"Conda ÁâàÊú¨\",\n",
    "        \"Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\" # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\n",
    "    ],\n",
    "    \"‰ø°ÊÅØ\": [ # ÂØπÂ∫îÁöÑ‰ø°ÊÅØÂàóË°®\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ÂàõÂª∫‰∏Ä‰∏™ pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# ÊâìÂç∞Ë°®Ê†º\n",
    "print(\"### ÁéØÂ¢É‰ø°ÊÅØ\") # ÊâìÂç∞Ê†áÈ¢ò\n",
    "print(df.to_markdown(index=False)) # Â∞Ü DataFrame ËΩ¨Êç¢‰∏∫ Markdown Ê†ºÂºèÂπ∂ÊâìÂç∞Ôºå‰∏çÂåÖÂê´Á¥¢Âºï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {
    "id": "147e576c"
   },
   "source": [
    "# ÂõæÁä∂ÊÄÅÁºñËæë‰∏é‰∫∫Â∑•ÂèçÈ¶à\n",
    "\n",
    "\n",
    "## Êú¨ÊïôÁ®ãÁÆÄ‰ªã\n",
    "\n",
    "Êú¨ÊïôÁ®ãÂ∞ÜÂêëÊÇ®Â±ïÁ§∫Â¶Ç‰ΩïÂú®LangGraph‰∏≠ÁºñËæëÂõæÁä∂ÊÄÅÂπ∂ÈõÜÊàê‰∫∫Â∑•ÂèçÈ¶à„ÄÇËøôÊòØÊûÑÂª∫‰∫∫Êú∫Âçè‰ΩúAIÁ≥ªÁªüÁöÑÂÖ≥ÈîÆÊäÄÊúØÔºåËÆ©‰∫∫Á±ªÂèØ‰ª•Âú®AIÊâßË°åËøáÁ®ã‰∏≠ËøõË°åÂπ≤È¢ÑÂíåÊåáÂØº„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {
    "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b"
   },
   "source": [
    "# ÁºñËæëÂõæÁä∂ÊÄÅ\n",
    "\n",
    "## ÂõûÈ°æ\n",
    "\n",
    "Êàë‰ª¨‰πãÂâçËÆ®ËÆ∫‰∫Ü‰∫∫Êú∫Âçè‰ΩúÔºàhuman-in-the-loopÔºâÁöÑÂä®Êú∫Ôºö\n",
    "\n",
    "**(1) ÂÆ°ÊâπÔºàApprovalÔºâ** - Êàë‰ª¨ÂèØ‰ª•‰∏≠Êñ≠Êô∫ËÉΩ‰ΩìÔºåÂêëÁî®Êà∑Â±ïÁ§∫Áä∂ÊÄÅÔºåÂπ∂ÂÖÅËÆ∏Áî®Êà∑Êé•ÂèóÊüê‰∏™Êìç‰Ωú\n",
    "\n",
    "**(2) Ë∞ÉËØïÔºàDebuggingÔºâ** - Êàë‰ª¨ÂèØ‰ª•ÂõûÊªöÂõæÊù•ÈáçÁé∞ÊàñÈÅøÂÖçÈóÆÈ¢ò\n",
    "\n",
    "**(3) ÁºñËæëÔºàEditingÔºâ** - ÊÇ®ÂèØ‰ª•‰øÆÊîπÁä∂ÊÄÅ\n",
    "\n",
    "Êàë‰ª¨Â±ïÁ§∫‰∫ÜÊñ≠ÁÇπÂ¶Ç‰ΩïÊîØÊåÅÁî®Êà∑ÂÆ°ÊâπÔºå‰ΩÜËøò‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÂú®ÂõæË¢´‰∏≠Êñ≠Âêé‰øÆÊîπÂõæÁä∂ÊÄÅÔºÅ\n",
    "\n",
    "## Â≠¶‰π†ÁõÆÊ†á\n",
    "\n",
    "Áé∞Âú®ÔºåËÆ©Êàë‰ª¨Â±ïÁ§∫Â¶Ç‰ΩïÁõ¥Êé•ÁºñËæëÂõæÁä∂ÊÄÅÂπ∂ÊèíÂÖ•‰∫∫Â∑•ÂèçÈ¶à„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {
    "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ÂÆâË£ÖÂøÖË¶ÅÁöÑ‰æùËµñÂåÖ\n",
    "# Ëøô‰∫õÂåÖÊòØÊûÑÂª∫LangGraphÂ∫îÁî®ÁöÑÊ†∏ÂøÉÁªÑ‰ª∂\n",
    "%pip install --quiet langgraph==0.6.7 langchain_openai==0.3.32 langgraph_sdk==0.2.6 langgraph-prebuilt==0.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5948594",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5948594",
    "outputId": "90174103-6cdd-4be5-a4c9-7c84d2b01331"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "OPENAI_BASE_URL:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "# ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"ÂÆâÂÖ®Âú∞ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôÊèêÁ§∫Áî®Êà∑ËæìÂÖ•\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ËÆæÁΩÆOpenAI APIÂØÜÈí•ÔºåËøôÊòØ‰ΩøÁî®OpenAIÊ®°ÂûãÊâÄÂøÖÈúÄÁöÑ\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# ËÆæÁΩÆ OpenAI API‰ª£ÁêÜÂú∞ÂùÄ (‰æãÂ¶ÇÔºöhttps://api.apiyi.com/v1Ôºâ\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {
    "id": "65a8df1f-a76a-4803-a532-ea9802106ac8"
   },
   "source": [
    "## ÁºñËæëÁä∂ÊÄÅ\n",
    "\n",
    "‰πãÂâçÔºåÊàë‰ª¨‰ªãÁªç‰∫ÜÊñ≠ÁÇπÔºàbreakpointsÔºâ„ÄÇ\n",
    "\n",
    "Êàë‰ª¨‰ΩøÁî®Êñ≠ÁÇπÊù•‰∏≠Êñ≠ÂõæÔºåÂπ∂Âú®ÊâßË°å‰∏ã‰∏Ä‰∏™ËäÇÁÇπ‰πãÂâçÁ≠âÂæÖÁî®Êà∑ÂÆ°Êâπ„ÄÇ\n",
    "\n",
    "‰ΩÜ**Êñ≠ÁÇπ‰πüÊòØ[‰øÆÊîπÂõæÁä∂ÊÄÅÁöÑÊú∫‰ºö](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)„ÄÇ**\n",
    "\n",
    "ËÆ©Êàë‰ª¨Âú®`assistant`ËäÇÁÇπ‰πãÂâçËÆæÁΩÆ‰∏Ä‰∏™Êñ≠ÁÇπÊù•ÊûÑÂª∫Êàë‰ª¨ÁöÑÊô∫ËÉΩ‰Ωì„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {
    "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4"
   },
   "outputs": [],
   "source": [
    "# ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ÂÆö‰πâÊï∞Â≠¶ËøêÁÆóÂ∑•ÂÖ∑ÂáΩÊï∞\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"‰πòÊ≥ïËøêÁÆóÔºöËÆ°ÁÆó‰∏§‰∏™Êï¥Êï∞ÁöÑ‰πòÁßØ\n",
    "\n",
    "    Args:\n",
    "        a: Á¨¨‰∏Ä‰∏™Êï¥Êï∞\n",
    "        b: Á¨¨‰∫å‰∏™Êï¥Êï∞\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Âä†Ê≥ïËøêÁÆóÔºöËÆ°ÁÆó‰∏§‰∏™Êï¥Êï∞ÁöÑÂíå\n",
    "\n",
    "    Args:\n",
    "        a: Á¨¨‰∏Ä‰∏™Êï¥Êï∞\n",
    "        b: Á¨¨‰∫å‰∏™Êï¥Êï∞\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Èô§Ê≥ïËøêÁÆóÔºöËÆ°ÁÆó‰∏§‰∏™Êï¥Êï∞ÁöÑÂïÜ\n",
    "\n",
    "    Args:\n",
    "        a: Ë¢´Èô§Êï∞\n",
    "        b: Èô§Êï∞\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "# Â∞ÜÂ∑•ÂÖ∑ÂáΩÊï∞ÁªÑÂêàÊàêÂ∑•ÂÖ∑ÂàóË°®\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# ÂàùÂßãÂåñOpenAIËÅäÂ§©Ê®°Âûã\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Â∞ÜÂ∑•ÂÖ∑ÁªëÂÆöÂà∞ËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üË∞ÉÁî®Ëøô‰∫õÂ∑•ÂÖ∑\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
    "outputId": "b0a5516f-31c0-495d-d439-caf0e80e825b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõæÂèØËßÜÂåñÔºö\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# ÂØºÂÖ•ÂøÖË¶ÅÁöÑÂ∫ì\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# ÂÆö‰πâÁ≥ªÁªüÊ∂àÊÅØÔºåÊåáÂØºAIÂä©ÊâãÁöÑË°å‰∏∫\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# ÂÆö‰πâÂä©ÊâãËäÇÁÇπÂáΩÊï∞\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"Âä©ÊâãËäÇÁÇπÔºö‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãÂ§ÑÁêÜÊ∂àÊÅØÂπ∂ÂèØËÉΩË∞ÉÁî®Â∑•ÂÖ∑\n",
    "\n",
    "    Args:\n",
    "        state: ÂåÖÂê´Ê∂àÊÅØÂàóË°®ÁöÑÂõæÁä∂ÊÄÅ\n",
    "\n",
    "    Returns:\n",
    "        ÂåÖÂê´AIÂìçÂ∫îÁöÑÊñ∞Áä∂ÊÄÅÊõ¥Êñ∞\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# ÂàõÂª∫Áä∂ÊÄÅÂõæÊûÑÂª∫Âô®\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# ÂÆö‰πâËäÇÁÇπÔºöËøô‰∫õËäÇÁÇπÊâßË°åÂÖ∑‰ΩìÁöÑÂ∑•‰Ωú\n",
    "builder.add_node(\"assistant\", assistant)  # AIÂä©ÊâãËäÇÁÇπ\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # Â∑•ÂÖ∑ÊâßË°åËäÇÁÇπ\n",
    "\n",
    "# ÂÆö‰πâËæπÔºöËøô‰∫õËæπÂÜ≥ÂÆöÊéßÂà∂ÊµÅÁ®ã\n",
    "builder.add_edge(START, \"assistant\")  # ‰ªéÂºÄÂßãÂà∞Âä©Êâã\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # Â¶ÇÊûúÂä©ÊâãÁöÑÊúÄÊñ∞Ê∂àÊÅØÊòØÂ∑•ÂÖ∑Ë∞ÉÁî® -> tools_condition Ë∑ØÁî±Âà∞Â∑•ÂÖ∑ËäÇÁÇπ\n",
    "    # Â¶ÇÊûúÂä©ÊâãÁöÑÊúÄÊñ∞Ê∂àÊÅØ‰∏çÊòØÂ∑•ÂÖ∑Ë∞ÉÁî® -> tools_condition Ë∑ØÁî±Âà∞ÁªìÊùü\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # ‰ªéÂ∑•ÂÖ∑ÂõûÂà∞Âä©Êâã\n",
    "\n",
    "# ÂàõÂª∫ÂÜÖÂ≠òÊ£ÄÊü•ÁÇπ‰øùÂ≠òÂô®ÔºåÁî®‰∫é‰øùÂ≠òÂõæÁä∂ÊÄÅ\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ÁºñËØëÂõæÔºåÂú®assistantËäÇÁÇπ‰πãÂâçËÆæÁΩÆ‰∏≠Êñ≠ÁÇπ\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# Â±ïÁ§∫ÂõæÁªìÊûÑ\n",
    "# ÂõæÂèØËßÜÂåñ\n",
    "print(\"ÂõæÂèØËßÜÂåñÔºö\")\n",
    "\n",
    "# ÊñπÊ°à1ÔºöÂ∞ùËØï‰ΩøÁî® Pyppeteer Êú¨Âú∞Ê∏≤ÊüìÔºàÊé®ËçêÔºâ\n",
    "try:\n",
    "    # ÂèØËßÜÂåñÔºöÈÄöËøá Mermaid Ê∏≤ÊüìÂõæÁªìÊûÑ\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pyppeteer Ê∏≤ÊüìÂ§±Ë¥•: {e}\")\n",
    "    \n",
    "    # ÊñπÊ°à2ÔºöÊòæÁ§∫ Mermaid ÊñáÊú¨Ê†ºÂºè\n",
    "    print(\"\\nüìù ÂõæÁªìÊûÑÔºàMermaid ÊñáÊú¨Ê†ºÂºèÔºâÔºö\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ÊñπÊ°à3ÔºöÊòæÁ§∫ÂõæÁöÑËäÇÁÇπÂíåËæπ‰ø°ÊÅØ\n",
    "    print(\"\\nüîó ÂõæÁªìÊûÑ‰ø°ÊÅØÔºö\")\n",
    "    print(\"ËäÇÁÇπ:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"Ëæπ:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # ÊñπÊ°à4ÔºöÊèê‰æõÊâãÂä®Ê∏≤ÊüìËØ¥Êòé\n",
    "    print(\"\\nüí° ÊâãÂä®Ê∏≤ÊüìËØ¥ÊòéÔºö\")\n",
    "    print(\"1. Â§çÂà∂‰∏äÈù¢ÁöÑ Mermaid ÊñáÊú¨\")\n",
    "    print(\"2. ËÆøÈóÆ https://mermaid.live/\")\n",
    "    print(\"3. Á≤òË¥¥ÊñáÊú¨Âà∞ÁºñËæëÂô®‰∏≠Êü•ÁúãÂõæÂΩ¢\")\n",
    "    print(\"4. ÊàñËÄÖ‰ΩøÁî®ÊîØÊåÅ Mermaid ÁöÑ Markdown ÁºñËæëÂô®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {
    "id": "92a47fd5-1f60-41dc-9206-698ed8ece530"
   },
   "source": [
    "ËÆ©Êàë‰ª¨ËøêË°åÂõæÔºÅ\n",
    "\n",
    "Êàë‰ª¨ÂèØ‰ª•ÁúãÂà∞ÂõæÂú®ËÅäÂ§©Ê®°ÂûãÂìçÂ∫î‰πãÂâçË¢´‰∏≠Êñ≠‰∫Ü„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
    "outputId": "7736c7bb-0693-433a-99c8-9a04c1458e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# ÂÆö‰πâÂàùÂßãËæìÂÖ•ÔºöÁî®Êà∑Ë¶ÅÊ±ÇËøõË°åÊï∞Â≠¶ËøêÁÆó\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# ÂàõÂª∫Á∫øÁ®ãÈÖçÁΩÆÔºåÁî®‰∫éË∑üË∏™ÂØπËØùÁä∂ÊÄÅ\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# ËøêË°åÂõæÁõ¥Âà∞Á¨¨‰∏Ä‰∏™‰∏≠Êñ≠ÁÇπ\n",
    "# Áî±‰∫éËÆæÁΩÆ‰∫Üinterrupt_before=[\"assistant\"]ÔºåÂõæ‰ºöÂú®assistantËäÇÁÇπÊâßË°åÂâçÂÅúÊ≠¢\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
    "outputId": "d898817a-3556-4785-c4e3-2fc1cc4a1229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='5855f46d-72f2-4621-baed-5207ca104cf3')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0bd4-1899-69ce-8000-9d9ccadd2f6f'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-04T00:58:35.728523+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0bd4-1897-6d45-bfff-f841e432f415'}}, tasks=(PregelTask(id='40606bf0-e3f4-76d4-31c5-4cba86eb22f6', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ëé∑ÂèñÂΩìÂâçÂõæÁä∂ÊÄÅÔºåÊü•Áúã‰∏≠Êñ≠Êó∂ÁöÑÁä∂ÊÄÅ‰ø°ÊÅØ\n",
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {
    "id": "36ef63a1-2ab8-416d-babf-d35054e294f0"
   },
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•Â∫îÁî®Áä∂ÊÄÅÊõ¥Êñ∞„ÄÇ\n",
    "\n",
    "ËÆ∞‰ΩèÔºåÂØπ`messages`ÈîÆÁöÑÊõ¥Êñ∞Â∞Ü‰ΩøÁî®`add_messages`ÂΩíÁ∫¶Âô®Ôºö\n",
    "\n",
    "* Â¶ÇÊûúÊàë‰ª¨ÊÉ≥Ë¶ÅË¶ÜÁõñÁé∞ÊúâÊ∂àÊÅØÔºåÂèØ‰ª•Êèê‰æõÊ∂àÊÅØÁöÑ`id`„ÄÇ\n",
    "* Â¶ÇÊûúÊàë‰ª¨Âè™ÊòØÊÉ≥Ë¶ÅËøΩÂä†Âà∞Ê∂àÊÅØÂàóË°®‰∏≠ÔºåÈÇ£‰πàÂèØ‰ª•‰º†ÈÄí‰∏Ä‰∏™Ê≤°ÊúâÊåáÂÆö`id`ÁöÑÊ∂àÊÅØÔºåÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
    "outputId": "1ea55096-4c34-41bd-8f31-6795d6cef635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a0bd4-18c2-676d-8001-bd9461ac7b7b'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Êõ¥Êñ∞ÂõæÁä∂ÊÄÅÔºöÊ∑ªÂä†Êñ∞ÁöÑ‰∫∫Á±ªÊ∂àÊÅØ\n",
    "# ËøôÈáåÊàë‰ª¨Ê∑ªÂä†‰∏ÄÊù°Êñ∞Ê∂àÊÅØÊù•‰øÆÊîπÁî®Êà∑ÁöÑÂéüÂßãËØ∑Ê±Ç\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {
    "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829"
   },
   "source": [
    "ËÆ©Êàë‰ª¨Áúã‰∏Ä‰∏ãÁªìÊûú„ÄÇ\n",
    "\n",
    "Êàë‰ª¨‰ΩøÁî®Êñ∞Ê∂àÊÅØË∞ÉÁî®‰∫Ü`update_state`„ÄÇ\n",
    "\n",
    "`add_messages`ÂΩíÁ∫¶Âô®Â∞ÜÂÖ∂ËøΩÂä†Âà∞Êàë‰ª¨ÁöÑÁä∂ÊÄÅÈîÆ`messages`‰∏≠„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
    "outputId": "29f6863a-e7ed-492a-8754-ad65919747d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "# Ëé∑ÂèñÊõ¥Êñ∞ÂêéÁöÑÁä∂ÊÄÅÂπ∂ÊòæÁ§∫ÊâÄÊúâÊ∂àÊÅØ\n",
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {
    "id": "e4041959-cc3a-4168-8cf7-06d1711921d8"
   },
   "source": [
    "Áé∞Âú®ÔºåËÆ©Êàë‰ª¨ÁªßÁª≠ÊâßË°åÊàë‰ª¨ÁöÑÊô∫ËÉΩ‰ΩìÔºåÂè™ÈúÄ‰º†ÈÄí`None`Âπ∂ÂÖÅËÆ∏ÂÆÉ‰ªéÂΩìÂâçÁä∂ÊÄÅÁªßÁª≠„ÄÇ\n",
    "\n",
    "Êàë‰ª¨ÂèëÂá∫ÂΩìÂâçÁä∂ÊÄÅÔºåÁÑ∂ÂêéÁªßÁª≠ÊâßË°åÂâ©‰ΩôÁöÑËäÇÁÇπ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
    "outputId": "ee0bd980-4ec0-49d3-e382-a65aa66b03d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_wpeAjQLX5n7nXgvolexlwRVS)\n",
      " Call ID: call_wpeAjQLX5n7nXgvolexlwRVS\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# ÁªßÁª≠ÊâßË°åÂõæÔºå‰ªéÂΩìÂâç‰∏≠Êñ≠ÁÇπÂºÄÂßã\n",
    "# ‰º†ÈÄíNoneË°®Á§∫‰ªéÂΩìÂâçÁä∂ÊÄÅÁªßÁª≠ÔºåËÄå‰∏çÊòØÈáçÊñ∞ÂºÄÂßã\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {
    "id": "b18dc1ca"
   },
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨ÂèàÂõûÂà∞‰∫Ü`assistant`ËäÇÁÇπÔºåÂÆÉËÆæÁΩÆ‰∫ÜÊàë‰ª¨ÁöÑ`breakpoint`„ÄÇ\n",
    "\n",
    "Êàë‰ª¨ÂèØ‰ª•ÂÜçÊ¨°‰º†ÈÄí`None`Êù•ÁªßÁª≠ÊâßË°å„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5952731-0170-4589-a399-ee787df35400",
    "outputId": "2f880747-c7b3-41d7-f6e1-165ab9ca18f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 and 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "# ÁªßÁª≠ÊâßË°åÂõæÔºåÂÆåÊàêÂâ©‰ΩôÁöÑËÆ°ÁÆó\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
