{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 🔧 环境配置和检查\n",
    "\n",
    "#### 概述\n",
    "\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助您：\n",
    "\n",
    "- 使用统一的conda环境：激活统一的学习环境\n",
    "- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n",
    "- 加速模型下载：设置HuggingFace镜像代理\n",
    "- 检查系统配置：检查硬件和软件配置\n",
    "\n",
    "#### 配置\n",
    "\n",
    "- **所需环境及其依赖已经部署好**\n",
    "- 在`Notebook`右上角选择`jupyter内核`为`python(flyai_agent_in_action)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\n",
      "=========================================\n",
      "✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\n",
      "✅ 正在使用的环境路径: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\n",
      "   如果需要后续单元格也使用此环境，请执行以下操作:\n",
      "   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. 激活 conda 环境 (仅对当前单元格有效)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. 检查当前激活的环境\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\"\n",
    "    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\"\n",
    "    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n",
    "    echo \"   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\"\n",
    "else\n",
    "    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(flyai_agent_in_action)'。\"\n",
    "    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n",
    "    echo \"\"\n",
    "    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# 必须在每个单元格都执行\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### 环境信息\n",
      "| 项目         | 信息                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| 操作系统     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU 信息     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| 内存信息     | 2015.36 GB (Available: 1667.73 GB)                                    |\n",
      "| GPU 信息     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA 信息    | 12.6                                                                  |\n",
      "| Python 版本  | 3.12.11                                                               |\n",
      "| Conda 版本   | conda 25.7.0                                                          |\n",
      "| 物理磁盘空间 | Total: 2014.78 GB, Used: 652.13 GB, Free: 1260.23 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助您：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/langchain-academy/blob/fly101/module-5/memory_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjeyB8-ZHmNS"
   },
   "source": [
    "# 记忆型智能体（Memory Agent）\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们已经构建过一个聊天机器人，它可以将语义型记忆保存到单一的[用户画像（profile）](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)或[集合（collection）](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)中。\n",
    "\n",
    "我们还引入了 [Trustcall](https://github.com/hinthornw/trustcall)，用于对上述任一模式（schema）进行结构化更新。\n",
    "\n",
    "## 目标\n",
    "\n",
    "现在，我们将把已学的组件组合起来，构建一个具备长期记忆能力的[智能体（agent）](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)。\n",
    "\n",
    "本次我们创建的智能体 `task_assistant` 将帮助我们管理一个待办清单（ToDo list）。\n",
    "\n",
    "此前的聊天机器人会在每轮对话后都进行反思并保存记忆。\n",
    "\n",
    "而 `task_assistant` 会自主决定“何时”保存记忆（即是否把内容加入待办）。\n",
    "\n",
    "此前的聊天机器人只会保存一种类型的记忆（profile 或 collection）。\n",
    "\n",
    "**`task_assistant` 可以决定将信息保存到用户画像，或保存为待办清单中的任务集合。**\n",
    "\n",
    "除了语义记忆，`task_assistant` **还会管理“过程性记忆”（procedural memory）。**\n",
    "\n",
    "这使得用户可以更新“如何创建待办项”的偏好与原则（例如是否偏好包含本地商家等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ahcf1O6nHmNY"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install -U langchain_openai langgraph trustcall langchain_core\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7 trustcall==0.0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-DLZXCDHmNa",
    "outputId": "d5d56589-542d-43f0-ee61-1b0e8b7de2e1"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # 检查该环境变量是否已在操作系统环境中设置\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # 如未设置，则提示用户输入\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # 将环境变量设置到当前进程\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"FlyAIBox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyTqFsu1HmNb",
    "outputId": "9404c71d-39f8-4152-ccb1-8c5e220d5808"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n",
      "OPENAI_BASE_URL:  ········\n"
     ]
    }
   ],
   "source": [
    "# 设置OpenAI API密钥\n",
    "# 您需要从 https://api.apiyi.com/v1 获取API密钥\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1D0-qcGHmNb"
   },
   "source": [
    "## 观察 Trustcall 的更新细节\n",
    "\n",
    "Trustcall 会创建和更新 JSON 模式（schema）。\n",
    "\n",
    "如果我们想了解 Trustcall 具体做了哪些“结构化变更”，该怎么办？\n",
    "\n",
    "例如，Trustcall 自带了一些工具可以：\n",
    "\n",
    "- 自动纠正校验失败的结果（self-correct）——参见示例追踪：[链接](https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r/9684db76-2003-443b-9aa2-9a9dbc5498b7)\n",
    "- 更新已有文档（patch/更新）——参见示例追踪：[链接](https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r/760f90e1-a5dc-48f1-8c34-79d6a3414ac3)\n",
    "\n",
    "对这些工具行为保持可见性，有助于我们后续构建的智能体进行调试与解释。\n",
    "\n",
    "下面将展示如何实现！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I93w9r-VHmNb"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"记忆的主要内容。例如：用户表达了想要学习法语的兴趣。\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"关于用户的一组记忆条目。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5F3FKAmHmNc"
   },
   "source": [
    "我们可以给 Trustcall 的抽取器添加一个[监听器（listener）](https://python.langchain.com/docs/how_to/lcel_cheatsheet/#add-lifecycle-listeners)。\n",
    "\n",
    "这样会将抽取器执行过程中的运行记录（runs）传递给我们自定义的 `Spy` 类。\n",
    "\n",
    "`Spy` 会提取 Trustcall 实际调用了哪些工具、对应的调用 ID 与参数，便于审计与调试。\n",
    "\n",
    "---\n",
    "`Spy` 帮我们记录下了 Trustcall 调用的工具信息，但这只是原始数据。为了更直观地看到 Trustcall 到底做了哪些“结构化变更”，我们需要对这些原始信息进行处理。\n",
    "\n",
    "`extract_tool_info` 函数就是用来做这件事的。它就像一个“翻译官”，把 `Spy` 记录的工具调用“翻译”成我们能理解的“变更摘要”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HsPJbMt1HmNc"
   },
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 检查 Trustcall 实际触发的工具调用\n",
    "# 这个 Spy 类就像一个“间谍”，用来监听和记录 Trustcall 在抽取过程中实际调用了哪些工具。\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        # 这个列表用来存放捕获到的工具调用信息。\n",
    "        self.called_tools = []\n",
    "\n",
    "    # 这个方法是监听器实际执行的功能。\n",
    "    # 当 Trustcall 内部发生一个“运行”（run）时，比如调用模型或工具，这个方法就会被调用。\n",
    "    # 'run' 参数包含了这次运行的详细信息。\n",
    "    def __call__(self, run):\n",
    "        # 这里我们通过一个队列来遍历当前运行及其所有的子运行（child_runs）。\n",
    "        # 这是因为 Trustcall 的内部执行可能是一个复杂的流程，包含多个嵌套的运行。\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            # 如果当前运行有子运行，就把它们添加到队列中，以便后续检查。\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            # 我们主要关注类型为“chat_model”的运行，这表示聊天模型被调用了。\n",
    "            # 模型在生成回复时，可能会决定调用工具。\n",
    "            if r.run_type == \"chat_model\":\n",
    "                # 从模型的输出中提取出工具调用的信息。\n",
    "                # 这些信息通常在模型的生成结果的特定位置。\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# 初始化监听器（Spy）实例\n",
    "spy = Spy()\n",
    "\n",
    "# 初始化聊天模型。Trustcall 会使用这个模型来执行抽取和可能的工具调用。\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 创建 Trustcall 抽取器。\n",
    "# 这个抽取器配置为使用我们定义的 Memory schema 作为工具。\n",
    "# tool_choice=\"Memory\" 表示模型应该尝试调用 Memory 工具来结构化信息。\n",
    "# enable_inserts=True 允许 Trustcall 在需要时插入新的 Memory 文档。\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# 将 Spy 监听器添加到 Trustcall 抽取器上。\n",
    "# on_end=spy 表示在抽取过程结束时，调用 Spy 实例（即执行 __call__ 方法），从而捕获工具调用信息。\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "28VrIpmtHmNd"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction（抽取任务说明）\n",
    "instruction = \"\"\"从以下对话中抽取记忆（Memories）：\"\"\"\n",
    "\n",
    "# 模拟对话内容\n",
    "conversation = [\n",
    "    HumanMessage(content=\"你好，我是 FLY\"),\n",
    "    AIMessage(content=\"很高兴认识你，FLY\"),\n",
    "    HumanMessage(content=\"今天早上我在湖边骑自行车\")\n",
    "]\n",
    "\n",
    "# Invoke the extractor（调用抽取器）\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ATEyqPPHmNd",
    "outputId": "66822edd-0da6-4fbd-8460-664205377f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_B07NoQ1S0P1JlRqu7ZqHCt0p)\n",
      " Call ID: call_B07NoQ1S0P1JlRqu7ZqHCt0p\n",
      "  Args:\n",
      "    content: FLY 今天早上在湖边骑自行车。\n"
     ]
    }
   ],
   "source": [
    "# 消息中包含了工具调用（tool calls）\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqXEqnVSHmNe",
    "outputId": "80dd4f24-273d-409e-e6bd-2ee920a0790a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='FLY 今天早上在湖边骑自行车。'\n"
     ]
    }
   ],
   "source": [
    "# responses（解析后的结果）包含符合 schema 的记忆\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ch0pzGoQHmNe",
    "outputId": "0b8827fc-10cf-4db4-d7d4-401f2a31aeda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_B07NoQ1S0P1JlRqu7ZqHCt0p'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadata（元信息）包含工具调用的 ID 等信息\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk3bh_AVHmNe",
    "outputId": "efcbf712-2828-4cde-c3d2-4be82c242444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'FLY 今天早上在湖边骑自行车。'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟对话的延续，用于演示记忆更新\n",
    "updated_conversation = [\n",
    "    AIMessage(content=\"太棒了，之后你做了什么？\"),\n",
    "    HumanMessage(content=\"我去了咖啡店喝了咖啡\"),\n",
    "    AIMessage(content=\"你还想说什么？\"),\n",
    "    HumanMessage(content=\"我在想去日本旅游，想今年冬天再去\"),\n",
    "]\n",
    "# Update the instruction（系统提示：基于新对话进行更新）\n",
    "system_msg = \"\"\"根据下面的对话，更新已有记忆并创建新的记忆：\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value（把已有记忆保存为 (id, 工具名, 值) 的三元组）\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bb7-xTjHHmNe"
   },
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
    "                             \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncSPyiAsHmNf",
    "outputId": "34c32b0a-b364-434e-d994-9cf8be2cbc85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_wTVv9Qo0zLvRE2GiVFIlhT7h'}\n",
      "{'id': 'call_Tm8yjCNSpDKqBOYPiyqw6goJ'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadata（元信息）包含工具调用的 ID 等信息\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAbu8DoZHmNf",
    "outputId": "26aa6ca7-8d4e-4815-c1bc-f3e057c84285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_wTVv9Qo0zLvRE2GiVFIlhT7h)\n",
      " Call ID: call_wTVv9Qo0zLvRE2GiVFIlhT7h\n",
      "  Args:\n",
      "    content: 去了咖啡店喝了咖啡。\n",
      "  Memory (call_Tm8yjCNSpDKqBOYPiyqw6goJ)\n",
      " Call ID: call_Tm8yjCNSpDKqBOYPiyqw6goJ\n",
      "  Args:\n",
      "    content: 想去日本旅游，计划今年冬天去。\n"
     ]
    }
   ],
   "source": [
    "# 消息中包含了工具调用（tool calls）\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lZYsstbHmNf",
    "outputId": "38d15a46-ccf6-4c83-9d71-c4d868d18816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='去了咖啡店喝了咖啡。'\n",
      "content='想去日本旅游，计划今年冬天去。'\n"
     ]
    }
   ],
   "source": [
    "# 解析后的 responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItTojpcUHmNf",
    "outputId": "104244f3-4f4d-45b1-fdf3-b85dbbf46125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'Memory',\n",
       "   'args': {'content': '去了咖啡店喝了咖啡。'},\n",
       "   'id': 'call_wTVv9Qo0zLvRE2GiVFIlhT7h',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': '想去日本旅游，计划今年冬天去。'},\n",
       "   'id': 'call_Tm8yjCNSpDKqBOYPiyqw6goJ',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 Trustcall 在这一步实际调用了哪些工具\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust version of extract_tool_info to avoid KeyError on optional fields\n",
    "\n",
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"从工具调用序列中抽取结构化“变更摘要”。同时支持补丁更新与新增。\n",
    "\n",
    "    参数：\n",
    "        tool_calls: 模型产生的工具调用列表（含并行批次）\n",
    "        schema_name: 目标 schema 名称（如 \"Memory\"、\"ToDo\"、\"Profile\"）\n",
    "    \"\"\"\n",
    "\n",
    "    changes = []\n",
    "\n",
    "    # tool_calls 是一个列表的列表，因为模型可能并行调用多个工具\n",
    "    for call_group in tool_calls or []:\n",
    "        if not isinstance(call_group, (list, tuple)):\n",
    "            continue\n",
    "        for call in call_group:\n",
    "            if not isinstance(call, dict):\n",
    "                continue\n",
    "            name = call.get(\"name\")\n",
    "            args = call.get(\"args\", {}) if isinstance(call.get(\"args\", {}), dict) else {}\n",
    "\n",
    "            # 更新已有文档（PatchDoc）\n",
    "            if name == \"PatchDoc\":\n",
    "                doc_id = args.get(\"json_doc_id\") or args.get(\"doc_id\") or \"N/A\"\n",
    "                planned_edits = args.get(\"planned_edits\", \"N/A\")\n",
    "\n",
    "                # 安全获取补丁内容\n",
    "                value = None\n",
    "                patches = args.get(\"patches\") or []\n",
    "                if isinstance(patches, list) and patches:\n",
    "                    first_patch = patches[0]\n",
    "                    if isinstance(first_patch, dict):\n",
    "                        value = (\n",
    "                            first_patch.get(\"value\")\n",
    "                            or first_patch.get(\"data\")\n",
    "                            or first_patch\n",
    "                        )\n",
    "                    else:\n",
    "                        value = first_patch\n",
    "\n",
    "                changes.append({\n",
    "                    \"type\": \"update\",\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"planned_edits\": planned_edits,\n",
    "                    \"value\": value if value is not None else args,\n",
    "                })\n",
    "\n",
    "            # 新增文档（与 schema 名称一致）\n",
    "            elif name == schema_name:\n",
    "                changes.append({\n",
    "                    \"type\": \"new\",\n",
    "                    \"value\": args if args else call.get(\"args\", {}),\n",
    "                })\n",
    "\n",
    "    # 格式化输出\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change.get(\"type\") == \"update\":\n",
    "            result_parts.append(\n",
    "                (\n",
    "                    f\"文档 {change.get('doc_id', 'N/A')} 已更新：\\n\"\n",
    "                    f\"计划：{change.get('planned_edits', 'N/A')}\\n\"\n",
    "                    f\"新增/替换内容：{change.get('value')}\"\n",
    "                )\n",
    "            )\n",
    "        elif change.get(\"type\") == \"new\":\n",
    "            result_parts.append(\n",
    "                f\"已创建新的 {schema_name}：\\n\"\n",
    "                f\"内容：{change.get('value')}\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\\n\".join(result_parts) if result_parts else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2AFKS0tHmNg"
   },
   "source": [
    "## 创建一个智能体\n",
    "\n",
    "可选的[智能体（agent）](https://langchain-ai.github.io/langgraph/concepts/high_level/)架构有很多。\n",
    "\n",
    "这里我们实现一个相对简单的 [ReAct](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation) 智能体。\n",
    "\n",
    "它将作为创建与管理 ToDo 清单的辅助搭档。\n",
    "\n",
    "该智能体可以自主决定更新三类长期记忆：\n",
    "\n",
    "(a) 创建/更新用户 `profile`（用户的基本信息）\n",
    "\n",
    "(b) 在 ToDo 列表 `collection` 中新增/更新任务\n",
    "\n",
    "(c) 更新它自己用于维护 ToDo 列表的 `instructions`（操作准则）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xQh4str6HmNg"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYXkmebzHmNg"
   },
   "source": [
    "## 图定义（Graph definition）\n",
    "\n",
    "我们添加一个简单的路由器 `route_message`，它会做一个二元决策：是否需要保存记忆，以及保存到哪一类长期记忆中。\n",
    "\n",
    "记忆集合（ToDo、Profile 等）的结构化更新由 `Trustcall` 负责，与前面的示例一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "nv6UFSaKHmNg",
    "outputId": "f1ea9074-1295-4521-d37f-15b6e9c11cb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model（初始化聊天模型）\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"当前聊天用户的画像（基本信息）\"\"\"\n",
    "    name: Optional[str] = Field(description=\"用户姓名\", default=None)\n",
    "    location: Optional[str] = Field(description=\"用户所在城市/地区\", default=None)\n",
    "    job: Optional[str] = Field(description=\"用户的职业\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"与用户相关的个人关系，如家人、朋友或同事\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"用户的兴趣爱好\",\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"要完成的任务\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"预计完成所需时间（分钟）\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"任务的截止时间（如适用）\",\n",
    "        default=None\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"可执行的解决方案清单（例如：具体想法、服务商、可落地的操作选项等）\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"任务当前状态\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profile（用于更新用户画像的 Trustcall 抽取器）\n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"你是一名乐于助人的聊天机器人。\n",
    "\n",
    "你的职责是作为用户的日常助手，帮助他们维护 ToDo 待办清单。\n",
    "\n",
    "你拥有一份长期记忆，记录三类信息：\n",
    "1. 用户画像（profile）：关于用户的一般性信息\n",
    "2. ToDo 列表：与用户任务相关的事项\n",
    "3. 维护 ToDo 列表的操作准则（instructions）\n",
    "\n",
    "以下是当前的用户画像（如果尚未收集信息，可能为空）：\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "以下是当前的 ToDo 列表（如果尚未添加任务，可能为空）：\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "以下是用户目前指定的 ToDo 维护偏好（如果尚未指定，可能为空）：\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "你的推理与行动规范如下：\n",
    "\n",
    "1. 认真理解下方的用户消息与上下文。\n",
    "\n",
    "2. 判断是否需要更新长期记忆中的任一部分：\n",
    "- 如果用户提供了个人信息，调用 UpdateMemory 工具并传入类型 `user`，用于更新用户画像\n",
    "- 如果用户提到任务，调用 UpdateMemory 工具并传入类型 `todo`，用于更新 ToDo 列表\n",
    "- 如果用户给出了如何维护 ToDo 的偏好/原则，调用 UpdateMemory 工具并传入类型 `instructions`，用于更新操作准则\n",
    "\n",
    "3. 在合适的情况下向用户反馈“记忆已更新”：\n",
    "- 不要告知用户你更新了用户画像\n",
    "- 当你更新了 ToDo 列表时，应当明确告知\n",
    "- 不要告知用户你更新了操作准则\n",
    "\n",
    "4. 在是否更新 ToDo 列表的问题上，宁可“多更新”也无需事先征求许可。\n",
    "\n",
    "5. 无论是否进行了工具调用，都要自然地继续与用户对话。\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"请认真回顾以下交互内容。\n",
    "\n",
    "使用提供的工具，保留与用户相关的必要记忆。\n",
    "\n",
    "如果需要同时进行“更新已有文档”和“新增文档”，请使用并行工具调用以提升效率。\n",
    "\n",
    "系统时间：{time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"请回顾以下交互内容。\n",
    "\n",
    "基于这次交互，更新你“如何维护 ToDo 列表条目”的操作准则。\n",
    "\n",
    "利用用户反馈，调整添加/更新条目的方式（例如是否偏好包含本地商家等）。\n",
    "\n",
    "你当前的准则如下：\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_assistant(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    task_assistant 节点：这是智能体接收用户消息并进行初步处理的地方。\n",
    "    它的主要作用是：\n",
    "    1. 从长期存储中加载用户的个性化记忆（用户画像、ToDo 列表、操作准则）。\n",
    "    2. 将这些记忆整合到系统提示中，用于指导模型的回复。\n",
    "    3. 调用模型，让模型根据用户消息和系统提示决定是否需要更新长期记忆（通过调用 UpdateMemory 工具）并生成回复。\n",
    "    \"\"\"\n",
    "\n",
    "    # 从配置中获取当前用户的唯一 ID。这个 ID 用于区分不同用户的长期记忆。\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # --- 加载长期记忆 ---\n",
    "\n",
    "    # 1. 读取用户画像（profile）记忆\n",
    "    # 构建命名空间 (namespace)。命名空间是 Trustcall Store 中用于组织和隔离数据的方式。\n",
    "    # 这里使用 (\"profile\", user_id) 作为命名空间，表示这是特定用户 (user_id) 的用户画像数据。\n",
    "    namespace = (\"profile\", user_id)\n",
    "    # 从存储中搜索该命名空间下的所有记忆。用户画像通常只有一个文档。\n",
    "    memories = store.search(namespace)\n",
    "    # 如果找到了记忆，提取第一个（也是唯一一个）记忆的值。\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        # 如果没有找到，说明还没有用户画像记忆，设置为 None。\n",
    "        user_profile = None\n",
    "\n",
    "    # 2. 读取 ToDo 列表记忆\n",
    "    # 构建 ToDo 列表的命名空间。\n",
    "    namespace = (\"todo\", user_id)\n",
    "    # 从存储中搜索该命名空间下的所有 ToDo 记忆。ToDo 列表可能包含多个任务。\n",
    "    memories = store.search(namespace)\n",
    "    # 将所有 ToDo 记忆的值（每个任务的描述）用换行符连接起来，形成一个字符串。\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # 3. 读取用户偏好/操作准则（instructions）记忆\n",
    "    # 构建操作准则的命名空间。\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    # 从存储中搜索该命名空间下的所有操作准则记忆。操作准则通常只有一个文档。\n",
    "    memories = store.search(namespace)\n",
    "    # 如果找到了记忆，提取第一个（也是唯一一个）记忆的值。\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        # 如果没有找到，说明还没有操作准则记忆，设置为空字符串。\n",
    "        instructions = \"\"\n",
    "\n",
    "    # --- 构建系统提示 ---\n",
    "\n",
    "    # 使用加载的记忆信息格式化主系统提示 (MODEL_SYSTEM_MESSAGE)。\n",
    "    # 这会将用户的 profile, todo 列表和 instructions 嵌入到提示中，\n",
    "    # 让模型在生成回复时能够参考这些个性化信息。\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # --- 调用模型生成回复和工具调用 ---\n",
    "\n",
    "    # 调用聊天模型。\n",
    "    # bind_tools([UpdateMemory], parallel_tool_calls=False) 表示模型在生成回复时，\n",
    "    # 可以选择调用 UpdateMemory 工具，并且每次只调用一个工具 (parallel_tool_calls=False)。\n",
    "    # invoke(...) 传入系统消息和当前的对话历史 (state[\"messages\"])。\n",
    "    # 模型会根据这些信息生成回复，如果判断需要更新记忆，则会包含 UpdateMemory 的工具调用。\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    # 返回模型的回复。这个回复会包含模型的文本回复以及可能存在的工具调用信息。\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_profile 节点：负责处理模型调用 UpdateMemory 工具并指定 update_type 为 'user' 的情况。\n",
    "    它的主要作用是：\n",
    "    1. 回顾对话历史，从中提取与用户画像相关的信息。\n",
    "    2. 使用 Trustcall 抽取器更新长期存储中的用户画像记忆。\n",
    "    \"\"\"\n",
    "\n",
    "    # 从配置中获取当前用户的唯一 ID。这个 ID 用于区分不同用户的长期记忆。\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 定义记忆的命名空间。Trustcall Store 使用命名空间来组织和隔离不同类型或不同用户的记忆。\n",
    "    # 这里使用 (\"profile\", user_id) 作为命名空间，表示这是特定用户 (user_id) 的用户画像数据。\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # 从存储中检索当前用户已有的用户画像记忆，作为 Trustcall 抽取器进行更新的上下文。\n",
    "    # 如果之前没有用户画像，这里将返回空列表。\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # 将现有的记忆格式化为 Trustcall 抽取器所需的输入格式。\n",
    "    # Trustcall 在进行更新时，需要知道现有文档的 ID、类型（schema 名称）和值。\n",
    "    tool_name = \"Profile\" # 指定要更新的 schema 名称为 \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # 如果 existing_items 不为空，则进行列表推导\n",
    "                          else None # 否则设置为 None\n",
    "                        )\n",
    "\n",
    "    # 合并系统指令和对话历史。Trustcall 抽取器需要完整的对话上下文来提取信息。\n",
    "    # TRUSTCALL_INSTRUCTION 是一个包含通用抽取指令的字符串模板。\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # 格式化指令，加入当前时间\n",
    "    # merge_message_runs 用于合并消息列表。这里将系统指令和对话历史 (除了最后一个工具调用消息) 合并。\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # 调用 Trustcall 抽取器。\n",
    "    # Trustcall 会根据提供的消息和现有记忆，决定是新增用户画像还是更新现有的。\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages,\n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # 将 Trustcall 抽取出的新记忆或更新后的记忆保存到长期存储 (store) 中。\n",
    "    # result[\"responses\"] 包含抽取出的符合 Profile schema 的 Pydantic 对象。\n",
    "    # result[\"response_metadata\"] 包含抽取出的对象的元信息，如 json_doc_id（如果 Trustcall 决定更新现有文档）。\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put 方法用于将数据存入存储。\n",
    "        # namespace: 指定存储的命名空间。\n",
    "        # key: 存储项的键。如果 Trustcall 返回了 json_doc_id，说明是更新，使用该 ID 作为键；否则生成一个新的 UUID 作为新文档的键。\n",
    "        # value: 要存储的值。这里将抽取出的 Pydantic 对象转换为 JSON 格式的字典。\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    # 获取 task_assistant 节点发出的工具调用信息。\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    # 返回一个工具消息 (ToolMessage)，表示 update_profile 节点已经执行完毕，\n",
    "    # 并将结果 (\"updated profile\") 发送回 task_assistant 节点。\n",
    "    # \"tool_call_id\" 用于关联这个 ToolMessage 和 task_assistant 发出的原始工具调用。\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_todos 节点：负责处理模型调用 UpdateMemory 工具并指定 update_type 为 'todo' 的情况。\n",
    "    它的主要作用是：\n",
    "    1. 回顾对话历史，从中提取与 ToDo 任务相关的信息。\n",
    "    2. 使用 Trustcall 抽取器更新长期存储中的 ToDo 列表记忆（新增或更新任务）。\n",
    "    3. 提取 Trustcall 的具体变更信息，并作为工具调用的结果返回给 task_assistant 节点。\n",
    "    \"\"\"\n",
    "\n",
    "    # 从配置中获取当前用户的唯一 ID。这个 ID 用于区分不同用户的长期记忆。\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 定义记忆的命名空间。Trustcall Store 使用命名空间来组织和隔离不同类型或不同用户的记忆。\n",
    "    # 这里使用 (\"todo\", user_id) 作为命名空间，表示这是特定用户 (user_id) 的 ToDo 数据。\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # 从存储中检索当前用户已有的 ToDo 记忆，作为 Trustcall 抽取器进行更新的上下文。\n",
    "    # 如果之前没有 ToDo，这里将返回空列表。\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # 将现有的记忆格式化为 Trustcall 抽取器所需的输入格式。\n",
    "    # Trustcall 在进行更新时，需要知道现有文档的 ID、类型（schema 名称）和值。\n",
    "    tool_name = \"ToDo\" # 指定要更新的 schema 名称为 \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # 如果 existing_items 不为空，则进行列表推导\n",
    "                          else None # 否则设置为 None\n",
    "                        )\n",
    "\n",
    "    # 合并系统指令和对话历史。Trustcall 抽取器需要完整的对话上下文来提取信息。\n",
    "    # TRUSTCALL_INSTRUCTION 是一个包含通用抽取指令的字符串模板。\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # 格式化指令，加入当前时间\n",
    "    # merge_message_runs 用于合并消息列表。这里将系统指令和对话历史 (除了最后一个工具调用消息) 合并。\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall（初始化监听器以观察 Trustcall 工具调用）\n",
    "    spy = Spy()\n",
    "\n",
    "    # Create the Trustcall extractor for updating the ToDo list（用于更新 ToDo 的 Trustcall 抽取器）\n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages,\n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store（将 Trustcall 抽取出的新记忆或更新后的记忆保存到长期存储 (store) 中）\n",
    "    # result[\"responses\"] 包含抽取出的符合 ToDo schema 的 Pydantic 对象。\n",
    "    # result[\"response_metadata\"] 包含抽取出的对象的元信息，如 json_doc_id（如果 Trustcall 决定更新现有文档）。\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put 方法用于将数据存入存储。\n",
    "        # namespace: 指定存储的命名空间。\n",
    "        # key: 存储项的键。如果 Trustcall 返回了 json_doc_id，说明是更新，使用该 ID 作为键；否则生成一个新的 UUID 作为新文档的键。\n",
    "        # value: 要存储的值。这里将抽取出的 Pydantic 对象转换为 JSON 格式的字典。\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "    # Respond to the tool call made in task_assistant, confirming the update（响应 task_assistant 节点发出的工具调用，确认更新已完成）\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_assistant（提取 Trustcall 进行的具体变更信息，并作为工具调用的结果返回给 task_assistant 节点）\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_instructions 节点：负责处理模型调用 UpdateMemory 工具并指定 update_type 为 'instructions' 的情况。\n",
    "    它的主要作用是：\n",
    "    1. 回顾对话历史，从中提取用户关于如何维护 ToDo 列表的偏好/原则。\n",
    "    2. 调用模型根据这些偏好更新长期存储中的操作准则记忆。\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store\n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "\n",
    "# Conditional edge（条件边：根据模型的工具调用结果路由）\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "    \"\"\"\n",
    "    route_message 函数：这是图中的条件边，负责根据 task_assistant 节点的输出（特别是模型是否调用了 UpdateMemory 工具及其参数）来决定下一个节点。\n",
    "    它的主要作用是：\n",
    "    1. 检查 task_assistant 返回的消息中是否包含工具调用。\n",
    "    2. 如果没有工具调用，说明模型认为不需要更新记忆，对话结束 (END)。\n",
    "    3. 如果有工具调用，检查 UpdateMemory 工具的 update_type 参数，并路由到相应的更新节点（update_profile, update_todos, 或 update_instructions）。\n",
    "    \"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    # 检查最后一条消息是否有工具调用\n",
    "    if len(message.tool_calls) ==0:\n",
    "        # 如果没有工具调用，结束对话\n",
    "        return END\n",
    "    else:\n",
    "        # 如果有工具调用，获取第一个工具调用（我们限制了 parallel_tool_calls=False，所以只会有一个）\n",
    "        tool_call = message.tool_calls[0]\n",
    "        # 根据工具调用的参数 'update_type' 来决定下一个节点\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            # 如果是更新用户画像，路由到 update_profile 节点\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            # 如果是更新 ToDo 列表，路由到 update_todos 节点\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            # 如果是更新操作准则，路由到 update_instructions 节点\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            # 如果 update_type 是未知类型，抛出错误\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "# 添加各个节点到图中\n",
    "builder.add_node(\"task_assistant\", task_assistant) # 添加 task_assistant 节点\n",
    "builder.add_node(\"update_todos\", update_todos)     # 添加 update_todos 节点\n",
    "builder.add_node(\"update_profile\", update_profile) # 添加 update_profile 节点\n",
    "builder.add_node(\"update_instructions\", update_instructions) # 添加 update_instructions 节点\n",
    "\n",
    "# 定义边的连接\n",
    "# 从 START（图的开始）连接到 task_assistant 节点\n",
    "builder.add_edge(START, \"task_assistant\")\n",
    "# 从 task_assistant 节点添加条件边，根据 route_message 函数的返回值决定去向\n",
    "builder.add_conditional_edges(\"task_assistant\", route_message)\n",
    "# 从各个更新节点（update_todos, update_profile, update_instructions）连接回 task_assistant 节点，\n",
    "# 这样在更新完成后，智能体可以回到 task_assistant 继续与用户交互。\n",
    "builder.add_edge(\"update_todos\", \"task_assistant\")\n",
    "builder.add_edge(\"update_profile\", \"task_assistant\")\n",
    "builder.add_edge(\"update_instructions\", \"task_assistant\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "# 初始化一个内存存储，用于长期（跨会话）记忆。\n",
    "# 在实际应用中，这里通常会使用数据库等持久化存储。\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "# 初始化一个检查点，用于短期（会话内）记忆。\n",
    "# 它会保存每个步骤的状态，以便在出现问题时可以从检查点恢复。\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "# 编译图，将节点和边连接起来，并配置检查点和长期存储。\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "# 绘制并显示图的可视化，帮助我们理解智能体的工作流程。\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5_tsKnXHmNh",
    "outputId": "fccc6b20-42d3-4184-afc4-4f0e2d0a3fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我是FLY。我和妻子生活在中国杭州。我有一个3岁的女儿。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_muUriNlzm9eR8tJ8cIALiEjX)\n",
      " Call ID: call_muUriNlzm9eR8tJ8cIALiEjX\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你好，FLY！很高兴认识你。你和家人在杭州生活一定很美好。有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "# 提供线程 ID（短期、会话级记忆）\n",
    "# 提供用户 ID（长期、跨会话记忆）\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# 用户输入：用于创建用户画像（profile）相关记忆\n",
    "input_messages = [HumanMessage(content=\"我是FLY。我和妻子生活在中国杭州。我有一个3岁的女儿。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8Bpj-W2HmNh",
    "outputId": "f9d71314-a674-43e8-fa1a-029dc1b5a604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我的妻子让我为宝宝预订游泳课程。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Xuw4LU3tZi6I7BzFvzLxO6Uj)\n",
      " Call ID: call_Xuw4LU3tZi6I7BzFvzLxO6Uj\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "已创建新的 ToDo：\n",
      "内容：{'task': '为宝宝预订游泳课程', 'status': 'not started', 'time_to_complete': 30}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "我已经为你添加了一个任务：为宝宝预订游泳课程。记忆已更新。你需要帮助来完成这个任务吗？\n"
     ]
    }
   ],
   "source": [
    "# 用户输入：添加一个 ToDo 任务\n",
    "input_messages = [HumanMessage(content=\"我的妻子让我为宝宝预订游泳课程。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKBO0zhSHmNh",
    "outputId": "d16f0b7f-27f3-4282-d482-9df955685b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "在创建或更新待办事项时，请包括具体的本地商家/供应商。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_LwzYU6JMMbPNRmrqexknboEH)\n",
      " Call ID: call_LwzYU6JMMbPNRmrqexknboEH\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "好的，我会在创建或更新待办事项时，尽量包括具体的本地商家或供应商。还有其他需要帮助的吗？\n"
     ]
    }
   ],
   "source": [
    "# 用户输入：更新 ToDo 创建/更新的操作准则（instructions）\n",
    "input_messages = [HumanMessage(content=\"在创建或更新待办事项时，请包括具体的本地商家/供应商。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjysywxnHmNh",
    "outputId": "57fda351-fd80-4946-d405-17b3a96d698a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': \"Based on the conversation, here are the updated guidelines for maintaining ToDo list entries:\\n\\n1. When creating or updating ToDo list entries, include specific local businesses or suppliers if applicable.\\n2. Consider the user's location and preferences when suggesting or adding details to tasks.\\n3. Ensure tasks are clear and actionable, providing additional context or assistance if needed.\\n\\nThese adjustments will help tailor the ToDo list to better suit the user's needs and preferences.\"}\n"
     ]
    }
   ],
   "source": [
    "# 检查 instructions 是否已更新\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# 查询持久化存储\n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa7Nvz_5HmNi",
    "outputId": "d5ab44fc-ab1b-44a8-e6da-982c7dfa08fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我需要修理门锁。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_hzoAfwZbiWeYiQEAIw6TCQ49)\n",
      " Call ID: call_hzoAfwZbiWeYiQEAIw6TCQ49\n",
      "  Args:\n",
      "    update_type: todo\n",
      "  UpdateMemory (call_yI63RVlcAKFF7vzo2bbhS7mx)\n",
      " Call ID: call_yI63RVlcAKFF7vzo2bbhS7mx\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "已创建新的 ToDo：\n",
      "内容：{'task': '修理门锁', 'time_to_complete': 60}\n",
      "\n",
      "文档 15226e46-3ae0-448f-8567-7fa56a15a9d6 已更新：\n",
      "计划：N/A\n",
      "新增/替换内容：杭州本地的五金店或锁匠\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': '', 'localized_message': '', 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m input_messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33m我需要修理门锁。\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 运行图（Graph）\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mtask_assistant\u001b[39m\u001b[34m(state, config, store)\u001b[39m\n\u001b[32m    180\u001b[39m system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# --- 调用模型生成回复和工具调用 ---\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# 调用聊天模型。\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# invoke(...) 传入系统消息和当前的对话历史 (state[\"messages\"])。\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# 模型会根据这些信息生成回复，如果判断需要更新记忆，则会包含 UpdateMemory 的工具调用。\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mUpdateMemory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_msg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m+\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# 返回模型的回复。这个回复会包含模型的文本回复以及可能存在的工具调用信息。\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/runnables/base.py:5495\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5488\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5490\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5493\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5494\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5498\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:393\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> BaseMessage:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    403\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1019\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m     **kwargs: Any,\n\u001b[32m   1017\u001b[39m ) -> LLMResult:\n\u001b[32m   1018\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:837\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    843\u001b[39m         )\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1085\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1183\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1182\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1185\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1186\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1188\u001b[39m ):\n\u001b[32m   1189\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1178\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1172\u001b[39m             response,\n\u001b[32m   1173\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1174\u001b[39m             metadata=generation_info,\n\u001b[32m   1175\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1176\u001b[39m         )\n\u001b[32m   1177\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1179\u001b[39m         response = raw_response.parse()\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': '', 'localized_message': '', 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
      "During task with name 'task_assistant' and id 'fe2fc318-3d46-6ac0-5535-91b78204200d'"
     ]
    }
   ],
   "source": [
    "# 用户输入：添加一个新的 ToDo 任务\n",
    "input_messages = [HumanMessage(content=\"我需要修理门锁。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvIT_lu6HmNi",
    "outputId": "0987d754-b183-4811-bfb7-ef81d194bd81"
   },
   "outputs": [],
   "source": [
    "# 查询用户的 ToDo 记忆集合\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# 遍历输出\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtEdyioSHmNi",
    "outputId": "4917ced5-1dee-45b0-8941-55e5660da85b"
   },
   "outputs": [],
   "source": [
    "# 用户输入：更新已有 ToDo 的截止时间\n",
    "input_messages = [HumanMessage(content=\"我需要在11月底之前完成学会游泳。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VREkQm-HmNi"
   },
   "source": [
    "我们可以看到，Trustcall 对已有记忆执行了“补丁式”更新（patch）：\n",
    "\n",
    "`https://smith.langchain.com/public/4ad3a8af-3b1e-493d-b163-3111aa3d575a/r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9B6khJXHmNi",
    "outputId": "dbb9457a-39ae-4338-fbae-86bc126c5c88"
   },
   "outputs": [],
   "source": [
    "# 用户输入：再添加一个新的 ToDo 任务\n",
    "input_messages = [HumanMessage(content=\"需要在晚上9点前发送会议总结。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhH21elZHmNj",
    "outputId": "cba5f715-986f-4aca-f9c2-68e126ee6cc4"
   },
   "outputs": [],
   "source": [
    "# 查询用户最新的 ToDo 记忆集合\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# 遍历输出\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAQVGLyHmNj"
   },
   "source": [
    "现在我们创建一个新的对话线程（thread）。\n",
    "\n",
    "这会开启一个新的会话。\n",
    "\n",
    "此前保存在长期存储中的 Profile、ToDos 与 Instructions 会被自动加载并用于个性化回复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-kMwYFYHmNj",
    "outputId": "b52ce01b-1a27-4a97-b066-3e0d394134d8"
   },
   "outputs": [],
   "source": [
    "# 提供线程 ID（短期、会话级记忆）\n",
    "# 提供用户 ID（长期、跨会话记忆）\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# 与聊天机器人对话\n",
    "input_messages = [HumanMessage(content=\"我有30分钟，我能完成哪些任务？\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko1cdB29HmNj",
    "outputId": "430d29ae-936b-49b1-9d8f-32fe2cf00b80"
   },
   "outputs": [],
   "source": [
    "# 与聊天机器人对话\n",
    "input_messages = [HumanMessage(content=\"是的，给我一些报名游泳课程的选项。\")]\n",
    "\n",
    "# 运行图（Graph）\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修复 task_assistant 函数中的消息处理问题\n",
    "# 重新定义 task_assistant 函数，添加消息验证\n",
    "\n",
    "def task_assistant_fixed(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    修复版的 task_assistant 节点：这是智能体接收用户消息并进行初步处理的地方。\n",
    "    主要修复了消息验证问题，避免向 OpenAI API 发送格式不正确的消息。\n",
    "    \"\"\"\n",
    "\n",
    "    # 从配置中获取当前用户的唯一 ID。这个 ID 用于区分不同用户的长期记忆。\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # --- 加载长期记忆 ---\n",
    "\n",
    "    # 1. 读取用户画像（profile）记忆\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # 2. 读取 ToDo 列表记忆\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # 3. 读取用户偏好/操作准则（instructions）记忆\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "\n",
    "    # --- 构建系统提示 ---\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # --- 消息验证和清理 ---\n",
    "    validated_messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        # 检查消息是否有有效的content\n",
    "        if hasattr(msg, 'content') and msg.content is not None:\n",
    "            content_str = str(msg.content).strip()\n",
    "            if content_str:  # content不为空\n",
    "                validated_messages.append(msg)\n",
    "        elif hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            # 保留有工具调用的消息，即使content为空\n",
    "            validated_messages.append(msg)\n",
    "        # 跳过内容为空或无效的消息\n",
    "\n",
    "    # 确保至少有一条有效消息\n",
    "    if not validated_messages:\n",
    "        validated_messages = [HumanMessage(content=\"Hello\")]\n",
    "\n",
    "    # --- 调用模型生成回复和工具调用 ---\n",
    "    try:\n",
    "        response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke(\n",
    "            [SystemMessage(content=system_msg)] + validated_messages\n",
    "        )\n",
    "        return {\"messages\": [response]}\n",
    "    except Exception as e:\n",
    "        print(f\"模型调用出错: {e}\")\n",
    "        print(f\"系统消息长度: {len(system_msg)}\")\n",
    "        print(f\"消息数量: {len(validated_messages)}\")\n",
    "        print(f\"消息内容: {[msg.content if hasattr(msg, 'content') else str(msg) for msg in validated_messages[:3]]}\")\n",
    "        # 返回一个错误消息\n",
    "        from langchain_core.messages import AIMessage\n",
    "        return {\"messages\": [AIMessage(content=\"抱歉，处理您的请求时出现了问题。请稍后再试。\")]}\n",
    "\n",
    "# 更新图定义以使用修复版的函数\n",
    "builder_fixed = StateGraph(MessagesState)\n",
    "\n",
    "# 使用修复版的 task_assistant 函数\n",
    "builder_fixed.add_node(\"task_assistant\", task_assistant_fixed)\n",
    "builder_fixed.add_node(\"update_todos\", update_todos)\n",
    "builder_fixed.add_node(\"update_profile\", update_profile) \n",
    "builder_fixed.add_node(\"update_instructions\", update_instructions)\n",
    "\n",
    "# 定义边的连接\n",
    "builder_fixed.add_edge(START, \"task_assistant\")\n",
    "builder_fixed.add_conditional_edges(\"task_assistant\", route_message)\n",
    "builder_fixed.add_edge(\"update_todos\", \"task_assistant\")\n",
    "builder_fixed.add_edge(\"update_profile\", \"task_assistant\")\n",
    "builder_fixed.add_edge(\"update_instructions\", \"task_assistant\")\n",
    "\n",
    "# 编译修复版的图\n",
    "graph_fixed = builder_fixed.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "print(\"✅ 修复版图已创建完成！现在可以使用 graph_fixed 来避免 BadRequestError\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx5e9Gv_HmNj"
   },
   "source": [
    "追踪（Trace）：\n",
    "\n",
    "`https://smith.langchain.com/o/7bfa9385-4ac5-468a-a06c-ffd7dbac42ec/projects/p/27f0e396-e7ab-4eac-9501-8df28b729149?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=aa03e9ad-84b7-4c38-98ae-0e87d60690dc&peeked_trace=aa03e9ad-84b7-4c38-98ae-0e87d60690dc`\n",
    "![](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509181621557.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试修复版的图，验证是否解决了 BadRequestError\n",
    "# 使用相同的配置和输入消息\n",
    "\n",
    "# 提供线程 ID（短期、会话级记忆）\n",
    "# 提供用户 ID（长期、跨会话记忆）\n",
    "config = {\"configurable\": {\"thread_id\": \"test_fixed\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# 用户输入：测试修复版\n",
    "input_messages = [HumanMessage(content=\"我需要修理门锁。\")]\n",
    "\n",
    "print(\"🔧 测试修复版图...\")\n",
    "try:\n",
    "    # 运行修复版图（Graph）\n",
    "    for chunk in graph_fixed.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "    print(\"✅ 修复版图运行成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 修复版图仍有问题: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 BadRequestError 问题解决方案\n",
    "\n",
    "### 问题分析\n",
    "\n",
    "您遇到的 `BadRequestError: Error code: 400` 错误是由于向 OpenAI API 发送了格式不正确的 `messages` 参数导致的。\n",
    "\n",
    "**常见原因：**\n",
    "1. **空内容消息**：消息对象的 `content` 字段为 `None`、空字符串或只包含空白字符\n",
    "2. **格式不正确的消息**：消息对象缺少必要的字段或格式错误\n",
    "3. **消息过长**：消息内容超过模型的 token 限制\n",
    "4. **编码问题**：消息内容包含特殊字符或编码问题\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "我们在修复版的 `task_assistant_fixed` 函数中添加了以下改进：\n",
    "\n",
    "1. **消息验证**：检查每个消息是否有有效的 content\n",
    "2. **消息清理**：过滤掉空内容或无效的消息\n",
    "3. **保留重要消息**：保留包含工具调用的消息，即使 content 为空\n",
    "4. **默认消息**：如果没有有效消息，提供一个默认的 \"Hello\" 消息\n",
    "5. **错误处理**：使用 try-catch 包装模型调用，提供详细的错误信息\n",
    "\n",
    "### 使用方法\n",
    "\n",
    "现在您可以使用 `graph_fixed` 替代原来的 `graph` 来避免这个错误：\n",
    "\n",
    "```python\n",
    "# 使用修复版图\n",
    "for chunk in graph_fixed.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "```\n",
    "\n",
    "### 验证修复\n",
    "\n",
    "运行上面的测试单元格来验证修复是否成功。如果仍有问题，错误信息会提供更详细的诊断信息。\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
