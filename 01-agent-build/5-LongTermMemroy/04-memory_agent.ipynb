{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(flyai_agent_in_action)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(flyai_agent_in_action)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU ä¿¡æ¯     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 2015.36 GB (Available: 1667.73 GB)                                    |\n",
      "| GPU ä¿¡æ¯     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA ä¿¡æ¯    | 12.6                                                                  |\n",
      "| Python ç‰ˆæœ¬  | 3.12.11                                                               |\n",
      "| Conda ç‰ˆæœ¬   | conda 25.7.0                                                          |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 2014.78 GB, Used: 652.13 GB, Free: 1260.23 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/langchain-academy/blob/fly101/module-5/memory_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjeyB8-ZHmNS"
   },
   "source": [
    "# è®°å¿†å‹æ™ºèƒ½ä½“ï¼ˆMemory Agentï¼‰\n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬å·²ç»æ„å»ºè¿‡ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥å°†è¯­ä¹‰å‹è®°å¿†ä¿å­˜åˆ°å•ä¸€çš„[ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)æˆ–[é›†åˆï¼ˆcollectionï¼‰](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)ä¸­ã€‚\n",
    "\n",
    "æˆ‘ä»¬è¿˜å¼•å…¥äº† [Trustcall](https://github.com/hinthornw/trustcall)ï¼Œç”¨äºå¯¹ä¸Šè¿°ä»»ä¸€æ¨¡å¼ï¼ˆschemaï¼‰è¿›è¡Œç»“æ„åŒ–æ›´æ–°ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†æŠŠå·²å­¦çš„ç»„ä»¶ç»„åˆèµ·æ¥ï¼Œæ„å»ºä¸€ä¸ªå…·å¤‡é•¿æœŸè®°å¿†èƒ½åŠ›çš„[æ™ºèƒ½ä½“ï¼ˆagentï¼‰](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)ã€‚\n",
    "\n",
    "æœ¬æ¬¡æˆ‘ä»¬åˆ›å»ºçš„æ™ºèƒ½ä½“ `task_assistant` å°†å¸®åŠ©æˆ‘ä»¬ç®¡ç†ä¸€ä¸ªå¾…åŠæ¸…å•ï¼ˆToDo listï¼‰ã€‚\n",
    "\n",
    "æ­¤å‰çš„èŠå¤©æœºå™¨äººä¼šåœ¨æ¯è½®å¯¹è¯åéƒ½è¿›è¡Œåæ€å¹¶ä¿å­˜è®°å¿†ã€‚\n",
    "\n",
    "è€Œ `task_assistant` ä¼šè‡ªä¸»å†³å®šâ€œä½•æ—¶â€ä¿å­˜è®°å¿†ï¼ˆå³æ˜¯å¦æŠŠå†…å®¹åŠ å…¥å¾…åŠï¼‰ã€‚\n",
    "\n",
    "æ­¤å‰çš„èŠå¤©æœºå™¨äººåªä¼šä¿å­˜ä¸€ç§ç±»å‹çš„è®°å¿†ï¼ˆprofile æˆ– collectionï¼‰ã€‚\n",
    "\n",
    "**`task_assistant` å¯ä»¥å†³å®šå°†ä¿¡æ¯ä¿å­˜åˆ°ç”¨æˆ·ç”»åƒï¼Œæˆ–ä¿å­˜ä¸ºå¾…åŠæ¸…å•ä¸­çš„ä»»åŠ¡é›†åˆã€‚**\n",
    "\n",
    "é™¤äº†è¯­ä¹‰è®°å¿†ï¼Œ`task_assistant` **è¿˜ä¼šç®¡ç†â€œè¿‡ç¨‹æ€§è®°å¿†â€ï¼ˆprocedural memoryï¼‰ã€‚**\n",
    "\n",
    "è¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥æ›´æ–°â€œå¦‚ä½•åˆ›å»ºå¾…åŠé¡¹â€çš„åå¥½ä¸åŸåˆ™ï¼ˆä¾‹å¦‚æ˜¯å¦åå¥½åŒ…å«æœ¬åœ°å•†å®¶ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ahcf1O6nHmNY"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install -U langchain_openai langgraph trustcall langchain_core\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7 trustcall==0.0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-DLZXCDHmNa",
    "outputId": "d5d56589-542d-43f0-ee61-1b0e8b7de2e1"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # æ£€æŸ¥è¯¥ç¯å¢ƒå˜é‡æ˜¯å¦å·²åœ¨æ“ä½œç³»ç»Ÿç¯å¢ƒä¸­è®¾ç½®\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # å¦‚æœªè®¾ç½®ï¼Œåˆ™æç¤ºç”¨æˆ·è¾“å…¥\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # å°†ç¯å¢ƒå˜é‡è®¾ç½®åˆ°å½“å‰è¿›ç¨‹\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"FlyAIBox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyTqFsu1HmNb",
    "outputId": "9404c71d-39f8-4152-ccb1-8c5e220d5808"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®OpenAI APIå¯†é’¥\n",
    "# æ‚¨éœ€è¦ä» https://api.apiyi.com/v1 è·å–APIå¯†é’¥\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1D0-qcGHmNb"
   },
   "source": [
    "## è§‚å¯Ÿ Trustcall çš„æ›´æ–°ç»†èŠ‚\n",
    "\n",
    "Trustcall ä¼šåˆ›å»ºå’Œæ›´æ–° JSON æ¨¡å¼ï¼ˆschemaï¼‰ã€‚\n",
    "\n",
    "å¦‚æœæˆ‘ä»¬æƒ³äº†è§£ Trustcall å…·ä½“åšäº†å“ªäº›â€œç»“æ„åŒ–å˜æ›´â€ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "ä¾‹å¦‚ï¼ŒTrustcall è‡ªå¸¦äº†ä¸€äº›å·¥å…·å¯ä»¥ï¼š\n",
    "\n",
    "- è‡ªåŠ¨çº æ­£æ ¡éªŒå¤±è´¥çš„ç»“æœï¼ˆself-correctï¼‰â€”â€”å‚è§ç¤ºä¾‹è¿½è¸ªï¼š[é“¾æ¥](https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r/9684db76-2003-443b-9aa2-9a9dbc5498b7)\n",
    "- æ›´æ–°å·²æœ‰æ–‡æ¡£ï¼ˆpatch/æ›´æ–°ï¼‰â€”â€”å‚è§ç¤ºä¾‹è¿½è¸ªï¼š[é“¾æ¥](https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r/760f90e1-a5dc-48f1-8c34-79d6a3414ac3)\n",
    "\n",
    "å¯¹è¿™äº›å·¥å…·è¡Œä¸ºä¿æŒå¯è§æ€§ï¼Œæœ‰åŠ©äºæˆ‘ä»¬åç»­æ„å»ºçš„æ™ºèƒ½ä½“è¿›è¡Œè°ƒè¯•ä¸è§£é‡Šã€‚\n",
    "\n",
    "ä¸‹é¢å°†å±•ç¤ºå¦‚ä½•å®ç°ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I93w9r-VHmNb"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"è®°å¿†çš„ä¸»è¦å†…å®¹ã€‚ä¾‹å¦‚ï¼šç”¨æˆ·è¡¨è¾¾äº†æƒ³è¦å­¦ä¹ æ³•è¯­çš„å…´è¶£ã€‚\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"å…³äºç”¨æˆ·çš„ä¸€ç»„è®°å¿†æ¡ç›®ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5F3FKAmHmNc"
   },
   "source": [
    "æˆ‘ä»¬å¯ä»¥ç»™ Trustcall çš„æŠ½å–å™¨æ·»åŠ ä¸€ä¸ª[ç›‘å¬å™¨ï¼ˆlistenerï¼‰](https://python.langchain.com/docs/how_to/lcel_cheatsheet/#add-lifecycle-listeners)ã€‚\n",
    "\n",
    "è¿™æ ·ä¼šå°†æŠ½å–å™¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿è¡Œè®°å½•ï¼ˆrunsï¼‰ä¼ é€’ç»™æˆ‘ä»¬è‡ªå®šä¹‰çš„ `Spy` ç±»ã€‚\n",
    "\n",
    "`Spy` ä¼šæå– Trustcall å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·ã€å¯¹åº”çš„è°ƒç”¨ ID ä¸å‚æ•°ï¼Œä¾¿äºå®¡è®¡ä¸è°ƒè¯•ã€‚\n",
    "\n",
    "---\n",
    "`Spy` å¸®æˆ‘ä»¬è®°å½•ä¸‹äº† Trustcall è°ƒç”¨çš„å·¥å…·ä¿¡æ¯ï¼Œä½†è¿™åªæ˜¯åŸå§‹æ•°æ®ã€‚ä¸ºäº†æ›´ç›´è§‚åœ°çœ‹åˆ° Trustcall åˆ°åº•åšäº†å“ªäº›â€œç»“æ„åŒ–å˜æ›´â€ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™äº›åŸå§‹ä¿¡æ¯è¿›è¡Œå¤„ç†ã€‚\n",
    "\n",
    "`extract_tool_info` å‡½æ•°å°±æ˜¯ç”¨æ¥åšè¿™ä»¶äº‹çš„ã€‚å®ƒå°±åƒä¸€ä¸ªâ€œç¿»è¯‘å®˜â€ï¼ŒæŠŠ `Spy` è®°å½•çš„å·¥å…·è°ƒç”¨â€œç¿»è¯‘â€æˆæˆ‘ä»¬èƒ½ç†è§£çš„â€œå˜æ›´æ‘˜è¦â€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HsPJbMt1HmNc"
   },
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# æ£€æŸ¥ Trustcall å®é™…è§¦å‘çš„å·¥å…·è°ƒç”¨\n",
    "# è¿™ä¸ª Spy ç±»å°±åƒä¸€ä¸ªâ€œé—´è°â€ï¼Œç”¨æ¥ç›‘å¬å’Œè®°å½• Trustcall åœ¨æŠ½å–è¿‡ç¨‹ä¸­å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·ã€‚\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        # è¿™ä¸ªåˆ—è¡¨ç”¨æ¥å­˜æ”¾æ•è·åˆ°çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "        self.called_tools = []\n",
    "\n",
    "    # è¿™ä¸ªæ–¹æ³•æ˜¯ç›‘å¬å™¨å®é™…æ‰§è¡Œçš„åŠŸèƒ½ã€‚\n",
    "    # å½“ Trustcall å†…éƒ¨å‘ç”Ÿä¸€ä¸ªâ€œè¿è¡Œâ€ï¼ˆrunï¼‰æ—¶ï¼Œæ¯”å¦‚è°ƒç”¨æ¨¡å‹æˆ–å·¥å…·ï¼Œè¿™ä¸ªæ–¹æ³•å°±ä¼šè¢«è°ƒç”¨ã€‚\n",
    "    # 'run' å‚æ•°åŒ…å«äº†è¿™æ¬¡è¿è¡Œçš„è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "    def __call__(self, run):\n",
    "        # è¿™é‡Œæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªé˜Ÿåˆ—æ¥éå†å½“å‰è¿è¡ŒåŠå…¶æ‰€æœ‰çš„å­è¿è¡Œï¼ˆchild_runsï¼‰ã€‚\n",
    "        # è¿™æ˜¯å› ä¸º Trustcall çš„å†…éƒ¨æ‰§è¡Œå¯èƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„æµç¨‹ï¼ŒåŒ…å«å¤šä¸ªåµŒå¥—çš„è¿è¡Œã€‚\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            # å¦‚æœå½“å‰è¿è¡Œæœ‰å­è¿è¡Œï¼Œå°±æŠŠå®ƒä»¬æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­ï¼Œä»¥ä¾¿åç»­æ£€æŸ¥ã€‚\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            # æˆ‘ä»¬ä¸»è¦å…³æ³¨ç±»å‹ä¸ºâ€œchat_modelâ€çš„è¿è¡Œï¼Œè¿™è¡¨ç¤ºèŠå¤©æ¨¡å‹è¢«è°ƒç”¨äº†ã€‚\n",
    "            # æ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶ï¼Œå¯èƒ½ä¼šå†³å®šè°ƒç”¨å·¥å…·ã€‚\n",
    "            if r.run_type == \"chat_model\":\n",
    "                # ä»æ¨¡å‹çš„è¾“å‡ºä¸­æå–å‡ºå·¥å…·è°ƒç”¨çš„ä¿¡æ¯ã€‚\n",
    "                # è¿™äº›ä¿¡æ¯é€šå¸¸åœ¨æ¨¡å‹çš„ç”Ÿæˆç»“æœçš„ç‰¹å®šä½ç½®ã€‚\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# åˆå§‹åŒ–ç›‘å¬å™¨ï¼ˆSpyï¼‰å®ä¾‹\n",
    "spy = Spy()\n",
    "\n",
    "# åˆå§‹åŒ–èŠå¤©æ¨¡å‹ã€‚Trustcall ä¼šä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥æ‰§è¡ŒæŠ½å–å’Œå¯èƒ½çš„å·¥å…·è°ƒç”¨ã€‚\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# åˆ›å»º Trustcall æŠ½å–å™¨ã€‚\n",
    "# è¿™ä¸ªæŠ½å–å™¨é…ç½®ä¸ºä½¿ç”¨æˆ‘ä»¬å®šä¹‰çš„ Memory schema ä½œä¸ºå·¥å…·ã€‚\n",
    "# tool_choice=\"Memory\" è¡¨ç¤ºæ¨¡å‹åº”è¯¥å°è¯•è°ƒç”¨ Memory å·¥å…·æ¥ç»“æ„åŒ–ä¿¡æ¯ã€‚\n",
    "# enable_inserts=True å…è®¸ Trustcall åœ¨éœ€è¦æ—¶æ’å…¥æ–°çš„ Memory æ–‡æ¡£ã€‚\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# å°† Spy ç›‘å¬å™¨æ·»åŠ åˆ° Trustcall æŠ½å–å™¨ä¸Šã€‚\n",
    "# on_end=spy è¡¨ç¤ºåœ¨æŠ½å–è¿‡ç¨‹ç»“æŸæ—¶ï¼Œè°ƒç”¨ Spy å®ä¾‹ï¼ˆå³æ‰§è¡Œ __call__ æ–¹æ³•ï¼‰ï¼Œä»è€Œæ•è·å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "28VrIpmtHmNd"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instructionï¼ˆæŠ½å–ä»»åŠ¡è¯´æ˜ï¼‰\n",
    "instruction = \"\"\"ä»ä»¥ä¸‹å¯¹è¯ä¸­æŠ½å–è®°å¿†ï¼ˆMemoriesï¼‰ï¼š\"\"\"\n",
    "\n",
    "# æ¨¡æ‹Ÿå¯¹è¯å†…å®¹\n",
    "conversation = [\n",
    "    HumanMessage(content=\"ä½ å¥½ï¼Œæˆ‘æ˜¯ FLY\"),\n",
    "    AIMessage(content=\"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ŒFLY\"),\n",
    "    HumanMessage(content=\"ä»Šå¤©æ—©ä¸Šæˆ‘åœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦\")\n",
    "]\n",
    "\n",
    "# Invoke the extractorï¼ˆè°ƒç”¨æŠ½å–å™¨ï¼‰\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ATEyqPPHmNd",
    "outputId": "66822edd-0da6-4fbd-8460-664205377f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_B07NoQ1S0P1JlRqu7ZqHCt0p)\n",
      " Call ID: call_B07NoQ1S0P1JlRqu7ZqHCt0p\n",
      "  Args:\n",
      "    content: FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¶ˆæ¯ä¸­åŒ…å«äº†å·¥å…·è°ƒç”¨ï¼ˆtool callsï¼‰\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqXEqnVSHmNe",
    "outputId": "80dd4f24-273d-409e-e6bd-2ee920a0790a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚'\n"
     ]
    }
   ],
   "source": [
    "# responsesï¼ˆè§£æåçš„ç»“æœï¼‰åŒ…å«ç¬¦åˆ schema çš„è®°å¿†\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ch0pzGoQHmNe",
    "outputId": "0b8827fc-10cf-4db4-d7d4-401f2a31aeda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_B07NoQ1S0P1JlRqu7ZqHCt0p'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadataï¼ˆå…ƒä¿¡æ¯ï¼‰åŒ…å«å·¥å…·è°ƒç”¨çš„ ID ç­‰ä¿¡æ¯\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk3bh_AVHmNe",
    "outputId": "efcbf712-2828-4cde-c3d2-4be82c242444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ¨¡æ‹Ÿå¯¹è¯çš„å»¶ç»­ï¼Œç”¨äºæ¼”ç¤ºè®°å¿†æ›´æ–°\n",
    "updated_conversation = [\n",
    "    AIMessage(content=\"å¤ªæ£’äº†ï¼Œä¹‹åä½ åšäº†ä»€ä¹ˆï¼Ÿ\"),\n",
    "    HumanMessage(content=\"æˆ‘å»äº†å’–å•¡åº—å–äº†å’–å•¡\"),\n",
    "    AIMessage(content=\"ä½ è¿˜æƒ³è¯´ä»€ä¹ˆï¼Ÿ\"),\n",
    "    HumanMessage(content=\"æˆ‘åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œæƒ³ä»Šå¹´å†¬å¤©å†å»\"),\n",
    "]\n",
    "# Update the instructionï¼ˆç³»ç»Ÿæç¤ºï¼šåŸºäºæ–°å¯¹è¯è¿›è¡Œæ›´æ–°ï¼‰\n",
    "system_msg = \"\"\"æ ¹æ®ä¸‹é¢çš„å¯¹è¯ï¼Œæ›´æ–°å·²æœ‰è®°å¿†å¹¶åˆ›å»ºæ–°çš„è®°å¿†ï¼š\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and valueï¼ˆæŠŠå·²æœ‰è®°å¿†ä¿å­˜ä¸º (id, å·¥å…·å, å€¼) çš„ä¸‰å…ƒç»„ï¼‰\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bb7-xTjHHmNe"
   },
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
    "                             \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncSPyiAsHmNf",
    "outputId": "34c32b0a-b364-434e-d994-9cf8be2cbc85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_wTVv9Qo0zLvRE2GiVFIlhT7h'}\n",
      "{'id': 'call_Tm8yjCNSpDKqBOYPiyqw6goJ'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadataï¼ˆå…ƒä¿¡æ¯ï¼‰åŒ…å«å·¥å…·è°ƒç”¨çš„ ID ç­‰ä¿¡æ¯\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAbu8DoZHmNf",
    "outputId": "26aa6ca7-8d4e-4815-c1bc-f3e057c84285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_wTVv9Qo0zLvRE2GiVFIlhT7h)\n",
      " Call ID: call_wTVv9Qo0zLvRE2GiVFIlhT7h\n",
      "  Args:\n",
      "    content: å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚\n",
      "  Memory (call_Tm8yjCNSpDKqBOYPiyqw6goJ)\n",
      " Call ID: call_Tm8yjCNSpDKqBOYPiyqw6goJ\n",
      "  Args:\n",
      "    content: æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å»ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¶ˆæ¯ä¸­åŒ…å«äº†å·¥å…·è°ƒç”¨ï¼ˆtool callsï¼‰\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lZYsstbHmNf",
    "outputId": "38d15a46-ccf6-4c83-9d71-c4d868d18816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚'\n",
      "content='æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å»ã€‚'\n"
     ]
    }
   ],
   "source": [
    "# è§£æåçš„ responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItTojpcUHmNf",
    "outputId": "104244f3-4f4d-45b1-fdf3-b85dbbf46125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'Memory',\n",
       "   'args': {'content': 'å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚'},\n",
       "   'id': 'call_wTVv9Qo0zLvRE2GiVFIlhT7h',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å»ã€‚'},\n",
       "   'id': 'call_Tm8yjCNSpDKqBOYPiyqw6goJ',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Trustcall åœ¨è¿™ä¸€æ­¥å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust version of extract_tool_info to avoid KeyError on optional fields\n",
    "\n",
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"ä»å·¥å…·è°ƒç”¨åºåˆ—ä¸­æŠ½å–ç»“æ„åŒ–â€œå˜æ›´æ‘˜è¦â€ã€‚åŒæ—¶æ”¯æŒè¡¥ä¸æ›´æ–°ä¸æ–°å¢ã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        tool_calls: æ¨¡å‹äº§ç”Ÿçš„å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆå«å¹¶è¡Œæ‰¹æ¬¡ï¼‰\n",
    "        schema_name: ç›®æ ‡ schema åç§°ï¼ˆå¦‚ \"Memory\"ã€\"ToDo\"ã€\"Profile\"ï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    changes = []\n",
    "\n",
    "    # tool_calls æ˜¯ä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨ï¼Œå› ä¸ºæ¨¡å‹å¯èƒ½å¹¶è¡Œè°ƒç”¨å¤šä¸ªå·¥å…·\n",
    "    for call_group in tool_calls or []:\n",
    "        if not isinstance(call_group, (list, tuple)):\n",
    "            continue\n",
    "        for call in call_group:\n",
    "            if not isinstance(call, dict):\n",
    "                continue\n",
    "            name = call.get(\"name\")\n",
    "            args = call.get(\"args\", {}) if isinstance(call.get(\"args\", {}), dict) else {}\n",
    "\n",
    "            # æ›´æ–°å·²æœ‰æ–‡æ¡£ï¼ˆPatchDocï¼‰\n",
    "            if name == \"PatchDoc\":\n",
    "                doc_id = args.get(\"json_doc_id\") or args.get(\"doc_id\") or \"N/A\"\n",
    "                planned_edits = args.get(\"planned_edits\", \"N/A\")\n",
    "\n",
    "                # å®‰å…¨è·å–è¡¥ä¸å†…å®¹\n",
    "                value = None\n",
    "                patches = args.get(\"patches\") or []\n",
    "                if isinstance(patches, list) and patches:\n",
    "                    first_patch = patches[0]\n",
    "                    if isinstance(first_patch, dict):\n",
    "                        value = (\n",
    "                            first_patch.get(\"value\")\n",
    "                            or first_patch.get(\"data\")\n",
    "                            or first_patch\n",
    "                        )\n",
    "                    else:\n",
    "                        value = first_patch\n",
    "\n",
    "                changes.append({\n",
    "                    \"type\": \"update\",\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"planned_edits\": planned_edits,\n",
    "                    \"value\": value if value is not None else args,\n",
    "                })\n",
    "\n",
    "            # æ–°å¢æ–‡æ¡£ï¼ˆä¸ schema åç§°ä¸€è‡´ï¼‰\n",
    "            elif name == schema_name:\n",
    "                changes.append({\n",
    "                    \"type\": \"new\",\n",
    "                    \"value\": args if args else call.get(\"args\", {}),\n",
    "                })\n",
    "\n",
    "    # æ ¼å¼åŒ–è¾“å‡º\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change.get(\"type\") == \"update\":\n",
    "            result_parts.append(\n",
    "                (\n",
    "                    f\"æ–‡æ¡£ {change.get('doc_id', 'N/A')} å·²æ›´æ–°ï¼š\\n\"\n",
    "                    f\"è®¡åˆ’ï¼š{change.get('planned_edits', 'N/A')}\\n\"\n",
    "                    f\"æ–°å¢/æ›¿æ¢å†…å®¹ï¼š{change.get('value')}\"\n",
    "                )\n",
    "            )\n",
    "        elif change.get(\"type\") == \"new\":\n",
    "            result_parts.append(\n",
    "                f\"å·²åˆ›å»ºæ–°çš„ {schema_name}ï¼š\\n\"\n",
    "                f\"å†…å®¹ï¼š{change.get('value')}\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\\n\".join(result_parts) if result_parts else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2AFKS0tHmNg"
   },
   "source": [
    "## åˆ›å»ºä¸€ä¸ªæ™ºèƒ½ä½“\n",
    "\n",
    "å¯é€‰çš„[æ™ºèƒ½ä½“ï¼ˆagentï¼‰](https://langchain-ai.github.io/langgraph/concepts/high_level/)æ¶æ„æœ‰å¾ˆå¤šã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸ªç›¸å¯¹ç®€å•çš„ [ReAct](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation) æ™ºèƒ½ä½“ã€‚\n",
    "\n",
    "å®ƒå°†ä½œä¸ºåˆ›å»ºä¸ç®¡ç† ToDo æ¸…å•çš„è¾…åŠ©æ­æ¡£ã€‚\n",
    "\n",
    "è¯¥æ™ºèƒ½ä½“å¯ä»¥è‡ªä¸»å†³å®šæ›´æ–°ä¸‰ç±»é•¿æœŸè®°å¿†ï¼š\n",
    "\n",
    "(a) åˆ›å»º/æ›´æ–°ç”¨æˆ· `profile`ï¼ˆç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼‰\n",
    "\n",
    "(b) åœ¨ ToDo åˆ—è¡¨ `collection` ä¸­æ–°å¢/æ›´æ–°ä»»åŠ¡\n",
    "\n",
    "(c) æ›´æ–°å®ƒè‡ªå·±ç”¨äºç»´æŠ¤ ToDo åˆ—è¡¨çš„ `instructions`ï¼ˆæ“ä½œå‡†åˆ™ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xQh4str6HmNg"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYXkmebzHmNg"
   },
   "source": [
    "## å›¾å®šä¹‰ï¼ˆGraph definitionï¼‰\n",
    "\n",
    "æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªç®€å•çš„è·¯ç”±å™¨ `route_message`ï¼Œå®ƒä¼šåšä¸€ä¸ªäºŒå…ƒå†³ç­–ï¼šæ˜¯å¦éœ€è¦ä¿å­˜è®°å¿†ï¼Œä»¥åŠä¿å­˜åˆ°å“ªä¸€ç±»é•¿æœŸè®°å¿†ä¸­ã€‚\n",
    "\n",
    "è®°å¿†é›†åˆï¼ˆToDoã€Profile ç­‰ï¼‰çš„ç»“æ„åŒ–æ›´æ–°ç”± `Trustcall` è´Ÿè´£ï¼Œä¸å‰é¢çš„ç¤ºä¾‹ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "nv6UFSaKHmNg",
    "outputId": "f1ea9074-1295-4521-d37f-15b6e9c11cb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the modelï¼ˆåˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼‰\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"å½“å‰èŠå¤©ç”¨æˆ·çš„ç”»åƒï¼ˆåŸºæœ¬ä¿¡æ¯ï¼‰\"\"\"\n",
    "    name: Optional[str] = Field(description=\"ç”¨æˆ·å§“å\", default=None)\n",
    "    location: Optional[str] = Field(description=\"ç”¨æˆ·æ‰€åœ¨åŸå¸‚/åœ°åŒº\", default=None)\n",
    "    job: Optional[str] = Field(description=\"ç”¨æˆ·çš„èŒä¸š\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"ä¸ç”¨æˆ·ç›¸å…³çš„ä¸ªäººå…³ç³»ï¼Œå¦‚å®¶äººã€æœ‹å‹æˆ–åŒäº‹\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"ç”¨æˆ·çš„å…´è¶£çˆ±å¥½\",\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"è¦å®Œæˆçš„ä»»åŠ¡\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"é¢„è®¡å®Œæˆæ‰€éœ€æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"ä»»åŠ¡çš„æˆªæ­¢æ—¶é—´ï¼ˆå¦‚é€‚ç”¨ï¼‰\",\n",
    "        default=None\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"å¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆæ¸…å•ï¼ˆä¾‹å¦‚ï¼šå…·ä½“æƒ³æ³•ã€æœåŠ¡å•†ã€å¯è½åœ°çš„æ“ä½œé€‰é¡¹ç­‰ï¼‰\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"ä»»åŠ¡å½“å‰çŠ¶æ€\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profileï¼ˆç”¨äºæ›´æ–°ç”¨æˆ·ç”»åƒçš„ Trustcall æŠ½å–å™¨ï¼‰\n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"ä½ æ˜¯ä¸€åä¹äºåŠ©äººçš„èŠå¤©æœºå™¨äººã€‚\n",
    "\n",
    "ä½ çš„èŒè´£æ˜¯ä½œä¸ºç”¨æˆ·çš„æ—¥å¸¸åŠ©æ‰‹ï¼Œå¸®åŠ©ä»–ä»¬ç»´æŠ¤ ToDo å¾…åŠæ¸…å•ã€‚\n",
    "\n",
    "ä½ æ‹¥æœ‰ä¸€ä»½é•¿æœŸè®°å¿†ï¼Œè®°å½•ä¸‰ç±»ä¿¡æ¯ï¼š\n",
    "1. ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰ï¼šå…³äºç”¨æˆ·çš„ä¸€èˆ¬æ€§ä¿¡æ¯\n",
    "2. ToDo åˆ—è¡¨ï¼šä¸ç”¨æˆ·ä»»åŠ¡ç›¸å…³çš„äº‹é¡¹\n",
    "3. ç»´æŠ¤ ToDo åˆ—è¡¨çš„æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å½“å‰çš„ç”¨æˆ·ç”»åƒï¼ˆå¦‚æœå°šæœªæ”¶é›†ä¿¡æ¯ï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å½“å‰çš„ ToDo åˆ—è¡¨ï¼ˆå¦‚æœå°šæœªæ·»åŠ ä»»åŠ¡ï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ç”¨æˆ·ç›®å‰æŒ‡å®šçš„ ToDo ç»´æŠ¤åå¥½ï¼ˆå¦‚æœå°šæœªæŒ‡å®šï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "ä½ çš„æ¨ç†ä¸è¡ŒåŠ¨è§„èŒƒå¦‚ä¸‹ï¼š\n",
    "\n",
    "1. è®¤çœŸç†è§£ä¸‹æ–¹çš„ç”¨æˆ·æ¶ˆæ¯ä¸ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°é•¿æœŸè®°å¿†ä¸­çš„ä»»ä¸€éƒ¨åˆ†ï¼š\n",
    "- å¦‚æœç”¨æˆ·æä¾›äº†ä¸ªäººä¿¡æ¯ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `user`ï¼Œç”¨äºæ›´æ–°ç”¨æˆ·ç”»åƒ\n",
    "- å¦‚æœç”¨æˆ·æåˆ°ä»»åŠ¡ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `todo`ï¼Œç”¨äºæ›´æ–° ToDo åˆ—è¡¨\n",
    "- å¦‚æœç”¨æˆ·ç»™å‡ºäº†å¦‚ä½•ç»´æŠ¤ ToDo çš„åå¥½/åŸåˆ™ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `instructions`ï¼Œç”¨äºæ›´æ–°æ“ä½œå‡†åˆ™\n",
    "\n",
    "3. åœ¨åˆé€‚çš„æƒ…å†µä¸‹å‘ç”¨æˆ·åé¦ˆâ€œè®°å¿†å·²æ›´æ–°â€ï¼š\n",
    "- ä¸è¦å‘ŠçŸ¥ç”¨æˆ·ä½ æ›´æ–°äº†ç”¨æˆ·ç”»åƒ\n",
    "- å½“ä½ æ›´æ–°äº† ToDo åˆ—è¡¨æ—¶ï¼Œåº”å½“æ˜ç¡®å‘ŠçŸ¥\n",
    "- ä¸è¦å‘ŠçŸ¥ç”¨æˆ·ä½ æ›´æ–°äº†æ“ä½œå‡†åˆ™\n",
    "\n",
    "4. åœ¨æ˜¯å¦æ›´æ–° ToDo åˆ—è¡¨çš„é—®é¢˜ä¸Šï¼Œå®å¯â€œå¤šæ›´æ–°â€ä¹Ÿæ— éœ€äº‹å…ˆå¾æ±‚è®¸å¯ã€‚\n",
    "\n",
    "5. æ— è®ºæ˜¯å¦è¿›è¡Œäº†å·¥å…·è°ƒç”¨ï¼Œéƒ½è¦è‡ªç„¶åœ°ç»§ç»­ä¸ç”¨æˆ·å¯¹è¯ã€‚\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"è¯·è®¤çœŸå›é¡¾ä»¥ä¸‹äº¤äº’å†…å®¹ã€‚\n",
    "\n",
    "ä½¿ç”¨æä¾›çš„å·¥å…·ï¼Œä¿ç•™ä¸ç”¨æˆ·ç›¸å…³çš„å¿…è¦è®°å¿†ã€‚\n",
    "\n",
    "å¦‚æœéœ€è¦åŒæ—¶è¿›è¡Œâ€œæ›´æ–°å·²æœ‰æ–‡æ¡£â€å’Œâ€œæ–°å¢æ–‡æ¡£â€ï¼Œè¯·ä½¿ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ä»¥æå‡æ•ˆç‡ã€‚\n",
    "\n",
    "ç³»ç»Ÿæ—¶é—´ï¼š{time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"è¯·å›é¡¾ä»¥ä¸‹äº¤äº’å†…å®¹ã€‚\n",
    "\n",
    "åŸºäºè¿™æ¬¡äº¤äº’ï¼Œæ›´æ–°ä½ â€œå¦‚ä½•ç»´æŠ¤ ToDo åˆ—è¡¨æ¡ç›®â€çš„æ“ä½œå‡†åˆ™ã€‚\n",
    "\n",
    "åˆ©ç”¨ç”¨æˆ·åé¦ˆï¼Œè°ƒæ•´æ·»åŠ /æ›´æ–°æ¡ç›®çš„æ–¹å¼ï¼ˆä¾‹å¦‚æ˜¯å¦åå¥½åŒ…å«æœ¬åœ°å•†å®¶ç­‰ï¼‰ã€‚\n",
    "\n",
    "ä½ å½“å‰çš„å‡†åˆ™å¦‚ä¸‹ï¼š\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_assistant(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    task_assistant èŠ‚ç‚¹ï¼šè¿™æ˜¯æ™ºèƒ½ä½“æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å¹¶è¿›è¡Œåˆæ­¥å¤„ç†çš„åœ°æ–¹ã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. ä»é•¿æœŸå­˜å‚¨ä¸­åŠ è½½ç”¨æˆ·çš„ä¸ªæ€§åŒ–è®°å¿†ï¼ˆç”¨æˆ·ç”»åƒã€ToDo åˆ—è¡¨ã€æ“ä½œå‡†åˆ™ï¼‰ã€‚\n",
    "    2. å°†è¿™äº›è®°å¿†æ•´åˆåˆ°ç³»ç»Ÿæç¤ºä¸­ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹çš„å›å¤ã€‚\n",
    "    3. è°ƒç”¨æ¨¡å‹ï¼Œè®©æ¨¡å‹æ ¹æ®ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»Ÿæç¤ºå†³å®šæ˜¯å¦éœ€è¦æ›´æ–°é•¿æœŸè®°å¿†ï¼ˆé€šè¿‡è°ƒç”¨ UpdateMemory å·¥å…·ï¼‰å¹¶ç”Ÿæˆå›å¤ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # --- åŠ è½½é•¿æœŸè®°å¿† ---\n",
    "\n",
    "    # 1. è¯»å–ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰è®°å¿†\n",
    "    # æ„å»ºå‘½åç©ºé—´ (namespace)ã€‚å‘½åç©ºé—´æ˜¯ Trustcall Store ä¸­ç”¨äºç»„ç»‡å’Œéš”ç¦»æ•°æ®çš„æ–¹å¼ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"profile\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ç”¨æˆ·ç”»åƒæ•°æ®ã€‚\n",
    "    namespace = (\"profile\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰è®°å¿†ã€‚ç”¨æˆ·ç”»åƒé€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æ¡£ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å¦‚æœæ‰¾åˆ°äº†è®°å¿†ï¼Œæå–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰è®°å¿†çš„å€¼ã€‚\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¯´æ˜è¿˜æ²¡æœ‰ç”¨æˆ·ç”»åƒè®°å¿†ï¼Œè®¾ç½®ä¸º Noneã€‚\n",
    "        user_profile = None\n",
    "\n",
    "    # 2. è¯»å– ToDo åˆ—è¡¨è®°å¿†\n",
    "    # æ„å»º ToDo åˆ—è¡¨çš„å‘½åç©ºé—´ã€‚\n",
    "    namespace = (\"todo\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰ ToDo è®°å¿†ã€‚ToDo åˆ—è¡¨å¯èƒ½åŒ…å«å¤šä¸ªä»»åŠ¡ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å°†æ‰€æœ‰ ToDo è®°å¿†çš„å€¼ï¼ˆæ¯ä¸ªä»»åŠ¡çš„æè¿°ï¼‰ç”¨æ¢è¡Œç¬¦è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # 3. è¯»å–ç”¨æˆ·åå¥½/æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰è®°å¿†\n",
    "    # æ„å»ºæ“ä½œå‡†åˆ™çš„å‘½åç©ºé—´ã€‚\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰æ“ä½œå‡†åˆ™è®°å¿†ã€‚æ“ä½œå‡†åˆ™é€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æ¡£ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å¦‚æœæ‰¾åˆ°äº†è®°å¿†ï¼Œæå–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰è®°å¿†çš„å€¼ã€‚\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¯´æ˜è¿˜æ²¡æœ‰æ“ä½œå‡†åˆ™è®°å¿†ï¼Œè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ã€‚\n",
    "        instructions = \"\"\n",
    "\n",
    "    # --- æ„å»ºç³»ç»Ÿæç¤º ---\n",
    "\n",
    "    # ä½¿ç”¨åŠ è½½çš„è®°å¿†ä¿¡æ¯æ ¼å¼åŒ–ä¸»ç³»ç»Ÿæç¤º (MODEL_SYSTEM_MESSAGE)ã€‚\n",
    "    # è¿™ä¼šå°†ç”¨æˆ·çš„ profile, todo åˆ—è¡¨å’Œ instructions åµŒå…¥åˆ°æç¤ºä¸­ï¼Œ\n",
    "    # è®©æ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶èƒ½å¤Ÿå‚è€ƒè¿™äº›ä¸ªæ€§åŒ–ä¿¡æ¯ã€‚\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # --- è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤å’Œå·¥å…·è°ƒç”¨ ---\n",
    "\n",
    "    # è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚\n",
    "    # bind_tools([UpdateMemory], parallel_tool_calls=False) è¡¨ç¤ºæ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶ï¼Œ\n",
    "    # å¯ä»¥é€‰æ‹©è°ƒç”¨ UpdateMemory å·¥å…·ï¼Œå¹¶ä¸”æ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…· (parallel_tool_calls=False)ã€‚\n",
    "    # invoke(...) ä¼ å…¥ç³»ç»Ÿæ¶ˆæ¯å’Œå½“å‰çš„å¯¹è¯å†å² (state[\"messages\"])ã€‚\n",
    "    # æ¨¡å‹ä¼šæ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆå›å¤ï¼Œå¦‚æœåˆ¤æ–­éœ€è¦æ›´æ–°è®°å¿†ï¼Œåˆ™ä¼šåŒ…å« UpdateMemory çš„å·¥å…·è°ƒç”¨ã€‚\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    # è¿”å›æ¨¡å‹çš„å›å¤ã€‚è¿™ä¸ªå›å¤ä¼šåŒ…å«æ¨¡å‹çš„æ–‡æœ¬å›å¤ä»¥åŠå¯èƒ½å­˜åœ¨çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_profile èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'user' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ä¸ç”¨æˆ·ç”»åƒç›¸å…³çš„ä¿¡æ¯ã€‚\n",
    "    2. ä½¿ç”¨ Trustcall æŠ½å–å™¨æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„ç”¨æˆ·ç”»åƒè®°å¿†ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # å®šä¹‰è®°å¿†çš„å‘½åç©ºé—´ã€‚Trustcall Store ä½¿ç”¨å‘½åç©ºé—´æ¥ç»„ç»‡å’Œéš”ç¦»ä¸åŒç±»å‹æˆ–ä¸åŒç”¨æˆ·çš„è®°å¿†ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"profile\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ç”¨æˆ·ç”»åƒæ•°æ®ã€‚\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # ä»å­˜å‚¨ä¸­æ£€ç´¢å½“å‰ç”¨æˆ·å·²æœ‰çš„ç”¨æˆ·ç”»åƒè®°å¿†ï¼Œä½œä¸º Trustcall æŠ½å–å™¨è¿›è¡Œæ›´æ–°çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "    # å¦‚æœä¹‹å‰æ²¡æœ‰ç”¨æˆ·ç”»åƒï¼Œè¿™é‡Œå°†è¿”å›ç©ºåˆ—è¡¨ã€‚\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # å°†ç°æœ‰çš„è®°å¿†æ ¼å¼åŒ–ä¸º Trustcall æŠ½å–å™¨æ‰€éœ€çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "    # Trustcall åœ¨è¿›è¡Œæ›´æ–°æ—¶ï¼Œéœ€è¦çŸ¥é“ç°æœ‰æ–‡æ¡£çš„ IDã€ç±»å‹ï¼ˆschema åç§°ï¼‰å’Œå€¼ã€‚\n",
    "    tool_name = \"Profile\" # æŒ‡å®šè¦æ›´æ–°çš„ schema åç§°ä¸º \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # å¦‚æœ existing_items ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œåˆ—è¡¨æ¨å¯¼\n",
    "                          else None # å¦åˆ™è®¾ç½®ä¸º None\n",
    "                        )\n",
    "\n",
    "    # åˆå¹¶ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å²ã€‚Trustcall æŠ½å–å™¨éœ€è¦å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡æ¥æå–ä¿¡æ¯ã€‚\n",
    "    # TRUSTCALL_INSTRUCTION æ˜¯ä¸€ä¸ªåŒ…å«é€šç”¨æŠ½å–æŒ‡ä»¤çš„å­—ç¬¦ä¸²æ¨¡æ¿ã€‚\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # æ ¼å¼åŒ–æŒ‡ä»¤ï¼ŒåŠ å…¥å½“å‰æ—¶é—´\n",
    "    # merge_message_runs ç”¨äºåˆå¹¶æ¶ˆæ¯åˆ—è¡¨ã€‚è¿™é‡Œå°†ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å² (é™¤äº†æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯) åˆå¹¶ã€‚\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # è°ƒç”¨ Trustcall æŠ½å–å™¨ã€‚\n",
    "    # Trustcall ä¼šæ ¹æ®æä¾›çš„æ¶ˆæ¯å’Œç°æœ‰è®°å¿†ï¼Œå†³å®šæ˜¯æ–°å¢ç”¨æˆ·ç”»åƒè¿˜æ˜¯æ›´æ–°ç°æœ‰çš„ã€‚\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages,\n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # å°† Trustcall æŠ½å–å‡ºçš„æ–°è®°å¿†æˆ–æ›´æ–°åçš„è®°å¿†ä¿å­˜åˆ°é•¿æœŸå­˜å‚¨ (store) ä¸­ã€‚\n",
    "    # result[\"responses\"] åŒ…å«æŠ½å–å‡ºçš„ç¬¦åˆ Profile schema çš„ Pydantic å¯¹è±¡ã€‚\n",
    "    # result[\"response_metadata\"] åŒ…å«æŠ½å–å‡ºçš„å¯¹è±¡çš„å…ƒä¿¡æ¯ï¼Œå¦‚ json_doc_idï¼ˆå¦‚æœ Trustcall å†³å®šæ›´æ–°ç°æœ‰æ–‡æ¡£ï¼‰ã€‚\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put æ–¹æ³•ç”¨äºå°†æ•°æ®å­˜å…¥å­˜å‚¨ã€‚\n",
    "        # namespace: æŒ‡å®šå­˜å‚¨çš„å‘½åç©ºé—´ã€‚\n",
    "        # key: å­˜å‚¨é¡¹çš„é”®ã€‚å¦‚æœ Trustcall è¿”å›äº† json_doc_idï¼Œè¯´æ˜æ˜¯æ›´æ–°ï¼Œä½¿ç”¨è¯¥ ID ä½œä¸ºé”®ï¼›å¦åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„ UUID ä½œä¸ºæ–°æ–‡æ¡£çš„é”®ã€‚\n",
    "        # value: è¦å­˜å‚¨çš„å€¼ã€‚è¿™é‡Œå°†æŠ½å–å‡ºçš„ Pydantic å¯¹è±¡è½¬æ¢ä¸º JSON æ ¼å¼çš„å­—å…¸ã€‚\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    # è·å– task_assistant èŠ‚ç‚¹å‘å‡ºçš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    # è¿”å›ä¸€ä¸ªå·¥å…·æ¶ˆæ¯ (ToolMessage)ï¼Œè¡¨ç¤º update_profile èŠ‚ç‚¹å·²ç»æ‰§è¡Œå®Œæ¯•ï¼Œ\n",
    "    # å¹¶å°†ç»“æœ (\"updated profile\") å‘é€å› task_assistant èŠ‚ç‚¹ã€‚\n",
    "    # \"tool_call_id\" ç”¨äºå…³è”è¿™ä¸ª ToolMessage å’Œ task_assistant å‘å‡ºçš„åŸå§‹å·¥å…·è°ƒç”¨ã€‚\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_todos èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'todo' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ä¸ ToDo ä»»åŠ¡ç›¸å…³çš„ä¿¡æ¯ã€‚\n",
    "    2. ä½¿ç”¨ Trustcall æŠ½å–å™¨æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„ ToDo åˆ—è¡¨è®°å¿†ï¼ˆæ–°å¢æˆ–æ›´æ–°ä»»åŠ¡ï¼‰ã€‚\n",
    "    3. æå– Trustcall çš„å…·ä½“å˜æ›´ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºå·¥å…·è°ƒç”¨çš„ç»“æœè¿”å›ç»™ task_assistant èŠ‚ç‚¹ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # å®šä¹‰è®°å¿†çš„å‘½åç©ºé—´ã€‚Trustcall Store ä½¿ç”¨å‘½åç©ºé—´æ¥ç»„ç»‡å’Œéš”ç¦»ä¸åŒç±»å‹æˆ–ä¸åŒç”¨æˆ·çš„è®°å¿†ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"todo\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ ToDo æ•°æ®ã€‚\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # ä»å­˜å‚¨ä¸­æ£€ç´¢å½“å‰ç”¨æˆ·å·²æœ‰çš„ ToDo è®°å¿†ï¼Œä½œä¸º Trustcall æŠ½å–å™¨è¿›è¡Œæ›´æ–°çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "    # å¦‚æœä¹‹å‰æ²¡æœ‰ ToDoï¼Œè¿™é‡Œå°†è¿”å›ç©ºåˆ—è¡¨ã€‚\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # å°†ç°æœ‰çš„è®°å¿†æ ¼å¼åŒ–ä¸º Trustcall æŠ½å–å™¨æ‰€éœ€çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "    # Trustcall åœ¨è¿›è¡Œæ›´æ–°æ—¶ï¼Œéœ€è¦çŸ¥é“ç°æœ‰æ–‡æ¡£çš„ IDã€ç±»å‹ï¼ˆschema åç§°ï¼‰å’Œå€¼ã€‚\n",
    "    tool_name = \"ToDo\" # æŒ‡å®šè¦æ›´æ–°çš„ schema åç§°ä¸º \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # å¦‚æœ existing_items ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œåˆ—è¡¨æ¨å¯¼\n",
    "                          else None # å¦åˆ™è®¾ç½®ä¸º None\n",
    "                        )\n",
    "\n",
    "    # åˆå¹¶ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å²ã€‚Trustcall æŠ½å–å™¨éœ€è¦å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡æ¥æå–ä¿¡æ¯ã€‚\n",
    "    # TRUSTCALL_INSTRUCTION æ˜¯ä¸€ä¸ªåŒ…å«é€šç”¨æŠ½å–æŒ‡ä»¤çš„å­—ç¬¦ä¸²æ¨¡æ¿ã€‚\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # æ ¼å¼åŒ–æŒ‡ä»¤ï¼ŒåŠ å…¥å½“å‰æ—¶é—´\n",
    "    # merge_message_runs ç”¨äºåˆå¹¶æ¶ˆæ¯åˆ—è¡¨ã€‚è¿™é‡Œå°†ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å² (é™¤äº†æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯) åˆå¹¶ã€‚\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcallï¼ˆåˆå§‹åŒ–ç›‘å¬å™¨ä»¥è§‚å¯Ÿ Trustcall å·¥å…·è°ƒç”¨ï¼‰\n",
    "    spy = Spy()\n",
    "\n",
    "    # Create the Trustcall extractor for updating the ToDo listï¼ˆç”¨äºæ›´æ–° ToDo çš„ Trustcall æŠ½å–å™¨ï¼‰\n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages,\n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the storeï¼ˆå°† Trustcall æŠ½å–å‡ºçš„æ–°è®°å¿†æˆ–æ›´æ–°åçš„è®°å¿†ä¿å­˜åˆ°é•¿æœŸå­˜å‚¨ (store) ä¸­ï¼‰\n",
    "    # result[\"responses\"] åŒ…å«æŠ½å–å‡ºçš„ç¬¦åˆ ToDo schema çš„ Pydantic å¯¹è±¡ã€‚\n",
    "    # result[\"response_metadata\"] åŒ…å«æŠ½å–å‡ºçš„å¯¹è±¡çš„å…ƒä¿¡æ¯ï¼Œå¦‚ json_doc_idï¼ˆå¦‚æœ Trustcall å†³å®šæ›´æ–°ç°æœ‰æ–‡æ¡£ï¼‰ã€‚\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put æ–¹æ³•ç”¨äºå°†æ•°æ®å­˜å…¥å­˜å‚¨ã€‚\n",
    "        # namespace: æŒ‡å®šå­˜å‚¨çš„å‘½åç©ºé—´ã€‚\n",
    "        # key: å­˜å‚¨é¡¹çš„é”®ã€‚å¦‚æœ Trustcall è¿”å›äº† json_doc_idï¼Œè¯´æ˜æ˜¯æ›´æ–°ï¼Œä½¿ç”¨è¯¥ ID ä½œä¸ºé”®ï¼›å¦åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„ UUID ä½œä¸ºæ–°æ–‡æ¡£çš„é”®ã€‚\n",
    "        # value: è¦å­˜å‚¨çš„å€¼ã€‚è¿™é‡Œå°†æŠ½å–å‡ºçš„ Pydantic å¯¹è±¡è½¬æ¢ä¸º JSON æ ¼å¼çš„å­—å…¸ã€‚\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "    # Respond to the tool call made in task_assistant, confirming the updateï¼ˆå“åº” task_assistant èŠ‚ç‚¹å‘å‡ºçš„å·¥å…·è°ƒç”¨ï¼Œç¡®è®¤æ›´æ–°å·²å®Œæˆï¼‰\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_assistantï¼ˆæå– Trustcall è¿›è¡Œçš„å…·ä½“å˜æ›´ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºå·¥å…·è°ƒç”¨çš„ç»“æœè¿”å›ç»™ task_assistant èŠ‚ç‚¹ï¼‰\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_instructions èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'instructions' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ç”¨æˆ·å…³äºå¦‚ä½•ç»´æŠ¤ ToDo åˆ—è¡¨çš„åå¥½/åŸåˆ™ã€‚\n",
    "    2. è°ƒç”¨æ¨¡å‹æ ¹æ®è¿™äº›åå¥½æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„æ“ä½œå‡†åˆ™è®°å¿†ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store\n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "\n",
    "# Conditional edgeï¼ˆæ¡ä»¶è¾¹ï¼šæ ¹æ®æ¨¡å‹çš„å·¥å…·è°ƒç”¨ç»“æœè·¯ç”±ï¼‰\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "    \"\"\"\n",
    "    route_message å‡½æ•°ï¼šè¿™æ˜¯å›¾ä¸­çš„æ¡ä»¶è¾¹ï¼Œè´Ÿè´£æ ¹æ® task_assistant èŠ‚ç‚¹çš„è¾“å‡ºï¼ˆç‰¹åˆ«æ˜¯æ¨¡å‹æ˜¯å¦è°ƒç”¨äº† UpdateMemory å·¥å…·åŠå…¶å‚æ•°ï¼‰æ¥å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. æ£€æŸ¥ task_assistant è¿”å›çš„æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ã€‚\n",
    "    2. å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ¨¡å‹è®¤ä¸ºä¸éœ€è¦æ›´æ–°è®°å¿†ï¼Œå¯¹è¯ç»“æŸ (END)ã€‚\n",
    "    3. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥ UpdateMemory å·¥å…·çš„ update_type å‚æ•°ï¼Œå¹¶è·¯ç”±åˆ°ç›¸åº”çš„æ›´æ–°èŠ‚ç‚¹ï¼ˆupdate_profile, update_todos, æˆ– update_instructionsï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨\n",
    "    if len(message.tool_calls) ==0:\n",
    "        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯\n",
    "        return END\n",
    "    else:\n",
    "        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè·å–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼ˆæˆ‘ä»¬é™åˆ¶äº† parallel_tool_calls=Falseï¼Œæ‰€ä»¥åªä¼šæœ‰ä¸€ä¸ªï¼‰\n",
    "        tool_call = message.tool_calls[0]\n",
    "        # æ ¹æ®å·¥å…·è°ƒç”¨çš„å‚æ•° 'update_type' æ¥å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–°ç”¨æˆ·ç”»åƒï¼Œè·¯ç”±åˆ° update_profile èŠ‚ç‚¹\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–° ToDo åˆ—è¡¨ï¼Œè·¯ç”±åˆ° update_todos èŠ‚ç‚¹\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–°æ“ä½œå‡†åˆ™ï¼Œè·¯ç”±åˆ° update_instructions èŠ‚ç‚¹\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            # å¦‚æœ update_type æ˜¯æœªçŸ¥ç±»å‹ï¼ŒæŠ›å‡ºé”™è¯¯\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "# æ·»åŠ å„ä¸ªèŠ‚ç‚¹åˆ°å›¾ä¸­\n",
    "builder.add_node(\"task_assistant\", task_assistant) # æ·»åŠ  task_assistant èŠ‚ç‚¹\n",
    "builder.add_node(\"update_todos\", update_todos)     # æ·»åŠ  update_todos èŠ‚ç‚¹\n",
    "builder.add_node(\"update_profile\", update_profile) # æ·»åŠ  update_profile èŠ‚ç‚¹\n",
    "builder.add_node(\"update_instructions\", update_instructions) # æ·»åŠ  update_instructions èŠ‚ç‚¹\n",
    "\n",
    "# å®šä¹‰è¾¹çš„è¿æ¥\n",
    "# ä» STARTï¼ˆå›¾çš„å¼€å§‹ï¼‰è¿æ¥åˆ° task_assistant èŠ‚ç‚¹\n",
    "builder.add_edge(START, \"task_assistant\")\n",
    "# ä» task_assistant èŠ‚ç‚¹æ·»åŠ æ¡ä»¶è¾¹ï¼Œæ ¹æ® route_message å‡½æ•°çš„è¿”å›å€¼å†³å®šå»å‘\n",
    "builder.add_conditional_edges(\"task_assistant\", route_message)\n",
    "# ä»å„ä¸ªæ›´æ–°èŠ‚ç‚¹ï¼ˆupdate_todos, update_profile, update_instructionsï¼‰è¿æ¥å› task_assistant èŠ‚ç‚¹ï¼Œ\n",
    "# è¿™æ ·åœ¨æ›´æ–°å®Œæˆåï¼Œæ™ºèƒ½ä½“å¯ä»¥å›åˆ° task_assistant ç»§ç»­ä¸ç”¨æˆ·äº¤äº’ã€‚\n",
    "builder.add_edge(\"update_todos\", \"task_assistant\")\n",
    "builder.add_edge(\"update_profile\", \"task_assistant\")\n",
    "builder.add_edge(\"update_instructions\", \"task_assistant\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªå†…å­˜å­˜å‚¨ï¼Œç”¨äºé•¿æœŸï¼ˆè·¨ä¼šè¯ï¼‰è®°å¿†ã€‚\n",
    "# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œé€šå¸¸ä¼šä½¿ç”¨æ•°æ®åº“ç­‰æŒä¹…åŒ–å­˜å‚¨ã€‚\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œç”¨äºçŸ­æœŸï¼ˆä¼šè¯å†…ï¼‰è®°å¿†ã€‚\n",
    "# å®ƒä¼šä¿å­˜æ¯ä¸ªæ­¥éª¤çš„çŠ¶æ€ï¼Œä»¥ä¾¿åœ¨å‡ºç°é—®é¢˜æ—¶å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤ã€‚\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "# ç¼–è¯‘å›¾ï¼Œå°†èŠ‚ç‚¹å’Œè¾¹è¿æ¥èµ·æ¥ï¼Œå¹¶é…ç½®æ£€æŸ¥ç‚¹å’Œé•¿æœŸå­˜å‚¨ã€‚\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "# ç»˜åˆ¶å¹¶æ˜¾ç¤ºå›¾çš„å¯è§†åŒ–ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹ã€‚\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5_tsKnXHmNh",
    "outputId": "fccc6b20-42d3-4184-afc4-4f0e2d0a3fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘æ˜¯FLYã€‚æˆ‘å’Œå¦»å­ç”Ÿæ´»åœ¨ä¸­å›½æ­å·ã€‚æˆ‘æœ‰ä¸€ä¸ª3å²çš„å¥³å„¿ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_muUriNlzm9eR8tJ8cIALiEjX)\n",
      " Call ID: call_muUriNlzm9eR8tJ8cIALiEjX\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼ŒFLYï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ å’Œå®¶äººåœ¨æ­å·ç”Ÿæ´»ä¸€å®šå¾ˆç¾å¥½ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# æä¾›çº¿ç¨‹ IDï¼ˆçŸ­æœŸã€ä¼šè¯çº§è®°å¿†ï¼‰\n",
    "# æä¾›ç”¨æˆ· IDï¼ˆé•¿æœŸã€è·¨ä¼šè¯è®°å¿†ï¼‰\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# ç”¨æˆ·è¾“å…¥ï¼šç”¨äºåˆ›å»ºç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰ç›¸å…³è®°å¿†\n",
    "input_messages = [HumanMessage(content=\"æˆ‘æ˜¯FLYã€‚æˆ‘å’Œå¦»å­ç”Ÿæ´»åœ¨ä¸­å›½æ­å·ã€‚æˆ‘æœ‰ä¸€ä¸ª3å²çš„å¥³å„¿ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8Bpj-W2HmNh",
    "outputId": "f9d71314-a674-43e8-fa1a-029dc1b5a604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘çš„å¦»å­è®©æˆ‘ä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Xuw4LU3tZi6I7BzFvzLxO6Uj)\n",
      " Call ID: call_Xuw4LU3tZi6I7BzFvzLxO6Uj\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ ToDoï¼š\n",
      "å†…å®¹ï¼š{'task': 'ä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹', 'status': 'not started', 'time_to_complete': 30}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æˆ‘å·²ç»ä¸ºä½ æ·»åŠ äº†ä¸€ä¸ªä»»åŠ¡ï¼šä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚è®°å¿†å·²æ›´æ–°ã€‚ä½ éœ€è¦å¸®åŠ©æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ·»åŠ ä¸€ä¸ª ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"æˆ‘çš„å¦»å­è®©æˆ‘ä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKBO0zhSHmNh",
    "outputId": "d16f0b7f-27f3-4282-d482-9df955685b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "åœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œè¯·åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶/ä¾›åº”å•†ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_LwzYU6JMMbPNRmrqexknboEH)\n",
      " Call ID: call_LwzYU6JMMbPNRmrqexknboEH\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¥½çš„ï¼Œæˆ‘ä¼šåœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œå°½é‡åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶æˆ–ä¾›åº”å•†ã€‚è¿˜æœ‰å…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ›´æ–° ToDo åˆ›å»º/æ›´æ–°çš„æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰\n",
    "input_messages = [HumanMessage(content=\"åœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œè¯·åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶/ä¾›åº”å•†ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjysywxnHmNh",
    "outputId": "57fda351-fd80-4946-d405-17b3a96d698a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': \"Based on the conversation, here are the updated guidelines for maintaining ToDo list entries:\\n\\n1. When creating or updating ToDo list entries, include specific local businesses or suppliers if applicable.\\n2. Consider the user's location and preferences when suggesting or adding details to tasks.\\n3. Ensure tasks are clear and actionable, providing additional context or assistance if needed.\\n\\nThese adjustments will help tailor the ToDo list to better suit the user's needs and preferences.\"}\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ instructions æ˜¯å¦å·²æ›´æ–°\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# æŸ¥è¯¢æŒä¹…åŒ–å­˜å‚¨\n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa7Nvz_5HmNi",
    "outputId": "d5ab44fc-ab1b-44a8-e6da-982c7dfa08fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_hzoAfwZbiWeYiQEAIw6TCQ49)\n",
      " Call ID: call_hzoAfwZbiWeYiQEAIw6TCQ49\n",
      "  Args:\n",
      "    update_type: todo\n",
      "  UpdateMemory (call_yI63RVlcAKFF7vzo2bbhS7mx)\n",
      " Call ID: call_yI63RVlcAKFF7vzo2bbhS7mx\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ ToDoï¼š\n",
      "å†…å®¹ï¼š{'task': 'ä¿®ç†é—¨é”', 'time_to_complete': 60}\n",
      "\n",
      "æ–‡æ¡£ 15226e46-3ae0-448f-8567-7fa56a15a9d6 å·²æ›´æ–°ï¼š\n",
      "è®¡åˆ’ï¼šN/A\n",
      "æ–°å¢/æ›¿æ¢å†…å®¹ï¼šæ­å·æœ¬åœ°çš„äº”é‡‘åº—æˆ–é”åŒ \n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': '', 'localized_message': '', 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m input_messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mæˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# è¿è¡Œå›¾ï¼ˆGraphï¼‰\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mtask_assistant\u001b[39m\u001b[34m(state, config, store)\u001b[39m\n\u001b[32m    180\u001b[39m system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# --- è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤å’Œå·¥å…·è°ƒç”¨ ---\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# invoke(...) ä¼ å…¥ç³»ç»Ÿæ¶ˆæ¯å’Œå½“å‰çš„å¯¹è¯å†å² (state[\"messages\"])ã€‚\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# æ¨¡å‹ä¼šæ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆå›å¤ï¼Œå¦‚æœåˆ¤æ–­éœ€è¦æ›´æ–°è®°å¿†ï¼Œåˆ™ä¼šåŒ…å« UpdateMemory çš„å·¥å…·è°ƒç”¨ã€‚\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mUpdateMemory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_msg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m+\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# è¿”å›æ¨¡å‹çš„å›å¤ã€‚è¿™ä¸ªå›å¤ä¼šåŒ…å«æ¨¡å‹çš„æ–‡æœ¬å›å¤ä»¥åŠå¯èƒ½å­˜åœ¨çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/runnables/base.py:5495\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5488\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5490\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5493\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5494\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5498\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:393\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> BaseMessage:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    403\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1019\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m     **kwargs: Any,\n\u001b[32m   1017\u001b[39m ) -> LLMResult:\n\u001b[32m   1018\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:837\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    843\u001b[39m         )\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1085\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1183\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1182\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1185\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1186\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1187\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1188\u001b[39m ):\n\u001b[32m   1189\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1178\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1172\u001b[39m             response,\n\u001b[32m   1173\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1174\u001b[39m             metadata=generation_info,\n\u001b[32m   1175\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1176\u001b[39m         )\n\u001b[32m   1177\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1179\u001b[39m         response = raw_response.parse()\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': '', 'localized_message': '', 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
      "During task with name 'task_assistant' and id 'fe2fc318-3d46-6ac0-5535-91b78204200d'"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ·»åŠ ä¸€ä¸ªæ–°çš„ ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"æˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvIT_lu6HmNi",
    "outputId": "0987d754-b183-4811-bfb7-ef81d194bd81"
   },
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢ç”¨æˆ·çš„ ToDo è®°å¿†é›†åˆ\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# éå†è¾“å‡º\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtEdyioSHmNi",
    "outputId": "4917ced5-1dee-45b0-8941-55e5660da85b"
   },
   "outputs": [],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ›´æ–°å·²æœ‰ ToDo çš„æˆªæ­¢æ—¶é—´\n",
    "input_messages = [HumanMessage(content=\"æˆ‘éœ€è¦åœ¨11æœˆåº•ä¹‹å‰å®Œæˆå­¦ä¼šæ¸¸æ³³ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VREkQm-HmNi"
   },
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒTrustcall å¯¹å·²æœ‰è®°å¿†æ‰§è¡Œäº†â€œè¡¥ä¸å¼â€æ›´æ–°ï¼ˆpatchï¼‰ï¼š\n",
    "\n",
    "`https://smith.langchain.com/public/4ad3a8af-3b1e-493d-b163-3111aa3d575a/r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9B6khJXHmNi",
    "outputId": "dbb9457a-39ae-4338-fbae-86bc126c5c88"
   },
   "outputs": [],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šå†æ·»åŠ ä¸€ä¸ªæ–°çš„ ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"éœ€è¦åœ¨æ™šä¸Š9ç‚¹å‰å‘é€ä¼šè®®æ€»ç»“ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhH21elZHmNj",
    "outputId": "cba5f715-986f-4aca-f9c2-68e126ee6cc4"
   },
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢ç”¨æˆ·æœ€æ–°çš„ ToDo è®°å¿†é›†åˆ\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# éå†è¾“å‡º\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAQVGLyHmNj"
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è¯çº¿ç¨‹ï¼ˆthreadï¼‰ã€‚\n",
    "\n",
    "è¿™ä¼šå¼€å¯ä¸€ä¸ªæ–°çš„ä¼šè¯ã€‚\n",
    "\n",
    "æ­¤å‰ä¿å­˜åœ¨é•¿æœŸå­˜å‚¨ä¸­çš„ Profileã€ToDos ä¸ Instructions ä¼šè¢«è‡ªåŠ¨åŠ è½½å¹¶ç”¨äºä¸ªæ€§åŒ–å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-kMwYFYHmNj",
    "outputId": "b52ce01b-1a27-4a97-b066-3e0d394134d8"
   },
   "outputs": [],
   "source": [
    "# æä¾›çº¿ç¨‹ IDï¼ˆçŸ­æœŸã€ä¼šè¯çº§è®°å¿†ï¼‰\n",
    "# æä¾›ç”¨æˆ· IDï¼ˆé•¿æœŸã€è·¨ä¼šè¯è®°å¿†ï¼‰\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# ä¸èŠå¤©æœºå™¨äººå¯¹è¯\n",
    "input_messages = [HumanMessage(content=\"æˆ‘æœ‰30åˆ†é’Ÿï¼Œæˆ‘èƒ½å®Œæˆå“ªäº›ä»»åŠ¡ï¼Ÿ\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko1cdB29HmNj",
    "outputId": "430d29ae-936b-49b1-9d8f-32fe2cf00b80"
   },
   "outputs": [],
   "source": [
    "# ä¸èŠå¤©æœºå™¨äººå¯¹è¯\n",
    "input_messages = [HumanMessage(content=\"æ˜¯çš„ï¼Œç»™æˆ‘ä¸€äº›æŠ¥åæ¸¸æ³³è¯¾ç¨‹çš„é€‰é¡¹ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®å¤ task_assistant å‡½æ•°ä¸­çš„æ¶ˆæ¯å¤„ç†é—®é¢˜\n",
    "# é‡æ–°å®šä¹‰ task_assistant å‡½æ•°ï¼Œæ·»åŠ æ¶ˆæ¯éªŒè¯\n",
    "\n",
    "def task_assistant_fixed(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    ä¿®å¤ç‰ˆçš„ task_assistant èŠ‚ç‚¹ï¼šè¿™æ˜¯æ™ºèƒ½ä½“æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å¹¶è¿›è¡Œåˆæ­¥å¤„ç†çš„åœ°æ–¹ã€‚\n",
    "    ä¸»è¦ä¿®å¤äº†æ¶ˆæ¯éªŒè¯é—®é¢˜ï¼Œé¿å…å‘ OpenAI API å‘é€æ ¼å¼ä¸æ­£ç¡®çš„æ¶ˆæ¯ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # --- åŠ è½½é•¿æœŸè®°å¿† ---\n",
    "\n",
    "    # 1. è¯»å–ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰è®°å¿†\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # 2. è¯»å– ToDo åˆ—è¡¨è®°å¿†\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # 3. è¯»å–ç”¨æˆ·åå¥½/æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰è®°å¿†\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "\n",
    "    # --- æ„å»ºç³»ç»Ÿæç¤º ---\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # --- æ¶ˆæ¯éªŒè¯å’Œæ¸…ç† ---\n",
    "    validated_messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦æœ‰æœ‰æ•ˆçš„content\n",
    "        if hasattr(msg, 'content') and msg.content is not None:\n",
    "            content_str = str(msg.content).strip()\n",
    "            if content_str:  # contentä¸ä¸ºç©º\n",
    "                validated_messages.append(msg)\n",
    "        elif hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            # ä¿ç•™æœ‰å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯ï¼Œå³ä½¿contentä¸ºç©º\n",
    "            validated_messages.append(msg)\n",
    "        # è·³è¿‡å†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆçš„æ¶ˆæ¯\n",
    "\n",
    "    # ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡æœ‰æ•ˆæ¶ˆæ¯\n",
    "    if not validated_messages:\n",
    "        validated_messages = [HumanMessage(content=\"Hello\")]\n",
    "\n",
    "    # --- è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤å’Œå·¥å…·è°ƒç”¨ ---\n",
    "    try:\n",
    "        response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke(\n",
    "            [SystemMessage(content=system_msg)] + validated_messages\n",
    "        )\n",
    "        return {\"messages\": [response]}\n",
    "    except Exception as e:\n",
    "        print(f\"æ¨¡å‹è°ƒç”¨å‡ºé”™: {e}\")\n",
    "        print(f\"ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(system_msg)}\")\n",
    "        print(f\"æ¶ˆæ¯æ•°é‡: {len(validated_messages)}\")\n",
    "        print(f\"æ¶ˆæ¯å†…å®¹: {[msg.content if hasattr(msg, 'content') else str(msg) for msg in validated_messages[:3]]}\")\n",
    "        # è¿”å›ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯\n",
    "        from langchain_core.messages import AIMessage\n",
    "        return {\"messages\": [AIMessage(content=\"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚\")]}\n",
    "\n",
    "# æ›´æ–°å›¾å®šä¹‰ä»¥ä½¿ç”¨ä¿®å¤ç‰ˆçš„å‡½æ•°\n",
    "builder_fixed = StateGraph(MessagesState)\n",
    "\n",
    "# ä½¿ç”¨ä¿®å¤ç‰ˆçš„ task_assistant å‡½æ•°\n",
    "builder_fixed.add_node(\"task_assistant\", task_assistant_fixed)\n",
    "builder_fixed.add_node(\"update_todos\", update_todos)\n",
    "builder_fixed.add_node(\"update_profile\", update_profile) \n",
    "builder_fixed.add_node(\"update_instructions\", update_instructions)\n",
    "\n",
    "# å®šä¹‰è¾¹çš„è¿æ¥\n",
    "builder_fixed.add_edge(START, \"task_assistant\")\n",
    "builder_fixed.add_conditional_edges(\"task_assistant\", route_message)\n",
    "builder_fixed.add_edge(\"update_todos\", \"task_assistant\")\n",
    "builder_fixed.add_edge(\"update_profile\", \"task_assistant\")\n",
    "builder_fixed.add_edge(\"update_instructions\", \"task_assistant\")\n",
    "\n",
    "# ç¼–è¯‘ä¿®å¤ç‰ˆçš„å›¾\n",
    "graph_fixed = builder_fixed.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "print(\"âœ… ä¿®å¤ç‰ˆå›¾å·²åˆ›å»ºå®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨ graph_fixed æ¥é¿å… BadRequestError\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx5e9Gv_HmNj"
   },
   "source": [
    "è¿½è¸ªï¼ˆTraceï¼‰ï¼š\n",
    "\n",
    "`https://smith.langchain.com/o/7bfa9385-4ac5-468a-a06c-ffd7dbac42ec/projects/p/27f0e396-e7ab-4eac-9501-8df28b729149?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=aa03e9ad-84b7-4c38-98ae-0e87d60690dc&peeked_trace=aa03e9ad-84b7-4c38-98ae-0e87d60690dc`\n",
    "![](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509181621557.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¿®å¤ç‰ˆçš„å›¾ï¼ŒéªŒè¯æ˜¯å¦è§£å†³äº† BadRequestError\n",
    "# ä½¿ç”¨ç›¸åŒçš„é…ç½®å’Œè¾“å…¥æ¶ˆæ¯\n",
    "\n",
    "# æä¾›çº¿ç¨‹ IDï¼ˆçŸ­æœŸã€ä¼šè¯çº§è®°å¿†ï¼‰\n",
    "# æä¾›ç”¨æˆ· IDï¼ˆé•¿æœŸã€è·¨ä¼šè¯è®°å¿†ï¼‰\n",
    "config = {\"configurable\": {\"thread_id\": \"test_fixed\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# ç”¨æˆ·è¾“å…¥ï¼šæµ‹è¯•ä¿®å¤ç‰ˆ\n",
    "input_messages = [HumanMessage(content=\"æˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\")]\n",
    "\n",
    "print(\"ğŸ”§ æµ‹è¯•ä¿®å¤ç‰ˆå›¾...\")\n",
    "try:\n",
    "    # è¿è¡Œä¿®å¤ç‰ˆå›¾ï¼ˆGraphï¼‰\n",
    "    for chunk in graph_fixed.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "    print(\"âœ… ä¿®å¤ç‰ˆå›¾è¿è¡ŒæˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¿®å¤ç‰ˆå›¾ä»æœ‰é—®é¢˜: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ BadRequestError é—®é¢˜è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "### é—®é¢˜åˆ†æ\n",
    "\n",
    "æ‚¨é‡åˆ°çš„ `BadRequestError: Error code: 400` é”™è¯¯æ˜¯ç”±äºå‘ OpenAI API å‘é€äº†æ ¼å¼ä¸æ­£ç¡®çš„ `messages` å‚æ•°å¯¼è‡´çš„ã€‚\n",
    "\n",
    "**å¸¸è§åŸå› ï¼š**\n",
    "1. **ç©ºå†…å®¹æ¶ˆæ¯**ï¼šæ¶ˆæ¯å¯¹è±¡çš„ `content` å­—æ®µä¸º `None`ã€ç©ºå­—ç¬¦ä¸²æˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦\n",
    "2. **æ ¼å¼ä¸æ­£ç¡®çš„æ¶ˆæ¯**ï¼šæ¶ˆæ¯å¯¹è±¡ç¼ºå°‘å¿…è¦çš„å­—æ®µæˆ–æ ¼å¼é”™è¯¯\n",
    "3. **æ¶ˆæ¯è¿‡é•¿**ï¼šæ¶ˆæ¯å†…å®¹è¶…è¿‡æ¨¡å‹çš„ token é™åˆ¶\n",
    "4. **ç¼–ç é—®é¢˜**ï¼šæ¶ˆæ¯å†…å®¹åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–ç¼–ç é—®é¢˜\n",
    "\n",
    "### è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "æˆ‘ä»¬åœ¨ä¿®å¤ç‰ˆçš„ `task_assistant_fixed` å‡½æ•°ä¸­æ·»åŠ äº†ä»¥ä¸‹æ”¹è¿›ï¼š\n",
    "\n",
    "1. **æ¶ˆæ¯éªŒè¯**ï¼šæ£€æŸ¥æ¯ä¸ªæ¶ˆæ¯æ˜¯å¦æœ‰æœ‰æ•ˆçš„ content\n",
    "2. **æ¶ˆæ¯æ¸…ç†**ï¼šè¿‡æ»¤æ‰ç©ºå†…å®¹æˆ–æ— æ•ˆçš„æ¶ˆæ¯\n",
    "3. **ä¿ç•™é‡è¦æ¶ˆæ¯**ï¼šä¿ç•™åŒ…å«å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯ï¼Œå³ä½¿ content ä¸ºç©º\n",
    "4. **é»˜è®¤æ¶ˆæ¯**ï¼šå¦‚æœæ²¡æœ‰æœ‰æ•ˆæ¶ˆæ¯ï¼Œæä¾›ä¸€ä¸ªé»˜è®¤çš„ \"Hello\" æ¶ˆæ¯\n",
    "5. **é”™è¯¯å¤„ç†**ï¼šä½¿ç”¨ try-catch åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "### ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ `graph_fixed` æ›¿ä»£åŸæ¥çš„ `graph` æ¥é¿å…è¿™ä¸ªé”™è¯¯ï¼š\n",
    "\n",
    "```python\n",
    "# ä½¿ç”¨ä¿®å¤ç‰ˆå›¾\n",
    "for chunk in graph_fixed.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "```\n",
    "\n",
    "### éªŒè¯ä¿®å¤\n",
    "\n",
    "è¿è¡Œä¸Šé¢çš„æµ‹è¯•å•å…ƒæ ¼æ¥éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸã€‚å¦‚æœä»æœ‰é—®é¢˜ï¼Œé”™è¯¯ä¿¡æ¯ä¼šæä¾›æ›´è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
