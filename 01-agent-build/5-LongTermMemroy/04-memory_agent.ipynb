{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {},
   "source": [
    "# ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "## æ¦‚è¿°\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®\n",
    "\n",
    "## é…ç½®æ­¥éª¤\n",
    "1. **Condaç¯å¢ƒç®¡ç†** - æ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "2. **åŒ…ç®¡ç†å™¨ä¼˜åŒ–** - é…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "3. **æ¨¡å‹ä¸‹è½½åŠ é€Ÿ** - è®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "4. **ç³»ç»Ÿç¯å¢ƒè¯Šæ–­** - æ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æ¿€æ´»condaç¯å¢ƒ\n",
    "%%script bash\n",
    "# åˆå§‹åŒ– conda\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "conda env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/langchain-academy/blob/fly101/module-5/memory_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjeyB8-ZHmNS"
   },
   "source": [
    "# è®°å¿†å‹æ™ºèƒ½ä½“ï¼ˆMemory Agentï¼‰\n",
    "\n",
    "## å›é¡¾\n",
    "\n",
    "æˆ‘ä»¬å·²ç»æ„å»ºè¿‡ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥å°†è¯­ä¹‰å‹è®°å¿†ä¿å­˜åˆ°å•ä¸€çš„[ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)æˆ–[é›†åˆï¼ˆcollectionï¼‰](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)ä¸­ã€‚\n",
    "\n",
    "æˆ‘ä»¬è¿˜å¼•å…¥äº† [Trustcall](https://github.com/hinthornw/trustcall)ï¼Œç”¨äºå¯¹ä¸Šè¿°ä»»ä¸€æ¨¡å¼ï¼ˆschemaï¼‰è¿›è¡Œç»“æ„åŒ–æ›´æ–°ã€‚\n",
    "\n",
    "## ç›®æ ‡\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†æŠŠå·²å­¦çš„ç»„ä»¶ç»„åˆèµ·æ¥ï¼Œæ„å»ºä¸€ä¸ªå…·å¤‡é•¿æœŸè®°å¿†èƒ½åŠ›çš„[æ™ºèƒ½ä½“ï¼ˆagentï¼‰](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)ã€‚\n",
    "\n",
    "æœ¬æ¬¡æˆ‘ä»¬åˆ›å»ºçš„æ™ºèƒ½ä½“ `task_assistant` å°†å¸®åŠ©æˆ‘ä»¬ç®¡ç†ä¸€ä¸ªå¾…åŠæ¸…å•ï¼ˆToDo listï¼‰ã€‚\n",
    "\n",
    "æ­¤å‰çš„èŠå¤©æœºå™¨äººä¼šåœ¨æ¯è½®å¯¹è¯åéƒ½è¿›è¡Œåæ€å¹¶ä¿å­˜è®°å¿†ã€‚\n",
    "\n",
    "è€Œ `task_assistant` ä¼šè‡ªä¸»å†³å®šâ€œä½•æ—¶â€ä¿å­˜è®°å¿†ï¼ˆå³æ˜¯å¦æŠŠå†…å®¹åŠ å…¥å¾…åŠï¼‰ã€‚\n",
    "\n",
    "æ­¤å‰çš„èŠå¤©æœºå™¨äººåªä¼šä¿å­˜ä¸€ç§ç±»å‹çš„è®°å¿†ï¼ˆprofile æˆ– collectionï¼‰ã€‚\n",
    "\n",
    "**`task_assistant` å¯ä»¥å†³å®šå°†ä¿¡æ¯ä¿å­˜åˆ°ç”¨æˆ·ç”»åƒï¼Œæˆ–ä¿å­˜ä¸ºå¾…åŠæ¸…å•ä¸­çš„ä»»åŠ¡é›†åˆã€‚**\n",
    "\n",
    "é™¤äº†è¯­ä¹‰è®°å¿†ï¼Œ`task_assistant` **è¿˜ä¼šç®¡ç†â€œè¿‡ç¨‹æ€§è®°å¿†â€ï¼ˆprocedural memoryï¼‰ã€‚**\n",
    "\n",
    "è¿™ä½¿å¾—ç”¨æˆ·å¯ä»¥æ›´æ–°â€œå¦‚ä½•åˆ›å»ºå¾…åŠé¡¹â€çš„åå¥½ä¸åŸåˆ™ï¼ˆä¾‹å¦‚æ˜¯å¦åå¥½åŒ…å«æœ¬åœ°å•†å®¶ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ahcf1O6nHmNY"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install -U langchain_openai langgraph trustcall langchain_core\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7 trustcall==0.0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H-DLZXCDHmNa",
    "outputId": "d5d56589-542d-43f0-ee61-1b0e8b7de2e1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # æ£€æŸ¥è¯¥ç¯å¢ƒå˜é‡æ˜¯å¦å·²åœ¨æ“ä½œç³»ç»Ÿç¯å¢ƒä¸­è®¾ç½®\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # å¦‚æœªè®¾ç½®ï¼Œåˆ™æç¤ºç”¨æˆ·è¾“å…¥\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    # å°†ç¯å¢ƒå˜é‡è®¾ç½®åˆ°å½“å‰è¿›ç¨‹\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"FlyAIBox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zyTqFsu1HmNb",
    "outputId": "9404c71d-39f8-4152-ccb1-8c5e220d5808",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®OpenAI APIå¯†é’¥\n",
    "# æ‚¨éœ€è¦ä» https://api.apiyi.com/v1 è·å–APIå¯†é’¥\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# è®¾ç½® OpenAI APIä»£ç†åœ°å€ (ä¾‹å¦‚ï¼šhttps://api.apiyi.com/v1ï¼‰\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1D0-qcGHmNb"
   },
   "source": [
    "## è§‚å¯Ÿ Trustcall çš„æ›´æ–°ç»†èŠ‚\n",
    "\n",
    "Trustcall ä¼šåˆ›å»ºå’Œæ›´æ–° JSON æ¨¡å¼ï¼ˆschemaï¼‰ã€‚\n",
    "\n",
    "å¦‚æœæˆ‘ä»¬æƒ³äº†è§£ Trustcall å…·ä½“åšäº†å“ªäº›â€œç»“æ„åŒ–å˜æ›´â€ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "ä¾‹å¦‚ï¼ŒTrustcall è‡ªå¸¦äº†ä¸€äº›å·¥å…·å¯ä»¥ï¼š\n",
    "\n",
    "- è‡ªåŠ¨çº æ­£æ ¡éªŒå¤±è´¥çš„ç»“æœï¼ˆself-correctï¼‰â€”â€”å‚è§ç¤ºä¾‹è¿½è¸ªï¼š[é“¾æ¥](https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r/9684db76-2003-443b-9aa2-9a9dbc5498b7)\n",
    "- æ›´æ–°å·²æœ‰æ–‡æ¡£ï¼ˆpatch/æ›´æ–°ï¼‰â€”â€”å‚è§ç¤ºä¾‹è¿½è¸ªï¼š[é“¾æ¥](https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r/760f90e1-a5dc-48f1-8c34-79d6a3414ac3)\n",
    "\n",
    "å¯¹è¿™äº›å·¥å…·è¡Œä¸ºä¿æŒå¯è§æ€§ï¼Œæœ‰åŠ©äºæˆ‘ä»¬åç»­æ„å»ºçš„æ™ºèƒ½ä½“è¿›è¡Œè°ƒè¯•ä¸è§£é‡Šã€‚\n",
    "\n",
    "ä¸‹é¢å°†å±•ç¤ºå¦‚ä½•å®ç°ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I93w9r-VHmNb"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"è®°å¿†çš„ä¸»è¦å†…å®¹ã€‚ä¾‹å¦‚ï¼šç”¨æˆ·è¡¨è¾¾äº†æƒ³è¦å­¦ä¹ æ³•è¯­çš„å…´è¶£ã€‚\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"å…³äºç”¨æˆ·çš„ä¸€ç»„è®°å¿†æ¡ç›®ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5F3FKAmHmNc"
   },
   "source": [
    "æˆ‘ä»¬å¯ä»¥ç»™ Trustcall çš„æŠ½å–å™¨æ·»åŠ ä¸€ä¸ª[ç›‘å¬å™¨ï¼ˆlistenerï¼‰](https://python.langchain.com/docs/how_to/lcel_cheatsheet/#add-lifecycle-listeners)ã€‚\n",
    "\n",
    "è¿™æ ·ä¼šå°†æŠ½å–å™¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿è¡Œè®°å½•ï¼ˆrunsï¼‰ä¼ é€’ç»™æˆ‘ä»¬è‡ªå®šä¹‰çš„ `Spy` ç±»ã€‚\n",
    "\n",
    "`Spy` ä¼šæå– Trustcall å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·ã€å¯¹åº”çš„è°ƒç”¨ ID ä¸å‚æ•°ï¼Œä¾¿äºå®¡è®¡ä¸è°ƒè¯•ã€‚\n",
    "\n",
    "---\n",
    "`Spy` å¸®æˆ‘ä»¬è®°å½•ä¸‹äº† Trustcall è°ƒç”¨çš„å·¥å…·ä¿¡æ¯ï¼Œä½†è¿™åªæ˜¯åŸå§‹æ•°æ®ã€‚ä¸ºäº†æ›´ç›´è§‚åœ°çœ‹åˆ° Trustcall åˆ°åº•åšäº†å“ªäº›â€œç»“æ„åŒ–å˜æ›´â€ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™äº›åŸå§‹ä¿¡æ¯è¿›è¡Œå¤„ç†ã€‚\n",
    "\n",
    "`extract_tool_info` å‡½æ•°å°±æ˜¯ç”¨æ¥åšè¿™ä»¶äº‹çš„ã€‚å®ƒå°±åƒä¸€ä¸ªâ€œç¿»è¯‘å®˜â€ï¼ŒæŠŠ `Spy` è®°å½•çš„å·¥å…·è°ƒç”¨â€œç¿»è¯‘â€æˆæˆ‘ä»¬èƒ½ç†è§£çš„â€œå˜æ›´æ‘˜è¦â€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HsPJbMt1HmNc"
   },
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# æ£€æŸ¥ Trustcall å®é™…è§¦å‘çš„å·¥å…·è°ƒç”¨\n",
    "# è¿™ä¸ª Spy ç±»å°±åƒä¸€ä¸ªâ€œé—´è°â€ï¼Œç”¨æ¥ç›‘å¬å’Œè®°å½• Trustcall åœ¨æŠ½å–è¿‡ç¨‹ä¸­å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·ã€‚\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        # è¿™ä¸ªåˆ—è¡¨ç”¨æ¥å­˜æ”¾æ•è·åˆ°çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "        self.called_tools = []\n",
    "\n",
    "    # è¿™ä¸ªæ–¹æ³•æ˜¯ç›‘å¬å™¨å®é™…æ‰§è¡Œçš„åŠŸèƒ½ã€‚\n",
    "    # å½“ Trustcall å†…éƒ¨å‘ç”Ÿä¸€ä¸ªâ€œè¿è¡Œâ€ï¼ˆrunï¼‰æ—¶ï¼Œæ¯”å¦‚è°ƒç”¨æ¨¡å‹æˆ–å·¥å…·ï¼Œè¿™ä¸ªæ–¹æ³•å°±ä¼šè¢«è°ƒç”¨ã€‚\n",
    "    # 'run' å‚æ•°åŒ…å«äº†è¿™æ¬¡è¿è¡Œçš„è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "    def __call__(self, run):\n",
    "        # è¿™é‡Œæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªé˜Ÿåˆ—æ¥éå†å½“å‰è¿è¡ŒåŠå…¶æ‰€æœ‰çš„å­è¿è¡Œï¼ˆchild_runsï¼‰ã€‚\n",
    "        # è¿™æ˜¯å› ä¸º Trustcall çš„å†…éƒ¨æ‰§è¡Œå¯èƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„æµç¨‹ï¼ŒåŒ…å«å¤šä¸ªåµŒå¥—çš„è¿è¡Œã€‚\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            # å¦‚æœå½“å‰è¿è¡Œæœ‰å­è¿è¡Œï¼Œå°±æŠŠå®ƒä»¬æ·»åŠ åˆ°é˜Ÿåˆ—ä¸­ï¼Œä»¥ä¾¿åç»­æ£€æŸ¥ã€‚\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            # æˆ‘ä»¬ä¸»è¦å…³æ³¨ç±»å‹ä¸ºâ€œchat_modelâ€çš„è¿è¡Œï¼Œè¿™è¡¨ç¤ºèŠå¤©æ¨¡å‹è¢«è°ƒç”¨äº†ã€‚\n",
    "            # æ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶ï¼Œå¯èƒ½ä¼šå†³å®šè°ƒç”¨å·¥å…·ã€‚\n",
    "            if r.run_type == \"chat_model\":\n",
    "                # ä»æ¨¡å‹çš„è¾“å‡ºä¸­æå–å‡ºå·¥å…·è°ƒç”¨çš„ä¿¡æ¯ã€‚\n",
    "                # è¿™äº›ä¿¡æ¯é€šå¸¸åœ¨æ¨¡å‹çš„ç”Ÿæˆç»“æœçš„ç‰¹å®šä½ç½®ã€‚\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# åˆå§‹åŒ–ç›‘å¬å™¨ï¼ˆSpyï¼‰å®ä¾‹\n",
    "spy = Spy()\n",
    "\n",
    "# åˆå§‹åŒ–èŠå¤©æ¨¡å‹ã€‚Trustcall ä¼šä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥æ‰§è¡ŒæŠ½å–å’Œå¯èƒ½çš„å·¥å…·è°ƒç”¨ã€‚\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# åˆ›å»º Trustcall æŠ½å–å™¨ã€‚\n",
    "# è¿™ä¸ªæŠ½å–å™¨é…ç½®ä¸ºä½¿ç”¨æˆ‘ä»¬å®šä¹‰çš„ Memory schema ä½œä¸ºå·¥å…·ã€‚\n",
    "# tool_choice=\"Memory\" è¡¨ç¤ºæ¨¡å‹åº”è¯¥å°è¯•è°ƒç”¨ Memory å·¥å…·æ¥ç»“æ„åŒ–ä¿¡æ¯ã€‚\n",
    "# enable_inserts=True å…è®¸ Trustcall åœ¨éœ€è¦æ—¶æ’å…¥æ–°çš„ Memory æ–‡æ¡£ã€‚\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# å°† Spy ç›‘å¬å™¨æ·»åŠ åˆ° Trustcall æŠ½å–å™¨ä¸Šã€‚\n",
    "# on_end=spy è¡¨ç¤ºåœ¨æŠ½å–è¿‡ç¨‹ç»“æŸæ—¶ï¼Œè°ƒç”¨ Spy å®ä¾‹ï¼ˆå³æ‰§è¡Œ __call__ æ–¹æ³•ï¼‰ï¼Œä»è€Œæ•è·å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "28VrIpmtHmNd"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instructionï¼ˆæŠ½å–ä»»åŠ¡è¯´æ˜ï¼‰\n",
    "instruction = \"\"\"ä»ä»¥ä¸‹å¯¹è¯ä¸­æŠ½å–è®°å¿†ï¼ˆMemoriesï¼‰ï¼š\"\"\"\n",
    "\n",
    "# æ¨¡æ‹Ÿå¯¹è¯å†…å®¹\n",
    "conversation = [\n",
    "    HumanMessage(content=\"ä½ å¥½ï¼Œæˆ‘æ˜¯ FLY\"),\n",
    "    AIMessage(content=\"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ŒFLY\"),\n",
    "    HumanMessage(content=\"ä»Šå¤©æ—©ä¸Šæˆ‘åœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦\")\n",
    "]\n",
    "\n",
    "# Invoke the extractorï¼ˆè°ƒç”¨æŠ½å–å™¨ï¼‰\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4ATEyqPPHmNd",
    "outputId": "66822edd-0da6-4fbd-8460-664205377f98",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_WWtiSYaZW3N0pBg0jqYxkWI2)\n",
      " Call ID: call_WWtiSYaZW3N0pBg0jqYxkWI2\n",
      "  Args:\n",
      "    content: FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¶ˆæ¯ä¸­åŒ…å«äº†å·¥å…·è°ƒç”¨ï¼ˆtool callsï¼‰\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qqXEqnVSHmNe",
    "outputId": "80dd4f24-273d-409e-e6bd-2ee920a0790a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content='FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚'\n"
     ]
    }
   ],
   "source": [
    "# responsesï¼ˆè§£æåçš„ç»“æœï¼‰åŒ…å«ç¬¦åˆ schema çš„è®°å¿†\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ch0pzGoQHmNe",
    "outputId": "0b8827fc-10cf-4db4-d7d4-401f2a31aeda",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': 'call_WWtiSYaZW3N0pBg0jqYxkWI2'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadataï¼ˆå…ƒä¿¡æ¯ï¼‰åŒ…å«å·¥å…·è°ƒç”¨çš„ ID ç­‰ä¿¡æ¯\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mk3bh_AVHmNe",
    "outputId": "efcbf712-2828-4cde-c3d2-4be82c242444",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'FLY ä»Šå¤©æ—©ä¸Šåœ¨æ¹–è¾¹éª‘è‡ªè¡Œè½¦ã€‚'})]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# æ¨¡æ‹Ÿå¯¹è¯çš„å»¶ç»­ï¼Œç”¨äºæ¼”ç¤ºè®°å¿†æ›´æ–°\n",
    "updated_conversation = [\n",
    "    AIMessage(content=\"å¤ªæ£’äº†ï¼Œä¹‹åä½ åšäº†ä»€ä¹ˆï¼Ÿ\"),\n",
    "    HumanMessage(content=\"æˆ‘å»äº†å’–å•¡åº—å–äº†å’–å•¡\"),\n",
    "    AIMessage(content=\"ä½ è¿˜æƒ³è¯´ä»€ä¹ˆï¼Ÿ\"),\n",
    "    HumanMessage(content=\"æˆ‘åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œæƒ³ä»Šå¹´å†¬å¤©å†å»\"),\n",
    "]\n",
    "# Update the instructionï¼ˆç³»ç»Ÿæç¤ºï¼šåŸºäºæ–°å¯¹è¯è¿›è¡Œæ›´æ–°ï¼‰\n",
    "system_msg = \"\"\"æ ¹æ®ä¸‹é¢çš„å¯¹è¯ï¼Œæ›´æ–°å·²æœ‰è®°å¿†å¹¶åˆ›å»ºæ–°çš„è®°å¿†ï¼š\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and valueï¼ˆæŠŠå·²æœ‰è®°å¿†ä¿å­˜ä¸º (id, å·¥å…·å, å€¼) çš„ä¸‰å…ƒç»„ï¼‰\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Bb7-xTjHHmNe"
   },
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
    "                             \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ncSPyiAsHmNf",
    "outputId": "34c32b0a-b364-434e-d994-9cf8be2cbc85",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': 'call_0DHarsWzWxQidhGPrBFG59uj'}\n",
      "{'id': 'call_8C7OqDmZ5jaCmAh1P7auhqCV'}\n"
     ]
    }
   ],
   "source": [
    "# response_metadataï¼ˆå…ƒä¿¡æ¯ï¼‰åŒ…å«å·¥å…·è°ƒç”¨çš„ ID ç­‰ä¿¡æ¯\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XAbu8DoZHmNf",
    "outputId": "26aa6ca7-8d4e-4815-c1bc-f3e057c84285",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_0DHarsWzWxQidhGPrBFG59uj)\n",
      " Call ID: call_0DHarsWzWxQidhGPrBFG59uj\n",
      "  Args:\n",
      "    content: ç”¨æˆ·å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚\n",
      "  Memory (call_8C7OqDmZ5jaCmAh1P7auhqCV)\n",
      " Call ID: call_8C7OqDmZ5jaCmAh1P7auhqCV\n",
      "  Args:\n",
      "    content: ç”¨æˆ·åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å†å»ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ¶ˆæ¯ä¸­åŒ…å«äº†å·¥å…·è°ƒç”¨ï¼ˆtool callsï¼‰\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6lZYsstbHmNf",
    "outputId": "38d15a46-ccf6-4c83-9d71-c4d868d18816",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "content='ç”¨æˆ·å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚'\n",
      "content='ç”¨æˆ·åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å†å»ã€‚'\n"
     ]
    }
   ],
   "source": [
    "# è§£æåçš„ responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ItTojpcUHmNf",
    "outputId": "104244f3-4f4d-45b1-fdf3-b85dbbf46125",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[{'name': 'Memory',\n",
       "   'args': {'content': 'ç”¨æˆ·å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚'},\n",
       "   'id': 'call_0DHarsWzWxQidhGPrBFG59uj',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'ç”¨æˆ·åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å†å»ã€‚'},\n",
       "   'id': 'call_8C7OqDmZ5jaCmAh1P7auhqCV',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# æŸ¥çœ‹ Trustcall åœ¨è¿™ä¸€æ­¥å®é™…è°ƒç”¨äº†å“ªäº›å·¥å…·\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oPGObkqlHmNf",
    "outputId": "e73b4905-a5cc-484b-af1f-2b8477d1adaa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "å·²åˆ›å»ºæ–°çš„ Memoryï¼š\n",
      "å†…å®¹ï¼š{'content': 'ç”¨æˆ·å»äº†å’–å•¡åº—å–äº†å’–å•¡ã€‚'}\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ Memoryï¼š\n",
      "å†…å®¹ï¼š{'content': 'ç”¨æˆ·åœ¨æƒ³å»æ—¥æœ¬æ—…æ¸¸ï¼Œè®¡åˆ’ä»Šå¹´å†¬å¤©å†å»ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"ä»å·¥å…·è°ƒç”¨åºåˆ—ä¸­æŠ½å–ç»“æ„åŒ–â€œå˜æ›´æ‘˜è¦â€ã€‚åŒæ—¶æ”¯æŒè¡¥ä¸æ›´æ–°ä¸æ–°å¢ã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        tool_calls: æ¨¡å‹äº§ç”Ÿçš„å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆå«å¹¶è¡Œæ‰¹æ¬¡ï¼‰\n",
    "        schema_name: ç›®æ ‡ schema åç§°ï¼ˆå¦‚ \"Memory\"ã€\"ToDo\"ã€\"Profile\"ï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    # å½’å¹¶å·¥å…·è°ƒç”¨ä¸ºâ€œå˜æ›´é¡¹â€\n",
    "    changes = []\n",
    "\n",
    "    # tool_calls æ˜¯ä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨ï¼Œå› ä¸ºæ¨¡å‹å¯èƒ½å¹¶è¡Œè°ƒç”¨å¤šä¸ªå·¥å…·ã€‚\n",
    "    # æˆ‘ä»¬éœ€è¦éå†æ¯ä¸€ç»„å·¥å…·è°ƒç”¨ã€‚\n",
    "    for call_group in tool_calls:\n",
    "        # åœ¨æ¯ä¸€ç»„å·¥å…·è°ƒç”¨ä¸­ï¼Œéå†æ¯ä¸€ä¸ªå…·ä½“çš„å·¥å…·è°ƒç”¨ã€‚\n",
    "        for call in call_group:\n",
    "            # æ£€æŸ¥å·¥å…·è°ƒç”¨çš„åç§°ã€‚Trustcall åœ¨æ›´æ–°å·²æœ‰æ–‡æ¡£æ—¶ä¼šè°ƒç”¨ 'PatchDoc' å·¥å…·ã€‚\n",
    "            if call['name'] == 'PatchDoc':\n",
    "                # å¦‚æœæ˜¯ PatchDoc è°ƒç”¨ï¼Œè¯´æ˜æ˜¯æ›´æ–°æ“ä½œã€‚\n",
    "                changes.append({\n",
    "                    'type': 'update', # æ ‡è®°å˜æ›´ç±»å‹ä¸ºâ€œæ›´æ–°â€\n",
    "                    'doc_id': call['args']['json_doc_id'], # è¢«æ›´æ–°æ–‡æ¡£çš„å”¯ä¸€ ID\n",
    "                    'planned_edits': call['args']['planned_edits'], # æ¨¡å‹å¯¹è¿™æ¬¡æ›´æ–°çš„æ–‡å­—æè¿°æˆ–è®¡åˆ’\n",
    "                    'value': call['args']['patches'][0]['value'] # å®é™…æ›´æ–°çš„å†…å®¹ï¼ˆè¡¥ä¸çš„å€¼ï¼‰\n",
    "                })\n",
    "            # æ£€æŸ¥å·¥å…·è°ƒç”¨çš„åç§°æ˜¯å¦ä¸æˆ‘ä»¬å…³æ³¨çš„ schema åç§°ä¸€è‡´ï¼ˆä¾‹å¦‚ \"Memory\"ï¼‰ã€‚\n",
    "            # å¦‚æœä¸€è‡´ï¼Œé€šå¸¸è¡¨ç¤ºæ¨¡å‹è¦åˆ›å»ºä¸€ä¸ªç¬¦åˆè¯¥ schema çš„æ–°æ–‡æ¡£ã€‚\n",
    "            elif call['name'] == schema_name:\n",
    "                # å¦‚æœæ˜¯ schema å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ˜¯æ–°å¢æ“ä½œã€‚\n",
    "                changes.append({\n",
    "                    'type': 'new', # æ ‡è®°å˜æ›´ç±»å‹ä¸ºâ€œæ–°å¢â€\n",
    "                    'value': call['args'] # æ–°å¢æ–‡æ¡£çš„å…·ä½“å†…å®¹ï¼Œä»¥å­—å…¸å½¢å¼å­˜å‚¨\n",
    "                })\n",
    "\n",
    "    # å°†å‰é¢å½’å¹¶çš„å˜æ›´ä¿¡æ¯æ ¼å¼åŒ–æˆæ›´å®¹æ˜“é˜…è¯»çš„ä¸­æ–‡æ–‡æœ¬ã€‚\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change['type'] == 'update':\n",
    "            # å¦‚æœæ˜¯æ›´æ–°æ“ä½œï¼Œç”Ÿæˆä¸€æ®µæè¿°æ€§æ–‡æœ¬ï¼ŒåŒ…å«æ–‡æ¡£ IDã€è®¡åˆ’å’Œå®é™…æ›´æ–°å†…å®¹ã€‚\n",
    "            result_parts.append(\n",
    "                f\"æ–‡æ¡£ {change['doc_id']} å·²æ›´æ–°ï¼š\\n\"\n",
    "                f\"è®¡åˆ’ï¼š{change['planned_edits']}\\n\"\n",
    "                f\"æ–°å¢/æ›¿æ¢å†…å®¹ï¼š{change['value']}\"\n",
    "            )\n",
    "        else:\n",
    "            # å¦‚æœæ˜¯æ–°å¢æ“ä½œï¼Œç”Ÿæˆä¸€æ®µæè¿°æ€§æ–‡æœ¬ï¼Œè¯´æ˜åˆ›å»ºäº†æ–°çš„ schema æ–‡æ¡£åŠå…¶å†…å®¹ã€‚\n",
    "            result_parts.append(\n",
    "                f\"å·²åˆ›å»ºæ–°çš„ {schema_name}ï¼š\\n\"\n",
    "                f\"å†…å®¹ï¼š{change['value']}\"\n",
    "            )\n",
    "\n",
    "    # æœ€åï¼Œä½¿ç”¨æ¢è¡Œç¬¦å°†æ‰€æœ‰æè¿°æ–‡æœ¬è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„å˜æ›´æ‘˜è¦å­—ç¬¦ä¸²ã€‚\n",
    "    return \"\\n\\n\".join(result_parts)\n",
    "\n",
    "# æŸ¥çœ‹æŠ½å–é˜¶æ®µçš„å®é™…å˜æ›´æ‘˜è¦\n",
    "schema_name = \"Memory\"\n",
    "changes = extract_tool_info(spy.called_tools, schema_name)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2AFKS0tHmNg"
   },
   "source": [
    "## åˆ›å»ºä¸€ä¸ªæ™ºèƒ½ä½“\n",
    "\n",
    "å¯é€‰çš„[æ™ºèƒ½ä½“ï¼ˆagentï¼‰](https://langchain-ai.github.io/langgraph/concepts/high_level/)æ¶æ„æœ‰å¾ˆå¤šã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸ªç›¸å¯¹ç®€å•çš„ [ReAct](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation) æ™ºèƒ½ä½“ã€‚\n",
    "\n",
    "å®ƒå°†ä½œä¸ºåˆ›å»ºä¸ç®¡ç† ToDo æ¸…å•çš„è¾…åŠ©æ­æ¡£ã€‚\n",
    "\n",
    "è¯¥æ™ºèƒ½ä½“å¯ä»¥è‡ªä¸»å†³å®šæ›´æ–°ä¸‰ç±»é•¿æœŸè®°å¿†ï¼š\n",
    "\n",
    "(a) åˆ›å»º/æ›´æ–°ç”¨æˆ· `profile`ï¼ˆç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼‰\n",
    "\n",
    "(b) åœ¨ ToDo åˆ—è¡¨ `collection` ä¸­æ–°å¢/æ›´æ–°ä»»åŠ¡\n",
    "\n",
    "(c) æ›´æ–°å®ƒè‡ªå·±ç”¨äºç»´æŠ¤ ToDo åˆ—è¡¨çš„ `instructions`ï¼ˆæ“ä½œå‡†åˆ™ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xQh4str6HmNg"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYXkmebzHmNg"
   },
   "source": [
    "## å›¾å®šä¹‰ï¼ˆGraph definitionï¼‰\n",
    "\n",
    "æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªç®€å•çš„è·¯ç”±å™¨ `route_message`ï¼Œå®ƒä¼šåšä¸€ä¸ªäºŒå…ƒå†³ç­–ï¼šæ˜¯å¦éœ€è¦ä¿å­˜è®°å¿†ï¼Œä»¥åŠä¿å­˜åˆ°å“ªä¸€ç±»é•¿æœŸè®°å¿†ä¸­ã€‚\n",
    "\n",
    "è®°å¿†é›†åˆï¼ˆToDoã€Profile ç­‰ï¼‰çš„ç»“æ„åŒ–æ›´æ–°ç”± `Trustcall` è´Ÿè´£ï¼Œä¸å‰é¢çš„ç¤ºä¾‹ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nv6UFSaKHmNg",
    "outputId": "f1ea9074-1295-4521-d37f-15b6e9c11cb3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the modelï¼ˆåˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼‰\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"å½“å‰èŠå¤©ç”¨æˆ·çš„ç”»åƒï¼ˆåŸºæœ¬ä¿¡æ¯ï¼‰\"\"\"\n",
    "    name: Optional[str] = Field(description=\"ç”¨æˆ·å§“å\", default=None)\n",
    "    location: Optional[str] = Field(description=\"ç”¨æˆ·æ‰€åœ¨åŸå¸‚/åœ°åŒº\", default=None)\n",
    "    job: Optional[str] = Field(description=\"ç”¨æˆ·çš„èŒä¸š\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"ä¸ç”¨æˆ·ç›¸å…³çš„ä¸ªäººå…³ç³»ï¼Œå¦‚å®¶äººã€æœ‹å‹æˆ–åŒäº‹\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"ç”¨æˆ·çš„å…´è¶£çˆ±å¥½\",\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"è¦å®Œæˆçš„ä»»åŠ¡\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"é¢„è®¡å®Œæˆæ‰€éœ€æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"ä»»åŠ¡çš„æˆªæ­¢æ—¶é—´ï¼ˆå¦‚é€‚ç”¨ï¼‰\",\n",
    "        default=None\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"å¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆæ¸…å•ï¼ˆä¾‹å¦‚ï¼šå…·ä½“æƒ³æ³•ã€æœåŠ¡å•†ã€å¯è½åœ°çš„æ“ä½œé€‰é¡¹ç­‰ï¼‰\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"ä»»åŠ¡å½“å‰çŠ¶æ€\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profileï¼ˆç”¨äºæ›´æ–°ç”¨æˆ·ç”»åƒçš„ Trustcall æŠ½å–å™¨ï¼‰\n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"ä½ æ˜¯ä¸€åä¹äºåŠ©äººçš„èŠå¤©æœºå™¨äººã€‚\n",
    "\n",
    "ä½ çš„èŒè´£æ˜¯ä½œä¸ºç”¨æˆ·çš„æ—¥å¸¸åŠ©æ‰‹ï¼Œå¸®åŠ©ä»–ä»¬ç»´æŠ¤ ToDo å¾…åŠæ¸…å•ã€‚\n",
    "\n",
    "ä½ æ‹¥æœ‰ä¸€ä»½é•¿æœŸè®°å¿†ï¼Œè®°å½•ä¸‰ç±»ä¿¡æ¯ï¼š\n",
    "1. ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰ï¼šå…³äºç”¨æˆ·çš„ä¸€èˆ¬æ€§ä¿¡æ¯\n",
    "2. ToDo åˆ—è¡¨ï¼šä¸ç”¨æˆ·ä»»åŠ¡ç›¸å…³çš„äº‹é¡¹\n",
    "3. ç»´æŠ¤ ToDo åˆ—è¡¨çš„æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å½“å‰çš„ç”¨æˆ·ç”»åƒï¼ˆå¦‚æœå°šæœªæ”¶é›†ä¿¡æ¯ï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å½“å‰çš„ ToDo åˆ—è¡¨ï¼ˆå¦‚æœå°šæœªæ·»åŠ ä»»åŠ¡ï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ç”¨æˆ·ç›®å‰æŒ‡å®šçš„ ToDo ç»´æŠ¤åå¥½ï¼ˆå¦‚æœå°šæœªæŒ‡å®šï¼Œå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "ä½ çš„æ¨ç†ä¸è¡ŒåŠ¨è§„èŒƒå¦‚ä¸‹ï¼š\n",
    "\n",
    "1. è®¤çœŸç†è§£ä¸‹æ–¹çš„ç”¨æˆ·æ¶ˆæ¯ä¸ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°é•¿æœŸè®°å¿†ä¸­çš„ä»»ä¸€éƒ¨åˆ†ï¼š\n",
    "- å¦‚æœç”¨æˆ·æä¾›äº†ä¸ªäººä¿¡æ¯ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `user`ï¼Œç”¨äºæ›´æ–°ç”¨æˆ·ç”»åƒ\n",
    "- å¦‚æœç”¨æˆ·æåˆ°ä»»åŠ¡ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `todo`ï¼Œç”¨äºæ›´æ–° ToDo åˆ—è¡¨\n",
    "- å¦‚æœç”¨æˆ·ç»™å‡ºäº†å¦‚ä½•ç»´æŠ¤ ToDo çš„åå¥½/åŸåˆ™ï¼Œè°ƒç”¨ UpdateMemory å·¥å…·å¹¶ä¼ å…¥ç±»å‹ `instructions`ï¼Œç”¨äºæ›´æ–°æ“ä½œå‡†åˆ™\n",
    "\n",
    "3. åœ¨åˆé€‚çš„æƒ…å†µä¸‹å‘ç”¨æˆ·åé¦ˆâ€œè®°å¿†å·²æ›´æ–°â€ï¼š\n",
    "- ä¸è¦å‘ŠçŸ¥ç”¨æˆ·ä½ æ›´æ–°äº†ç”¨æˆ·ç”»åƒ\n",
    "- å½“ä½ æ›´æ–°äº† ToDo åˆ—è¡¨æ—¶ï¼Œåº”å½“æ˜ç¡®å‘ŠçŸ¥\n",
    "- ä¸è¦å‘ŠçŸ¥ç”¨æˆ·ä½ æ›´æ–°äº†æ“ä½œå‡†åˆ™\n",
    "\n",
    "4. åœ¨æ˜¯å¦æ›´æ–° ToDo åˆ—è¡¨çš„é—®é¢˜ä¸Šï¼Œå®å¯â€œå¤šæ›´æ–°â€ä¹Ÿæ— éœ€äº‹å…ˆå¾æ±‚è®¸å¯ã€‚\n",
    "\n",
    "5. æ— è®ºæ˜¯å¦è¿›è¡Œäº†å·¥å…·è°ƒç”¨ï¼Œéƒ½è¦è‡ªç„¶åœ°ç»§ç»­ä¸ç”¨æˆ·å¯¹è¯ã€‚\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"è¯·è®¤çœŸå›é¡¾ä»¥ä¸‹äº¤äº’å†…å®¹ã€‚\n",
    "\n",
    "ä½¿ç”¨æä¾›çš„å·¥å…·ï¼Œä¿ç•™ä¸ç”¨æˆ·ç›¸å…³çš„å¿…è¦è®°å¿†ã€‚\n",
    "\n",
    "å¦‚æœéœ€è¦åŒæ—¶è¿›è¡Œâ€œæ›´æ–°å·²æœ‰æ–‡æ¡£â€å’Œâ€œæ–°å¢æ–‡æ¡£â€ï¼Œè¯·ä½¿ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ä»¥æå‡æ•ˆç‡ã€‚\n",
    "\n",
    "ç³»ç»Ÿæ—¶é—´ï¼š{time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"è¯·å›é¡¾ä»¥ä¸‹äº¤äº’å†…å®¹ã€‚\n",
    "\n",
    "åŸºäºè¿™æ¬¡äº¤äº’ï¼Œæ›´æ–°ä½ â€œå¦‚ä½•ç»´æŠ¤ ToDo åˆ—è¡¨æ¡ç›®â€çš„æ“ä½œå‡†åˆ™ã€‚\n",
    "\n",
    "åˆ©ç”¨ç”¨æˆ·åé¦ˆï¼Œè°ƒæ•´æ·»åŠ /æ›´æ–°æ¡ç›®çš„æ–¹å¼ï¼ˆä¾‹å¦‚æ˜¯å¦åå¥½åŒ…å«æœ¬åœ°å•†å®¶ç­‰ï¼‰ã€‚\n",
    "\n",
    "ä½ å½“å‰çš„å‡†åˆ™å¦‚ä¸‹ï¼š\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_assistant(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    task_assistant èŠ‚ç‚¹ï¼šè¿™æ˜¯æ™ºèƒ½ä½“æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å¹¶è¿›è¡Œåˆæ­¥å¤„ç†çš„åœ°æ–¹ã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. ä»é•¿æœŸå­˜å‚¨ä¸­åŠ è½½ç”¨æˆ·çš„ä¸ªæ€§åŒ–è®°å¿†ï¼ˆç”¨æˆ·ç”»åƒã€ToDo åˆ—è¡¨ã€æ“ä½œå‡†åˆ™ï¼‰ã€‚\n",
    "    2. å°†è¿™äº›è®°å¿†æ•´åˆåˆ°ç³»ç»Ÿæç¤ºä¸­ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹çš„å›å¤ã€‚\n",
    "    3. è°ƒç”¨æ¨¡å‹ï¼Œè®©æ¨¡å‹æ ¹æ®ç”¨æˆ·æ¶ˆæ¯å’Œç³»ç»Ÿæç¤ºå†³å®šæ˜¯å¦éœ€è¦æ›´æ–°é•¿æœŸè®°å¿†ï¼ˆé€šè¿‡è°ƒç”¨ UpdateMemory å·¥å…·ï¼‰å¹¶ç”Ÿæˆå›å¤ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # --- åŠ è½½é•¿æœŸè®°å¿† ---\n",
    "\n",
    "    # 1. è¯»å–ç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰è®°å¿†\n",
    "    # æ„å»ºå‘½åç©ºé—´ (namespace)ã€‚å‘½åç©ºé—´æ˜¯ Trustcall Store ä¸­ç”¨äºç»„ç»‡å’Œéš”ç¦»æ•°æ®çš„æ–¹å¼ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"profile\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ç”¨æˆ·ç”»åƒæ•°æ®ã€‚\n",
    "    namespace = (\"profile\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰è®°å¿†ã€‚ç”¨æˆ·ç”»åƒé€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æ¡£ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å¦‚æœæ‰¾åˆ°äº†è®°å¿†ï¼Œæå–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰è®°å¿†çš„å€¼ã€‚\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¯´æ˜è¿˜æ²¡æœ‰ç”¨æˆ·ç”»åƒè®°å¿†ï¼Œè®¾ç½®ä¸º Noneã€‚\n",
    "        user_profile = None\n",
    "\n",
    "    # 2. è¯»å– ToDo åˆ—è¡¨è®°å¿†\n",
    "    # æ„å»º ToDo åˆ—è¡¨çš„å‘½åç©ºé—´ã€‚\n",
    "    namespace = (\"todo\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰ ToDo è®°å¿†ã€‚ToDo åˆ—è¡¨å¯èƒ½åŒ…å«å¤šä¸ªä»»åŠ¡ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å°†æ‰€æœ‰ ToDo è®°å¿†çš„å€¼ï¼ˆæ¯ä¸ªä»»åŠ¡çš„æè¿°ï¼‰ç”¨æ¢è¡Œç¬¦è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # 3. è¯»å–ç”¨æˆ·åå¥½/æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰è®°å¿†\n",
    "    # æ„å»ºæ“ä½œå‡†åˆ™çš„å‘½åç©ºé—´ã€‚\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    # ä»å­˜å‚¨ä¸­æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰æ“ä½œå‡†åˆ™è®°å¿†ã€‚æ“ä½œå‡†åˆ™é€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æ¡£ã€‚\n",
    "    memories = store.search(namespace)\n",
    "    # å¦‚æœæ‰¾åˆ°äº†è®°å¿†ï¼Œæå–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰è®°å¿†çš„å€¼ã€‚\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¯´æ˜è¿˜æ²¡æœ‰æ“ä½œå‡†åˆ™è®°å¿†ï¼Œè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ã€‚\n",
    "        instructions = \"\"\n",
    "\n",
    "    # --- æ„å»ºç³»ç»Ÿæç¤º ---\n",
    "\n",
    "    # ä½¿ç”¨åŠ è½½çš„è®°å¿†ä¿¡æ¯æ ¼å¼åŒ–ä¸»ç³»ç»Ÿæç¤º (MODEL_SYSTEM_MESSAGE)ã€‚\n",
    "    # è¿™ä¼šå°†ç”¨æˆ·çš„ profile, todo åˆ—è¡¨å’Œ instructions åµŒå…¥åˆ°æç¤ºä¸­ï¼Œ\n",
    "    # è®©æ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶èƒ½å¤Ÿå‚è€ƒè¿™äº›ä¸ªæ€§åŒ–ä¿¡æ¯ã€‚\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # --- è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤å’Œå·¥å…·è°ƒç”¨ ---\n",
    "\n",
    "    # è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚\n",
    "    # bind_tools([UpdateMemory], parallel_tool_calls=False) è¡¨ç¤ºæ¨¡å‹åœ¨ç”Ÿæˆå›å¤æ—¶ï¼Œ\n",
    "    # å¯ä»¥é€‰æ‹©è°ƒç”¨ UpdateMemory å·¥å…·ï¼Œå¹¶ä¸”æ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…· (parallel_tool_calls=False)ã€‚\n",
    "    # invoke(...) ä¼ å…¥ç³»ç»Ÿæ¶ˆæ¯å’Œå½“å‰çš„å¯¹è¯å†å² (state[\"messages\"])ã€‚\n",
    "    # æ¨¡å‹ä¼šæ ¹æ®è¿™äº›ä¿¡æ¯ç”Ÿæˆå›å¤ï¼Œå¦‚æœåˆ¤æ–­éœ€è¦æ›´æ–°è®°å¿†ï¼Œåˆ™ä¼šåŒ…å« UpdateMemory çš„å·¥å…·è°ƒç”¨ã€‚\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    # è¿”å›æ¨¡å‹çš„å›å¤ã€‚è¿™ä¸ªå›å¤ä¼šåŒ…å«æ¨¡å‹çš„æ–‡æœ¬å›å¤ä»¥åŠå¯èƒ½å­˜åœ¨çš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_profile èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'user' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ä¸ç”¨æˆ·ç”»åƒç›¸å…³çš„ä¿¡æ¯ã€‚\n",
    "    2. ä½¿ç”¨ Trustcall æŠ½å–å™¨æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„ç”¨æˆ·ç”»åƒè®°å¿†ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # å®šä¹‰è®°å¿†çš„å‘½åç©ºé—´ã€‚Trustcall Store ä½¿ç”¨å‘½åç©ºé—´æ¥ç»„ç»‡å’Œéš”ç¦»ä¸åŒç±»å‹æˆ–ä¸åŒç”¨æˆ·çš„è®°å¿†ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"profile\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ç”¨æˆ·ç”»åƒæ•°æ®ã€‚\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # ä»å­˜å‚¨ä¸­æ£€ç´¢å½“å‰ç”¨æˆ·å·²æœ‰çš„ç”¨æˆ·ç”»åƒè®°å¿†ï¼Œä½œä¸º Trustcall æŠ½å–å™¨è¿›è¡Œæ›´æ–°çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "    # å¦‚æœä¹‹å‰æ²¡æœ‰ç”¨æˆ·ç”»åƒï¼Œè¿™é‡Œå°†è¿”å›ç©ºåˆ—è¡¨ã€‚\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # å°†ç°æœ‰çš„è®°å¿†æ ¼å¼åŒ–ä¸º Trustcall æŠ½å–å™¨æ‰€éœ€çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "    # Trustcall åœ¨è¿›è¡Œæ›´æ–°æ—¶ï¼Œéœ€è¦çŸ¥é“ç°æœ‰æ–‡æ¡£çš„ IDã€ç±»å‹ï¼ˆschema åç§°ï¼‰å’Œå€¼ã€‚\n",
    "    tool_name = \"Profile\" # æŒ‡å®šè¦æ›´æ–°çš„ schema åç§°ä¸º \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # å¦‚æœ existing_items ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œåˆ—è¡¨æ¨å¯¼\n",
    "                          else None # å¦åˆ™è®¾ç½®ä¸º None\n",
    "                        )\n",
    "\n",
    "    # åˆå¹¶ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å²ã€‚Trustcall æŠ½å–å™¨éœ€è¦å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡æ¥æå–ä¿¡æ¯ã€‚\n",
    "    # TRUSTCALL_INSTRUCTION æ˜¯ä¸€ä¸ªåŒ…å«é€šç”¨æŠ½å–æŒ‡ä»¤çš„å­—ç¬¦ä¸²æ¨¡æ¿ã€‚\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # æ ¼å¼åŒ–æŒ‡ä»¤ï¼ŒåŠ å…¥å½“å‰æ—¶é—´\n",
    "    # merge_message_runs ç”¨äºåˆå¹¶æ¶ˆæ¯åˆ—è¡¨ã€‚è¿™é‡Œå°†ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å² (é™¤äº†æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯) åˆå¹¶ã€‚\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # è°ƒç”¨ Trustcall æŠ½å–å™¨ã€‚\n",
    "    # Trustcall ä¼šæ ¹æ®æä¾›çš„æ¶ˆæ¯å’Œç°æœ‰è®°å¿†ï¼Œå†³å®šæ˜¯æ–°å¢ç”¨æˆ·ç”»åƒè¿˜æ˜¯æ›´æ–°ç°æœ‰çš„ã€‚\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages,\n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # å°† Trustcall æŠ½å–å‡ºçš„æ–°è®°å¿†æˆ–æ›´æ–°åçš„è®°å¿†ä¿å­˜åˆ°é•¿æœŸå­˜å‚¨ (store) ä¸­ã€‚\n",
    "    # result[\"responses\"] åŒ…å«æŠ½å–å‡ºçš„ç¬¦åˆ Profile schema çš„ Pydantic å¯¹è±¡ã€‚\n",
    "    # result[\"response_metadata\"] åŒ…å«æŠ½å–å‡ºçš„å¯¹è±¡çš„å…ƒä¿¡æ¯ï¼Œå¦‚ json_doc_idï¼ˆå¦‚æœ Trustcall å†³å®šæ›´æ–°ç°æœ‰æ–‡æ¡£ï¼‰ã€‚\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put æ–¹æ³•ç”¨äºå°†æ•°æ®å­˜å…¥å­˜å‚¨ã€‚\n",
    "        # namespace: æŒ‡å®šå­˜å‚¨çš„å‘½åç©ºé—´ã€‚\n",
    "        # key: å­˜å‚¨é¡¹çš„é”®ã€‚å¦‚æœ Trustcall è¿”å›äº† json_doc_idï¼Œè¯´æ˜æ˜¯æ›´æ–°ï¼Œä½¿ç”¨è¯¥ ID ä½œä¸ºé”®ï¼›å¦åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„ UUID ä½œä¸ºæ–°æ–‡æ¡£çš„é”®ã€‚\n",
    "        # value: è¦å­˜å‚¨çš„å€¼ã€‚è¿™é‡Œå°†æŠ½å–å‡ºçš„ Pydantic å¯¹è±¡è½¬æ¢ä¸º JSON æ ¼å¼çš„å­—å…¸ã€‚\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    # è·å– task_assistant èŠ‚ç‚¹å‘å‡ºçš„å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    # è¿”å›ä¸€ä¸ªå·¥å…·æ¶ˆæ¯ (ToolMessage)ï¼Œè¡¨ç¤º update_profile èŠ‚ç‚¹å·²ç»æ‰§è¡Œå®Œæ¯•ï¼Œ\n",
    "    # å¹¶å°†ç»“æœ (\"updated profile\") å‘é€å› task_assistant èŠ‚ç‚¹ã€‚\n",
    "    # \"tool_call_id\" ç”¨äºå…³è”è¿™ä¸ª ToolMessage å’Œ task_assistant å‘å‡ºçš„åŸå§‹å·¥å…·è°ƒç”¨ã€‚\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_todos èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'todo' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ä¸ ToDo ä»»åŠ¡ç›¸å…³çš„ä¿¡æ¯ã€‚\n",
    "    2. ä½¿ç”¨ Trustcall æŠ½å–å™¨æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„ ToDo åˆ—è¡¨è®°å¿†ï¼ˆæ–°å¢æˆ–æ›´æ–°ä»»åŠ¡ï¼‰ã€‚\n",
    "    3. æå– Trustcall çš„å…·ä½“å˜æ›´ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºå·¥å…·è°ƒç”¨çš„ç»“æœè¿”å›ç»™ task_assistant èŠ‚ç‚¹ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # ä»é…ç½®ä¸­è·å–å½“å‰ç”¨æˆ·çš„å”¯ä¸€ IDã€‚è¿™ä¸ª ID ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€‚\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # å®šä¹‰è®°å¿†çš„å‘½åç©ºé—´ã€‚Trustcall Store ä½¿ç”¨å‘½åç©ºé—´æ¥ç»„ç»‡å’Œéš”ç¦»ä¸åŒç±»å‹æˆ–ä¸åŒç”¨æˆ·çš„è®°å¿†ã€‚\n",
    "    # è¿™é‡Œä½¿ç”¨ (\"todo\", user_id) ä½œä¸ºå‘½åç©ºé—´ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹å®šç”¨æˆ· (user_id) çš„ ToDo æ•°æ®ã€‚\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # ä»å­˜å‚¨ä¸­æ£€ç´¢å½“å‰ç”¨æˆ·å·²æœ‰çš„ ToDo è®°å¿†ï¼Œä½œä¸º Trustcall æŠ½å–å™¨è¿›è¡Œæ›´æ–°çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "    # å¦‚æœä¹‹å‰æ²¡æœ‰ ToDoï¼Œè¿™é‡Œå°†è¿”å›ç©ºåˆ—è¡¨ã€‚\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # å°†ç°æœ‰çš„è®°å¿†æ ¼å¼åŒ–ä¸º Trustcall æŠ½å–å™¨æ‰€éœ€çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "    # Trustcall åœ¨è¿›è¡Œæ›´æ–°æ—¶ï¼Œéœ€è¦çŸ¥é“ç°æœ‰æ–‡æ¡£çš„ IDã€ç±»å‹ï¼ˆschema åç§°ï¼‰å’Œå€¼ã€‚\n",
    "    tool_name = \"ToDo\" # æŒ‡å®šè¦æ›´æ–°çš„ schema åç§°ä¸º \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items # å¦‚æœ existing_items ä¸ä¸ºç©ºï¼Œåˆ™è¿›è¡Œåˆ—è¡¨æ¨å¯¼\n",
    "                          else None # å¦åˆ™è®¾ç½®ä¸º None\n",
    "                        )\n",
    "\n",
    "    # åˆå¹¶ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å²ã€‚Trustcall æŠ½å–å™¨éœ€è¦å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡æ¥æå–ä¿¡æ¯ã€‚\n",
    "    # TRUSTCALL_INSTRUCTION æ˜¯ä¸€ä¸ªåŒ…å«é€šç”¨æŠ½å–æŒ‡ä»¤çš„å­—ç¬¦ä¸²æ¨¡æ¿ã€‚\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat()) # æ ¼å¼åŒ–æŒ‡ä»¤ï¼ŒåŠ å…¥å½“å‰æ—¶é—´\n",
    "    # merge_message_runs ç”¨äºåˆå¹¶æ¶ˆæ¯åˆ—è¡¨ã€‚è¿™é‡Œå°†ç³»ç»ŸæŒ‡ä»¤å’Œå¯¹è¯å†å² (é™¤äº†æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨æ¶ˆæ¯) åˆå¹¶ã€‚\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcallï¼ˆåˆå§‹åŒ–ç›‘å¬å™¨ä»¥è§‚å¯Ÿ Trustcall å·¥å…·è°ƒç”¨ï¼‰\n",
    "    spy = Spy()\n",
    "\n",
    "    # Create the Trustcall extractor for updating the ToDo listï¼ˆç”¨äºæ›´æ–° ToDo çš„ Trustcall æŠ½å–å™¨ï¼‰\n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages,\n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the storeï¼ˆå°† Trustcall æŠ½å–å‡ºçš„æ–°è®°å¿†æˆ–æ›´æ–°åçš„è®°å¿†ä¿å­˜åˆ°é•¿æœŸå­˜å‚¨ (store) ä¸­ï¼‰\n",
    "    # result[\"responses\"] åŒ…å«æŠ½å–å‡ºçš„ç¬¦åˆ ToDo schema çš„ Pydantic å¯¹è±¡ã€‚\n",
    "    # result[\"response_metadata\"] åŒ…å«æŠ½å–å‡ºçš„å¯¹è±¡çš„å…ƒä¿¡æ¯ï¼Œå¦‚ json_doc_idï¼ˆå¦‚æœ Trustcall å†³å®šæ›´æ–°ç°æœ‰æ–‡æ¡£ï¼‰ã€‚\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        # store.put æ–¹æ³•ç”¨äºå°†æ•°æ®å­˜å…¥å­˜å‚¨ã€‚\n",
    "        # namespace: æŒ‡å®šå­˜å‚¨çš„å‘½åç©ºé—´ã€‚\n",
    "        # key: å­˜å‚¨é¡¹çš„é”®ã€‚å¦‚æœ Trustcall è¿”å›äº† json_doc_idï¼Œè¯´æ˜æ˜¯æ›´æ–°ï¼Œä½¿ç”¨è¯¥ ID ä½œä¸ºé”®ï¼›å¦åˆ™ç”Ÿæˆä¸€ä¸ªæ–°çš„ UUID ä½œä¸ºæ–°æ–‡æ¡£çš„é”®ã€‚\n",
    "        # value: è¦å­˜å‚¨çš„å€¼ã€‚è¿™é‡Œå°†æŠ½å–å‡ºçš„ Pydantic å¯¹è±¡è½¬æ¢ä¸º JSON æ ¼å¼çš„å­—å…¸ã€‚\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "    # Respond to the tool call made in task_assistant, confirming the updateï¼ˆå“åº” task_assistant èŠ‚ç‚¹å‘å‡ºçš„å·¥å…·è°ƒç”¨ï¼Œç¡®è®¤æ›´æ–°å·²å®Œæˆï¼‰\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_assistantï¼ˆæå– Trustcall è¿›è¡Œçš„å…·ä½“å˜æ›´ä¿¡æ¯ï¼Œå¹¶ä½œä¸ºå·¥å…·è°ƒç”¨çš„ç»“æœè¿”å›ç»™ task_assistant èŠ‚ç‚¹ï¼‰\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"\n",
    "    update_instructions èŠ‚ç‚¹ï¼šè´Ÿè´£å¤„ç†æ¨¡å‹è°ƒç”¨ UpdateMemory å·¥å…·å¹¶æŒ‡å®š update_type ä¸º 'instructions' çš„æƒ…å†µã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. å›é¡¾å¯¹è¯å†å²ï¼Œä»ä¸­æå–ç”¨æˆ·å…³äºå¦‚ä½•ç»´æŠ¤ ToDo åˆ—è¡¨çš„åå¥½/åŸåˆ™ã€‚\n",
    "    2. è°ƒç”¨æ¨¡å‹æ ¹æ®è¿™äº›åå¥½æ›´æ–°é•¿æœŸå­˜å‚¨ä¸­çš„æ“ä½œå‡†åˆ™è®°å¿†ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store\n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "\n",
    "# Conditional edgeï¼ˆæ¡ä»¶è¾¹ï¼šæ ¹æ®æ¨¡å‹çš„å·¥å…·è°ƒç”¨ç»“æœè·¯ç”±ï¼‰\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "    \"\"\"\n",
    "    route_message å‡½æ•°ï¼šè¿™æ˜¯å›¾ä¸­çš„æ¡ä»¶è¾¹ï¼Œè´Ÿè´£æ ¹æ® task_assistant èŠ‚ç‚¹çš„è¾“å‡ºï¼ˆç‰¹åˆ«æ˜¯æ¨¡å‹æ˜¯å¦è°ƒç”¨äº† UpdateMemory å·¥å…·åŠå…¶å‚æ•°ï¼‰æ¥å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚\n",
    "    å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ï¼š\n",
    "    1. æ£€æŸ¥ task_assistant è¿”å›çš„æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ã€‚\n",
    "    2. å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ¨¡å‹è®¤ä¸ºä¸éœ€è¦æ›´æ–°è®°å¿†ï¼Œå¯¹è¯ç»“æŸ (END)ã€‚\n",
    "    3. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥ UpdateMemory å·¥å…·çš„ update_type å‚æ•°ï¼Œå¹¶è·¯ç”±åˆ°ç›¸åº”çš„æ›´æ–°èŠ‚ç‚¹ï¼ˆupdate_profile, update_todos, æˆ– update_instructionsï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨\n",
    "    if len(message.tool_calls) ==0:\n",
    "        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯\n",
    "        return END\n",
    "    else:\n",
    "        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè·å–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼ˆæˆ‘ä»¬é™åˆ¶äº† parallel_tool_calls=Falseï¼Œæ‰€ä»¥åªä¼šæœ‰ä¸€ä¸ªï¼‰\n",
    "        tool_call = message.tool_calls[0]\n",
    "        # æ ¹æ®å·¥å…·è°ƒç”¨çš„å‚æ•° 'update_type' æ¥å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–°ç”¨æˆ·ç”»åƒï¼Œè·¯ç”±åˆ° update_profile èŠ‚ç‚¹\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–° ToDo åˆ—è¡¨ï¼Œè·¯ç”±åˆ° update_todos èŠ‚ç‚¹\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            # å¦‚æœæ˜¯æ›´æ–°æ“ä½œå‡†åˆ™ï¼Œè·¯ç”±åˆ° update_instructions èŠ‚ç‚¹\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            # å¦‚æœ update_type æ˜¯æœªçŸ¥ç±»å‹ï¼ŒæŠ›å‡ºé”™è¯¯\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "# æ·»åŠ å„ä¸ªèŠ‚ç‚¹åˆ°å›¾ä¸­\n",
    "builder.add_node(\"task_assistant\", task_assistant) # æ·»åŠ  task_assistant èŠ‚ç‚¹\n",
    "builder.add_node(\"update_todos\", update_todos)     # æ·»åŠ  update_todos èŠ‚ç‚¹\n",
    "builder.add_node(\"update_profile\", update_profile) # æ·»åŠ  update_profile èŠ‚ç‚¹\n",
    "builder.add_node(\"update_instructions\", update_instructions) # æ·»åŠ  update_instructions èŠ‚ç‚¹\n",
    "\n",
    "# å®šä¹‰è¾¹çš„è¿æ¥\n",
    "# ä» STARTï¼ˆå›¾çš„å¼€å§‹ï¼‰è¿æ¥åˆ° task_assistant èŠ‚ç‚¹\n",
    "builder.add_edge(START, \"task_assistant\")\n",
    "# ä» task_assistant èŠ‚ç‚¹æ·»åŠ æ¡ä»¶è¾¹ï¼Œæ ¹æ® route_message å‡½æ•°çš„è¿”å›å€¼å†³å®šå»å‘\n",
    "builder.add_conditional_edges(\"task_assistant\", route_message)\n",
    "# ä»å„ä¸ªæ›´æ–°èŠ‚ç‚¹ï¼ˆupdate_todos, update_profile, update_instructionsï¼‰è¿æ¥å› task_assistant èŠ‚ç‚¹ï¼Œ\n",
    "# è¿™æ ·åœ¨æ›´æ–°å®Œæˆåï¼Œæ™ºèƒ½ä½“å¯ä»¥å›åˆ° task_assistant ç»§ç»­ä¸ç”¨æˆ·äº¤äº’ã€‚\n",
    "builder.add_edge(\"update_todos\", \"task_assistant\")\n",
    "builder.add_edge(\"update_profile\", \"task_assistant\")\n",
    "builder.add_edge(\"update_instructions\", \"task_assistant\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªå†…å­˜å­˜å‚¨ï¼Œç”¨äºé•¿æœŸï¼ˆè·¨ä¼šè¯ï¼‰è®°å¿†ã€‚\n",
    "# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œé€šå¸¸ä¼šä½¿ç”¨æ•°æ®åº“ç­‰æŒä¹…åŒ–å­˜å‚¨ã€‚\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œç”¨äºçŸ­æœŸï¼ˆä¼šè¯å†…ï¼‰è®°å¿†ã€‚\n",
    "# å®ƒä¼šä¿å­˜æ¯ä¸ªæ­¥éª¤çš„çŠ¶æ€ï¼Œä»¥ä¾¿åœ¨å‡ºç°é—®é¢˜æ—¶å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤ã€‚\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "# ç¼–è¯‘å›¾ï¼Œå°†èŠ‚ç‚¹å’Œè¾¹è¿æ¥èµ·æ¥ï¼Œå¹¶é…ç½®æ£€æŸ¥ç‚¹å’Œé•¿æœŸå­˜å‚¨ã€‚\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "# ç»˜åˆ¶å¹¶æ˜¾ç¤ºå›¾çš„å¯è§†åŒ–ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹ã€‚\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h5_tsKnXHmNh",
    "outputId": "fccc6b20-42d3-4184-afc4-4f0e2d0a3fe2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘æ˜¯FLYã€‚æˆ‘å’Œå¦»å­ç”Ÿæ´»åœ¨ä¸­å›½æ­å·ã€‚æˆ‘æœ‰ä¸€ä¸ª3å²çš„å¥³å„¿ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_kK2lwEy4f7Lm3tOwroIGSMkW)\n",
      " Call ID: call_kK2lwEy4f7Lm3tOwroIGSMkW\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼ŒFLYï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# æä¾›çº¿ç¨‹ IDï¼ˆçŸ­æœŸã€ä¼šè¯çº§è®°å¿†ï¼‰\n",
    "# æä¾›ç”¨æˆ· IDï¼ˆé•¿æœŸã€è·¨ä¼šè¯è®°å¿†ï¼‰\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# ç”¨æˆ·è¾“å…¥ï¼šç”¨äºåˆ›å»ºç”¨æˆ·ç”»åƒï¼ˆprofileï¼‰ç›¸å…³è®°å¿†\n",
    "input_messages = [HumanMessage(content=\"æˆ‘æ˜¯FLYã€‚æˆ‘å’Œå¦»å­ç”Ÿæ´»åœ¨ä¸­å›½æ­å·ã€‚æˆ‘æœ‰ä¸€ä¸ª3å²çš„å¥³å„¿ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "y8Bpj-W2HmNh",
    "outputId": "f9d71314-a674-43e8-fa1a-029dc1b5a604",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘çš„å¦»å­è®©æˆ‘ä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_nGF8JB2idZM5A9Qicb8BVsxR)\n",
      " Call ID: call_nGF8JB2idZM5A9Qicb8BVsxR\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ ToDoï¼š\n",
      "å†…å®¹ï¼š{'task': 'ä¸º3å²çš„å¥³å„¿é¢„è®¢æ¸¸æ³³è¯¾ç¨‹', 'time_to_complete': 30, 'solutions': ['è”ç³»å½“åœ°çš„å„¿ç«¥æ¸¸æ³³åŸ¹è®­æœºæ„', 'æŸ¥çœ‹æ­å·çš„æ¸¸æ³³é¦†æ˜¯å¦æä¾›å„¿ç«¥è¯¾ç¨‹', 'å’¨è¯¢å…¶ä»–å®¶é•¿æ¨èçš„æ¸¸æ³³è¯¾ç¨‹'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æˆ‘å·²ç»å¸®ä½ è®°å½•äº†è¿™ä¸ªä»»åŠ¡ï¼šä¸º3å²çš„å¥³å„¿é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚å¦‚æœéœ€è¦è¿›ä¸€æ­¥å¸®åŠ©ï¼Œæ¯”å¦‚æŸ¥æ‰¾å…·ä½“çš„åŸ¹è®­æœºæ„æˆ–è¯¾ç¨‹ä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ·»åŠ ä¸€ä¸ª ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"æˆ‘çš„å¦»å­è®©æˆ‘ä¸ºå®å®é¢„è®¢æ¸¸æ³³è¯¾ç¨‹ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tKBO0zhSHmNh",
    "outputId": "d16f0b7f-27f3-4282-d482-9df955685b19",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "åœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œè¯·åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶/ä¾›åº”å•†ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_mZigkmcHwE8E031Jhy1wo6Vo)\n",
      " Call ID: call_mZigkmcHwE8E031Jhy1wo6Vo\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "å¥½çš„ï¼Œæˆ‘ä¼šåœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œå°½é‡åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶æˆ–ä¾›åº”å•†ã€‚éœ€è¦æˆ‘å¸®ä½ æŸ¥æ‰¾æ­å·çš„å„¿ç«¥æ¸¸æ³³è¯¾ç¨‹å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ›´æ–° ToDo åˆ›å»º/æ›´æ–°çš„æ“ä½œå‡†åˆ™ï¼ˆinstructionsï¼‰\n",
    "input_messages = [HumanMessage(content=\"åœ¨åˆ›å»ºæˆ–æ›´æ–°å¾…åŠäº‹é¡¹æ—¶ï¼Œè¯·åŒ…æ‹¬å…·ä½“çš„æœ¬åœ°å•†å®¶/ä¾›åº”å•†ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZjysywxnHmNh",
    "outputId": "57fda351-fd80-4946-d405-17b3a96d698a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'memory': 'Got it! I will now update the instructions to include specific local businesses or suppliers when creating or updating ToDo list entries.'}\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ instructions æ˜¯å¦å·²æ›´æ–°\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# æŸ¥è¯¢æŒä¹…åŒ–å­˜å‚¨\n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fa7Nvz_5HmNi",
    "outputId": "d5ab44fc-ab1b-44a8-e6da-982c7dfa08fd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "è¿™ä¸ªä»»åŠ¡å·²ç»è®°å½•åœ¨ä½ çš„å¾…åŠäº‹é¡¹ä¸­äº†ï¼šä¿®ç†é—¨é”ã€‚å¦‚æœéœ€è¦è¿›ä¸€æ­¥å¸®åŠ©ï¼Œæ¯”å¦‚æŸ¥æ‰¾å…·ä½“çš„é”åŒ æœåŠ¡ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ·»åŠ ä¸€ä¸ªæ–°çš„ ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"æˆ‘éœ€è¦ä¿®ç†é—¨é”ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HvIT_lu6HmNi",
    "outputId": "0987d754-b183-4811-bfb7-ef81d194bd81",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'task': 'ä¸º3å²çš„å¥³å„¿é¢„è®¢æ¸¸æ³³è¯¾ç¨‹', 'time_to_complete': 30, 'deadline': None, 'solutions': ['è”ç³»å½“åœ°çš„å„¿ç«¥æ¸¸æ³³åŸ¹è®­æœºæ„', 'æŸ¥çœ‹æ­å·çš„æ¸¸æ³³é¦†æ˜¯å¦æä¾›å„¿ç«¥è¯¾ç¨‹', 'å’¨è¯¢å…¶ä»–å®¶é•¿æ¨èçš„æ¸¸æ³³è¯¾ç¨‹'], 'status': 'not started'}\n",
      "{'task': 'ä¿®ç†é—¨é”', 'time_to_complete': 60, 'deadline': None, 'solutions': ['è”ç³»æ­å·æœ¬åœ°çš„é”åŒ æœåŠ¡', 'æŸ¥çœ‹æ˜¯å¦æœ‰ä¸Šé—¨ä¿®é”æœåŠ¡', 'å’¨è¯¢é‚»å±…æ¨èçš„ä¿®é”å¸ˆå‚…'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥è¯¢ç”¨æˆ·çš„ ToDo è®°å¿†é›†åˆ\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# éå†è¾“å‡º\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DtEdyioSHmNi",
    "outputId": "4917ced5-1dee-45b0-8941-55e5660da85b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘éœ€è¦åœ¨11æœˆåº•ä¹‹å‰å®Œæˆå­¦ä¼šæ¸¸æ³³ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_rwCjDcl6eNfb0wesvELmNV6a)\n",
      " Call ID: call_rwCjDcl6eNfb0wesvELmNV6a\n",
      "  Args:\n",
      "    update_type: todo\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:extraction:2 validation errors for ToDo\n",
      "task\n",
      "  Field required [type=missing, input_value={'update_type': 'user'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "time_to_complete\n",
      "  Field required [type=missing, input_value={'update_type': 'user'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ ToDoï¼š\n",
      "å†…å®¹ï¼š{'task': 'å­¦ä¼šæ¸¸æ³³', 'time_to_complete': None, 'deadline': '2025-11-30T23:59:59', 'solutions': ['æŠ¥åæˆäººæ¸¸æ³³è¯¾ç¨‹', 'è¯·ç§äººæ•™ç»ƒè¿›è¡Œä¸€å¯¹ä¸€æ•™å­¦', 'åˆ©ç”¨å‘¨æœ«æ—¶é—´è‡ªå­¦'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æˆ‘å·²ç»å¸®ä½ è®°å½•äº†è¿™ä¸ªç›®æ ‡ï¼šåœ¨2025å¹´11æœˆåº•ä¹‹å‰å­¦ä¼šæ¸¸æ³³ã€‚å¦‚æœéœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ æŸ¥æ‰¾æ­å·çš„æ¸¸æ³³è¯¾ç¨‹æˆ–ç§äººæ•™ç»ƒä¿¡æ¯ã€‚éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šæ›´æ–°å·²æœ‰ ToDo çš„æˆªæ­¢æ—¶é—´\n",
    "input_messages = [HumanMessage(content=\"æˆ‘éœ€è¦åœ¨11æœˆåº•ä¹‹å‰å®Œæˆå­¦ä¼šæ¸¸æ³³ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VREkQm-HmNi"
   },
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒTrustcall å¯¹å·²æœ‰è®°å¿†æ‰§è¡Œäº†â€œè¡¥ä¸å¼â€æ›´æ–°ï¼ˆpatchï¼‰ï¼š\n",
    "\n",
    "`https://smith.langchain.com/public/4ad3a8af-3b1e-493d-b163-3111aa3d575a/r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o9B6khJXHmNi",
    "outputId": "dbb9457a-39ae-4338-fbae-86bc126c5c88",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "éœ€è¦åœ¨æ™šä¸Š9ç‚¹å‰å‘é€ä¼šè®®æ€»ç»“ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_fklcF1lBX2Hl1owQZl28Orkd)\n",
      " Call ID: call_fklcF1lBX2Hl1owQZl28Orkd\n",
      "  Args:\n",
      "    update_type: todo\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:extraction:2 validation errors for ToDo\n",
      "task\n",
      "  Field required [type=missing, input_value={'update_type': 'todo'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "time_to_complete\n",
      "  Field required [type=missing, input_value={'update_type': 'todo'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "å·²åˆ›å»ºæ–°çš„ ToDoï¼š\n",
      "å†…å®¹ï¼š{'task': 'å‘é€ä¼šè®®æ€»ç»“', 'time_to_complete': 30, 'deadline': '2025-09-18T21:00:00', 'solutions': ['æ•´ç†ä¼šè®®è®°å½•', 'æç‚¼å…³é”®ç‚¹', 'é€šè¿‡é‚®ä»¶å‘é€ç»™ç›¸å…³äººå‘˜'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æˆ‘å·²ç»å¸®ä½ è®°å½•äº†è¿™ä¸ªä»»åŠ¡ï¼šåœ¨æ™šä¸Š9ç‚¹å‰å‘é€ä¼šè®®æ€»ç»“ã€‚å¦‚æœéœ€è¦ååŠ©æ•´ç†ä¼šè®®è®°å½•æˆ–æç‚¼å…³é”®ç‚¹ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# ç”¨æˆ·è¾“å…¥ï¼šå†æ·»åŠ ä¸€ä¸ªæ–°çš„ ToDo ä»»åŠ¡\n",
    "input_messages = [HumanMessage(content=\"éœ€è¦åœ¨æ™šä¸Š9ç‚¹å‰å‘é€ä¼šè®®æ€»ç»“ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LhH21elZHmNj",
    "outputId": "cba5f715-986f-4aca-f9c2-68e126ee6cc4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'task': 'ä¸º3å²çš„å¥³å„¿é¢„è®¢æ¸¸æ³³è¯¾ç¨‹', 'time_to_complete': 30, 'deadline': None, 'solutions': ['è”ç³»å½“åœ°çš„å„¿ç«¥æ¸¸æ³³åŸ¹è®­æœºæ„', 'æŸ¥çœ‹æ­å·çš„æ¸¸æ³³é¦†æ˜¯å¦æä¾›å„¿ç«¥è¯¾ç¨‹', 'å’¨è¯¢å…¶ä»–å®¶é•¿æ¨èçš„æ¸¸æ³³è¯¾ç¨‹'], 'status': 'not started'}\n",
      "{'task': 'ä¿®ç†é—¨é”', 'time_to_complete': 60, 'deadline': None, 'solutions': ['è”ç³»æ­å·æœ¬åœ°çš„é”åŒ æœåŠ¡', 'æŸ¥çœ‹æ˜¯å¦æœ‰ä¸Šé—¨ä¿®é”æœåŠ¡', 'å’¨è¯¢é‚»å±…æ¨èçš„ä¿®é”å¸ˆå‚…'], 'status': 'not started'}\n",
      "{'task': 'å­¦ä¼šæ¸¸æ³³', 'time_to_complete': None, 'deadline': '2025-11-30T23:59:59', 'solutions': ['æŠ¥åæˆäººæ¸¸æ³³è¯¾ç¨‹', 'è¯·ç§äººæ•™ç»ƒè¿›è¡Œä¸€å¯¹ä¸€æ•™å­¦', 'åˆ©ç”¨å‘¨æœ«æ—¶é—´è‡ªå­¦'], 'status': 'not started'}\n",
      "{'task': 'å‘é€ä¼šè®®æ€»ç»“', 'time_to_complete': 30, 'deadline': '2025-09-18T21:00:00', 'solutions': ['æ•´ç†ä¼šè®®è®°å½•', 'æç‚¼å…³é”®ç‚¹', 'é€šè¿‡é‚®ä»¶å‘é€ç»™ç›¸å…³äººå‘˜'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥è¯¢ç”¨æˆ·æœ€æ–°çš„ ToDo è®°å¿†é›†åˆ\n",
    "user_id = \"FLY\"\n",
    "\n",
    "# éå†è¾“å‡º\n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAQVGLyHmNj"
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è¯çº¿ç¨‹ï¼ˆthreadï¼‰ã€‚\n",
    "\n",
    "è¿™ä¼šå¼€å¯ä¸€ä¸ªæ–°çš„ä¼šè¯ã€‚\n",
    "\n",
    "æ­¤å‰ä¿å­˜åœ¨é•¿æœŸå­˜å‚¨ä¸­çš„ Profileã€ToDos ä¸ Instructions ä¼šè¢«è‡ªåŠ¨åŠ è½½å¹¶ç”¨äºä¸ªæ€§åŒ–å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "X-kMwYFYHmNj",
    "outputId": "b52ce01b-1a27-4a97-b066-3e0d394134d8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘æœ‰30åˆ†é’Ÿï¼Œæˆ‘èƒ½å®Œæˆå“ªäº›ä»»åŠ¡ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ ¹æ®ä½ çš„ ToDo åˆ—è¡¨ï¼Œä»¥ä¸‹ä»»åŠ¡å¯ä»¥åœ¨30åˆ†é’Ÿå†…å®Œæˆï¼š\n",
      "\n",
      "1. **ä¸º3å²çš„å¥³å„¿é¢„è®¢æ¸¸æ³³è¯¾ç¨‹**  \n",
      "   - æ—¶é—´ä¼°è®¡ï¼š30åˆ†é’Ÿ  \n",
      "   - å»ºè®®è¡ŒåŠ¨ï¼šè”ç³»å½“åœ°çš„å„¿ç«¥æ¸¸æ³³åŸ¹è®­æœºæ„æˆ–æŸ¥çœ‹æ­å·çš„æ¸¸æ³³é¦†æ˜¯å¦æä¾›å„¿ç«¥è¯¾ç¨‹ã€‚\n",
      "\n",
      "2. **å‘é€ä¼šè®®æ€»ç»“**  \n",
      "   - æ—¶é—´ä¼°è®¡ï¼š30åˆ†é’Ÿ  \n",
      "   - å»ºè®®è¡ŒåŠ¨ï¼šæ•´ç†ä¼šè®®è®°å½•ï¼Œæç‚¼å…³é”®ç‚¹ï¼Œå¹¶é€šè¿‡é‚®ä»¶å‘é€ç»™ç›¸å…³äººå‘˜ã€‚\n",
      "\n",
      "ä½ å¯ä»¥é€‰æ‹©å…¶ä¸­ä¸€ä¸ªä»»åŠ¡å¼€å§‹å®Œæˆï¼éœ€è¦æˆ‘å¸®ä½ åˆ¶å®šå…·ä½“çš„æ­¥éª¤æˆ–æä¾›ååŠ©å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# æä¾›çº¿ç¨‹ IDï¼ˆçŸ­æœŸã€ä¼šè¯çº§è®°å¿†ï¼‰\n",
    "# æä¾›ç”¨æˆ· IDï¼ˆé•¿æœŸã€è·¨ä¼šè¯è®°å¿†ï¼‰\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"FLY\"}}\n",
    "\n",
    "# ä¸èŠå¤©æœºå™¨äººå¯¹è¯\n",
    "input_messages = [HumanMessage(content=\"æˆ‘æœ‰30åˆ†é’Ÿï¼Œæˆ‘èƒ½å®Œæˆå“ªäº›ä»»åŠ¡ï¼Ÿ\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ko1cdB29HmNj",
    "outputId": "430d29ae-936b-49b1-9d8f-32fe2cf00b80",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æ˜¯çš„ï¼Œç»™æˆ‘ä¸€äº›æŠ¥åæ¸¸æ³³è¯¾ç¨‹çš„é€‰é¡¹ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä»¥ä¸‹æ˜¯ä¸€äº›åœ¨æ­å·å¯ä»¥ä¸ºä½ å¥³å„¿æŠ¥åæ¸¸æ³³è¯¾ç¨‹çš„é€‰é¡¹ï¼š\n",
      "\n",
      "1. **æ­å·æ¸¸æ³³é¦†**  \n",
      "   - è®¸å¤šæ¸¸æ³³é¦†æä¾›å„¿ç«¥æ¸¸æ³³è¯¾ç¨‹ï¼Œä½ å¯ä»¥è”ç³»ç¦»å®¶è¾ƒè¿‘çš„æ¸¸æ³³é¦†ï¼Œè¯¢é—®æ˜¯å¦æœ‰é€‚åˆ3å²å­©å­çš„è¯¾ç¨‹ã€‚  \n",
      "   - æ¨èï¼šæ­å·é»„é¾™ä½“è‚²ä¸­å¿ƒæ¸¸æ³³é¦†ã€æ­å·å¥¥ä½“ä¸­å¿ƒæ¸¸æ³³é¦†ã€‚\n",
      "\n",
      "2. **å„¿ç«¥æ¸¸æ³³åŸ¹è®­æœºæ„**  \n",
      "   - **é‡‘å®è´æ¸¸æ³³ä¸­å¿ƒ**ï¼šä¸“æ³¨äºå„¿ç«¥æ—©æ•™å’Œæ¸¸æ³³è¯¾ç¨‹ï¼Œé€‚åˆ3å²å­©å­ã€‚  \n",
      "   - **æ°´å­©å­å›½é™…æ¸¸æ³³å­¦æ ¡**ï¼šæä¾›ä¸“ä¸šçš„å„¿ç«¥æ¸¸æ³³è¯¾ç¨‹ï¼Œæ³¨é‡å®‰å…¨å’Œå…´è¶£åŸ¹å…»ã€‚\n",
      "\n",
      "3. **å®¶é•¿æ¨è**  \n",
      "   - ä½ å¯ä»¥å’¨è¯¢å…¶ä»–å®¶é•¿ï¼Œäº†è§£ä»–ä»¬æ¨èçš„è¯¾ç¨‹æˆ–æœºæ„ï¼Œå°¤å…¶æ˜¯æœ‰å­©å­åœ¨å­¦æ¸¸æ³³çš„æœ‹å‹ã€‚\n",
      "\n",
      "4. **çº¿ä¸Šå¹³å°æŸ¥è¯¢**  \n",
      "   - ä½¿ç”¨å¤§ä¼—ç‚¹è¯„ã€ç¾å›¢ç­‰å¹³å°æœç´¢â€œå„¿ç«¥æ¸¸æ³³è¯¾ç¨‹â€ï¼ŒæŸ¥çœ‹è¯„ä»·å’Œè¯¾ç¨‹è¯¦æƒ…ã€‚\n",
      "\n",
      "ä½ å¯ä»¥ä»è¿™äº›é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªå¼€å§‹è”ç³»ï¼Œæˆ–è€…å‘Šè¯‰æˆ‘ä½ çš„å…·ä½“éœ€æ±‚ï¼Œæˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥ç­›é€‰ï¼\n"
     ]
    }
   ],
   "source": [
    "# ä¸èŠå¤©æœºå™¨äººå¯¹è¯\n",
    "input_messages = [HumanMessage(content=\"æ˜¯çš„ï¼Œç»™æˆ‘ä¸€äº›æŠ¥åæ¸¸æ³³è¯¾ç¨‹çš„é€‰é¡¹ã€‚\")]\n",
    "\n",
    "# è¿è¡Œå›¾ï¼ˆGraphï¼‰\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx5e9Gv_HmNj"
   },
   "source": [
    "è¿½è¸ªï¼ˆTraceï¼‰ï¼š\n",
    "\n",
    "`https://smith.langchain.com/o/7bfa9385-4ac5-468a-a06c-ffd7dbac42ec/projects/p/27f0e396-e7ab-4eac-9501-8df28b729149?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=aa03e9ad-84b7-4c38-98ae-0e87d60690dc&peeked_trace=aa03e9ad-84b7-4c38-98ae-0e87d60690dc`\n",
    "![](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509181621557.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}