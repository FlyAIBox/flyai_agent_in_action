{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {},
   "source": [
    "### 🔧 环境配置和检查\n\n#### 概述\n\n本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助您：\n\n- 使用统一的conda环境：激活统一的学习环境\n- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n- 加速模型下载：设置HuggingFace镜像代理\n- 检查系统配置：检查硬件和软件配置\n\n#### 配置\n\n- **所需环境及其依赖已经部署好**\n- 在`Notebook`右上角选择`jupyter内核`为`python(flyai_agent_in_action)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n\n# 1. 激活 conda 环境 (仅对当前单元格有效)\neval \"$(conda shell.bash hook)\"\nconda activate flyai_agent_in_action\n\necho \"=========================================\"\necho \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\necho \"=========================================\"\n\n# 2. 检查当前激活的环境\nCURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n\nif [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n    echo \"✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\"\n    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n    echo \"\"\n    echo \"💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\"\n    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n    echo \"   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\"\nelse\n    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n    echo \"\"\n    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(flyai_agent_in_action)'。\"\n    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n    echo \"\"\n    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n    echo \"\"\n    echo \"%%script bash\"\n    echo \"# 必须在每个单元格都执行\"\n    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n    echo \"conda activate flyai_agent_in_action\"\nfi\n\necho \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助您：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智能助手（Assistants）\n",
    "\n",
    "[智能助手](https://langchain-ai.github.io/langgraph/concepts/assistants/#resources) 为开发者提供了一种快速、结构化的方式来调整和版本化 LangGraph 智能体，便于持续迭代实验与测试。\n",
    "\n",
    "## 为图（Graph）提供配置\n",
    "\n",
    "我们的 `task_maistro` 图已经完成了接入智能助手所需的配置。\n",
    "\n",
    "该图包含一个 `configuration.py` 文件，用于声明可以被助手覆盖的可配置字段，并在运行时自动加载。\n",
    "\n",
    "在图的节点逻辑内部，我们可以通过 `user_id`、`todo_category`、`task_maistro_role` 等字段读取不同助手之间的差异。\n",
    "\n",
    "## 创建智能助手\n",
    "\n",
    "回到我们在前面章节中持续构建的 `task_maistro` 应用，它的最佳实践用例是什么？\n",
    "\n",
    "对我而言，优势在于能够为不同场景维护独立的任务清单。\n",
    "\n",
    "例如，我希望一个助手专注管理个人生活的待办事项，另一个助手负责工作任务。\n",
    "\n",
    "这一目标可以通过调整 `todo_category` 与 `task_maistro_role` 这两个可配置字段轻松实现。\n",
    "\n",
    "![智能助手配置界面截图](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/673d50597f4e9eae9abf4869_Screenshot%202024-11-19%20at%206.57.01%E2%80%AFPM.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装或升级 LangGraph SDK\n",
    "# 使用 %%capture 魔法命令隐藏安装过程中的常规输出\n",
    "# --no-stderr 参数确保出现错误时仍会显示在终端\n",
    "%%capture --no-stderr\n",
    "%pip install -U langgraph_sdk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是部署图时自动创建的默认智能助手，可以作为之后定制助手的参照基线。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 LangGraph SDK 客户端工厂\n",
    "from langgraph_sdk import get_client\n",
    "\n",
    "# 设置本地部署的 URL 地址\n",
    "# 这里使用通过 CLI 启动的本地服务\n",
    "url_for_cli_deployment = \"http://localhost:8123\"\n",
    "\n",
    "# 创建客户端实例，用于与部署的图交互\n",
    "client = get_client(url=url_for_cli_deployment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 个人助手\n",
    "\n",
    "首先我们构建一个专门处理个人事务的智能助手。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建个人助手\n",
    "# 调用客户端在部署的图上新建一个智能助手实例\n",
    "personal_assistant = await client.assistants.create(\n",
    "    # \"task_maistro\" 是该部署图的名称\n",
    "    \"task_maistro\", \n",
    "    # 配置参数：待办类别设置为 \"personal\"（个人）\n",
    "    config={\"configurable\": {\"todo_category\": \"personal\"}}\n",
    ")\n",
    "\n",
    "# 输出助手的关键信息，确认配置是否生效\n",
    "print(personal_assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们进一步完善这个助手，补充 `user_id` 等专属信息，并[创建一个新版本](https://langchain-ai.github.io/langgraph/cloud/how-tos/assistant_versioning/#create-a-new-version-for-your-assistant)。这样可以在不影响线上环境的前提下安全迭代配置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义个人助手的角色设定\n",
    "# 这段系统提示词决定了助手的语气与处理逻辑\n",
    "task_maistro_role = \"\"\"你是一位友好且条理清晰的个人任务助手，你的主要职责是帮助用户掌握个人任务和承诺的进度。具体要求：\n",
    "\n",
    "- 协助跟踪并整理个人任务\n",
    "- 当需要提供“待办事项摘要”时：\n",
    "  1. 按截止时间（已逾期、今天、本周、未来）分组列出所有当前任务\n",
    "  2. 标注任何缺少截止日期的任务，并温和地鼓励用户补充\n",
    "  3. 提醒那些看起来重要却缺少预计耗时的任务\n",
    "- 如果新增任务没有截止日期，要主动询问用户是否需要补充\n",
    "- 在帮助用户保持自我管理的同时，始终保持支持性的语气\n",
    "- 根据截止时间和重要性协助用户排列任务优先级\n",
    "\n",
    "你的沟通风格应该积极、乐于助人，而不是评判。\n",
    "\n",
    "当任务缺少截止日期时，可以这样回应：“我注意到 [任务] 还没有截止日期。要不要补充一个，帮助我们更好地追踪？”\"\"\"\n",
    "\n",
    "# 组合需要更新的配置项\n",
    "configurations = {\"todo_category\": \"personal\", \n",
    "                  \"user_id\": \"lance\",\n",
    "                  \"task_maistro_role\": task_maistro_role}\n",
    "\n",
    "# 更新个人助手配置\n",
    "personal_assistant = await client.assistants.update(\n",
    "    personal_assistant[\"assistant_id\"],\n",
    "    config={\"configurable\": configurations}\n",
    ")\n",
    "\n",
    "# 打印更新后的助手信息\n",
    "print(personal_assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工作助手\n",
    "\n",
    "接下来再创建一个面向工作任务的助手，帮助我跟进团队安排。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_maistro_role = \"\"\"你是一位专注且高效的工作任务助手。\n",
    "\n",
    "你的核心职责是帮助用户以现实可行的时间表管理工作承诺。\n",
    "\n",
    "具体要求：\n",
    "\n",
    "- 协助跟踪并整理工作任务\n",
    "- 当提供“待办事项摘要”时：\n",
    "  1. 按截止时间（已逾期、今天、本周、未来）分组列出所有当前任务\n",
    "  2. 标注任何缺少截止日期的任务，并温和地提醒用户补充\n",
    "  3. 提醒那些看起来重要却缺少预计耗时的任务\n",
    "- 与用户讨论新任务时，结合任务类型给出合理的时间建议：\n",
    "  - 开发者关系相关功能：通常需要 1 天\n",
    "  - 课程课件评审或反馈：通常需要 2 天\n",
    "  - 文档冲刺：通常需要 3 天\n",
    "- 根据截止日期和团队依赖关系帮助用户安排优先级\n",
    "- 在协助用户履行承诺时保持专业、务实的语气\n",
    "\n",
    "当任务缺少截止日期时，可以这样回应：“我注意到 [任务] 还没有截止日期。参考类似的任务，这类工作大约需要 [建议时长]。要不要据此设定一个截止日期？”\"\"\"\n",
    "\n",
    "configurations = {\"todo_category\": \"work\", \n",
    "                  \"user_id\": \"lance\",\n",
    "                  \"task_maistro_role\": task_maistro_role}\n",
    "\n",
    "# 创建工作助手\n",
    "# 使用客户端创建一个新的工作助手实例\n",
    "work_assistant = await client.assistants.create(\n",
    "    # \"task_maistro\" 是我们部署的图的名称\n",
    "    \"task_maistro\", \n",
    "    # 配置参数：待办类别设置为 \"work\"（工作）\n",
    "    config={\"configurable\": configurations}\n",
    ")\n",
    "\n",
    "# 打印创建的工作助手信息\n",
    "print(work_assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用智能助手\n",
    "\n",
    "智能助手的配置被持久化在部署所使用的 `Postgres` 数据库中。借助 SDK，我们可以方便地[检索](https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/)并管理这些助手。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索所有智能助手\n",
    "# 使用客户端搜索功能获取所有已创建的助手\n",
    "assistants = await client.assistants.search()\n",
    "\n",
    "# 遍历并打印每个助手的基本信息\n",
    "for assistant in assistants:\n",
    "    print({\n",
    "        'assistant_id': assistant['assistant_id'],  # 助手的唯一标识符\n",
    "        'version': assistant['version'],            # 助手的版本号\n",
    "        'config': assistant['config']               # 助手的配置信息\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以通过 SDK 维护这些助手，例如删除不再使用的测试助手。\n",
    "\n",
    "> 视频中的示例语法已经过时。下面的代码展示了更新后的做法：先创建一个临时助手，再将其删除。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个临时的智能助手\n",
    "# 用于演示删除功能\n",
    "temp_assistant = await client.assistants.create(\n",
    "    \"task_maistro\", \n",
    "    config={\"configurable\": configurations}\n",
    ")\n",
    "\n",
    "# 搜索所有助手并显示删除前的状态\n",
    "assistants = await client.assistants.search()\n",
    "for assistant in assistants:\n",
    "    print(f\"删除前: {{'assistant_id': {assistant['assistant_id']}}}\")\n",
    "    \n",
    "# 删除我们的临时助手\n",
    "# 删除最后一个助手（刚创建的临时助手）\n",
    "await client.assistants.delete(assistants[-1][\"assistant_id\"])\n",
    "print()\n",
    "\n",
    "# 再次搜索所有助手并显示删除后的状态\n",
    "assistants = await client.assistants.search()\n",
    "for assistant in assistants:\n",
    "    print(f\"删除后: {{'assistant_id': {assistant['assistant_id']} }}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，保存个人助手和工作助手的 ID，方便后续调用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置助手ID变量，方便后续使用\n",
    "# 从搜索结果中获取工作助手和个人助手的ID\n",
    "work_assistant_id = assistants[0]['assistant_id']      # 工作助手的ID\n",
    "personal_assistant_id = assistants[1]['assistant_id']  # 个人助手的ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工作助手\n",
    "\n",
    "先让工作助手处理几条任务，观察它的响应。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的消息类型和转换工具\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "# 用户输入：创建或更新几条待办事项\n",
    "user_input = \"请帮我创建或更新几条待办事项：1）今天下班前重新录制第 6 模块第 5 课。2）在下周一之前更新 audioUX。\"\n",
    "\n",
    "# 创建一个新的对话线程\n",
    "# 线程用于管理用户与助手之间的完整对话历史\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# 使用工作助手处理用户输入\n",
    "# 通过流式处理持续获取助手的响应\n",
    "async for chunk in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      work_assistant_id,\n",
    "                                      input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "                                      stream_mode=\"values\"):\n",
    "\n",
    "    # 当接收到值事件时，处理并显示助手的响应\n",
    "    if chunk.event == 'values':\n",
    "        state = chunk.data\n",
    "        # 将消息转换为可读格式并打印最后一条消息\n",
    "        convert_to_messages(state[\"messages\"])[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为工作助手新增一条待办\n",
    "user_input = \"再创建一条待办：完成报表生成教程的最终稿。\"\n",
    "\n",
    "# 新建对话线程，用于承载对话上下文\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# 流式运行：将用户消息发送给工作助手，并逐步读取返回值\n",
    "async for chunk in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      work_assistant_id,\n",
    "                                      input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "                                      stream_mode=\"values\"):\n",
    "\n",
    "    # 当事件类型为 values 时，代表有新的状态返回\n",
    "    if chunk.event == 'values':\n",
    "        state = chunk.data\n",
    "        # 打印助手的最后一条消息\n",
    "        convert_to_messages(state[\"messages\"])[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "助手会按照它的系统提示来约束输出，例如在创建任务时提醒我补充截止日期。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回复助手：为该任务设置下周二为截止日期\n",
    "user_input = \"好的，这项任务就安排在下周二完成。\"\n",
    "\n",
    "# 继续在同一个线程中进行流式交互\n",
    "async for chunk in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      work_assistant_id,\n",
    "                                      input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "                                      stream_mode=\"values\"):\n",
    "\n",
    "    # 处理返回的状态值\n",
    "    if chunk.event == 'values':\n",
    "        state = chunk.data\n",
    "        # 打印助手的最后一条消息\n",
    "        convert_to_messages(state[\"messages\"])[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 个人助手\n",
    "\n",
    "同样的流程也适用于个人助手，我们可以为它创建或查询待办事项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为个人助手批量创建两条待办\n",
    "user_input = \"请创建两条待办：1）本周末了解宝宝游泳课的安排。2）为冬季出行确认 AmEx 积分。\"\n",
    "\n",
    "# 新建线程并以流式方式与个人助手交互\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      personal_assistant_id,\n",
    "                                      input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "                                      stream_mode=\"values\"):\n",
    "\n",
    "    # 处理返回值事件\n",
    "    if chunk.event == 'values':\n",
    "        state = chunk.data\n",
    "        # 打印助手的最后一条消息\n",
    "        convert_to_messages(state[\"messages\"])[-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让个人助手给出当前待办摘要\n",
    "user_input = \"请给我一个待办事项摘要。\"\n",
    "\n",
    "# 新建线程并请求摘要\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      personal_assistant_id,\n",
    "                                      input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "                                      stream_mode=\"values\"):\n",
    "\n",
    "    # 处理流式返回并打印最终消息\n",
    "    if chunk.event == 'values':\n",
    "        state = chunk.data\n",
    "        convert_to_messages(state[\"messages\"])[-1].pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}