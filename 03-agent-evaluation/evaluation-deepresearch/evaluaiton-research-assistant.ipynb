{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### üîß ÁéØÂ¢ÉÈÖçÁΩÆÂíåÊ£ÄÊü•\n",
    "\n",
    "#### Ê¶ÇËø∞\n",
    "\n",
    "Êú¨ÊïôÁ®ãÈúÄË¶ÅÁâπÂÆöÁöÑÁéØÂ¢ÉÈÖçÁΩÆ‰ª•Á°Æ‰øùÊúÄ‰Ω≥Â≠¶‰π†‰ΩìÈ™å„ÄÇ‰ª•‰∏ãÈÖçÁΩÆÂ∞ÜÂ∏ÆÂä©ÊÇ®Ôºö\n",
    "\n",
    "- ‰ΩøÁî®Áªü‰∏ÄÁöÑcondaÁéØÂ¢ÉÔºöÊøÄÊ¥ªÁªü‰∏ÄÁöÑÂ≠¶‰π†ÁéØÂ¢É\n",
    "- ÈÄöËøáÂõΩÂÜÖÈïúÂÉèÊ∫êÂø´ÈÄüÂÆâË£Ö‰æùËµñÔºöÈÖçÁΩÆpip‰ΩøÁî®Ê∏ÖÂçéÈïúÂÉèÊ∫ê\n",
    "- Âä†ÈÄüÊ®°Âûã‰∏ãËΩΩÔºöËÆæÁΩÆHuggingFaceÈïúÂÉè‰ª£ÁêÜ\n",
    "- Ê£ÄÊü•Á≥ªÁªüÈÖçÁΩÆÔºöÊ£ÄÊü•Á°¨‰ª∂ÂíåËΩØ‰ª∂ÈÖçÁΩÆ\n",
    "\n",
    "#### ÈÖçÁΩÆ\n",
    "\n",
    "- **ÊâÄÈúÄÁéØÂ¢ÉÂèäÂÖ∂‰æùËµñÂ∑≤ÁªèÈÉ®ÁΩ≤Â•Ω**\n",
    "- Âú®`Notebook`Âè≥‰∏äËßíÈÄâÊã©`jupyterÂÜÖÊ†∏`‰∏∫`python(flyai_agent_in_action)`ÔºåÂç≥ÂèØÊâßË°å‰∏ãÊñπ‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\n",
      "=========================================\n",
      "‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ flyai_agent_in_action ÁéØÂ¢É„ÄÇ\n",
      "‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑ Python ÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî® Notebook ÂΩìÂâçÈÄâÊã©ÁöÑ Jupyter ÂÜÖÊ†∏„ÄÇ\n",
      "   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\n",
      "   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(flyai_agent_in_action)'„ÄÇ\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. ÊøÄÊ¥ª conda ÁéØÂ¢É (‰ªÖÂØπÂΩìÂâçÂçïÂÖÉÊ†ºÊúâÊïà)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. Ê£ÄÊü•ÂΩìÂâçÊøÄÊ¥ªÁöÑÁéØÂ¢É\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ flyai_agent_in_action ÁéØÂ¢É„ÄÇ\"\n",
    "    echo \"‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑ Python ÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî® Notebook ÂΩìÂâçÈÄâÊã©ÁöÑ Jupyter ÂÜÖÊ†∏„ÄÇ\"\n",
    "    echo \"   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\"\n",
    "    echo \"   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(flyai_agent_in_action)'„ÄÇ\"\n",
    "else\n",
    "    echo \"‚ùå ÊøÄÊ¥ªÂ§±Ë¥•ÊàñÁéØÂ¢ÉÂêçÁß∞‰∏çÂåπÈÖç„ÄÇÂΩìÂâçÁéØÂ¢É: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"‚ö†Ô∏è ‰∏•ÈáçÊèêÁ§∫: Âª∫ËÆÆÂ∞Ü Notebook ÁöÑ Jupyter **ÂÜÖÊ†∏ (Kernel)** ÂàáÊç¢‰∏∫ 'python(flyai_agent_in_action)'„ÄÇ\"\n",
    "    echo \"   (ÈÄöÂ∏∏‰Ωç‰∫é Notebook Âè≥‰∏äËßíÊàñ 'ÂÜÖÊ†∏' ËèúÂçï‰∏≠)\"\n",
    "    echo \"\"\n",
    "    echo \"üìö Â§áÁî®ÊñπÊ≥ï (‰∏çÊé®Ëçê): Â¶ÇÊûúÊó†Ê≥ïÂàáÊç¢ÂÜÖÊ†∏ÔºåÂàôÂøÖÈ°ªÂú®**ÊØè‰∏™**‰ª£Á†ÅÂçïÂÖÉÊ†ºÁöÑÂ§¥ÈÉ®ÈáçÂ§ç‰ª•‰∏ãÂëΩ‰ª§:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# ÂøÖÈ°ªÂú®ÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩÊâßË°å\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. ËÆæÁΩÆpip ‰∏∫Ê∏ÖÂçéÊ∫ê\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. ËÆæÁΩÆHuggingFace‰ª£ÁêÜ\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# È™åËØÅÔºö‰ΩøÁî®shellÂëΩ‰ª§Ê£ÄÊü•\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ÁéØÂ¢É‰ø°ÊÅØ\n",
      "| È°πÁõÆ         | ‰ø°ÊÅØ                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| Êìç‰ΩúÁ≥ªÁªü     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU ‰ø°ÊÅØ     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| ÂÜÖÂ≠ò‰ø°ÊÅØ     | 2015.36 GB (Available: 1869.00 GB)                                    |\n",
      "| GPU ‰ø°ÊÅØ     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA ‰ø°ÊÅØ    | 12.6                                                                  |\n",
      "| Python ÁâàÊú¨  | 3.12.11                                                               |\n",
      "| Conda ÁâàÊú¨   | conda 25.7.0                                                          |\n",
      "| Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥ | Total: 2014.78 GB, Used: 788.88 GB, Free: 1123.48 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# üîç ÁéØÂ¢É‰ø°ÊÅØÊ£ÄÊü•ËÑöÊú¨\n",
    "#\n",
    "# Êú¨ËÑöÊú¨ÁöÑ‰ΩúÁî®Ôºö\n",
    "# 1. ÂÆâË£Ö pandas Â∫ìÁî®‰∫éÊï∞ÊçÆË°®Ê†ºÂ±ïÁ§∫\n",
    "# 2. Ê£ÄÊü•Á≥ªÁªüÁöÑÂêÑÈ°πÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "# 3. ÁîüÊàêËØ¶ÁªÜÁöÑÁéØÂ¢ÉÊä•ÂëäË°®Ê†º\n",
    "#\n",
    "# ÂØπ‰∫éÂàùÂ≠¶ËÄÖÊù•ËØ¥ÔºåËøô‰∏™Ê≠•È™§Â∏ÆÂä©ÊÇ®Ôºö\n",
    "# - ‰∫ÜËß£ÂΩìÂâçËøêË°åÁéØÂ¢ÉÁöÑÁ°¨‰ª∂ÈÖçÁΩÆ\n",
    "# - Á°ÆËÆ§ÊòØÂê¶Êª°Ë∂≥Ê®°ÂûãËøêË°åÁöÑÊúÄ‰ΩéË¶ÅÊ±Ç\n",
    "# - Â≠¶‰π†Â¶Ç‰ΩïÈÄöËøá‰ª£Á†ÅËé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "\n",
    "# ÂÆâË£Ö pandas Â∫ì - Áî®‰∫éÂàõÂª∫ÂíåÂ±ïÁ§∫Êï∞ÊçÆË°®Ê†º\n",
    "# pandas ÊòØ Python ‰∏≠ÊúÄÊµÅË°åÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂíåÂàÜÊûêÂ∫ì\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # ÂØºÂÖ• platform Ê®°Âùó‰ª•Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "import os # ÂØºÂÖ• os Ê®°Âùó‰ª•‰∏éÊìç‰ΩúÁ≥ªÁªü‰∫§‰∫í\n",
    "import subprocess # ÂØºÂÖ• subprocess Ê®°Âùó‰ª•ËøêË°åÂ§ñÈÉ®ÂëΩ‰ª§\n",
    "import pandas as pd # ÂØºÂÖ• pandas Ê®°ÂùóÔºåÈÄöÂ∏∏Áî®‰∫éÊï∞ÊçÆÂ§ÑÁêÜÔºåËøôÈáåÁî®‰∫éÂàõÂª∫Ë°®Ê†º\n",
    "import shutil # ÂØºÂÖ• shutil Ê®°Âùó‰ª•Ëé∑ÂèñÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ CPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨Ê†∏ÂøÉÊï∞Èáè\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # ÂàùÂßãÂåñ CPU ‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # Â¶ÇÊûúÊòØ Windows Á≥ªÁªü\n",
    "        cpu_info = platform.processor() # ‰ΩøÁî® platform.processor() Ëé∑Âèñ CPU ‰ø°ÊÅØ\n",
    "        try:\n",
    "            # Ëé∑Âèñ Windows ‰∏äÁöÑÊ†∏ÂøÉÊï∞Èáè (ÈúÄË¶Å WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # Â¶ÇÊûú WMI ‰∏çÂèØÁî®ÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # Êõ¥Êñ∞ PATH ÁéØÂ¢ÉÂèòÈáè\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/cpuinfo Êñá‰ª∂Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # Êü•Êâæ‰ª• 'model name'ÂºÄÂ§¥ÁöÑË°å\n",
    "                        if not cpu_info: # Âè™Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™ model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # Êü•Êâæ‰ª• 'cpu cores' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # Êü•Êâæ‰ª• 'processor' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # ËøîÂõû CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "\n",
    "\n",
    "# Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # ÂàùÂßãÂåñÂÜÖÂ≠ò‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    if platform.system() == \"Windows\":\n",
    "        # Âú® Windows ‰∏ä‰∏çÂÆπÊòìÈÄöËøáÊ†áÂáÜÂ∫ìËé∑ÂèñÔºåÈúÄË¶ÅÂ§ñÈÉ®Â∫ìÊàñ PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # ËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞è\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # ËøêË°å sysctl ÂëΩ‰ª§\n",
    "        stdout, stderr = process.communicate() # Ëé∑ÂèñÊ†áÂáÜËæìÂá∫ÂíåÊ†áÂáÜÈîôËØØ\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # Ëß£ÊûêËæìÂá∫ÔºåËé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞èÔºàÂ≠óËäÇÔºâ\n",
    "        mem_gb = mem_bytes / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/meminfo Êñá‰ª∂Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # Êü•Êâæ‰ª• 'MemTotal' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÊÄªÂÜÖÂ≠òÔºàKBÔºâ\n",
    "                    elif line.startswith('MemAvailable'): # Êü•Êâæ‰ª• 'MemAvailable' ÂºÄÂ§¥ÁöÑË°å\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÂèØÁî®ÂÜÖÂ≠òÔºàKBÔºâ\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # ËΩ¨Êç¢‰∏∫ GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫ÊÄªÂÜÖÂ≠ò\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # Ê∑ªÂä†ÂèØÁî®ÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "    return mem_info # ËøîÂõûÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ GPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨ÊòæÂ≠ò\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvidia-smi Ëé∑Âèñ NVIDIA GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # Ëß£ÊûêËæìÂá∫ÔºåËé∑Âèñ GPU ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # Ê†ºÂºèÂåñ GPU ‰ø°ÊÅØ\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # ËøîÂõû GPU ‰ø°ÊÅØÊàñÊèêÁ§∫‰ø°ÊÅØ\n",
    "        else:\n",
    "             # Â∞ùËØï‰ΩøÁî® lshw Ëé∑ÂèñÂÖ∂‰ªñ GPU ‰ø°ÊÅØ (ÈúÄË¶ÅÂÆâË£Ö lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "                     # ÁÆÄÂçïËß£ÊûêËæìÂá∫‰∏≠ÁöÑ product ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # Ê∑ªÂä†ÊúÄÂêé‰∏Ä‰∏™ GPU ÁöÑ‰ø°ÊÅØ\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # Â¶ÇÊûúÊâæÂà∞ GPU ‰ΩÜ‰ø°ÊÅØÊó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # Â¶ÇÊûú‰∏§‰∏™ÂëΩ‰ª§ÈÉΩÊâæ‰∏çÂà∞ GPUÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ lshw ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvidia-smi ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# Ëé∑Âèñ CUDA ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvcc --version Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # Êü•ÊâæÂåÖÂê´ 'release' ÁöÑË°å\n",
    "                    return line.split('release ')[1].split(',')[0] # Ëß£ÊûêË°åÔºåÊèêÂèñÁâàÊú¨Âè∑\n",
    "        return \"CUDA not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ CUDA ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvcc ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ Python ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_python_version():\n",
    "    return platform.python_version() # Ëé∑Âèñ Python ÁâàÊú¨\n",
    "\n",
    "# Ëé∑Âèñ Conda ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® conda --version Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            return result.stdout.strip() # ËøîÂõû Conda ÁâàÊú¨\n",
    "        return \"Conda not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ Conda ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ conda ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # Ëé∑ÂèñÊ†πÁõÆÂΩïÁöÑÁ£ÅÁõò‰ΩøÁî®ÊÉÖÂÜµ\n",
    "        total_gb = total / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        used_gb = used / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        free_gb = free / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # Â¶ÇÊûúËé∑Âèñ‰ø°ÊÅØÂá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁéØÂ¢É‰ø°ÊÅØ\n",
    "os_name = platform.system() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÂêçÁß∞\n",
    "os_version = platform.release() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÁâàÊú¨\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # Âú® Linux ‰∏äÂ∞ùËØïËé∑ÂèñÂèëË°åÁâàÂíåÁâàÊú¨\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # Êü•ÊâæÂåÖÂê´ 'Description:' ÁöÑË°å\n",
    "                    os_version = line.split('Description:')[1].strip() # ÊèêÂèñÊèèËø∞‰ø°ÊÅØ‰Ωú‰∏∫ÁâàÊú¨\n",
    "                    break # ÊâæÂà∞ÂêéÈÄÄÂá∫Âæ™ÁéØ\n",
    "                elif 'Release:' in line: # Êü•ÊâæÂåÖÂê´ 'Release:' ÁöÑË°å\n",
    "                     os_version = line.split('Release:')[1].strip() # ÊèêÂèñÁâàÊú¨Âè∑\n",
    "                     # Â∞ùËØïËé∑Âèñ codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # Â∞Ü codename Ê∑ªÂä†Âà∞ÁâàÊú¨‰ø°ÊÅØ‰∏≠\n",
    "                     except:\n",
    "                         pass # Â¶ÇÊûúËé∑Âèñ codename Â§±Ë¥•ÂàôÂøΩÁï•\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release ÂèØËÉΩÊú™ÂÆâË£ÖÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ÁªÑÂêàÂÆåÊï¥ÁöÑÊìç‰ΩúÁ≥ªÁªü‰ø°ÊÅØ\n",
    "cpu_info = get_cpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "memory_info = get_memory_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "gpu_info = get_gpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "cuda_version = get_cuda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "python_version = get_python_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Python ÁâàÊú¨\n",
    "conda_version = get_conda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "disk_info = get_disk_space() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# ÂàõÂª∫Áî®‰∫éÂ≠òÂÇ®Êï∞ÊçÆÁöÑÂ≠óÂÖ∏\n",
    "env_data = {\n",
    "    \"È°πÁõÆ\": [ # È°πÁõÆÂêçÁß∞ÂàóË°®\n",
    "        \"Êìç‰ΩúÁ≥ªÁªü\",\n",
    "        \"CPU ‰ø°ÊÅØ\",\n",
    "        \"ÂÜÖÂ≠ò‰ø°ÊÅØ\",\n",
    "        \"GPU ‰ø°ÊÅØ\",\n",
    "        \"CUDA ‰ø°ÊÅØ\",\n",
    "        \"Python ÁâàÊú¨\",\n",
    "        \"Conda ÁâàÊú¨\",\n",
    "        \"Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\" # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\n",
    "    ],\n",
    "    \"‰ø°ÊÅØ\": [ # ÂØπÂ∫îÁöÑ‰ø°ÊÅØÂàóË°®\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ÂàõÂª∫‰∏Ä‰∏™ pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# ÊâìÂç∞Ë°®Ê†º\n",
    "print(\"### ÁéØÂ¢É‰ø°ÊÅØ\") # ÊâìÂç∞Ê†áÈ¢ò\n",
    "print(df.to_markdown(index=False)) # Â∞Ü DataFrame ËΩ¨Êç¢‰∏∫ Markdown Ê†ºÂºèÂπ∂ÊâìÂç∞Ôºå‰∏çÂåÖÂê´Á¥¢Âºï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b",
   "metadata": {
    "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b"
   },
   "source": [
    "# üî¨ Ê∑±Â∫¶Á†îÁ©∂Âä©Êâã - Êô∫ËÉΩ‰ΩìËØÑ‰º∞Áâà\n",
    "\n",
    "## üìñ ÊïôÁ®ãÊ¶ÇËø∞\n",
    "\n",
    "Êú¨ÊïôÁ®ãÂ∞ÜÂú®Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÁöÑÂü∫Á°Ä‰∏äÔºåÈõÜÊàê **Langfuse** ÂèØËßÇÊµãÊÄßÂπ≥Âè∞ÔºåÂÆûÁé∞Êô∫ËÉΩ‰ΩìÁöÑÂÖ®Èù¢ËØÑ‰º∞ÂíåÁõëÊéß„ÄÇÊàë‰ª¨Â∞ÜÂ≠¶‰π†Â¶Ç‰ΩïÔºö\n",
    "\n",
    "- **üîç ÂÆûÊó∂ËøΩË∏™**ÔºöÁõëÊéßÁ†îÁ©∂Âä©ÊâãÁöÑÊØè‰∏™ÊâßË°åÊ≠•È™§\n",
    "- **üìä ÊÄßËÉΩËØÑ‰º∞**ÔºöÂàÜÊûêÊàêÊú¨„ÄÅÂª∂Ëøü„ÄÅÂáÜÁ°ÆÊÄßÁ≠âÂÖ≥ÈîÆÊåáÊ†á  \n",
    "- **üë• Áî®Êà∑ÂèçÈ¶à**ÔºöÊî∂ÈõÜÂíåÂàÜÊûêÁî®Êà∑ÂØπÁ†îÁ©∂ÁªìÊûúÁöÑÂèçÈ¶à\n",
    "- **üéØ Á¶ªÁ∫øËØÑ‰º∞**Ôºö‰ΩøÁî®Âü∫ÂáÜÊï∞ÊçÆÈõÜËøõË°åÁ≥ªÁªüÊÄßÊµãËØï\n",
    "\n",
    "## üéØ Á†îÁ©∂Âä©ÊâãÂõûÈ°æ\n",
    "\n",
    "Êàë‰ª¨ÁöÑÊ∑±Â∫¶Á†îÁ©∂Âä©ÊâãÊòØ‰∏Ä‰∏™Âü∫‰∫é LangGraph ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÔºö\n",
    "\n",
    "### Ê†∏ÂøÉÂäüËÉΩÊ®°Âùó\n",
    "- **üìù ÂàÜÊûêÂ∏àÁîüÊàê**ÔºöÊ†πÊçÆÁ†îÁ©∂‰∏ªÈ¢òËá™Âä®ÂàõÂª∫‰∏ì‰∏öÂàÜÊûêÂ∏àÂõ¢Èòü\n",
    "- **ü§ù ‰∫∫Êú∫ÂçèÂêå**ÔºöÈÄöËøá‰∫∫Á±ªÂèçÈ¶à‰ºòÂåñÂàÜÊûêÂ∏àÈÖçÁΩÆ\n",
    "- **üí¨ ‰∏ìÂÆ∂ËÆøË∞à**ÔºöÊØè‰ΩçÂàÜÊûêÂ∏à‰∏é AI ‰∏ìÂÆ∂ËøõË°åÊ∑±Â∫¶ÂØπËØù\n",
    "- **üîç Âπ∂Ë°åÊêúÁ¥¢**Ôºö‰ªéÂ§ö‰∏™Ê∫êÔºàÁΩëÁªú„ÄÅÁôæÁßëÔºâÊ£ÄÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ\n",
    "- **üìÑ Êä•ÂëäÁîüÊàê**ÔºöÂ∞ÜËÆøË∞àÁªìÊûúÊï¥Âêà‰∏∫ÁªìÊûÑÂåñÊä•Âëä\n",
    "\n",
    "### üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁöÑÈáçË¶ÅÊÄß\n",
    "\n",
    "Âú®ÈÉ®ÁΩ≤Á†îÁ©∂Âä©ÊâãÂà∞Áîü‰∫ßÁéØÂ¢ÉÂâçÔºåËØÑ‰º∞ÊòØÁ°Æ‰øùÁ≥ªÁªüË¥®ÈáèÁöÑÂÖ≥ÈîÆÁéØËäÇÔºö\n",
    "\n",
    "- **üêõ ÈóÆÈ¢òËØäÊñ≠**ÔºöÂø´ÈÄüÂÆö‰ΩçÁ†îÁ©∂ÊµÅÁ®ã‰∏≠ÁöÑÈóÆÈ¢òËäÇÁÇπ\n",
    "- **üìà ÊÄßËÉΩ‰ºòÂåñ**ÔºöËØÜÂà´È´òÊàêÊú¨Êìç‰ΩúÂπ∂ËøõË°å‰ºòÂåñ\n",
    "- **üéØ Ë¥®Èáè‰øùËØÅ**ÔºöÁ°Æ‰øùÁîüÊàêÁöÑÁ†îÁ©∂Êä•ÂëäËææÂà∞È¢ÑÊúüÊ†áÂáÜ\n",
    "- **üìä ÊåÅÁª≠ÊîπËøõ**ÔºöÈÄöËøáÊï∞ÊçÆÈ©±Âä®ÁöÑÊñπÂºèÊèêÂçáÁ≥ªÁªüË°®Áé∞\n",
    "\n",
    "![Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÊû∂ÊûÑÂõæ](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb164d61c93d48e604091_research-assistant1.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Êú¨ÊïôÁ®ãÁâπËâ≤\n",
    "\n",
    "- **üìö ÂàùÂ≠¶ËÄÖÂèãÂ•Ω**ÔºöËØ¶ÁªÜÁöÑ‰∏≠ÊñáÊ≥®ÈáäÂíåÊ¶ÇÂøµËß£Èáä\n",
    "- **üîß ÂÆûÊàòÂØºÂêë**ÔºöÂü∫‰∫éÁúüÂÆû‰∏öÂä°Âú∫ÊôØÁöÑËØÑ‰º∞ÊñπÊ°à\n",
    "- **üìä ÂÖ®Èù¢ÁõëÊéß**ÔºöË¶ÜÁõñÂú®Á∫øÂíåÁ¶ªÁ∫ø‰∏§ÁßçËØÑ‰º∞Ê®°Âºè\n",
    "- **üéØ ÂèØÊìç‰Ωú**ÔºöÊèê‰æõÂÖ∑‰ΩìÁöÑ‰ºòÂåñÂª∫ËÆÆÂíåÊúÄ‰Ω≥ÂÆûË∑µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6",
   "metadata": {
    "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# üì¶ ÂÆâË£ÖÈ°πÁõÆÊâÄÈúÄÁöÑPythonÂåÖÔºàÂ∏¶ËØÑ‰º∞ÂäüËÉΩÔºâ\n",
    "# ‰ΩøÁî® %%capture --no-stderr Êù•ÈöêËóèÂÆâË£ÖËøáÁ®ã‰∏≠ÁöÑËæìÂá∫‰ø°ÊÅØÔºå‰øùÊåÅnotebookÊï¥Ê¥Å\n",
    "\n",
    "# üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁâàÊú¨ÂåÖÂê´È¢ùÂ§ñÁöÑ Langfuse ÊîØÊåÅ\n",
    "%pip install langgraph==0.6.7 langchain_openai==0.3.31 langchain_community==0.3.27 langchain_core==0.3.75 tavily-python==0.7.12 wikipedia==1.4.0 langfuse==3.3.0\n",
    "\n",
    "# üìö ÂêÑÂåÖÂäüËÉΩËØ¥ÊòéÔºö\n",
    "# Ê†∏ÂøÉÊ°ÜÊû∂Ôºö\n",
    "# - langgraph==0.6.7: LangGraphÊ°ÜÊû∂ÔºåÁî®‰∫éÊûÑÂª∫Â§öÊô∫ËÉΩ‰ΩìÂ∑•‰ΩúÊµÅ\n",
    "# - langchain_openai==0.3.31: LangChainÁöÑOpenAIÈõÜÊàêÔºåÁî®‰∫éË∞ÉÁî®GPTÊ®°Âûã\n",
    "# - langchain_community==0.3.27: LangChainÁ§æÂå∫Â∑•ÂÖ∑ÈõÜÔºåÂåÖÂê´ÂêÑÁßçÁ¨¨‰∏âÊñπÈõÜÊàê\n",
    "# - langchain_core==0.3.75: LangChainÊ†∏ÂøÉÁªÑ‰ª∂ÔºåÊèê‰æõÂü∫Á°ÄÂäüËÉΩ\n",
    "\n",
    "# Êï∞ÊçÆÊ£ÄÁ¥¢Ôºö\n",
    "# - tavily-python==0.7.12: TavilyÊêúÁ¥¢APIÂÆ¢Êà∑Á´ØÔºåÁî®‰∫éÁΩëÁªúÊêúÁ¥¢\n",
    "# - wikipedia==1.4.0: Áª¥Âü∫ÁôæÁßëAPIÂÆ¢Êà∑Á´ØÔºåÁî®‰∫éÁôæÁßëÊêúÁ¥¢\n",
    "# - baike_loader.py: ÁôæÂ∫¶ÁôæÁßëÂä†ËΩΩÂô®ÔºàÊú¨‰ªìÂ∫ìÂÜÖÁΩÆÔºâ\n",
    "\n",
    "# üî¨ ËØÑ‰º∞‰∏éÁõëÊéßÔºàÊñ∞Â¢ûÔºâÔºö\n",
    "# - langfuse==3.3.0: LLMÂ∫îÁî®ÁöÑÂèØËßÇÊµãÊÄßÂíåËØÑ‰º∞Âπ≥Âè∞ÔºåÊîØÊåÅËøΩË∏™„ÄÅÁõëÊéßÂíåËØÑ‰º∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914",
   "metadata": {
    "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914"
   },
   "source": [
    "## ÁéØÂ¢ÉÂáÜÂ§áÔºàSetupÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba917800-10e4-4e2a-8e9e-30893b731e97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba917800-10e4-4e2a-8e9e-30893b731e97",
    "outputId": "d651b4af-0c90-457a-f4c7-33c8d2b91688"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "OPENAI_BASE_URL:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ ÈÖçÁΩÆ Langfuse ËØÑ‰º∞Âπ≥Âè∞...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGFUSE_PUBLIC_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "LANGFUSE_SECRET_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "LANGFUSE_HOST:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API ÂØÜÈí•ÈÖçÁΩÆÂÆåÊàêÔºÅ\n",
      "üìä Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÂäüËÉΩÂ∑≤ÂêØÁî®\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    ÂÆâÂÖ®ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÁöÑËæÖÂä©ÂáΩÊï∞\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        var (str): ÁéØÂ¢ÉÂèòÈáèÂêçÁß∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        - Ê£ÄÊü•ÁéØÂ¢ÉÂèòÈáèÊòØÂê¶Â∑≤Â≠òÂú®\n",
    "        - Â¶ÇÊûú‰∏çÂ≠òÂú®ÔºåÂàôÈÄöËøágetpassÂÆâÂÖ®Âú∞Ëé∑ÂèñÁî®Êà∑ËæìÂÖ•\n",
    "        - Â∞ÜÁî®Êà∑ËæìÂÖ•ËÆæÁΩÆ‰∏∫ÁéØÂ¢ÉÂèòÈáèÂÄº\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ü§ñ ËÆæÁΩÆ OpenAI API ÂØÜÈí•\n",
    "# ËøôÊòØ‰ΩøÁî® OpenAI Ê®°ÂûãÊâÄÂøÖÈúÄÁöÑÔºåÁî®‰∫éË∫´‰ªΩÈ™åËØÅ\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ËÆæÁΩÆ OpenAI API‰ª£ÁêÜÂú∞ÂùÄ (‰æãÂ¶ÇÔºöhttps://api.apiyi.com/v1Ôºâ\n",
    "# Áî®‰∫éÈÖçÁΩÆAPIËØ∑Ê±ÇÁöÑÂü∫Á°ÄURLÔºåÊîØÊåÅ‰ΩøÁî®‰ª£ÁêÜÊúçÂä°\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# üî¨ ËÆæÁΩÆ Langfuse API ÂØÜÈí•ÔºàÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÂøÖÈúÄÔºâ\n",
    "# Langfuse ÊòØÁî®‰∫é LLM Â∫îÁî®ÂèØËßÇÊµãÊÄßÂíåËØÑ‰º∞ÁöÑÂπ≥Âè∞\n",
    "# Ê≥®ÂÜåÂú∞ÂùÄÔºöhttps://cloud.langfuse.com\n",
    "print(\"üî¨ ÈÖçÁΩÆ Langfuse ËØÑ‰º∞Âπ≥Âè∞...\")\n",
    "\n",
    "# ÂÖ¨ÂºÄÂØÜÈí•ÔºöÁî®‰∫éÊ†áËØÜ‰Ω†ÁöÑÈ°πÁõÆ\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# ÁßòÂØÜÂØÜÈí•ÔºöÁî®‰∫éËÆ§ËØÅÔºåËØ∑Â¶•ÂñÑ‰øùÁÆ°\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# ÊúçÂä°Âô®Âú∞ÂùÄÔºöÈÄâÊã©Á¶ª‰Ω†ÊúÄËøëÁöÑÂå∫Âüü\n",
    "# üá™üá∫ Ê¨ßÁõüÂå∫Âüü(Êé®Ëçê) https://cloud.langfuse.com\n",
    "# üá∫üá∏ ÁæéÂõΩÂå∫Âüü https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "print(\"‚úÖ API ÂØÜÈí•ÈÖçÁΩÆÂÆåÊàêÔºÅ\")\n",
    "print(\"üìä Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÂäüËÉΩÂ∑≤ÂêØÁî®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe9ff57-0826-4669-b88b-4d0501a509f5",
   "metadata": {
    "id": "afe9ff57-0826-4669-b88b-4d0501a509f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Langfuse ÂÆ¢Êà∑Á´ØËøûÊé•ÊàêÂäüÔºÅ\n",
      "üìä Êô∫ËÉΩ‰ΩìËøΩË∏™ÂíåËØÑ‰º∞ÂäüËÉΩÂ∑≤Â∞±Áª™\n",
      "üîó ËÆøÈóÆ‰ª™Ë°®Êùø: https://cloud.langfuse.com/traces\n",
      "\n",
      "üöÄ Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÔºàËØÑ‰º∞ÁâàÔºâÂàùÂßãÂåñÂÆåÊàêÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# üîß ÂàùÂßãÂåñÊ†∏ÂøÉÁªÑ‰ª∂ÔºöLLM Âíå Langfuse ÂÆ¢Êà∑Á´Ø\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langfuse import get_client\n",
    "\n",
    "# ü§ñ ÂàùÂßãÂåñOpenAIËÅäÂ§©Ê®°Âûã\n",
    "# ‰ΩøÁî®GPT-4oÊ®°ÂûãÔºåËøôÊòØOpenAIÊúÄÊñ∞ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã\n",
    "# temperature=0 Á°Æ‰øùËæìÂá∫ÁªìÊûúÂÖ∑ÊúâÁ°ÆÂÆöÊÄßÂíå‰∏ÄËá¥ÊÄßÔºåÈÄÇÂêàÈúÄË¶ÅÁ®≥ÂÆöËæìÂá∫ÁöÑÂú∫ÊôØ\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# üî¨ ÂàùÂßãÂåñ Langfuse ÂÆ¢Êà∑Á´ØÔºàÊô∫ËÉΩ‰ΩìËØÑ‰º∞Ê†∏ÂøÉÔºâ\n",
    "# get_client() ‰ºöËá™Âä®‰ªéÁéØÂ¢ÉÂèòÈáè‰∏≠ËØªÂèñ API Âá≠ËØÅ\n",
    "langfuse = get_client()\n",
    "\n",
    "# ‚úÖ È™åËØÅ Langfuse ËøûÊé•\n",
    "if langfuse.auth_check():\n",
    "    print(\"‚úÖ Langfuse ÂÆ¢Êà∑Á´ØËøûÊé•ÊàêÂäüÔºÅ\")\n",
    "    print(\"üìä Êô∫ËÉΩ‰ΩìËøΩË∏™ÂíåËØÑ‰º∞ÂäüËÉΩÂ∑≤Â∞±Áª™\")\n",
    "    print(\"üîó ËÆøÈóÆ‰ª™Ë°®Êùø: https://cloud.langfuse.com/traces\")\n",
    "else:\n",
    "    print(\"‚ùå Langfuse ËÆ§ËØÅÂ§±Ë¥•ÔºÅËØ∑Ê£ÄÊü• API ÂØÜÈí•ÈÖçÁΩÆ\")\n",
    "    print(\"üí° ÊèêÁ§∫ÔºöËØ∑Á°Æ‰øù LANGFUSE_PUBLIC_KEY„ÄÅLANGFUSE_SECRET_KEY Âíå LANGFUSE_HOST Ê≠£Á°ÆËÆæÁΩÆ\")\n",
    "\n",
    "print(\"\\nüöÄ Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÔºàËØÑ‰º∞ÁâàÔºâÂàùÂßãÂåñÂÆåÊàêÔºÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419257b-2c6b-4d68-ae38-4a266cc02982",
   "metadata": {
    "id": "3419257b-2c6b-4d68-ae38-4a266cc02982"
   },
   "source": [
    "Êàë‰ª¨Â∞Ü‰ΩøÁî® [LangSmith](https://docs.smith.langchain.com/) ËøõË°å[ÈìæË∑ØËøΩË∏™ÔºàtracingÔºâ](https://docs.smith.langchain.com/concepts/tracing)Ôºå‰æø‰∫éË∞ÉËØï‰∏éÂàÜÊûê„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d",
    "outputId": "9ef35fad-1514-41ed-e436-bdf87699f20e"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ËøΩË∏™ÈÖçÁΩÆËØ¥ÊòéÔºö\n",
      "  üî¨ ‰∏ªË¶Å‰ΩøÁî® Langfuse ËøõË°åÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÂíåÁõëÊéß\n",
      "  üìà ÂèØÈÄâÂêØÁî® LangSmith ËøõË°åÈìæË∑ØËøΩË∏™Ë°•ÂÖÖ\n",
      "  üéØ ‰∏§‰∏™Âπ≥Âè∞ÈÖçÂêà‰ΩøÁî®ÔºåÊèê‰æõÂÖ®Êñπ‰ΩçÁöÑÂèØËßÇÊµãÊÄß\n"
     ]
    }
   ],
   "source": [
    "# üî¨ ËÆæÁΩÆ Langfuse ËøΩË∏™ÈÖçÁΩÆÔºàÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÂøÖÈúÄÔºâ\n",
    "# LangSmithÂíåLangfuseÈÉΩÊòØ‰ºòÁßÄÁöÑËøΩË∏™Âπ≥Âè∞ÔºåËøôÈáåÊàë‰ª¨‰ΩøÁî®LangfuseËøõË°åËØÑ‰º∞\n",
    "\n",
    "# ËÆæÁΩÆLangSmithËøΩË∏™ÈÖçÁΩÆÔºàÂèØÈÄâÔºåÁî®‰∫éÈ¢ùÂ§ñÁöÑÈìæË∑ØËøΩË∏™Ôºâ\n",
    "# LangSmithÊòØLangChainÁöÑÂÆòÊñπÁõëÊéßÂíåË∞ÉËØïÂπ≥Âè∞\n",
    "_set_env(\"LANGSMITH_API_KEY\")  # ËÆæÁΩÆLangSmith APIÂØÜÈí•ÔºàÂèØÈÄâÔºâ\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # ÂêØÁî®ÈìæË∑ØËøΩË∏™ÂäüËÉΩ\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"DeepResearch-Assistant-Evaluation\" # ËÆæÁΩÆÈ°πÁõÆÂêçÁß∞\n",
    "\n",
    "print(\"üìä ËøΩË∏™ÈÖçÁΩÆËØ¥ÊòéÔºö\")\n",
    "print(\"  üî¨ ‰∏ªË¶Å‰ΩøÁî® Langfuse ËøõË°åÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÂíåÁõëÊéß\")\n",
    "print(\"  üìà ÂèØÈÄâÂêØÁî® LangSmith ËøõË°åÈìæË∑ØËøΩË∏™Ë°•ÂÖÖ\")\n",
    "print(\"  üéØ ‰∏§‰∏™Âπ≥Âè∞ÈÖçÂêà‰ΩøÁî®ÔºåÊèê‰æõÂÖ®Êñπ‰ΩçÁöÑÂèØËßÇÊµãÊÄß\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea",
   "metadata": {
    "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea"
   },
   "source": [
    "## ÂàÜÊûêÂ∏àÔºö‰∫∫Êú∫ÂçèÂêåÔºàHuman-In-The-LoopÔºâ\n",
    "\n",
    "ÈÄöËøá‰∫∫Êú∫ÂçèÂêåÁöÑÊñπÂºèÁîüÊàêÂπ∂ÂÆ°Ê†∏ÂàÜÊûêÂ∏àËßíËâ≤„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e",
   "metadata": {
    "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    \"\"\"\n",
    "    ÂàÜÊûêÂ∏àÊï∞ÊçÆÊ®°Âûã\n",
    "\n",
    "    Áî®‰∫éÂÆö‰πâÊØè‰∏™AIÂàÜÊûêÂ∏àÁöÑÂü∫Êú¨‰ø°ÊÅØÂíåËßíËâ≤ÁâπÂæÅ\n",
    "    ÊØè‰∏™ÂàÜÊûêÂ∏à‰ª£Ë°®‰∏Ä‰∏™ÁâπÂÆöÁöÑÁ†îÁ©∂ËßÜËßíÂíå‰∏ìÈïøÈ¢ÜÂüü\n",
    "    \"\"\"\n",
    "    affiliation: str = Field(\n",
    "        description=\"ÂàÜÊûêÂ∏àÁöÑ‰∏ªË¶ÅÈö∂Â±ûÊú∫ÊûÑÊàñÁªÑÁªá\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"ÂàÜÊûêÂ∏àÂßìÂêç\"\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"ÂàÜÊûêÂ∏àÂú®Á†îÁ©∂‰∏ªÈ¢ò‰∏≠ÁöÑÂÖ∑‰ΩìËßíËâ≤ÂÆö‰Ωç\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"ÂàÜÊûêÂ∏àÁöÑÂÖ≥Ê≥®ÁÑ¶ÁÇπ„ÄÅÂÖ≥ÂàáÁÇπÂíåÂä®Êú∫ÁöÑËØ¶ÁªÜÊèèËø∞\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        \"\"\"\n",
    "        ÁîüÊàêÂàÜÊûêÂ∏à‰∫∫ËÆæÊèèËø∞\n",
    "\n",
    "        ËøîÂõû:\n",
    "            str: Ê†ºÂºèÂåñÁöÑÂàÜÊûêÂ∏à‰∫∫ËÆæ‰ø°ÊÅØÔºåÁî®‰∫éÂêéÁª≠ÁöÑAIÂØπËØù‰∏≠\n",
    "        \"\"\"\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    \"\"\"\n",
    "    ÂàÜÊûêÂ∏àÈõÜÂêàÊï∞ÊçÆÊ®°Âûã\n",
    "\n",
    "    Áî®‰∫éÂ≠òÂÇ®ÂíåÁÆ°ÁêÜÂ§ö‰∏™ÂàÜÊûêÂ∏àÁöÑ‰ø°ÊÅØ\n",
    "    ÊîØÊåÅÁªìÊûÑÂåñËæìÂá∫ÔºåÁ°Æ‰øùAIÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØÊ†ºÂºèÊ≠£Á°Æ\n",
    "    \"\"\"\n",
    "    analysts: List[Analyst] = Field(\n",
    "        description=\"ÂåÖÂê´ÊâÄÊúâÂàÜÊûêÂ∏àËßíËâ≤ÂíåÈö∂Â±ûÊú∫ÊûÑÁöÑÁªºÂêàÂàóË°®\",\n",
    "    )\n",
    "\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    \"\"\"\n",
    "    ÂàÜÊûêÂ∏àÁîüÊàêÁä∂ÊÄÅÁÆ°ÁêÜ\n",
    "\n",
    "    Áî®‰∫éÂú®LangGraphÂ∑•‰ΩúÊµÅ‰∏≠ÁÆ°ÁêÜÂàÜÊûêÂ∏àÁîüÊàêËøáÁ®ãÁöÑÁä∂ÊÄÅ‰ø°ÊÅØ\n",
    "    \"\"\"\n",
    "    topic: str  # Á†îÁ©∂‰∏ªÈ¢ò\n",
    "    max_analysts: int  # ÂàÜÊûêÂ∏àÊï∞Èáè‰∏äÈôê\n",
    "    human_analyst_feedback: str  # ‰∫∫Á±ªÂèçÈ¶à‰ø°ÊÅØÔºåÁî®‰∫é‰∫∫Êú∫ÂçèÂêåË∞ÉÊï¥\n",
    "    analysts: List[Analyst]  # ÁîüÊàêÁöÑÂàÜÊûêÂ∏àÂàóË°®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
    "outputId": "a7d4bbfb-b9e1-4c81-d490-f8f9214425ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁâàÂàÜÊûêÂ∏àÁîüÊàêÂ∑•‰ΩúÊµÅÊûÑÂª∫ÂÆåÊàêÔºÅ\n",
      "üìä ÊâÄÊúâËäÇÁÇπË∞ÉÁî®ÈÉΩ‰ºöËá™Âä®ËÆ∞ÂΩïÂà∞ Langfuse Âπ≥Âè∞\n",
      "üéØ ‰∏ªË¶ÅËØÑ‰º∞ÊåáÊ†áÔºöLLM Ë∞ÉÁî®Ê¨°Êï∞„ÄÅ‰ª§ÁâåÊ∂àËÄó„ÄÅÊâßË°åÊó∂Èó¥„ÄÅË∑ØÁî±ÂÜ≥Á≠ñ\n",
      "\n",
      "ÂõæÂèØËßÜÂåñÔºö\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# üîß ÂØºÂÖ•Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÊâÄÈúÄÁöÑËøΩË∏™ÁªÑ‰ª∂\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# üî¨ ÂØºÂÖ• Langfuse ËøΩË∏™Â§ÑÁêÜÂô®ÔºàÊô∫ËÉΩ‰ΩìËØÑ‰º∞Ê†∏ÂøÉÔºâ\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ÂàÜÊûêÂ∏àÁîüÊàêÊåá‰ª§Ê®°Êùø\n",
    "# Ëøô‰∏™ÊèêÁ§∫ËØçÊåáÂØºAIÂ¶Ç‰ΩïÊ†πÊçÆÁ†îÁ©∂‰∏ªÈ¢òÂàõÂª∫ÂêàÈÄÇÁöÑÂàÜÊûêÂ∏àÂõ¢Èòü\n",
    "analyst_instructions=\"\"\"‰Ω†ÈúÄË¶ÅÂàõÂª∫‰∏ÄÁªÑ AI ÂàÜÊûêÂ∏à‰∫∫ËÆæ„ÄÇËØ∑‰∏•Ê†ºÈÅµÂæ™‰ª•‰∏ãÊåáÂºïÔºö\n",
    "\n",
    "1. ÂÖàÂÆ°ÈòÖÁ†îÁ©∂‰∏ªÈ¢òÔºö\n",
    "{topic}\n",
    "\n",
    "2. Êü•ÁúãÔºàÂèØÈÄâÁöÑÔºâÁºñËæëÂèçÈ¶àÔºåÂÆÉÂ∞ÜÊåáÂØºÂàÜÊûêÂ∏àÁöÑ‰∫∫ËÆæÂàõÂª∫Ôºö\n",
    "\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. Âü∫‰∫é‰∏äËø∞ÊñáÊ°£‰∏é/ÊàñÂèçÈ¶àÔºåËØÜÂà´ÊúÄÂÄºÂæóÂÖ≥Ê≥®ÁöÑ‰∏ªÈ¢ò„ÄÇ\n",
    "\n",
    "4. ÈÄâÂá∫Ââç {max_analysts} ‰∏™‰∏ªÈ¢ò„ÄÇ\n",
    "\n",
    "5. ‰∏∫ÊØè‰∏™‰∏ªÈ¢òÂàÜÈÖç‰∏Ä‰ΩçÂàÜÊûêÂ∏à„ÄÇ\"\"\"\n",
    "\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    ÂàõÂª∫ÂàÜÊûêÂ∏à‰∫∫ËÆæÁöÑÊ†∏ÂøÉÂáΩÊï∞ÔºàÂ∏¶Êô∫ËÉΩ‰ΩìËØÑ‰º∞Ôºâ\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Ê†πÊçÆÁ†îÁ©∂‰∏ªÈ¢òÂíå‰∫∫Á±ªÂèçÈ¶àÁîüÊàêÂàÜÊûêÂ∏àÂõ¢Èòü\n",
    "        2. ‰ΩøÁî®ÁªìÊûÑÂåñËæìÂá∫Á°Æ‰øùÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØÊ†ºÂºèÊ≠£Á°Æ\n",
    "        3. Â∞ÜÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØÂ≠òÂÇ®Âà∞Áä∂ÊÄÅ‰∏≠\n",
    "        4. üî¨ Ëá™Âä®ËÆ∞ÂΩïÂà∞ Langfuse ËøõË°åÊÄßËÉΩËøΩË∏™\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´Á†îÁ©∂‰∏ªÈ¢ò„ÄÅÂàÜÊûêÂ∏àÊï∞ÈáèÈôêÂà∂Âíå‰∫∫Á±ªÂèçÈ¶àÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÁîüÊàêÁöÑÂàÜÊûêÂ∏àÂàóË°®ÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # ‰ªéÁä∂ÊÄÅ‰∏≠ÊèêÂèñÂøÖË¶Å‰ø°ÊÅØ\n",
    "    topic = state['topic']\n",
    "    max_analysts = state['max_analysts']\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback', '')\n",
    "\n",
    "    # ÈÖçÁΩÆÁªìÊûÑÂåñËæìÂá∫ÔºåÁ°Æ‰øùËøîÂõûPerspectivesÊ†ºÂºèÁöÑÊï∞ÊçÆ\n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØÔºåÂåÖÂê´Á†îÁ©∂‰∏ªÈ¢ò„ÄÅÂèçÈ¶àÂíåÊï∞ÈáèÈôêÂà∂\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts\n",
    "    )\n",
    "\n",
    "    # üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞Ôºö‰ΩøÁî® Langfuse ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®ËÆ∞ÂΩïËøôÊ¨°Ë∞ÉÁî®\n",
    "    with langfuse.start_as_current_span(name=\"create_analysts\") as span:\n",
    "        # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàêÂàÜÊûêÂ∏àÈõÜÂêà\n",
    "        analysts = structured_llm.invoke([\n",
    "            SystemMessage(content=system_message),\n",
    "            HumanMessage(content=\"ÁîüÊàêÂàÜÊûêÂ∏àÈõÜÂêà„ÄÇ\")\n",
    "        ])\n",
    "        \n",
    "        # ËÆ∞ÂΩïËæìÂÖ•ËæìÂá∫Âà∞ Langfuse\n",
    "        span.update_trace(\n",
    "            input={\"topic\": topic, \"max_analysts\": max_analysts, \"feedback\": human_analyst_feedback},\n",
    "            output={\"analysts_count\": len(analysts.analysts), \"analysts\": [a.name for a in analysts.analysts]}\n",
    "        )\n",
    "\n",
    "    # Â∞ÜÂàÜÊûêÂ∏àÂàóË°®ÂÜôÂÖ•Áä∂ÊÄÅÔºå‰æõÂêéÁª≠ËäÇÁÇπ‰ΩøÁî®\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    ‰∫∫Êú∫ÂçèÂêå‰∏≠Êñ≠ÁÇπËäÇÁÇπÔºàÂ∏¶ËØÑ‰º∞ËøΩË∏™Ôºâ\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        - ‰Ωú‰∏∫Â∑•‰ΩúÊµÅÁöÑ‰∏≠Êñ≠ÁÇπÔºåÂÖÅËÆ∏‰∫∫Á±ªÂÆ°Êü•Âíå‰øÆÊîπÁîüÊàêÁöÑÂàÜÊûêÂ∏à\n",
    "        - ËøôÊòØ‰∏Ä‰∏™Á©∫Êìç‰ΩúËäÇÁÇπÔºå‰∏ªË¶ÅÁî®‰∫éÊµÅÁ®ãÊéßÂà∂\n",
    "        - ‰∫∫Á±ªÂèØ‰ª•Âú®Ê≠§ËäÇÁÇπÊèê‰æõÂèçÈ¶àÔºåÁ≥ªÁªü‰ºöÊ†πÊçÆÂèçÈ¶àÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "        - üî¨ ËÆ∞ÂΩï‰∫∫Êú∫‰∫§‰∫íÊï∞ÊçÆÂà∞ Langfuse\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂΩìÂâçÁä∂ÊÄÅÂØπË±°\n",
    "    \"\"\"\n",
    "    # üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÔºöËÆ∞ÂΩï‰∫∫Êú∫‰∫§‰∫íËäÇÁÇπ\n",
    "    with langfuse.start_as_current_span(name=\"human_feedback\") as span:\n",
    "        human_feedback_content = state.get('human_analyst_feedback', 'No feedback')\n",
    "        span.update_trace(\n",
    "            input={\"current_analysts\": len(state.get('analysts', []))},\n",
    "            output={\"feedback_provided\": bool(human_feedback_content and human_feedback_content != 'No feedback')}\n",
    "        )\n",
    "    pass\n",
    "\n",
    "def should_continue(state: GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    Êù°‰ª∂Ë∑ØÁî±ÂáΩÊï∞ÔºöÂÜ≥ÂÆöÂ∑•‰ΩúÊµÅÁöÑ‰∏ã‰∏ÄÊ≠•ÊâßË°åÔºàÂ∏¶ËØÑ‰º∞ËÆ∞ÂΩïÔºâ\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        - Ê£ÄÊü•ÊòØÂê¶Êúâ‰∫∫Á±ªÂèçÈ¶à\n",
    "        - Â¶ÇÊûúÊúâÂèçÈ¶àÔºåÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "        - Â¶ÇÊûúÊ≤°ÊúâÂèçÈ¶àÔºåÁªìÊùüÊµÅÁ®ã\n",
    "        - üî¨ ËÆ∞ÂΩïË∑ØÁî±ÂÜ≥Á≠ñÂà∞ Langfuse\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂΩìÂâçÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        str: ‰∏ã‰∏Ä‰∏™Ë¶ÅÊâßË°åÁöÑËäÇÁÇπÂêçÁß∞\n",
    "    \"\"\"\n",
    "    # Ê£ÄÊü•ÊòØÂê¶Êúâ‰∫∫Á±ªÂèçÈ¶à\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback', None)\n",
    "    \n",
    "    # üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÔºöËÆ∞ÂΩïË∑ØÁî±ÂÜ≥Á≠ñ\n",
    "    with langfuse.start_as_current_span(name=\"routing_decision\") as span:\n",
    "        if human_analyst_feedback:\n",
    "            span.update_trace(\n",
    "                input={\"has_feedback\": True, \"feedback\": human_analyst_feedback},\n",
    "                output={\"next_node\": \"create_analysts\"}\n",
    "            )\n",
    "            return \"create_analysts\"  # ÊúâÂèçÈ¶àÔºåÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "        else:\n",
    "            span.update_trace(\n",
    "                input={\"has_feedback\": False},\n",
    "                output={\"next_node\": \"END\"}\n",
    "            )\n",
    "            return END  # Ê≤°ÊúâÂèçÈ¶àÔºåÁªìÊùüÊµÅÁ®ã\n",
    "\n",
    "# ÊûÑÂª∫LangGraphÂ∑•‰ΩúÊµÅ\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "\n",
    "# Ê∑ªÂä†ËäÇÁÇπÂà∞Â∑•‰ΩúÊµÅ\n",
    "builder.add_node(\"create_analysts\", create_analysts)  # ÂàÜÊûêÂ∏àÁîüÊàêËäÇÁÇπ\n",
    "builder.add_node(\"human_feedback\", human_feedback)    # ‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπ\n",
    "\n",
    "# Ê∑ªÂä†ËæπËøûÊé•ËäÇÁÇπ\n",
    "builder.add_edge(START, \"create_analysts\")  # ÂºÄÂßã -> ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")  # ÁîüÊàêÂàÜÊûêÂ∏à -> ‰∫∫Á±ªÂèçÈ¶à\n",
    "\n",
    "# Ê∑ªÂä†Êù°‰ª∂ËæπÔºöÊ†πÊçÆÊòØÂê¶ÊúâÂèçÈ¶àÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\",\n",
    "    should_continue,\n",
    "    [\"create_analysts\", END]\n",
    ")\n",
    "\n",
    "# ÁºñËØëÂ∑•‰ΩúÊµÅ\n",
    "memory = MemorySaver()  # ‰ΩøÁî®ÂÜÖÂ≠òÊ£ÄÊü•ÁÇπ‰øùÂ≠òÁä∂ÊÄÅ\n",
    "graph = builder.compile(\n",
    "    interrupt_before=['human_feedback'],  # Âú®‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπÂâç‰∏≠Êñ≠\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "# Â±ïÁ§∫ÂõæÁªìÊûÑ\n",
    "print(\"üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁâàÂàÜÊûêÂ∏àÁîüÊàêÂ∑•‰ΩúÊµÅÊûÑÂª∫ÂÆåÊàêÔºÅ\")\n",
    "print(\"üìä ÊâÄÊúâËäÇÁÇπË∞ÉÁî®ÈÉΩ‰ºöËá™Âä®ËÆ∞ÂΩïÂà∞ Langfuse Âπ≥Âè∞\")\n",
    "print(\"üéØ ‰∏ªË¶ÅËØÑ‰º∞ÊåáÊ†áÔºöLLM Ë∞ÉÁî®Ê¨°Êï∞„ÄÅ‰ª§ÁâåÊ∂àËÄó„ÄÅÊâßË°åÊó∂Èó¥„ÄÅË∑ØÁî±ÂÜ≥Á≠ñ\")\n",
    "\n",
    "# ÂõæÂèØËßÜÂåñ\n",
    "print(\"\\nÂõæÂèØËßÜÂåñÔºö\")\n",
    "\n",
    "# ÊñπÊ°à1ÔºöÂ∞ùËØï‰ΩøÁî® Pyppeteer Êú¨Âú∞Ê∏≤ÊüìÔºàÊé®ËçêÔºâ\n",
    "try:\n",
    "    # ÂèØËßÜÂåñÔºöÈÄöËøá Mermaid Ê∏≤ÊüìÂõæÁªìÊûÑ\n",
    "    display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "    print(\"‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pyppeteer Ê∏≤ÊüìÂ§±Ë¥•: {e}\")\n",
    "    \n",
    "    # ÊñπÊ°à2ÔºöÊòæÁ§∫ Mermaid ÊñáÊú¨Ê†ºÂºè\n",
    "    print(\"\\nüìù ÂõæÁªìÊûÑÔºàMermaid ÊñáÊú¨Ê†ºÂºèÔºâÔºö\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ÊñπÊ°à3ÔºöÊòæÁ§∫ÂõæÁöÑËäÇÁÇπÂíåËæπ‰ø°ÊÅØ\n",
    "    print(\"\\nüîó ÂõæÁªìÊûÑ‰ø°ÊÅØÔºö\")\n",
    "    print(\"ËäÇÁÇπ:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"Ëæπ:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # ÊñπÊ°à4ÔºöÊèê‰æõÊâãÂä®Ê∏≤ÊüìËØ¥Êòé\n",
    "    print(\"\\nüí° ÊâãÂä®Ê∏≤ÊüìËØ¥ÊòéÔºö\")\n",
    "    print(\"1. Â§çÂà∂‰∏äÈù¢ÁöÑ Mermaid ÊñáÊú¨\")\n",
    "    print(\"2. ËÆøÈóÆ https://mermaid.live/\")\n",
    "    print(\"3. Á≤òË¥¥ÊñáÊú¨Âà∞ÁºñËæëÂô®‰∏≠Êü•ÁúãÂõæÂΩ¢\")\n",
    "    print(\"4. ÊàñËÄÖ‰ΩøÁî®ÊîØÊåÅ Mermaid ÁöÑ Markdown ÁºñËæëÂô®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd42b0a-188c-4374-a03c-a2ca8272cdcf",
   "metadata": {},
   "source": [
    "![image-20250930152238678](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509301522726.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
    "outputId": "ca196d63-2a1c-4019-b769-e85da2f5c873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ÂêØÂä®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁâàÊ∑±Â∫¶Á†îÁ©∂Âä©Êâã...\n",
      "üìä Á†îÁ©∂‰∏ªÈ¢ò: ÈááÁî®LangGraph‰Ωú‰∏∫AI AgentÊ°ÜÊû∂ÁöÑÂ•ΩÂ§Ñ\n",
      "üë• ÂàÜÊûêÂ∏àÊï∞Èáè: 3\n",
      "üî¨ ÊâÄÊúâÊâßË°åÊ≠•È™§Â∞ÜËá™Âä®ËÆ∞ÂΩïÂà∞ Langfuse ËøõË°åËØÑ‰º∞\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Pregel.stream() got multiple values for argument 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# ËøêË°åÂ∑•‰ΩúÊµÅÁõ¥Âà∞Á¨¨‰∏Ä‰∏™‰∏≠Êñ≠ÁÇπÔºà‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπÔºâ\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# üî¨ ÂêØÁî® Langfuse ËøΩË∏™\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_analysts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_analysts\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlangfuse_handler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ÂêØÁî®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ËøΩË∏™\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m:\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Ê£ÄÊü•Âπ∂ÊòæÁ§∫ÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØ\u001b[39;00m\n\u001b[32m     26\u001b[39m     analysts = event.get(\u001b[33m'\u001b[39m\u001b[33manalysts\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m analysts:\n",
      "\u001b[31mTypeError\u001b[39m: Pregel.stream() got multiple values for argument 'config'"
     ]
    }
   ],
   "source": [
    "# üî¨ ‰ΩøÁî®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÂäüËÉΩËøêË°åÂàÜÊûêÂ∏àÁîüÊàêÊµÅÁ®ã\n",
    "\n",
    "# üéØ ËæìÂÖ•ÂèÇÊï∞\n",
    "max_analysts = 3  # ÂàÜÊûêÂ∏àÊï∞Èáè\n",
    "topic = \"ÈááÁî®LangGraph‰Ωú‰∏∫AI AgentÊ°ÜÊû∂ÁöÑÂ•ΩÂ§Ñ\"  # Á†îÁ©∂‰∏ªÈ¢ò\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}  # Á∫øÁ®ãIDÔºåÁî®‰∫éÁä∂ÊÄÅÁÆ°ÁêÜ\n",
    "\n",
    "# üî¨ ÂàùÂßãÂåñ Langfuse ÂõûË∞ÉÂ§ÑÁêÜÂô®ÔºåËá™Âä®ËøΩË∏™ÊâÄÊúâ LangChain Ë∞ÉÁî®\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "print(\"üöÄ ÂêØÂä®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁâàÊ∑±Â∫¶Á†îÁ©∂Âä©Êâã...\")\n",
    "print(f\"üìä Á†îÁ©∂‰∏ªÈ¢ò: {topic}\")\n",
    "print(f\"üë• ÂàÜÊûêÂ∏àÊï∞Èáè: {max_analysts}\")\n",
    "print(\"üî¨ ÊâÄÊúâÊâßË°åÊ≠•È™§Â∞ÜËá™Âä®ËÆ∞ÂΩïÂà∞ Langfuse ËøõË°åËØÑ‰º∞\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ËøêË°åÂ∑•‰ΩúÊµÅÁõ¥Âà∞Á¨¨‰∏Ä‰∏™‰∏≠Êñ≠ÁÇπÔºà‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπÔºâ\n",
    "# üî¨ ÂêØÁî® Langfuse ËøΩË∏™\n",
    "for event in graph.stream(\n",
    "    {\"topic\": topic, \"max_analysts\": max_analysts}, \n",
    "    thread, \n",
    "    stream_mode=\"values\",\n",
    "    config={\"callbacks\": [langfuse_handler]}  # ÂêØÁî®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ËøΩË∏™\n",
    "):\n",
    "    # Ê£ÄÊü•Âπ∂ÊòæÁ§∫ÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØ\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        print(\"‚úÖ ÂàÜÊûêÂ∏àÂõ¢ÈòüÁîüÊàêÂÆåÊàêÔºÅ‰ª•‰∏ãÊòØÁ≥ªÁªüÊé®ËçêÁöÑÂàÜÊûêÂ∏àÔºö\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, analyst in enumerate(analysts, 1):\n",
    "            print(f\"üìã ÂàÜÊûêÂ∏à {i}:\")\n",
    "            print(f\"   ÂßìÂêç: {analyst.name}\")\n",
    "            print(f\"   Êú∫ÊûÑ: {analyst.affiliation}\")\n",
    "            print(f\"   ËßíËâ≤: {analyst.role}\")\n",
    "            print(f\"   ÊèèËø∞: {analyst.description}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞Êï∞ÊçÆËÆ∞ÂΩïËØ¥Êòé:\")\n",
    "print(\"üìä Â∑≤ËÆ∞ÂΩïÊåáÊ†á:\")\n",
    "print(\"  - üïê ÊâßË°åÊó∂Èó¥: ÊØè‰∏™ËäÇÁÇπÁöÑÂ§ÑÁêÜËÄóÊó∂\")  \n",
    "print(\"  - üí∞ ÊàêÊú¨ÂàÜÊûê: LLM Ë∞ÉÁî®ÁöÑ‰ª§ÁâåÊ∂àËÄó\")\n",
    "print(\"  - üîÑ Ë∑ØÁî±ÂÜ≥Á≠ñ: Â∑•‰ΩúÊµÅÁöÑÊâßË°åË∑ØÂæÑ\")\n",
    "print(\"  - üìà ÊàêÂäüÁéá: ÂàÜÊûêÂ∏àÁîüÊàêÁöÑÊàêÂäü‰∏éÂ§±Ë¥•\")\n",
    "print(\"üîó ËÆøÈóÆ Langfuse ‰ª™Ë°®ÊùøÊü•ÁúãËØ¶ÁªÜÊï∞ÊçÆ: https://cloud.langfuse.com/traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
    "outputId": "f2d95e38-5acf-4c43-8974-a637aac666ac"
   },
   "outputs": [],
   "source": [
    "# üî¨ ÊºîÁ§∫‰∫∫Êú∫ÂçèÂêå‰∏éËØÑ‰º∞ÂèçÈ¶àÂäüËÉΩ\n",
    "\n",
    "# Ëé∑ÂèñÂΩìÂâçÁä∂ÊÄÅÔºåÊ£ÄÊü•Â∑•‰ΩúÊµÅËøõÂ±ï\n",
    "state = graph.get_state(thread)\n",
    "print(f\"üîç ÂΩìÂâçÂ∑•‰ΩúÊµÅÁä∂ÊÄÅ: {state.next}\")\n",
    "print(\"üí° Á≥ªÁªüÊ≠£Âú®Á≠âÂæÖ‰∫∫Á±ªÂèçÈ¶à‰ª•‰ºòÂåñÂàÜÊûêÂ∏àÂõ¢Èòü\")\n",
    "\n",
    "# üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÔºöËÆ∞ÂΩïÁî®Êà∑ÂèçÈ¶à‰∫ã‰ª∂\n",
    "with langfuse.start_as_current_span(name=\"user_feedback_collection\") as span:\n",
    "    user_feedback = \"Âä†ÂÖ•‰∏Ä‰ΩçÊù•Ëá™ÂàùÂàõÂÖ¨Âè∏ÁöÑ‰∫∫Ôºå‰ª•Â¢ûÂä†Âàõ‰∏öËÄÖÁöÑËßÜËßí\"\n",
    "    \n",
    "    # ËÆ∞ÂΩïÁî®Êà∑ÂèçÈ¶àÂà∞ËØÑ‰º∞Á≥ªÁªü\n",
    "    span.update_trace(\n",
    "        input={\"feedback_request\": \"‰ºòÂåñÂàÜÊûêÂ∏àÂõ¢Èòü\"},\n",
    "        output={\"user_feedback\": user_feedback, \"feedback_type\": \"add_perspective\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"üë§ Áî®Êà∑ÂèçÈ¶à: {user_feedback}\")\n",
    "    print(\"üîÑ Á≥ªÁªüÂ∞ÜÊ†πÊçÆÂèçÈ¶àÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏àÂõ¢Èòü...\")\n",
    "\n",
    "# Êõ¥Êñ∞Áä∂ÊÄÅÔºöÊèê‰æõ‰∫∫Á±ªÂèçÈ¶à\n",
    "graph.update_state(thread, {\n",
    "    \"human_analyst_feedback\": user_feedback\n",
    "}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
    "outputId": "d5bb8423-a691-4567-83c1-4e1d072d54bb"
   },
   "outputs": [],
   "source": [
    "# üîÑ ÁªßÁª≠ÊâßË°åÂ∑•‰ΩúÊµÅÔºåËßÇÂØüÂèçÈ¶àÂêéÁöÑÊîπËøõÊïàÊûú\n",
    "\n",
    "print(\"üîÑ Ê†πÊçÆÁî®Êà∑ÂèçÈ¶àÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏àÂõ¢Èòü...\")\n",
    "print(\"üî¨ ÁªßÁª≠ËÆ∞ÂΩïËØÑ‰º∞Êï∞ÊçÆÂà∞ Langfuse Âπ≥Âè∞\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ÁªßÁª≠ÂõæÊâßË°åÔºåÂêØÁî®ËØÑ‰º∞ËøΩË∏™\n",
    "for event in graph.stream(\n",
    "    None, \n",
    "    thread, \n",
    "    stream_mode=\"values\",\n",
    "    config={\"callbacks\": [langfuse_handler]}  # ÁªßÁª≠ÂêØÁî®Êô∫ËÉΩ‰ΩìËØÑ‰º∞ËøΩË∏™\n",
    "):\n",
    "    # ÊòæÁ§∫Êõ¥Êñ∞ÂêéÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØ\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        print(\"‚úÖ Ê†πÊçÆÁî®Êà∑ÂèçÈ¶àÈáçÊñ∞ÁîüÊàêÁöÑÂàÜÊûêÂ∏àÂõ¢ÈòüÔºö\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, analyst in enumerate(analysts, 1):\n",
    "            print(f\"üìã ÂàÜÊûêÂ∏à {i}:\")\n",
    "            print(f\"   ÂßìÂêç: {analyst.name}\")\n",
    "            print(f\"   Êú∫ÊûÑ: {analyst.affiliation}\")\n",
    "            print(f\"   ËßíËâ≤: {analyst.role}\")\n",
    "            print(f\"   ÊèèËø∞: {analyst.description}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüî¨ ‰∫∫Êú∫ÂçèÂêåËØÑ‰º∞ÊåáÊ†áËÆ∞ÂΩï:\")\n",
    "print(\"üìä Êñ∞Â¢ûËØÑ‰º∞Êï∞ÊçÆ:\")\n",
    "print(\"  - üë• Áî®Êà∑ÂèçÈ¶àË¥®Èáè: ÂèçÈ¶àÂÜÖÂÆπÁöÑÊúâÊïàÊÄß\")\n",
    "print(\"  - üîÑ Ëø≠‰ª£ÊîπËøõÊïàÊûú: ÂâçÂêéÂàÜÊûêÂ∏àÂõ¢ÈòüÁöÑÂØπÊØî\")\n",
    "print(\"  - ‚è±Ô∏è ÂèçÈ¶àÂìçÂ∫îÊó∂Èó¥: ‰ªéÂèçÈ¶àÂà∞ÈáçÊñ∞ÁîüÊàêÁöÑËÄóÊó∂\")\n",
    "print(\"  - üéØ Áî®Êà∑Êª°ÊÑèÂ∫¶: ÊîπËøõÂêéÁöÑÁªìÊûúË¥®Èáè\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8816eb9-9906-441b-b552-be71107db14f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8816eb9-9906-441b-b552-be71107db14f",
    "outputId": "c250ffd5-e4a2-441b-851e-28e76f049f77"
   },
   "outputs": [],
   "source": [
    "# üî¨ ÊºîÁ§∫Âú®Á∫øËØÑ‰º∞ÔºöÁî®Êà∑ÂèçÈ¶àÊâìÂàÜÂäüËÉΩ\n",
    "\n",
    "print(\"üî¨ ÊºîÁ§∫Âú®Á∫øËØÑ‰º∞ÂäüËÉΩÔºöÁî®Êà∑ÂèçÈ¶àÊî∂ÈõÜ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÔºöÊî∂ÈõÜÁî®Êà∑ÂØπÂàÜÊûêÂ∏àÂõ¢ÈòüÁöÑÂèçÈ¶à\n",
    "def collect_user_feedback_on_analysts(analysts_list, langfuse_client):\n",
    "    \"\"\"\n",
    "    Êî∂ÈõÜÁî®Êà∑ÂØπÂàÜÊûêÂ∏àÂõ¢ÈòüÁöÑÂèçÈ¶àËØÑÂàÜ\n",
    "    \n",
    "    ËøôÊòØÂú®Á∫øËØÑ‰º∞ÁöÑÈáçË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºåÁî®‰∫éÔºö\n",
    "    - Êî∂ÈõÜÁúüÂÆûÁî®Êà∑ÂØπ AI ËæìÂá∫ÁöÑËØÑ‰ª∑\n",
    "    - Âª∫Á´ãËØÑ‰º∞Êï∞ÊçÆÈõÜÁî®‰∫éÊ®°ÂûãÊîπËøõ\n",
    "    - ÁõëÊéßÁ≥ªÁªüÊÄßËÉΩÈöèÊó∂Èó¥ÁöÑÂèòÂåñ\n",
    "    \"\"\"\n",
    "    with langfuse_client.start_as_current_span(name=\"user_feedback_scoring\") as span:\n",
    "        # Ê®°ÊãüÁî®Êà∑ÂØπÂàÜÊûêÂ∏àÂõ¢ÈòüÁöÑËØÑÂàÜ\n",
    "        user_score = 4  # 1-5 ÂàÜÔºå5ÂàÜ‰∏∫ÊúÄÈ´ò\n",
    "        feedback_comment = \"ÂàÜÊûêÂ∏àÂõ¢ÈòüÂæàÂ•ΩÂú∞Ë¶ÜÁõñ‰∫Ü‰∏çÂêåËßíÂ∫¶ÔºåÂàõ‰∏öËÄÖËßÜËßíÁöÑÂä†ÂÖ•ÁâπÂà´Êúâ‰ª∑ÂÄº\"\n",
    "        \n",
    "        # ËÆ∞ÂΩïÂà∞ Langfuse Áî®‰∫éÂàÜÊûê\n",
    "        span.score_trace(\n",
    "            name=\"analyst_team_quality\",\n",
    "            value=user_score,\n",
    "            data_type=\"NUMERIC\",\n",
    "            comment=feedback_comment\n",
    "        )\n",
    "        \n",
    "        # ËÆ∞ÂΩïËØ¶ÁªÜÁöÑÂèçÈ¶àÊï∞ÊçÆ\n",
    "        span.update_trace(\n",
    "            input={\"analysts_count\": len(analysts_list), \"analysts_roles\": [a.role for a in analysts_list]},\n",
    "            output={\"user_score\": user_score, \"feedback\": feedback_comment}\n",
    "        )\n",
    "        \n",
    "        print(f\"üë§ Áî®Êà∑ËØÑÂàÜ: {user_score}/5\")\n",
    "        print(f\"üí¨ Áî®Êà∑ËØÑËÆ∫: {feedback_comment}\")\n",
    "        \n",
    "        return user_score, feedback_comment\n",
    "\n",
    "# Ëé∑ÂèñÊúÄÁªàÁöÑÂàÜÊûêÂ∏àÂõ¢Èòü\n",
    "final_state = graph.get_state(thread)\n",
    "analysts = final_state.values.get('analysts')\n",
    "\n",
    "if analysts:\n",
    "    # Êî∂ÈõÜÁî®Êà∑ÂèçÈ¶à\n",
    "    score, comment = collect_user_feedback_on_analysts(analysts, langfuse)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ÂàÜÊûêÂ∏àÂõ¢ÈòüÊúÄÁªàÁ°ÆÂÆöÔºÅ\")\n",
    "    print(f\"üë• Âõ¢ÈòüËßÑÊ®°: {len(analysts)} ‰ΩçÂàÜÊûêÂ∏à\")\n",
    "    print(f\"üìä Áî®Êà∑Êª°ÊÑèÂ∫¶: {score}/5\")\n",
    "    \n",
    "    print(\"\\nüî¨ Âú®Á∫øËØÑ‰º∞Êï∞ÊçÆËÆ∞ÂΩïÂÆåÊàêÔºö\")\n",
    "    print(\"  - ‚úÖ Áî®Êà∑ÂèçÈ¶àËØÑÂàÜÂ∑≤ËÆ∞ÂΩï\")\n",
    "    print(\"  - üìà Á≥ªÁªüÊÄßËÉΩÊåáÊ†áÂ∑≤Êõ¥Êñ∞\") \n",
    "    print(\"  - üéØ Ë¥®ÈáèÊîπËøõÊï∞ÊçÆÂ∑≤Êî∂ÈõÜ\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Êú™ÊâæÂà∞ÂàÜÊûêÂ∏àÊï∞ÊçÆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ac322-5926-4932-8653-68206fec0d2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a43ac322-5926-4932-8653-68206fec0d2c",
    "outputId": "771be8c3-bb76-4d6f-e00b-06afcf620aa6"
   },
   "outputs": [],
   "source": [
    "# üî¨ ÂÆåÊàêÂàÜÊûêÂ∏àÁîüÊàêÈò∂ÊÆµÔºåÂáÜÂ§áËøõÂÖ•ËÆøË∞àËØÑ‰º∞Èò∂ÊÆµ\n",
    "\n",
    "# Á°ÆËÆ§Êª°ÊÑèÂΩìÂâçÁöÑÂàÜÊûêÂ∏àÂõ¢ÈòüÔºåÁªßÁª≠ÊâßË°åÂêéÁª≠ÊµÅÁ®ã\n",
    "# ËÆæÁΩÆÂèçÈ¶à‰∏∫NoneË°®Á§∫Ê≤°ÊúâËøõ‰∏ÄÊ≠•ÁöÑ‰øÆÊîπÈúÄÊ±Ç\n",
    "graph.update_state(thread, {\n",
    "    \"human_analyst_feedback\": None\n",
    "}, as_node=\"human_feedback\")\n",
    "\n",
    "print(\"‚úÖ ÂàÜÊûêÂ∏àÂõ¢ÈòüÁ°ÆËÆ§ÂÆåÊàê\")\n",
    "print(\"üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÊÄªÁªì - ÂàÜÊûêÂ∏àÁîüÊàêÈò∂ÊÆµÔºö\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä Â∑≤Êî∂ÈõÜÁöÑËØÑ‰º∞ÊåáÊ†áÔºö\")\n",
    "print(\"  - üïê ÂàÜÊûêÂ∏àÁîüÊàêÊó∂Èó¥\")\n",
    "print(\"  - üí∞ LLM Ë∞ÉÁî®ÊàêÊú¨\")\n",
    "print(\"  - üë• Áî®Êà∑ÂèçÈ¶àË¥®ÈáèËØÑÂàÜ\")\n",
    "print(\"  - üîÑ ‰∫∫Êú∫‰∫§‰∫íÊîπËøõÊïàÊûú\")\n",
    "print(\"  - üìà Âõ¢ÈòüÁªÑÊàê‰ºòÂåñÁ®ãÂ∫¶\")\n",
    "\n",
    "# üî¨ Èò∂ÊÆµËØÑ‰º∞ÔºöËÆ∞ÂΩïÂàÜÊûêÂ∏àÁîüÊàêÈò∂ÊÆµÂÆåÊàê\n",
    "with langfuse.start_as_current_span(name=\"analyst_generation_completion\") as span:\n",
    "    span.update_trace(\n",
    "        input={\"phase\": \"analyst_generation\", \"status\": \"completed\"},\n",
    "        output={\"next_phase\": \"expert_interviews\", \"analysts_ready\": len(analysts)}\n",
    "    )\n",
    "\n",
    "print(\"\\nüöÄ ÂáÜÂ§áËøõÂÖ•‰∏ã‰∏ÄÈò∂ÊÆµÔºö‰∏ìÂÆ∂ËÆøË∞à‰∏éËØÑ‰º∞\")\n",
    "print(\"üî¨ ËÆøË∞àÈò∂ÊÆµÂ∞ÜËÆ∞ÂΩïÊõ¥Â§öËØÑ‰º∞ÊåáÊ†áÔºåÂåÖÊã¨Ôºö\")\n",
    "print(\"  - üó£Ô∏è ÂØπËØùË¥®ÈáèËØÑ‰º∞\")\n",
    "print(\"  - üîç ‰ø°ÊÅØÊ£ÄÁ¥¢ÊïàÊûú\")\n",
    "print(\"  - üìù Êä•ÂëäÁîüÊàêË¥®Èáè\")\n",
    "print(\"  - ‚è±Ô∏è Á´ØÂà∞Á´ØÊâßË°åÊó∂Èó¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab034e65-aeee-4723-8d6d-74541b548425",
   "metadata": {
    "id": "ab034e65-aeee-4723-8d6d-74541b548425"
   },
   "outputs": [],
   "source": [
    "# Continue the graph execution to end\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f204e8a-285c-4e46-8223-a695caec7764",
   "metadata": {
    "id": "2f204e8a-285c-4e46-8223-a695caec7764"
   },
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "analysts = final_state.values.get('analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
    "outputId": "d16bd1df-ec14-43c0-aa4e-8440c4bef1e7"
   },
   "outputs": [],
   "source": [
    "final_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf",
    "outputId": "bd20945d-6717-4ee7-c981-36ffb06f9e89"
   },
   "outputs": [],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7",
   "metadata": {
    "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7"
   },
   "source": [
    "## ËøõË°åËÆøË∞àÔºàConduct InterviewÔºâ\n",
    "\n",
    "### ÁîüÊàêÈóÆÈ¢òÔºàGenerate QuestionÔºâ\n",
    "\n",
    "ÂàÜÊûêÂ∏àÂ∞ÜÂêë‰∏ìÂÆ∂ÊèêÂá∫ÈóÆÈ¢ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c",
   "metadata": {
    "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    \"\"\"\n",
    "    ËÆøË∞àÁä∂ÊÄÅÁÆ°ÁêÜÁ±ª\n",
    "\n",
    "    ÁªßÊâøËá™MessagesStateÔºåÁî®‰∫éÁÆ°ÁêÜÂàÜÊûêÂ∏à‰∏é‰∏ìÂÆ∂‰πãÈó¥ÁöÑÂØπËØùÁä∂ÊÄÅ\n",
    "    ÂåÖÂê´ËÆøË∞àËøáÁ®ã‰∏≠ÁöÑÊâÄÊúâÂøÖË¶Å‰ø°ÊÅØÂíå‰∏ä‰∏ãÊñá\n",
    "    \"\"\"\n",
    "    max_num_turns: int  # ÂØπËØùËΩÆÊ¨°‰∏äÈôêÔºåÊéßÂà∂ËÆøË∞àÊ∑±Â∫¶\n",
    "    context: Annotated[list, operator.add]  # Ê£ÄÁ¥¢Âà∞ÁöÑÊ∫êÊñáÊ°£ÂàóË°®Ôºå‰ΩøÁî®operator.addËøõË°åÁ¥ØÂä†\n",
    "    analyst: Analyst  # ÂΩìÂâçËøõË°åËÆøË∞àÁöÑÂàÜÊûêÂ∏àÂØπË±°\n",
    "    interview: str  # ÂÆåÊï¥ÁöÑËÆøË∞àËÆ∞ÂΩïÊñáÊú¨\n",
    "    sections: list  # ËÆøË∞àÊëòË¶ÅÂ∞èËäÇÂàóË°®ÔºåÁî®‰∫éÊúÄÁªàÊä•ÂëäÁîüÊàê\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    ÊêúÁ¥¢Êü•ËØ¢Êï∞ÊçÆÊ®°Âûã\n",
    "\n",
    "    Áî®‰∫éÁªìÊûÑÂåñÁîüÊàêÊêúÁ¥¢Êü•ËØ¢ÔºåÁ°Æ‰øùÊêúÁ¥¢ËØ∑Ê±ÇÊ†ºÂºèÊ≠£Á°Æ\n",
    "    \"\"\"\n",
    "    search_query: str = Field(None, description=\"Áî®‰∫éÊ£ÄÁ¥¢ÁöÑÊêúÁ¥¢Êü•ËØ¢ËØ≠Âè•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0",
   "metadata": {
    "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0"
   },
   "outputs": [],
   "source": [
    "# ÈóÆÈ¢òÁîüÊàêÊåá‰ª§Ê®°Êùø\n",
    "# ÊåáÂØºAIÂàÜÊûêÂ∏àÂ¶Ç‰Ωï‰∏é‰∏ìÂÆ∂ËøõË°åÊúâÊïàÁöÑËÆøË∞àÂØπËØù\n",
    "question_instructions = \"\"\"‰Ω†ÊòØ‰∏ÄÂêçÂàÜÊûêÂ∏àÔºåÈúÄË¶ÅÈÄöËøáËÆøË∞à‰∏ìÂÆ∂Êù•‰∫ÜËß£‰∏Ä‰∏™ÂÖ∑‰Ωì‰∏ªÈ¢ò„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑÁõÆÊ†áÊòØÊèêÁÇº‰∏éËØ•‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑ„ÄåÊúâË∂£‰∏îÂÖ∑‰Ωì„ÄçÁöÑÊ¥ûËßÅ„ÄÇ\n",
    "\n",
    "1. ÊúâË∂£ÔºàInterestingÔºâÔºöËÆ©‰∫∫ÊÑüÂà∞ÊÑèÂ§ñÊàñÈùûÊòæËÄåÊòìËßÅÁöÑËßÇÁÇπ„ÄÇ\n",
    "\n",
    "2. ÂÖ∑‰ΩìÔºàSpecificÔºâÔºöÈÅøÂÖçÊ≥õÊ≥õËÄåË∞àÔºåÂåÖÂê´‰∏ìÂÆ∂Êèê‰æõÁöÑÂÖ∑‰ΩìÊ°à‰æãÊàñÁªÜËäÇ„ÄÇ\n",
    "\n",
    "‰ª•‰∏ãÊòØ‰Ω†ÁöÑÂÖ≥Ê≥®‰∏ªÈ¢ò‰∏éÁõÆÊ†áËÆæÂÆöÔºö{goals}\n",
    "\n",
    "ËØ∑ÂÖàÁî®Á¨¶Âêà‰Ω†‰∫∫ËÆæÁöÑÂêçÂ≠óËøõË°åËá™Êàë‰ªãÁªçÔºåÁÑ∂ÂêéÊèêÂá∫‰Ω†ÁöÑÁ¨¨‰∏Ä‰∏™ÈóÆÈ¢ò„ÄÇ\n",
    "\n",
    "ÊåÅÁª≠ËøΩÈóÆÔºåÈÄêÊ≠•Ê∑±ÂÖ•ÔºåÈÄêÊ≠•ÂÆåÂñÑ‰Ω†ÂØπËØ•‰∏ªÈ¢òÁöÑÁêÜËß£„ÄÇ\n",
    "\n",
    "ÂΩì‰Ω†ËÆ§‰∏∫‰ø°ÊÅØÂ∑≤ÂÖÖÂàÜÔºåËØ∑‰ª•ËøôÂè•ËØùÁªìÊùüËÆøË∞àÔºö„ÄåÈùûÂ∏∏ÊÑüË∞¢ÊÇ®ÁöÑÂ∏ÆÂä©!„Äç\n",
    "\n",
    "ËØ∑ÂßãÁªà‰øùÊåÅ‰∏é‰Ω†ÁöÑ‰∫∫ËÆæ‰∏éÁõÆÊ†á‰∏ÄËá¥ÁöÑËØ¥ËØùÊñπÂºè„ÄÇ\"\"\"\n",
    "\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêËÆøË∞àÈóÆÈ¢òÁöÑÊ†∏ÂøÉÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Ê†πÊçÆÂàÜÊûêÂ∏àÁöÑ‰∫∫ËÆæÂíåÂΩìÂâçÂØπËØùÂéÜÂè≤ÁîüÊàê‰∏ã‰∏Ä‰∏™ÈóÆÈ¢ò\n",
    "        2. Á°Æ‰øùÈóÆÈ¢òÁ¨¶ÂêàÂàÜÊûêÂ∏àÁöÑÂÖ≥Ê≥®ÁÇπÂíåËßíËâ≤ÂÆö‰Ωç\n",
    "        3. Áª¥Êä§ÂØπËØùÁöÑËøûË¥ØÊÄßÂíåÊ∑±Â∫¶\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂàÜÊûêÂ∏à‰ø°ÊÅØÂíåÂØπËØùÂéÜÂè≤ÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´Êñ∞ÁîüÊàêÈóÆÈ¢òÁöÑÊ∂àÊÅØÂàóË°®\n",
    "    \"\"\"\n",
    "    # ‰ªéÁä∂ÊÄÅ‰∏≠Ëé∑ÂèñÂàÜÊûêÂ∏à‰ø°ÊÅØÂíåÂΩìÂâçÂØπËØùÂéÜÂè≤\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØÔºåÂåÖÂê´ÂàÜÊûêÂ∏àÁöÑ‰∫∫ËÆæ‰ø°ÊÅØ\n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàê‰∏ã‰∏Ä‰∏™ÈóÆÈ¢ò\n",
    "    question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # Â∞ÜÁîüÊàêÁöÑÈóÆÈ¢òÊ∑ªÂä†Âà∞Ê∂àÊÅØÂéÜÂè≤‰∏≠\n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ff33a-6232-4a79-8a82-882a645394f5",
   "metadata": {
    "id": "be2ff33a-6232-4a79-8a82-882a645394f5"
   },
   "source": [
    "### ÁîüÊàêÂõûÁ≠îÔºöÂπ∂Ë°åÂåñÔºàParallelizationÔºâ\n",
    "\n",
    "‰∏ìÂÆ∂Â∞ÜÂπ∂Ë°åÂú∞‰ªéÂ§ö‰∏™Êù•Ê∫êÊî∂ÈõÜ‰ø°ÊÅØÊù•ÂõûÁ≠îÈóÆÈ¢ò„ÄÇ\n",
    "\n",
    "‰æãÂ¶ÇÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®Ôºö\n",
    "\n",
    "- ÂÖ∑‰ΩìÁΩëÁ´ôÔºà‰æãÂ¶ÇÈÄöËøá [`WebBaseLoader`](https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/) ÊäìÂèñÔºâ\n",
    "- Â∑≤Âª∫Á´ãÁ¥¢ÂºïÁöÑÊñáÊ°£Ôºà‰æãÂ¶ÇÂü∫‰∫é [RAG](https://python.langchain.com/v0.2/docs/tutorials/rag/) ÁöÑÊ£ÄÁ¥¢Ôºâ\n",
    "- Web ÊêúÁ¥¢\n",
    "- ÁôæÁßëÊêúÁ¥¢ÔºàÁôæÂ∫¶ÁôæÁßëÔºâ\n",
    "\n",
    "‰Ω†‰πüÂèØ‰ª•Â∞ùËØï‰∏çÂêåÁöÑ Web ÊêúÁ¥¢Â∑•ÂÖ∑ÔºåÊØîÂ¶Ç [Tavily](https://tavily.com/)„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ea95b-e811-4299-8b66-835d4016c338",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "606ea95b-e811-4299-8b66-835d4016c338",
    "outputId": "52495f61-eb30-4785-8b55-fdfc00eca71a"
   },
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    ÂÆâÂÖ®ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÁöÑËæÖÂä©ÂáΩÊï∞ÔºàÈáçÂ§çÂÆö‰πâÔºå‰øùÊåÅ‰ª£Á†ÅÂÆåÊï¥ÊÄßÔºâ\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ËÆæÁΩÆTavilyÊêúÁ¥¢APIÂØÜÈí•\n",
    "# TavilyÊòØ‰∏Ä‰∏™‰∏ìÈó®‰∏∫AIÂ∫îÁî®‰ºòÂåñÁöÑÊêúÁ¥¢APIÔºåÊèê‰æõÈ´òË¥®ÈáèÁöÑÊêúÁ¥¢ÁªìÊûú\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789",
    "outputId": "01c8bb14-5945-4d7e-c81f-dcdaf6ec9a37"
   },
   "outputs": [],
   "source": [
    "# ÁΩëÁªúÊêúÁ¥¢Â∑•ÂÖ∑ÈÖçÁΩÆ\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# ÂàùÂßãÂåñTavilyÊêúÁ¥¢Â∑•ÂÖ∑\n",
    "# max_results=3 ÈôêÂà∂ÊØèÊ¨°ÊêúÁ¥¢ËøîÂõûÁöÑÁªìÊûúÊï∞ÈáèÔºåÂπ≥Ë°°‰ø°ÊÅØ‰∏∞ÂØåÂ∫¶ÂíåÂ§ÑÁêÜÊïàÁéá\n",
    "tavily_search = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c",
   "metadata": {
    "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c"
   },
   "outputs": [],
   "source": [
    "# ÁôæÁßëÊêúÁ¥¢Â∑•ÂÖ∑ÈÖçÁΩÆÔºàÁôæÂ∫¶ÁôæÁßëÔºâ\n",
    "# Â∑≤ÊõøÊç¢‰∏∫ BaiduBaikeLoader\n",
    "# ÁôæÂ∫¶ÁôæÁßëÊêúÁ¥¢Â∑•ÂÖ∑ÈÖçÁΩÆ\n",
    "from baike_loader import BaiduBaikeLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb1603",
   "metadata": {
    "id": "06cb1603"
   },
   "source": [
    "Êé•‰∏ãÊù•ÔºåÊàë‰ª¨Â∞ÜÂàõÂª∫Áî®‰∫é Web ‰∏éÁôæÁßëÔºàÁôæÂ∫¶ÁôæÁßëÔºâÊ£ÄÁ¥¢ÁöÑËäÇÁÇπ„ÄÇ\n",
    "\n",
    "Ëøò‰ºöÂàõÂª∫‰∏Ä‰∏™Áî®‰∫éÂõûÁ≠îÂàÜÊûêÂ∏àÈóÆÈ¢òÁöÑËäÇÁÇπ„ÄÇ\n",
    "\n",
    "ÊúÄÂêéÔºåÂàõÂª∫Áî®‰∫é‰øùÂ≠òÂÆåÊï¥ËÆøË∞àÂÜÖÂÆπÔºå‰ª•ÂèäÊí∞ÂÜôËÆøË∞àÊëòË¶ÅÔºà‚Äúsection‚ÄùÔºâÁöÑËäÇÁÇπ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
    "outputId": "c0063b88-b11a-4fa3-e621-34dab72fa120"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "# ÊêúÁ¥¢Êü•ËØ¢ÁîüÊàêÊåá‰ª§\n",
    "# ÊåáÂØºAIÂ¶Ç‰Ωï‰ªéÂØπËØù‰∏≠ÊèêÂèñÊúâÊïàÁöÑÊêúÁ¥¢Êü•ËØ¢\n",
    "search_instructions = SystemMessage(content=f\"\"\"‰Ω†Â∞ÜËé∑Âæó‰∏ÄÊÆµÂàÜÊûêÂ∏à‰∏é‰∏ìÂÆ∂‰πãÈó¥ÁöÑÂØπËØù„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑÁõÆÊ†áÊòØÂü∫‰∫éËøôÊÆµÂØπËØùÔºå‰∏∫WebÊêúÁ¥¢ÁîüÊàê‰∏ÄÊù°ÁªìÊûÑËâØÂ•ΩÁöÑÊü•ËØ¢ËØ≠Âè•„ÄÇ\n",
    "\n",
    "È¶ñÂÖàÔºåÈÄöËØªÊï¥ÊÆµÂØπËØù„ÄÇ\n",
    "\n",
    "ÁâπÂà´ÂÖ≥Ê≥®ÂàÜÊûêÂ∏àÊúÄÂêéÊèêÂá∫ÁöÑÈóÆÈ¢ò„ÄÇ\n",
    "\n",
    "Â∞ÜËøô‰∏™ÊúÄÁªàÈóÆÈ¢òËΩ¨Âåñ‰∏∫ÁªìÊûÑËâØÂ•ΩÁöÑ Web ÊêúÁ¥¢Êü•ËØ¢„ÄÇ\"\"\")\n",
    "\n",
    "def search_web(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ÈÄöËøáWebÊêúÁ¥¢Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. ÂàÜÊûêÂΩìÂâçÂØπËØùÂÜÖÂÆπÔºåÁîüÊàêÂêàÈÄÇÁöÑÊêúÁ¥¢Êü•ËØ¢\n",
    "        2. ‰ΩøÁî®Tavily APIÊâßË°åÁΩëÁªúÊêúÁ¥¢\n",
    "        3. Ê†ºÂºèÂåñÊêúÁ¥¢ÁªìÊûúÔºå‰æø‰∫éÂêéÁª≠Â§ÑÁêÜ\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂØπËØùÂéÜÂè≤ÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´Ê†ºÂºèÂåñÊêúÁ¥¢ÁªìÊûúÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ\n",
    "    \"\"\"\n",
    "    # ‰ΩøÁî®ÁªìÊûÑÂåñËæìÂá∫ÁîüÊàêÊêúÁ¥¢Êü•ËØ¢\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "\n",
    "    # ÊâßË°åTavilyÁΩëÁªúÊêúÁ¥¢\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "\n",
    "    # Ê†ºÂºèÂåñÊêúÁ¥¢ÁªìÊûúÔºåÊ∑ªÂä†Êù•Ê∫ê‰ø°ÊÅØ\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    ])\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "def search_baike(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ÈÄöËøáÁôæÁßëÔºàÁôæÂ∫¶ÁôæÁßëÔºâÊ£ÄÁ¥¢Áõ∏ÂÖ≥ÊñáÊ°£\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. ÂàÜÊûêÂΩìÂâçÂØπËØùÂÜÖÂÆπÔºåÁîüÊàêÁôæÁßëÊêúÁ¥¢Êü•ËØ¢\n",
    "        2. ‰ΩøÁî®BaiduBaikeLoaderËé∑ÂèñÁôæÁßëÂÜÖÂÆπ\n",
    "        3. Ê†ºÂºèÂåñÊêúÁ¥¢ÁªìÊûúÔºå‰æø‰∫éÂêéÁª≠Â§ÑÁêÜ\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂØπËØùÂéÜÂè≤ÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´Ê†ºÂºèÂåñÁôæÁßëÊêúÁ¥¢ÁªìÊûúÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ\n",
    "    \"\"\"\n",
    "    # ‰ΩøÁî®ÁªìÊûÑÂåñËæìÂá∫ÁîüÊàêÊêúÁ¥¢Êü•ËØ¢\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "\n",
    "    # ÊâßË°åÁôæÁßëÊêúÁ¥¢ÔºàÁôæÂ∫¶ÁôæÁßëÔºâÔºåÈôêÂà∂ÊúÄÂ§ö2‰∏™ÊñáÊ°£\n",
    "    search_docs = BaiduBaikeLoader(\n",
    "        query=search_query.search_query,\n",
    "        load_max_docs=2\n",
    "    ).load()\n",
    "\n",
    "    # Ê†ºÂºèÂåñÁôæÁßëÊêúÁ¥¢ÁªìÊûú\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join([\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    ])\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "# ‰∏ìÂÆ∂ÂõûÁ≠îÊåá‰ª§Ê®°Êùø\n",
    "# ÊåáÂØºAI‰∏ìÂÆ∂Â¶Ç‰ΩïÂü∫‰∫éÊ£ÄÁ¥¢Âà∞ÁöÑ‰ø°ÊÅØÂõûÁ≠îÂàÜÊûêÂ∏àÁöÑÈóÆÈ¢ò\n",
    "answer_instructions = \"\"\"‰Ω†ÊòØ‰∏Ä‰ΩçË¢´ÂàÜÊûêÂ∏àËÆøË∞àÁöÑ‰∏ìÂÆ∂„ÄÇ\n",
    "\n",
    "‰ª•‰∏ãÊòØÂàÜÊûêÂ∏àÁöÑÂÖ≥Ê≥®È¢ÜÂüüÔºö{goals}„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑÁõÆÊ†áÊòØÂõûÁ≠îËÆøË∞àËÄÖÊèêÂá∫ÁöÑÈóÆÈ¢ò„ÄÇ\n",
    "\n",
    "ÂõûÁ≠îÈóÆÈ¢òÊó∂ÔºåËØ∑‰ªÖ‰ΩøÁî®‰ª•‰∏ã‰∏ä‰∏ãÊñáÔºö\n",
    "\n",
    "{context}\n",
    "\n",
    "ÂõûÁ≠îÈ°ªÈÅµÂæ™Â¶Ç‰∏ãË¶ÅÊ±ÇÔºö\n",
    "\n",
    "1. Âè™‰ΩøÁî®‰∏ä‰∏ãÊñá‰∏≠Êèê‰æõÁöÑ‰ø°ÊÅØ„ÄÇ\n",
    "\n",
    "2. ‰∏çË¶ÅÂºïÂÖ•‰∏ä‰∏ãÊñá‰πãÂ§ñÁöÑ‰ø°ÊÅØÔºå‰πü‰∏çË¶ÅÂÅöÊú™Âú®‰∏ä‰∏ãÊñáÊòéÁ°ÆËØ¥ÊòéÁöÑÂÅáËÆæ„ÄÇ\n",
    "\n",
    "3. ‰∏ä‰∏ãÊñáÂú®ÊØèÊÆµÊñáÊ°£È°∂ÈÉ®ÂåÖÂê´Êù•Ê∫ê‰ø°ÊÅØ„ÄÇ\n",
    "\n",
    "4. Âú®Ê∂âÂèäÂÖ∑‰ΩìËÆ∫Êñ≠Êó∂ÔºåËØ∑Âú®Áõ∏Â∫îÂÜÖÂÆπÊóÅÊ†áÊ≥®ÂºïÁî®Êù•Ê∫êÁºñÂè∑„ÄÇ‰æãÂ¶ÇÔºåÈíàÂØπÊù•Ê∫ê 1 ‰ΩøÁî® [1]„ÄÇ\n",
    "\n",
    "5. Âú®Á≠îÊ°àÁªìÂ∞æÂ§ÑÊåâÈ°∫Â∫èÂàóÂá∫ÂºïÁî®Êù•Ê∫êÔºåÂ¶ÇÔºö[1] Source 1, [2] Source 2 Á≠â„ÄÇ\n",
    "\n",
    "6. Ëã•Êù•Ê∫êÂΩ¢Â¶ÇÔºö<Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>ÔºåÂàôÂú®ÂºïÁî®ÂàóË°®‰∏≠Âè™ÂÜôÔºö\n",
    "\n",
    "[1] assistant/docs/llama3_1.pdf, page 7\n",
    "\n",
    "Âπ∂‰∏î‰∏çË¶ÅÂÜçÈáçÂ§çÂä†‰∏≠Êã¨Âè∑Ôºå‰πü‰∏çË¶ÅÈôÑÂä† Document source ÂâçÁºÄ„ÄÇ\"\"\"\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàê‰∏ìÂÆ∂ÂõûÁ≠îÁöÑÊ†∏ÂøÉÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Âü∫‰∫éÊ£ÄÁ¥¢Âà∞ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØÂõûÁ≠îÂàÜÊûêÂ∏àÁöÑÈóÆÈ¢ò\n",
    "        2. Á°Æ‰øùÂõûÁ≠îÁ¨¶Âêà‰∏ìÂÆ∂ÁöÑËßíËâ≤ÂÆö‰Ωç\n",
    "        3. Êèê‰æõÂáÜÁ°ÆÁöÑÂºïÁî®ÂíåÊù•Ê∫ê‰ø°ÊÅØ\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂàÜÊûêÂ∏à‰ø°ÊÅØ„ÄÅÂØπËØùÂéÜÂè≤ÂíåÊ£ÄÁ¥¢‰∏ä‰∏ãÊñáÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´‰∏ìÂÆ∂ÂõûÁ≠îÁöÑÊ∂àÊÅØÂàóË°®\n",
    "    \"\"\"\n",
    "    # ‰ªéÁä∂ÊÄÅ‰∏≠Ëé∑ÂèñÂøÖË¶Å‰ø°ÊÅØ\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØÔºåÂåÖÂê´ÂàÜÊûêÂ∏àÂÖ≥Ê≥®ÁÇπÂíåÊ£ÄÁ¥¢‰∏ä‰∏ãÊñá\n",
    "    system_message = answer_instructions.format(\n",
    "        goals=analyst.persona,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàê‰∏ìÂÆ∂ÂõûÁ≠î\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # Ê†áËÆ∞ËØ•Ê∂àÊÅØÊù•Ëá™‰∏ìÂÆ∂Ôºå‰æø‰∫éÂêéÁª≠Ë∑ØÁî±\n",
    "    answer.name = \"expert\"\n",
    "\n",
    "    # Â∞Ü‰∏ìÂÆ∂ÂõûÁ≠îÊ∑ªÂä†Âà∞Ê∂àÊÅØÂéÜÂè≤‰∏≠\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ‰øùÂ≠òËÆøË∞àÂÜÖÂÆπÁöÑÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Â∞ÜÂÆåÊï¥ÁöÑÂØπËØùÂéÜÂè≤ËΩ¨Êç¢‰∏∫ÊñáÊú¨Ê†ºÂºè\n",
    "        2. ‰øùÂ≠òËÆøË∞àËÆ∞ÂΩïÔºå‰æõÂêéÁª≠Êä•ÂëäÁîüÊàê‰ΩøÁî®\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂØπËØùÂéÜÂè≤ÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÂÆåÊï¥ËÆøË∞àËÆ∞ÂΩïÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÊâÄÊúâÂØπËØùÊ∂àÊÅØ\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Â∞ÜÊ∂àÊÅØÂàóË°®ËΩ¨Êç¢‰∏∫Ê†ºÂºèÂåñÁöÑÂ≠óÁ¨¶‰∏≤\n",
    "    interview = get_buffer_string(messages)\n",
    "\n",
    "    # Â∞ÜËÆøË∞àËÆ∞ÂΩï‰øùÂ≠òÂà∞Áä∂ÊÄÅ‰∏≠\n",
    "    return {\"interview\": interview}\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"expert\"):\n",
    "    \"\"\"\n",
    "    Ê∂àÊÅØË∑ØÁî±ÂáΩÊï∞ÔºöÂÜ≥ÂÆöËÆøË∞àÊµÅÁ®ãÁöÑ‰∏ã‰∏ÄÊ≠•\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Ê£ÄÊü•ÊòØÂê¶ËææÂà∞ÊúÄÂ§ßÂØπËØùËΩÆÊ¨°\n",
    "        2. Ê£ÄÊü•ÂàÜÊûêÂ∏àÊòØÂê¶Ë°®Á§∫ËÆøË∞àÁªìÊùü\n",
    "        3. ÂÜ≥ÂÆöÊòØÁªßÁª≠ÊèêÈóÆËøòÊòØ‰øùÂ≠òËÆøË∞à\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂΩìÂâçËÆøË∞àÁä∂ÊÄÅ\n",
    "        name: ‰∏ìÂÆ∂Ê∂àÊÅØÁöÑÊ†áËØÜÁ¨¶ÔºåÈªòËÆ§‰∏∫\"expert\"\n",
    "\n",
    "    ËøîÂõû:\n",
    "        str: ‰∏ã‰∏Ä‰∏™Ë¶ÅÊâßË°åÁöÑËäÇÁÇπÂêçÁß∞\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÂØπËØùÊ∂àÊÅØÂíåÊúÄÂ§ßËΩÆÊ¨°ËÆæÁΩÆ\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get('max_num_turns', 2)\n",
    "\n",
    "    # ÁªüËÆ°‰∏ìÂÆ∂ÂõûÁ≠îÊ¨°Êï∞\n",
    "    num_responses = len([\n",
    "        m for m in messages\n",
    "        if isinstance(m, AIMessage) and m.name == name\n",
    "    ])\n",
    "\n",
    "    # Â¶ÇÊûúËææÂà∞ÊúÄÂ§ßËΩÆÊ¨°ÔºåÁªìÊùüËÆøË∞à\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # Ê£ÄÊü•‰∏ä‰∏Ä‰∏™ÈóÆÈ¢òÊòØÂê¶Ë°®ÊòéÂØπËØùÁªìÊùü\n",
    "    # Ê≥®ÊÑèÔºöËøôÈáåÂÅáËÆæÂÄíÊï∞Á¨¨‰∫å‰∏™Ê∂àÊÅØÊòØÂàÜÊûêÂ∏àÁöÑÈóÆÈ¢ò\n",
    "    last_question = messages[-2]\n",
    "\n",
    "    if \"ÈùûÂ∏∏ÊÑüË∞¢ÊÇ®ÁöÑÂ∏ÆÂä©!\" in last_question.content:\n",
    "        return 'save_interview'\n",
    "\n",
    "    # ÁªßÁª≠ÊèêÈóÆ\n",
    "    return \"ask_question\"\n",
    "\n",
    "# Êä•ÂëäÂ∞èËäÇÂÜô‰ΩúÊåá‰ª§Ê®°Êùø\n",
    "# ÊåáÂØºAIÂ¶Ç‰ΩïÂ∞ÜËÆøË∞àÂÜÖÂÆπËΩ¨Êç¢‰∏∫ÁªìÊûÑÂåñÁöÑÊä•ÂëäÂ∞èËäÇ\n",
    "section_writer_instructions = \"\"\"‰Ω†ÊòØ‰∏ÄÂêçËµÑÊ∑±ÊäÄÊúØÂÜô‰ΩúËÄÖ„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑ‰ªªÂä°ÊòØÂü∫‰∫é‰∏ÄÁªÑÊù•Ê∫êÊñáÊ°£ÔºåÊí∞ÂÜô‰∏ÄÊÆµÁÆÄÊ¥Å„ÄÅÊòìËØªÁöÑÊä•ÂëäÂ∞èËäÇ„ÄÇ\n",
    "\n",
    "1. ÂÖàÂàÜÊûêÊù•Ê∫êÊñáÊ°£ÂÜÖÂÆπÔºö\n",
    "- ÊØè‰∏™ÊñáÊ°£ÁöÑÂêçÁß∞Âú®ÊñáÊ°£ÂºÄÂ§¥Ôºå‰ª• <Document Ê†áÁ≠æÂëàÁé∞„ÄÇ\n",
    "\n",
    "2. ‰ΩøÁî® Markdown Âà∂‰ΩúÂ∞èËäÇÁªìÊûÑÔºö\n",
    "- Áî® ## ‰Ωú‰∏∫Â∞èËäÇÊ†áÈ¢ò\n",
    "- Áî® ### ‰Ωú‰∏∫Â∞èËäÇÂÜÖÁöÑÂ∞èÊ†áÈ¢ò\n",
    "\n",
    "3. ÊåâÁªìÊûÑÊí∞ÂÜôÔºö\n",
    " a. Ê†áÈ¢òÔºà## Â§¥Ôºâ\n",
    " b. ÊëòË¶ÅÔºà### Â§¥Ôºâ\n",
    " c. ÂèÇËÄÉÊù•Ê∫êÔºà### Â§¥Ôºâ\n",
    "\n",
    "4. Ê†áÈ¢òÈúÄË¶ÅË¥¥ÂêàÂàÜÊûêÂ∏àÁöÑÂÖ≥Ê≥®ÁÇπÂπ∂ÂÖ∑ÊúâÂê∏ÂºïÂäõÔºö\n",
    "{focus}\n",
    "\n",
    "5. ÂÖ≥‰∫éÊëòË¶ÅÈÉ®ÂàÜÔºö\n",
    "- ÂÖàÁªôÂá∫‰∏éÂàÜÊûêÂ∏àÂÖ≥Ê≥®ÁÇπÁõ∏ÂÖ≥ÁöÑËÉåÊôØ/‰∏ä‰∏ãÊñá\n",
    "- Âº∫Ë∞ÉËÆøË∞à‰∏≠Ëé∑ÂæóÁöÑÊñ∞È¢ñ„ÄÅÊúâË∂£Êàñ‰ª§‰∫∫ÊÑèÂ§ñÁöÑÊ¥ûËßÅ\n",
    "- ‰ΩøÁî®Âà∞Êù•Ê∫êÊñáÊ°£Êó∂ÔºåÊåâ‰ΩøÁî®È°∫Â∫èÂàõÂª∫ÁºñÂè∑\n",
    "- ‰∏çË¶ÅÊèêÂèäËÆøË∞àËÄÖÊàñ‰∏ìÂÆ∂ÁöÑÂêçÂ≠ó\n",
    "- ÊéßÂà∂Âú®Á∫¶ 400 Â≠ó‰ª•ÂÜÖ\n",
    "- Âú®Êä•ÂëäÊ≠£Êñá‰∏≠‰ΩøÁî®Êï∞Â≠óÂºïÁî®ÔºàÂ¶Ç [1]„ÄÅ[2]ÔºâÔºåÂü∫‰∫éÊù•Ê∫êÊñáÊ°£‰ø°ÊÅØ\n",
    "- **ÈáçË¶ÅÔºöÁîüÊàêÁöÑÂ∞èËäÇÂÜÖÂÆπÂøÖÈ°ªÂÖ®ÈÉ®‰ΩøÁî®‰∏≠ÊñáÔºåÊâÄÊúâÂÜÖÂÆπÈÉΩÂøÖÈ°ªÊòØ‰∏≠ÊñáËæìÂá∫**\n",
    "\n",
    "6. Âú®ÂèÇËÄÉÊù•Ê∫êÈÉ®ÂàÜÔºö\n",
    "- ÂàóÂá∫Êä•Âëä‰∏≠‰ΩøÁî®Âà∞ÁöÑÂÖ®ÈÉ®Êù•Ê∫ê\n",
    "- ÁªôÂá∫ÂÆåÊï¥ÈìæÊé•ÊàñÂÖ∑‰ΩìÊñáÊ°£Ë∑ØÂæÑ\n",
    "- ÊØè‰∏™Êù•Ê∫êÂçïÁã¨‰∏ÄË°åÔºõÂú®Ë°åÂ∞æÂä†‰∏§‰∏™Á©∫Ê†º‰ª•‰∫ßÁîü Markdown Êç¢Ë°å\n",
    "- ÂèÇËÄÉÊ†ºÂºèÔºö\n",
    "\n",
    "### Sources\n",
    "[1] ÈìæÊé•ÊàñÊñáÊ°£Âêç\n",
    "[2] ÈìæÊé•ÊàñÊñáÊ°£Âêç\n",
    "\n",
    "7. ÂêàÂπ∂ÈáçÂ§çÊù•Ê∫ê„ÄÇ‰æãÂ¶Ç‰ª•‰∏ãÊòØ‰∏çÊ≠£Á°ÆÁöÑÔºö\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "Â∫îÂéªÈáç‰∏∫Ôºö\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "8. ÊúÄÁªàÊ£ÄÊü•Ôºö\n",
    "- Á°Æ‰øùÊä•ÂëäÁªìÊûÑÁ¨¶ÂêàË¶ÅÊ±Ç\n",
    "- Ê†áÈ¢òÂâç‰∏çË¶ÅÊúâ‰ªª‰ΩïÂâçË®Ä\n",
    "- Ê£ÄÊü•ÊòØÂê¶ÈÅµÂæ™‰∫ÜÂÖ®ÈÉ®ËßÑËåÉ\"\"\"\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêÊä•ÂëäÂ∞èËäÇÁöÑÊ†∏ÂøÉÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Âü∫‰∫éËÆøË∞àÂÜÖÂÆπÂíåÊ£ÄÁ¥¢Âà∞ÁöÑÊñáÊ°£ÁîüÊàêÁªìÊûÑÂåñÁöÑÊä•ÂëäÂ∞èËäÇ\n",
    "        2. Á°Æ‰øùÂ∞èËäÇÂÜÖÂÆπÁ¨¶ÂêàÂàÜÊûêÂ∏àÁöÑ‰∏ì‰∏öÂÖ≥Ê≥®ÁÇπ\n",
    "        3. Êèê‰æõÂáÜÁ°ÆÁöÑÂºïÁî®ÂíåÊù•Ê∫ê‰ø°ÊÅØ\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ËÆøË∞àËÆ∞ÂΩï„ÄÅÊ£ÄÁ¥¢‰∏ä‰∏ãÊñáÂíåÂàÜÊûêÂ∏à‰ø°ÊÅØÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÁîüÊàêÁöÑÂ∞èËäÇÂÜÖÂÆπÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # ‰ªéÁä∂ÊÄÅ‰∏≠Ëé∑ÂèñÂøÖË¶Å‰ø°ÊÅØ\n",
    "    interview = state[\"interview\"]\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØÔºåÂåÖÂê´ÂàÜÊûêÂ∏àÁöÑÂÖ≥Ê≥®ÁÇπÊèèËø∞\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàêÊä•ÂëäÂ∞èËäÇ\n",
    "    section = llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=f\"‰ΩøÁî®Ëøô‰∫õÊù•Ê∫êÊí∞ÂÜô‰Ω†ÁöÑÂ∞èËäÇ: {context}\")\n",
    "    ])\n",
    "\n",
    "    # Â∞ÜÁîüÊàêÁöÑÂ∞èËäÇÊ∑ªÂä†Âà∞Áä∂ÊÄÅ‰∏≠\n",
    "    return {\"sections\": [section.content]}\n",
    "\n",
    "# ÊûÑÂª∫ËÆøË∞àÂ∑•‰ΩúÊµÅ\n",
    "interview_builder = StateGraph(InterviewState)\n",
    "\n",
    "# Ê∑ªÂä†ÂêÑ‰∏™ÂäüËÉΩËäÇÁÇπ\n",
    "interview_builder.add_node(\"ask_question\", generate_question)      # ÁîüÊàêÈóÆÈ¢òËäÇÁÇπ\n",
    "interview_builder.add_node(\"search_web\", search_web)              # ÁΩëÁªúÊêúÁ¥¢ËäÇÁÇπ\n",
    "interview_builder.add_node(\"search_baike\", search_baike)  # ÁôæÁßëÔºàÁôæÂ∫¶ÁôæÁßëÔºâÊêúÁ¥¢ËäÇÁÇπ\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)    # ÁîüÊàêÂõûÁ≠îËäÇÁÇπ\n",
    "interview_builder.add_node(\"save_interview\", save_interview)      # ‰øùÂ≠òËÆøË∞àËäÇÁÇπ\n",
    "interview_builder.add_node(\"write_section\", write_section)        # Êí∞ÂÜôÂ∞èËäÇËäÇÁÇπ\n",
    "\n",
    "# ÂÆö‰πâÂ∑•‰ΩúÊµÅËøûÊé•ÂÖ≥Á≥ª\n",
    "interview_builder.add_edge(START, \"ask_question\")  # ÂºÄÂßã -> ÊèêÈóÆ\n",
    "interview_builder.add_edge(\"ask_question\", \"search_web\")  # ÊèêÈóÆ -> ÁΩëÁªúÊêúÁ¥¢\n",
    "interview_builder.add_edge(\"ask_question\", \"search_baike\")  # ÊèêÈóÆ -> ÁôæÁßëÊêúÁ¥¢\n",
    "interview_builder.add_edge(\"search_web\", \"answer_question\")  # ÁΩëÁªúÊêúÁ¥¢ -> ÂõûÁ≠î\n",
    "interview_builder.add_edge(\"search_baike\", \"answer_question\")  # ÁôæÁßëÊêúÁ¥¢ -> ÂõûÁ≠î\n",
    "\n",
    "# Êù°‰ª∂ËæπÔºöÊ†πÊçÆÂØπËØùÁä∂ÊÄÅÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•\n",
    "interview_builder.add_conditional_edges(\n",
    "    \"answer_question\",\n",
    "    route_messages,\n",
    "    ['ask_question', 'save_interview']\n",
    ")\n",
    "\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")  # ‰øùÂ≠òËÆøË∞à -> Êí∞ÂÜôÂ∞èËäÇ\n",
    "interview_builder.add_edge(\"write_section\", END)  # Êí∞ÂÜôÂ∞èËäÇ -> ÁªìÊùü\n",
    "\n",
    "# ÁºñËØëËÆøË∞àÂ∑•‰ΩúÊµÅ\n",
    "memory = MemorySaver()\n",
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
    "\n",
    "\n",
    "# ÂõæÂèØËßÜÂåñ\n",
    "print(\"ÂõæÂèØËßÜÂåñÔºö\")\n",
    "\n",
    "# ÊñπÊ°à1ÔºöÂ∞ùËØï‰ΩøÁî® Pyppeteer Êú¨Âú∞Ê∏≤ÊüìÔºàÊé®ËçêÔºâ\n",
    "try:\n",
    "    # ÂèØËßÜÂåñÔºöÈÄöËøá Mermaid Ê∏≤ÊüìÂõæÁªìÊûÑ\n",
    "    display(Image(interview_graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"‚úÖ ÂõæÊ∏≤ÊüìÊàêÂäüÔºÅ\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Pyppeteer Ê∏≤ÊüìÂ§±Ë¥•: {e}\")\n",
    "    \n",
    "    # ÊñπÊ°à2ÔºöÊòæÁ§∫ Mermaid ÊñáÊú¨Ê†ºÂºè\n",
    "    print(\"\\nüìù ÂõæÁªìÊûÑÔºàMermaid ÊñáÊú¨Ê†ºÂºèÔºâÔºö\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = interview_graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ÊñπÊ°à3ÔºöÊòæÁ§∫ÂõæÁöÑËäÇÁÇπÂíåËæπ‰ø°ÊÅØ\n",
    "    print(\"\\nüîó ÂõæÁªìÊûÑ‰ø°ÊÅØÔºö\")\n",
    "    print(\"ËäÇÁÇπ:\", list(interview_graph.get_graph().nodes.keys()))\n",
    "    print(\"Ëæπ:\", list(interview_graph.get_graph().edges))\n",
    "    \n",
    "    # ÊñπÊ°à4ÔºöÊèê‰æõÊâãÂä®Ê∏≤ÊüìËØ¥Êòé\n",
    "    print(\"\\nüí° ÊâãÂä®Ê∏≤ÊüìËØ¥ÊòéÔºö\")\n",
    "    print(\"1. Â§çÂà∂‰∏äÈù¢ÁöÑ Mermaid ÊñáÊú¨\")\n",
    "    print(\"2. ËÆøÈóÆ https://mermaid.live/\")\n",
    "    print(\"3. Á≤òË¥¥ÊñáÊú¨Âà∞ÁºñËæëÂô®‰∏≠Êü•ÁúãÂõæÂΩ¢\")\n",
    "    print(\"4. ÊàñËÄÖ‰ΩøÁî®ÊîØÊåÅ Mermaid ÁöÑ Markdown ÁºñËæëÂô®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd4445-7147-41d3-91f5-21bbe48f2e00",
   "metadata": {},
   "source": [
    "![image-20250930152452478](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509301524600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
    "outputId": "b65a5a0a-3276-4cb0-98e1-0f948ffa5295"
   },
   "outputs": [],
   "source": [
    "# Pick one analyst\n",
    "analysts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750ac4f-f458-4b2d-8bad-32ce34895758",
   "metadata": {
    "id": "3750ac4f-f458-4b2d-8bad-32ce34895758"
   },
   "source": [
    "Ê≠§Â§ÑÊàë‰ª¨ËøêË°å‰∏ÄÊ¨°ËÆøË∞àÔºåÂπ∂‰º†ÂÖ•‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥ÁöÑ llama3.1 ËÆ∫ÊñáÁ¥¢Âºï‰Ωú‰∏∫ÂèÇËÄÉ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28",
    "outputId": "db68b62e-29b6-4372-80a0-50e906028c33"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "messages = [HumanMessage(f\"ÊâÄ‰ª•‰Ω†ËØ¥‰Ω†Âú®ÂÜô‰∏ÄÁØáÂÖ≥‰∫é{topic}ÁöÑÊñáÁ´†?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "interview = interview_graph.invoke({\"analyst\": analysts[0], \"messages\": messages, \"max_num_turns\": 2}, thread)\n",
    "Markdown(interview['sections'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b739e87-68bb-4e96-a86a-704e84240a6c",
   "metadata": {
    "id": "3b739e87-68bb-4e96-a86a-704e84240a6c"
   },
   "source": [
    "### Âπ∂Ë°åËÆøË∞àÔºöMap-Reduce\n",
    "\n",
    "Êàë‰ª¨ÈÄöËøá `Send()` API Âπ∂Ë°åËøêË°åÊØè‰∏™ËÆøË∞àÔºàmap Ê≠•Ôºâ„ÄÇ\n",
    "\n",
    "ÈöèÂêéÂú® reduce Ê≠•‰∏≠Â∞ÜÂÆÉ‰ª¨ÂêàÂπ∂‰∏∫Êä•Âëä‰∏ª‰Ωì„ÄÇ\n",
    "\n",
    "### Êî∂Â∞æÔºàFinalizeÔºâ\n",
    "\n",
    "ÊúÄÂêéÂ¢ûÂä†‰∏ÄÊ≠•Ôºå‰∏∫ÊúÄÁªàÊä•ÂëäÂÜôÂá∫ÂºïË®Ä‰∏éÁªìËÆ∫„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140",
   "metadata": {
    "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class ResearchGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Á†îÁ©∂ÂõæÁä∂ÊÄÅÁÆ°ÁêÜÁ±ª\n",
    "\n",
    "    Áî®‰∫éÁÆ°ÁêÜÊï¥‰∏™Á†îÁ©∂ÊµÅÁ®ãÁöÑÁä∂ÊÄÅ‰ø°ÊÅØÔºåÂåÖÊã¨ÂàÜÊûêÂ∏àÁîüÊàê„ÄÅÂπ∂Ë°åËÆøË∞àÂíåÊä•ÂëäÁîüÊàê\n",
    "    ËøôÊòØÊï¥‰∏™Á†îÁ©∂Âä©ÁêÜÁ≥ªÁªüÁöÑÊ†∏ÂøÉÁä∂ÊÄÅÁÆ°ÁêÜÁ±ª\n",
    "    \"\"\"\n",
    "    topic: str  # Á†îÁ©∂‰∏ªÈ¢ò\n",
    "    max_analysts: int  # ÂàÜÊûêÂ∏àÊï∞Èáè‰∏äÈôê\n",
    "    human_analyst_feedback: str  # ‰∫∫Á±ªÂèçÈ¶à‰ø°ÊÅØ\n",
    "    analysts: List[Analyst]  # ÂàÜÊûêÂ∏àÂàóË°®\n",
    "    sections: Annotated[list, operator.add]  # Êä•ÂëäÂ∞èËäÇÂàóË°®Ôºå‰ΩøÁî®operator.addËøõË°åÁ¥ØÂä†\n",
    "    introduction: str  # ÊúÄÁªàÊä•ÂëäÁöÑÂºïË®ÄÈÉ®ÂàÜ\n",
    "    content: str  # ÊúÄÁªàÊä•ÂëäÁöÑ‰∏ª‰ΩìÂÜÖÂÆπ\n",
    "    conclusion: str  # ÊúÄÁªàÊä•ÂëäÁöÑÁªìËÆ∫ÈÉ®ÂàÜ\n",
    "    final_report: str  # ÂÆåÊï¥ÁöÑÊúÄÁªàÊä•Âëä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2224592-d2ff-469d-97bd-928809f896d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c2224592-d2ff-469d-97bd-928809f896d7",
    "outputId": "9031b724-0a08-49bd-fc4a-74dbcb81ad3f"
   },
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    \"\"\"\n",
    "    ÂêØÂä®ÊâÄÊúâÂπ∂Ë°åËÆøË∞àÁöÑMapÊ≠•È™§\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Ê£ÄÊü•ÊòØÂê¶Êúâ‰∫∫Á±ªÂèçÈ¶àÔºåÂ¶ÇÊûúÊúâÂàôÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "        2. Â¶ÇÊûúÊ≤°ÊúâÂèçÈ¶àÔºåÂàôÂπ∂Ë°åÂêØÂä®ÊâÄÊúâÂàÜÊûêÂ∏àÁöÑËÆøË∞àÊµÅÁ®ã\n",
    "        3. ‰ΩøÁî®Send APIÂÆûÁé∞ÁúüÊ≠£ÁöÑÂπ∂Ë°åÊâßË°å\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂàÜÊûêÂ∏àÂàóË°®ÂíåÁ†îÁ©∂‰∏ªÈ¢òÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        str Êàñ List[Send]: Â¶ÇÊûúÊúâ‰∫∫Á±ªÂèçÈ¶àËøîÂõûËäÇÁÇπÂêçÔºåÂê¶ÂàôËøîÂõûSendÂØπË±°ÂàóË°®\n",
    "    \"\"\"\n",
    "    # Ê£ÄÊü•ÊòØÂê¶Êúâ‰∫∫Á±ªÂèçÈ¶à\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        # Êúâ‰∫∫Á±ªÂèçÈ¶àÔºåÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    # Ê≤°ÊúâÂèçÈ¶àÔºåÂπ∂Ë°åÂêØÂä®ÊâÄÊúâËÆøË∞à\n",
    "    else:\n",
    "        topic = state[\"topic\"]\n",
    "        # ‰∏∫ÊØè‰∏™ÂàÜÊûêÂ∏àÂàõÂª∫‰∏Ä‰∏™SendÂØπË±°ÔºåÂÆûÁé∞Âπ∂Ë°åÊâßË°å\n",
    "        return [\n",
    "            Send(\"conduct_interview\", {\n",
    "                \"analyst\": analyst,\n",
    "                \"messages\": [HumanMessage(\n",
    "                    content=f\"ÊâÄ‰ª•‰Ω†ËØ¥‰Ω†Âú®ÂÜô‰∏ÄÁØáÂÖ≥‰∫é{topic}ÁöÑÊñáÁ´†?\"\n",
    "                )]\n",
    "            })\n",
    "            for analyst in state[\"analysts\"]\n",
    "        ]\n",
    "\n",
    "# Êä•ÂëäÂÜô‰ΩúÊåá‰ª§Ê®°Êùø\n",
    "# ÊåáÂØºAIÂ¶Ç‰ΩïÂ∞ÜÂ§ö‰∏™ÂàÜÊûêÂ∏àÁöÑÂ∞èËäÇÊï¥Âêà‰∏∫Áªü‰∏ÄÁöÑÊä•Âëä‰∏ª‰Ωì\n",
    "report_writer_instructions = \"\"\"‰Ω†ÊòØ‰∏ÄÂêçÊäÄÊúØÂÜô‰ΩúËÄÖÔºåÊ≠£Âú®‰∏∫Â¶Ç‰∏ã‰∏ªÈ¢òÊí∞ÂÜôÊä•ÂëäÔºö\n",
    "\n",
    "{topic}\n",
    "\n",
    "‰Ω†Êã•Êúâ‰∏ÄÊîØÂàÜÊûêÂ∏àÂõ¢Èòü„ÄÇÊØè‰ΩçÂàÜÊûêÂ∏àÂÆåÊàê‰∫Ü‰∏§‰ª∂‰∫ãÔºö\n",
    "\n",
    "1. Âõ¥Áªï‰∏Ä‰∏™ÂÖ∑‰ΩìÂ≠ê‰∏ªÈ¢òÔºåËÆøË∞à‰∫Ü‰∏Ä‰Ωç‰∏ìÂÆ∂„ÄÇ\n",
    "2. Â∞ÜÂèëÁé∞ÂÜôÊàê‰∏Ä‰ªΩÂ§áÂøòÂΩïÔºàmemoÔºâ„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑ‰ªªÂä°Ôºö\n",
    "\n",
    "1. ‰Ω†Â∞ÜÊî∂Âà∞ÂàÜÊûêÂ∏à‰ª¨ÁöÑÂ§áÂøòÂΩïÈõÜÂêà„ÄÇ\n",
    "2. ‰ªîÁªÜÊÄùËÄÉÊØè‰ªΩÂ§áÂøòÂΩïÁöÑÊ¥ûËßÅ„ÄÇ\n",
    "3. Â∞ÜÂÆÉ‰ª¨Êï¥Âêà‰∏∫ÁÆÄÊ¥ÅÁöÑÊÄª‰ΩìÊÄªÁªìÔºå‰∏≤ËÅîËµ∑ÊâÄÊúâÂ§áÂøòÂΩïÁöÑ‰∏≠ÂøÉËßÇÁÇπ„ÄÇ\n",
    "4. ÊääÊØè‰ªΩÂ§áÂøòÂΩïÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÂΩíÁ∫≥Êàê‰∏Ä‰∏™ËøûË¥ØÁöÑÂçï‰∏ÄÂèôËø∞„ÄÇ\n",
    "\n",
    "**ÈáçË¶ÅË¶ÅÊ±ÇÔºöÁîüÊàêÁöÑÊä•ÂëäÂøÖÈ°ªÂÖ®ÈÉ®‰ΩøÁî®‰∏≠ÊñáÔºåÊâÄÊúâÂÜÖÂÆπÈÉΩÂøÖÈ°ªÊòØ‰∏≠ÊñáËæìÂá∫ÔºåÂåÖÊã¨Ê†áÈ¢ò„ÄÅÊ≠£Êñá„ÄÅÊúØËØ≠Ëß£ÈáäÁ≠â„ÄÇÂØπ‰∫éÁâπÊÆäÁöÑËã±ÊñáÊúØËØ≠ÔºåÂèØ‰ª•Âú®‰∏≠ÊñáÂêéÈù¢Âä†‰∏äËã±ÊñáÊ†áÊ≥®„ÄÇ**\n",
    "\n",
    "Êä•ÂëäÊ†ºÂºèË¶ÅÊ±ÇÔºö\n",
    "\n",
    "1. ‰ΩøÁî® Markdown Ê†ºÂºè„ÄÇ\n",
    "2. Êä•Âëä‰∏çË¶ÅÊúâ‰ªª‰ΩïÂâçË®Ä„ÄÇ\n",
    "3. ‰∏ç‰ΩøÁî®‰ªª‰ΩïÂ∞èÊ†áÈ¢ò„ÄÇ\n",
    "4. Êä•Âëä‰ª•‰∏Ä‰∏™Ê†áÈ¢òÂºÄÂ§¥Ôºö## Insights\n",
    "5. Êä•Âëä‰∏≠‰∏çË¶ÅÊèêÂèä‰ªª‰ΩïÂàÜÊûêÂ∏àÁöÑÂêçÂ≠ó„ÄÇ\n",
    "6. ‰øùÁïôÂ§áÂøòÂΩï‰∏≠ÁöÑÂºïÁî®Ê†áÊ≥®ÔºàÂ¶Ç [1]„ÄÅ[2]Ôºâ„ÄÇ\n",
    "7. Ê±áÊÄªÊúÄÁªàÊù•Ê∫êÂàóË°®ÔºåÂπ∂‰ª• `## Sources` ‰Ωú‰∏∫Â∞èËäÇÊ†áÈ¢ò„ÄÇ\n",
    "8. ÊåâÈ°∫Â∫èÂàóÂá∫Êù•Ê∫ê‰∏î‰∏çË¶ÅÈáçÂ§ç„ÄÇ\n",
    "\n",
    "[1] Source 1\n",
    "[2] Source 2\n",
    "\n",
    "‰ª•‰∏ãÊòØÂàÜÊûêÂ∏àÊèê‰æõÁöÑÂ§áÂøòÂΩïÔºåËØ∑Âü∫‰∫éÊ≠§Êí∞ÂÜôÊä•ÂëäÔºö\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "def write_report(state: ResearchGraphState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêÊúÄÁªàÊä•Âëä‰∏ª‰ΩìÂÜÖÂÆπÁöÑÂáΩÊï∞ÔºàReduceÊ≠•È™§Ôºâ\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Êî∂ÈõÜÊâÄÊúâÂàÜÊûêÂ∏àÁöÑÂ∞èËäÇÂÜÖÂÆπ\n",
    "        2. Â∞ÜÂ§ö‰∏™Â∞èËäÇÊï¥Âêà‰∏∫Áªü‰∏ÄÁöÑÊä•Âëä‰∏ª‰Ωì\n",
    "        3. Á°Æ‰øùÊä•ÂëäÁªìÊûÑÊ∏ÖÊô∞„ÄÅÂÜÖÂÆπËøûË¥Ø\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢òÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´Êä•Âëä‰∏ª‰ΩìÂÜÖÂÆπÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢ò\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Â∞ÜÊâÄÊúâÂ∞èËäÇÊãºÊé•‰∏∫ÂÆåÊï¥ÊñáÊú¨\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØÔºåÂåÖÂê´Á†îÁ©∂‰∏ªÈ¢òÂíåÂ∞èËäÇÂÜÖÂÆπ\n",
    "    system_message = report_writer_instructions.format(\n",
    "        topic=topic,\n",
    "        context=formatted_str_sections\n",
    "    )\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàêÊä•Âëä‰∏ª‰Ωì\n",
    "    report = llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=f\"Âü∫‰∫éËøô‰∫õÂ§áÂøòÂΩïÊí∞ÂÜô‰∏Ä‰ªΩÊä•Âëä„ÄÇ\")\n",
    "    ])\n",
    "\n",
    "    return {\"content\": report.content}\n",
    "\n",
    "# ÂºïË®ÄÂíåÁªìËÆ∫ÂÜô‰ΩúÊåá‰ª§Ê®°Êùø\n",
    "# ÊåáÂØºAIÂ¶Ç‰Ωï‰∏∫Êä•ÂëäÁîüÊàêÁÆÄÊ¥ÅÊúâÂäõÁöÑÂºïË®ÄÂíåÁªìËÆ∫\n",
    "intro_conclusion_instructions = \"\"\"‰Ω†ÊòØ‰∏ÄÂêçÊäÄÊúØÂÜô‰ΩúËÄÖÔºåÊ≠£Âú®ÂÆåÊàê‰∏ªÈ¢ò‰∏∫ {topic} ÁöÑÊä•Âëä„ÄÇ\n",
    "\n",
    "‰Ω†Â∞ÜËé∑ÂæóÊä•ÂëäÁöÑÂÖ®ÈÉ®Â∞èËäÇ„ÄÇ\n",
    "\n",
    "‰Ω†ÁöÑ‰ªªÂä°ÊòØÊí∞ÂÜôÁÆÄÊ¥ÅËÄåÊúâËØ¥ÊúçÂäõÁöÑÂºïË®ÄÊàñÁªìËÆ∫„ÄÇ\n",
    "\n",
    "Áî±Áî®Êà∑ÂëäÁü•ÂÜôÂºïË®ÄËøòÊòØÁªìËÆ∫„ÄÇ\n",
    "\n",
    "‰∏§ËÄÖÂùá‰∏çÈúÄË¶Å‰ªª‰ΩïÂâçË®Ä„ÄÇ\n",
    "\n",
    "ÁõÆÊ†áÁ∫¶ 100 Â≠óÔºö\n",
    "- ÂºïË®ÄÔºöÁ≤æÁÇºÈ¢ÑËßàÂêÑÂ∞èËäÇË¶ÅÁÇπ\n",
    "- ÁªìËÆ∫ÔºöÁ≤æÁÇºÂõûÈ°æÂêÑÂ∞èËäÇË¶ÅÁÇπ\n",
    "\n",
    "‰ΩøÁî® Markdown Ê†ºÂºè„ÄÇ\n",
    "\n",
    "**ÈáçË¶ÅË¶ÅÊ±ÇÔºöÁîüÊàêÁöÑÊä•ÂëäÂøÖÈ°ªÂÖ®ÈÉ®‰ΩøÁî®‰∏≠ÊñáÔºåÊâÄÊúâÂÜÖÂÆπÈÉΩÂøÖÈ°ªÊòØ‰∏≠ÊñáËæìÂá∫ÔºåÂåÖÊã¨Ê†áÈ¢ò„ÄÅÊ≠£Êñá„ÄÅÊúØËØ≠Ëß£ÈáäÁ≠â„ÄÇÂØπ‰∫éÁâπÊÆäÁöÑËã±ÊñáÊúØËØ≠ÔºåÂèØ‰ª•Âú®‰∏≠ÊñáÂêéÈù¢Âä†‰∏äËã±ÊñáÊ†áÊ≥®„ÄÇ**\n",
    "\n",
    "ÂºïË®ÄË¶ÅÊ±ÇÔºöÂàõÂª∫‰∏Ä‰∏™ÊúâÂê∏ÂºïÂäõÁöÑÊ†áÈ¢òÔºåÂπ∂Áî® # ‰Ωú‰∏∫Ê†áÈ¢òÂ§¥„ÄÇ\n",
    "\n",
    "ÂºïË®ÄÂ∞èËäÇÊ†áÈ¢ò‰ΩøÁî®Ôºö## ÂºïË®Ä\n",
    "\n",
    "ÁªìËÆ∫Â∞èËäÇÊ†áÈ¢ò‰ΩøÁî®Ôºö## ÁªìËÆ∫\n",
    "\n",
    "Êí∞ÂÜôÊó∂ÂèØÂèÇËÄÉ‰ª•‰∏ãÂ∞èËäÇÂÜÖÂÆπÔºö{formatted_str_sections}\"\"\"\n",
    "\n",
    "def write_introduction(state: ResearchGraphState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêÊä•ÂëäÂºïË®ÄÁöÑÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Âü∫‰∫éÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÁîüÊàêÊä•ÂëäÂºïË®Ä\n",
    "        2. Êèê‰æõÊä•ÂëäÁöÑÊï¥‰ΩìÊ¶ÇËßàÂíåÂê∏ÂºïÂäõ\n",
    "        3. ‰∏∫ËØªËÄÖÊèê‰æõÈòÖËØªÊåáÂØº\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢òÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÂºïË®ÄÂÜÖÂÆπÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢ò\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Â∞ÜÊâÄÊúâÂ∞èËäÇÊãºÊé•‰∏∫ÂÆåÊï¥ÊñáÊú¨\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ÊûÑÂª∫Êåá‰ª§ÔºåÂåÖÂê´Á†îÁ©∂‰∏ªÈ¢òÂíåÂ∞èËäÇÂÜÖÂÆπ\n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic,\n",
    "        formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàêÂºïË®Ä\n",
    "    intro = llm.invoke([\n",
    "        instructions,\n",
    "        HumanMessage(content=f\"Êí∞ÂÜôÊä•ÂëäÂºïË®Ä\")\n",
    "    ])\n",
    "\n",
    "    return {\"introduction\": intro.content}\n",
    "\n",
    "def write_conclusion(state: ResearchGraphState):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêÊä•ÂëäÁªìËÆ∫ÁöÑÂáΩÊï∞\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Âü∫‰∫éÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÁîüÊàêÊä•ÂëäÁªìËÆ∫\n",
    "        2. ÊÄªÁªìÊä•ÂëäÁöÑ‰∏ªË¶ÅÂèëÁé∞ÂíåÊ¥ûÂØü\n",
    "        3. ‰∏∫ËØªËÄÖÊèê‰æõÊ∏ÖÊô∞ÁöÑÊÄªÁªì\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢òÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÁªìËÆ∫ÂÜÖÂÆπÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÊâÄÊúâÂ∞èËäÇÂÜÖÂÆπÂíåÁ†îÁ©∂‰∏ªÈ¢ò\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # Â∞ÜÊâÄÊúâÂ∞èËäÇÊãºÊé•‰∏∫ÂÆåÊï¥ÊñáÊú¨\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ÊûÑÂª∫Êåá‰ª§ÔºåÂåÖÂê´Á†îÁ©∂‰∏ªÈ¢òÂíåÂ∞èËäÇÂÜÖÂÆπ\n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic,\n",
    "        formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "\n",
    "    # Ë∞ÉÁî®Â§ßÊ®°ÂûãÁîüÊàêÁªìËÆ∫\n",
    "    conclusion = llm.invoke([\n",
    "        instructions,\n",
    "        HumanMessage(content=f\"Êí∞ÂÜôÊä•ÂëäÁªìËÆ∫\")\n",
    "    ])\n",
    "\n",
    "    return {\"conclusion\": conclusion.content}\n",
    "\n",
    "def finalize_report(state: ResearchGraphState):\n",
    "    \"\"\"\n",
    "    ÊúÄÁªàÊä•ÂëäÁîüÊàêÂáΩÊï∞ÔºàReduceÊ≠•È™§ÁöÑÊúÄÁªàÈò∂ÊÆµÔºâ\n",
    "\n",
    "    ÂäüËÉΩ:\n",
    "        1. Êï¥ÂêàÂºïË®Ä„ÄÅ‰∏ª‰ΩìÂÜÖÂÆπÂíåÁªìËÆ∫\n",
    "        2. Â§ÑÁêÜÊù•Ê∫ê‰ø°ÊÅØÁöÑÊ†ºÂºè\n",
    "        3. ÁîüÊàêÂÆåÊï¥ÁöÑÊúÄÁªàÊä•Âëä\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state: ÂåÖÂê´ÂºïË®Ä„ÄÅ‰∏ª‰ΩìÂÜÖÂÆπ„ÄÅÁªìËÆ∫ÂíåÊù•Ê∫ê‰ø°ÊÅØÁöÑÁä∂ÊÄÅÂØπË±°\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ÂÆåÊï¥ÊúÄÁªàÊä•ÂëäÁöÑÂ≠óÂÖ∏\n",
    "    \"\"\"\n",
    "    # Ëé∑ÂèñÊä•Âëä‰∏ª‰ΩìÂÜÖÂÆπ\n",
    "    content = state[\"content\"]\n",
    "\n",
    "    # Ê∏ÖÁêÜÂÜÖÂÆπÊ†ºÂºèÔºåÁßªÈô§ÈáçÂ§çÁöÑÊ†áÈ¢ò\n",
    "    if content.startswith(\"## Insights\"):\n",
    "        content = content.strip(\"## Insights\")\n",
    "\n",
    "    # ÂàÜÁ¶ª‰∏ª‰ΩìÂÜÖÂÆπÂíåÊù•Ê∫ê‰ø°ÊÅØ\n",
    "    if \"## Sources\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## Sources\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "\n",
    "    # ÁªÑÂêàÂÆåÊï¥ÁöÑÊúÄÁªàÊä•Âëä\n",
    "    final_report = (\n",
    "        state[\"introduction\"] +\n",
    "        \"\\n\\n---\\n\\n\" +\n",
    "        content +\n",
    "        \"\\n\\n---\\n\\n\" +\n",
    "        state[\"conclusion\"]\n",
    "    )\n",
    "\n",
    "    # Â¶ÇÊûúÊúâÊù•Ê∫ê‰ø°ÊÅØÔºåÊ∑ªÂä†Âà∞Êä•ÂëäÊú´Â∞æ\n",
    "    if sources is not None:\n",
    "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
    "\n",
    "    return {\"final_report\": final_report}\n",
    "\n",
    "# ÊûÑÂª∫ÂÆåÊï¥ÁöÑÁ†îÁ©∂ÂõæÂ∑•‰ΩúÊµÅ\n",
    "builder = StateGraph(ResearchGraphState)\n",
    "\n",
    "# Ê∑ªÂä†ÊâÄÊúâÂäüËÉΩËäÇÁÇπ\n",
    "builder.add_node(\"create_analysts\", create_analysts)  # ÂàÜÊûêÂ∏àÁîüÊàêËäÇÁÇπ\n",
    "builder.add_node(\"human_feedback\", human_feedback)    # ‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπ\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())  # ËÆøË∞àÂ≠êÂõæËäÇÁÇπ\n",
    "builder.add_node(\"write_report\", write_report)        # Êä•Âëä‰∏ª‰ΩìÂÜô‰ΩúËäÇÁÇπ\n",
    "builder.add_node(\"write_introduction\", write_introduction)  # ÂºïË®ÄÂÜô‰ΩúËäÇÁÇπ\n",
    "builder.add_node(\"write_conclusion\", write_conclusion)      # ÁªìËÆ∫ÂÜô‰ΩúËäÇÁÇπ\n",
    "builder.add_node(\"finalize_report\", finalize_report)        # ÊúÄÁªàÊä•ÂëäÁîüÊàêËäÇÁÇπ\n",
    "\n",
    "# ÂÆö‰πâÂ∑•‰ΩúÊµÅËøûÊé•ÂÖ≥Á≥ª\n",
    "builder.add_edge(START, \"create_analysts\")  # ÂºÄÂßã -> ÁîüÊàêÂàÜÊûêÂ∏à\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")  # ÁîüÊàêÂàÜÊûêÂ∏à -> ‰∫∫Á±ªÂèçÈ¶à\n",
    "\n",
    "# Êù°‰ª∂ËæπÔºöÊ†πÊçÆÊòØÂê¶ÊúâÂèçÈ¶àÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\",\n",
    "    initiate_all_interviews,\n",
    "    [\"create_analysts\", \"conduct_interview\"]\n",
    ")\n",
    "\n",
    "# Âπ∂Ë°åÊâßË°åÔºöËÆøË∞àÂÆåÊàêÂêéÂêåÊó∂ËøõË°åÊä•ÂëäÂÜô‰Ωú„ÄÅÂºïË®ÄÂÜô‰ΩúÂíåÁªìËÆ∫ÂÜô‰Ωú\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "\n",
    "# Á≠âÂæÖÊâÄÊúâÂÜô‰Ωú‰ªªÂä°ÂÆåÊàêÂêéÔºåËøõË°åÊúÄÁªàÊä•ÂëäÁîüÊàê\n",
    "builder.add_edge(\n",
    "    [\"write_conclusion\", \"write_report\", \"write_introduction\"],\n",
    "    \"finalize_report\"\n",
    ")\n",
    "builder.add_edge(\"finalize_report\", END)  # ÊúÄÁªàÊä•ÂëäÁîüÊàê -> ÁªìÊùü\n",
    "\n",
    "# ÁºñËØëÂÆåÊï¥ÁöÑÁ†îÁ©∂ÂõæÂ∑•‰ΩúÊµÅ\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(\n",
    "    interrupt_before=['human_feedback'],  # Âú®‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπÂâç‰∏≠Êñ≠\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "# ÊòæÁ§∫ÂÆåÊï¥ÁöÑÂ∑•‰ΩúÊµÅÂõæ\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0",
   "metadata": {
    "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0"
   },
   "source": [
    "Êàë‰ª¨Êù•Â∞± LangGraph Êèê‰∏Ä‰∏™ÂºÄÊîæÂºèÈóÆÈ¢ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
    "outputId": "2498f7ea-2c34-426b-caa2-efe6c2137bdf"
   },
   "outputs": [],
   "source": [
    "# ÊºîÁ§∫ÔºöËøêË°åÁ†îÁ©∂Âä©ÁêÜÁ≥ªÁªü\n",
    "# ËÆæÁΩÆËæìÂÖ•ÂèÇÊï∞\n",
    "max_analysts = 3  # ÂàÜÊûêÂ∏àÊï∞Èáè\n",
    "topic = \"ÈááÁî®LangGraph‰Ωú‰∏∫AI AgentÊ°ÜÊû∂ÁöÑÂ•ΩÂ§Ñ\"  # Á†îÁ©∂‰∏ªÈ¢ò\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}  # Á∫øÁ®ãIDÔºåÁî®‰∫éÁä∂ÊÄÅÁÆ°ÁêÜ\n",
    "\n",
    "# ËøêË°åÂ∑•‰ΩúÊµÅÁõ¥Âà∞Á¨¨‰∏Ä‰∏™‰∏≠Êñ≠ÁÇπÔºà‰∫∫Á±ªÂèçÈ¶àËäÇÁÇπÔºâ\n",
    "for event in graph.stream({\n",
    "    \"topic\": topic,\n",
    "    \"max_analysts\": max_analysts\n",
    "}, thread, stream_mode=\"values\"):\n",
    "\n",
    "    # Ê£ÄÊü•ÊòØÂê¶ÊúâÂàÜÊûêÂ∏à‰ø°ÊÅØËæìÂá∫\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        # ÊòæÁ§∫ÁîüÊàêÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØ\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
    "outputId": "9ac87141-cc10-4e31-b453-f7c1d288bc06"
   },
   "outputs": [],
   "source": [
    "# Ê®°Êãü‰∫∫Á±ªÂèçÈ¶àÔºöÊ∑ªÂä†‰∏Ä‰∏™AIÂéüÁîüÂàùÂàõÂÖ¨Âè∏ÁöÑCEOËßÜËßí\n",
    "# ËøôÂ±ïÁ§∫‰∫Ü‰∫∫Êú∫ÂçèÂêåÔºàHuman-in-the-loopÔºâÂäüËÉΩÁöÑ‰ΩøÁî®\n",
    "graph.update_state(thread, {\n",
    "    \"human_analyst_feedback\": \"Ê∑ªÂä†‰∏Ä‰∏™AIÂéüÁîüÂàùÂàõÂÖ¨Âè∏ÁöÑCEO\"\n",
    "}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
    "outputId": "d507e3b8-68c4-43bd-da1a-026413e162f8"
   },
   "outputs": [],
   "source": [
    "# Ê£ÄÊü•Êõ¥Êñ∞ÂêéÁöÑÂàÜÊûêÂ∏àÂàóË°®\n",
    "# Á≥ªÁªü‰ºöÊ†πÊçÆ‰∫∫Á±ªÂèçÈ¶àÈáçÊñ∞ÁîüÊàêÂàÜÊûêÂ∏àÂõ¢Èòü\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        # ÊòæÁ§∫Êõ¥Êñ∞ÂêéÁöÑÂàÜÊûêÂ∏à‰ø°ÊÅØ\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af41f54-88d9-4597-98b0-444c08322095",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0af41f54-88d9-4597-98b0-444c08322095",
    "outputId": "44858e67-bb8a-44de-c5ef-2b191f117013"
   },
   "outputs": [],
   "source": [
    "# Á°ÆËÆ§Êª°ÊÑèÂΩìÂâçÁöÑÂàÜÊûêÂ∏àÂõ¢ÈòüÔºåÁªßÁª≠ÊâßË°åÂêéÁª≠ÊµÅÁ®ã\n",
    "# ËÆæÁΩÆÂèçÈ¶à‰∏∫NoneË°®Á§∫Ê≤°ÊúâËøõ‰∏ÄÊ≠•ÁöÑ‰øÆÊîπÈúÄÊ±Ç\n",
    "graph.update_state(thread, {\n",
    "    \"human_analyst_feedback\": None\n",
    "}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
    "outputId": "dc7eee62-2047-4aff-9fd7-bae60e914aa7"
   },
   "outputs": [],
   "source": [
    "# ÁªßÁª≠ÊâßË°åÂÆåÊï¥ÁöÑÁ†îÁ©∂ÊµÅÁ®ã\n",
    "# ÂåÖÊã¨Âπ∂Ë°åËÆøË∞à„ÄÅÊä•ÂëäÁîüÊàêÁ≠âÊâÄÊúâÂêéÁª≠Ê≠•È™§\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
    "outputId": "14cfbc76-d0f9-436f-ccd1-c30110f6d3c7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# Ëé∑ÂèñÊúÄÁªàÁä∂ÊÄÅÂπ∂ÊòæÁ§∫ÁîüÊàêÁöÑÊä•Âëä\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "\n",
    "# ‰ΩøÁî®MarkdownÊ†ºÂºèÊòæÁ§∫ÊúÄÁªàÊä•Âëä\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55516",
   "metadata": {},
   "source": [
    "## üî¨ Êô∫ËÉΩ‰ΩìÂú®Á∫øËØÑ‰º∞ÔºöÊÄßËÉΩÁõëÊéß‰∏éÁî®Êà∑ÂèçÈ¶à\n",
    "\n",
    "Âú®Á∫øËØÑ‰º∞ÊòØÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÁöÑÈáçË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºåÂÆÉÂÖÅËÆ∏Êàë‰ª¨Âú®Áîü‰∫ßÁéØÂ¢É‰∏≠ÂÆûÊó∂ÁõëÊéßÁ≥ªÁªüË°®Áé∞„ÄÇ\n",
    "\n",
    "### üìä ‰∏ªË¶ÅËØÑ‰º∞ÊåáÊ†á\n",
    "\n",
    "#### 1. ÊàêÊú¨ÁõëÊéß (Cost Monitoring)\n",
    "- **LLM Ë∞ÉÁî®ÊàêÊú¨**ÔºöËøΩË∏™ÊØèÊ¨°Ê®°ÂûãË∞ÉÁî®ÁöÑ‰ª§ÁâåÊ∂àËÄó\n",
    "- **API Ë∞ÉÁî®È¢ëÁéá**ÔºöÁõëÊéßÂêÑ‰∏™ÊúçÂä°ÁöÑË∞ÉÁî®Ê¨°Êï∞\n",
    "- **ËµÑÊ∫ê‰ΩøÁî®ÊïàÁéá**ÔºöËØÑ‰º∞Á≥ªÁªüËµÑÊ∫êÁöÑÂêàÁêÜÈÖçÁΩÆ\n",
    "\n",
    "#### 2. ÊÄßËÉΩÊåáÊ†á (Performance Metrics)\n",
    "- **ÂìçÂ∫îÂª∂Ëøü**ÔºöÊµãÈáè‰ªéÁî®Êà∑ËæìÂÖ•Âà∞Á≥ªÁªüËæìÂá∫ÁöÑÊó∂Èó¥\n",
    "- **ÂêûÂêêÈáè**ÔºöÁªüËÆ°Âçï‰ΩçÊó∂Èó¥ÂÜÖÂ§ÑÁêÜÁöÑËØ∑Ê±ÇÊï∞Èáè\n",
    "- **ÊàêÂäüÁéá**ÔºöËÆ°ÁÆó‰ªªÂä°ÂÆåÊàêÁöÑÊàêÂäüÊØî‰æã\n",
    "\n",
    "#### 3. Áî®Êà∑‰ΩìÈ™å (User Experience)\n",
    "- **Áî®Êà∑Êª°ÊÑèÂ∫¶**ÔºöÊî∂ÈõÜÁî®Êà∑ÂØπËæìÂá∫Ë¥®ÈáèÁöÑÂèçÈ¶à\n",
    "- **‰∫§‰∫íÊïàÊûú**ÔºöËØÑ‰º∞‰∫∫Êú∫ÂçèÂêåÁöÑÊµÅÁïÖÁ®ãÂ∫¶\n",
    "- **ËæìÂá∫Ë¥®Èáè**ÔºöÂàÜÊûêÁîüÊàêÂÜÖÂÆπÁöÑÂáÜÁ°ÆÊÄßÂíåÊúâÁî®ÊÄß\n",
    "\n",
    "#### 4. Á≥ªÁªüÁ®≥ÂÆöÊÄß (System Reliability)\n",
    "- **ÈîôËØØÁéá**ÔºöÁõëÊéßÁ≥ªÁªüÂºÇÂ∏∏ÂíåÂ§±Ë¥•ÊÉÖÂÜµ\n",
    "- **ÂèØÁî®ÊÄß**ÔºöÁ°Æ‰øùÊúçÂä°ÁöÑÊåÅÁª≠Á®≥ÂÆöËøêË°å\n",
    "- **ÂÆπÈîôËÉΩÂäõ**ÔºöÊµãËØïÁ≥ªÁªüÂú®ÂºÇÂ∏∏ÊÉÖÂÜµ‰∏ãÁöÑË°®Áé∞\n",
    "\n",
    "### üéØ ËØÑ‰º∞ÁöÑ‰ª∑ÂÄº\n",
    "\n",
    "ÈÄöËøáÊåÅÁª≠ÁöÑÂú®Á∫øËØÑ‰º∞ÔºåÊàë‰ª¨ÂèØ‰ª•Ôºö\n",
    "- **Âø´ÈÄüÂèëÁé∞ÈóÆÈ¢ò**ÔºöÂèäÊó∂ËØÜÂà´ÊÄßËÉΩ‰∏ãÈôçÊàñË¥®ÈáèÈóÆÈ¢ò\n",
    "- **‰ºòÂåñËµÑÊ∫êÈÖçÁΩÆ**ÔºöÊ†πÊçÆÂÆûÈôÖ‰ΩøÁî®ÊÉÖÂÜµË∞ÉÊï¥Á≥ªÁªüÂèÇÊï∞\n",
    "- **ÊîπËøõÁî®Êà∑‰ΩìÈ™å**ÔºöÂü∫‰∫éÁúüÂÆûÂèçÈ¶àÊåÅÁª≠‰ºòÂåñ‰∫ßÂìÅ\n",
    "- **Êï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ**ÔºöÁî®Êï∞ÊçÆÊîØÊíë‰∫ßÂìÅËø≠‰ª£ÂíåÊäÄÊúØÈÄâÂûã\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177dfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ ÊºîÁ§∫ÂÆåÊï¥ÁöÑÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÔºöÁ´ØÂà∞Á´ØÁ†îÁ©∂ÊµÅÁ®ã\n",
    "\n",
    "print(\"üöÄ ÂêØÂä®ÂÆåÊï¥ÁöÑÊ∑±Â∫¶Á†îÁ©∂Âä©ÊâãËØÑ‰º∞ÊºîÁ§∫\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üî¨ ‰ΩøÁî®Â¢ûÂº∫ÁâàÁöÑËÆøË∞àÂ∑•‰ΩúÊµÅÔºàÂ∏¶ËØÑ‰º∞ÂäüËÉΩÔºâ\n",
    "def create_enhanced_interview_workflow():\n",
    "    \"\"\"\n",
    "    ÂàõÂª∫Â∏¶ÊúâÂÆåÊï¥ËØÑ‰º∞ÂäüËÉΩÁöÑËÆøË∞àÂ∑•‰ΩúÊµÅ\n",
    "    \n",
    "    Â¢ûÂº∫ÂäüËÉΩÂåÖÊã¨Ôºö\n",
    "    - üîç ÊêúÁ¥¢Êìç‰ΩúÁöÑË¥®ÈáèËØÑ‰º∞\n",
    "    - ‚è±Ô∏è ËÆøË∞àËøáÁ®ãÁöÑÊÄßËÉΩÁõëÊéß  \n",
    "    - üìù ÁîüÊàêÂÜÖÂÆπÁöÑË¥®ÈáèËØÑ‰º∞\n",
    "    - üîÑ Êï¥‰ΩìÊµÅÁ®ãÁöÑÊïàÁéáÂàÜÊûê\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_question_with_eval(state: InterviewState):\n",
    "        \"\"\"ÁîüÊàêËÆøË∞àÈóÆÈ¢òÔºàÂ∏¶ËØÑ‰º∞Ôºâ\"\"\"\n",
    "        with langfuse.start_as_current_span(name=\"generate_question\") as span:\n",
    "            analyst = state[\"analyst\"]\n",
    "            messages = state[\"messages\"]\n",
    "            \n",
    "            # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØ\n",
    "            system_message = question_instructions.format(goals=analyst.persona)\n",
    "            question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "            \n",
    "            # ËÆ∞ÂΩïÈóÆÈ¢òÁîüÊàêË¥®Èáè\n",
    "            span.update_trace(\n",
    "                input={\"analyst_role\": analyst.role, \"conversation_turns\": len(messages)},\n",
    "                output={\"question_length\": len(question.content), \"question_preview\": question.content[:100]}\n",
    "            )\n",
    "            \n",
    "            return {\"messages\": [question]}\n",
    "    \n",
    "    def generate_answer_with_eval(state: InterviewState):\n",
    "        \"\"\"ÁîüÊàê‰∏ìÂÆ∂ÂõûÁ≠îÔºàÂ∏¶ËØÑ‰º∞Ôºâ\"\"\"\n",
    "        with langfuse.start_as_current_span(name=\"generate_answer\") as span:\n",
    "            analyst = state[\"analyst\"]\n",
    "            messages = state[\"messages\"]\n",
    "            context = state[\"context\"]\n",
    "            \n",
    "            # ÊûÑÂª∫Á≥ªÁªüÊ∂àÊÅØ\n",
    "            system_message = answer_instructions.format(\n",
    "                goals=analyst.persona,\n",
    "                context=context\n",
    "            )\n",
    "            \n",
    "            answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "            answer.name = \"expert\"\n",
    "            \n",
    "            # ËØÑ‰º∞ÂõûÁ≠îË¥®Èáè\n",
    "            span.update_trace(\n",
    "                input={\n",
    "                    \"context_length\": len(str(context)),\n",
    "                    \"conversation_turns\": len(messages)\n",
    "                },\n",
    "                output={\n",
    "                    \"answer_length\": len(answer.content),\n",
    "                    \"has_citations\": \"[\" in answer.content and \"]\" in answer.content,\n",
    "                    \"answer_preview\": answer.content[:150]\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            return {\"messages\": [answer]}\n",
    "    \n",
    "    def save_interview_with_eval(state: InterviewState):\n",
    "        \"\"\"‰øùÂ≠òËÆøË∞àÂÜÖÂÆπÔºàÂ∏¶ËØÑ‰º∞Ôºâ\"\"\"\n",
    "        with langfuse.start_as_current_span(name=\"save_interview\") as span:\n",
    "            messages = state[\"messages\"]\n",
    "            interview = get_buffer_string(messages)\n",
    "            \n",
    "            # ËØÑ‰º∞ËÆøË∞àË¥®Èáè\n",
    "            span.update_trace(\n",
    "                input={\"messages_count\": len(messages)},\n",
    "                output={\n",
    "                    \"interview_length\": len(interview),\n",
    "                    \"qa_pairs\": len([m for m in messages if m.name == \"expert\"]),\n",
    "                    \"interview_summary\": f\"ÂÆåÊàê {len([m for m in messages if m.name == 'expert'])} ËΩÆÈóÆÁ≠î\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            return {\"interview\": interview}\n",
    "    \n",
    "    return generate_question_with_eval, generate_answer_with_eval, save_interview_with_eval\n",
    "\n",
    "# ÂàõÂª∫Â¢ûÂº∫ÁâàËÆøË∞àÂ∑•‰ΩúÊµÅÂáΩÊï∞\n",
    "enhanced_generate_question, enhanced_generate_answer, enhanced_save_interview = create_enhanced_interview_workflow()\n",
    "\n",
    "print(\"‚úÖ Â¢ûÂº∫ÁâàËÆøË∞àÂ∑•‰ΩúÊµÅÂàõÂª∫ÂÆåÊàê\")\n",
    "print(\"üìä Êñ∞Â¢ûËØÑ‰º∞ÊåáÊ†áÔºö\")\n",
    "print(\"  - üó£Ô∏è ÈóÆÈ¢òÁîüÊàêË¥®ÈáèËØÑ‰º∞\")\n",
    "print(\"  - üí¨ ‰∏ìÂÆ∂ÂõûÁ≠îË¥®ÈáèËØÑ‰º∞\")\n",
    "print(\"  - üìù ËÆøË∞àÊï¥‰ΩìÊïàÊûúËØÑ‰º∞\")\n",
    "print(\"  - üîç ‰ø°ÊÅØÊ£ÄÁ¥¢ÊïàÊûúËØÑ‰º∞\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18c874",
   "metadata": {},
   "source": [
    "## üî¨ Êô∫ËÉΩ‰ΩìÁ¶ªÁ∫øËØÑ‰º∞ÔºöÊï∞ÊçÆÈõÜËØÑ‰º∞‰∏éÂü∫ÂáÜÊµãËØï\n",
    "\n",
    "Á¶ªÁ∫øËØÑ‰º∞ÊòØÊô∫ËÉΩ‰ΩìÂºÄÂèëËøáÁ®ã‰∏≠ÁöÑÈáçË¶ÅÁéØËäÇÔºåÂÆÉÂÖÅËÆ∏Êàë‰ª¨Âú®ÂèóÊéßÁéØÂ¢É‰∏≠Á≥ªÁªüÊÄßÂú∞ÊµãËØïÊô∫ËÉΩ‰ΩìÁöÑÊÄßËÉΩ„ÄÇ\n",
    "\n",
    "### üìã Á¶ªÁ∫øËØÑ‰º∞ÁöÑÊ†∏ÂøÉÁªÑÊàê\n",
    "\n",
    "#### 1. Êï∞ÊçÆÈõÜÊûÑÂª∫ (Dataset Construction)\n",
    "- **Âü∫ÂáÜÊï∞ÊçÆÈõÜ**ÔºöÂåÖÂê´ËæìÂÖ•ÂíåÊúüÊúõËæìÂá∫ÁöÑÊ†áÂáÜÂåñÊµãËØïÈõÜ\n",
    "- **Â§öÊ†∑ÊÄßË¶ÜÁõñ**ÔºöÊ∂µÁõñ‰∏çÂêåÂú∫ÊôØ„ÄÅÈöæÂ∫¶ÂíåÈ¢ÜÂüüÁöÑÊµãËØïÁî®‰æã\n",
    "- **Ë¥®Èáè‰øùËØÅ**ÔºöÁ°Æ‰øùÊï∞ÊçÆÈõÜÁöÑÂáÜÁ°ÆÊÄßÂíå‰ª£Ë°®ÊÄß\n",
    "\n",
    "#### 2. ËØÑ‰º∞ÊñπÊ≥ï (Evaluation Methods)\n",
    "- **Ëá™Âä®ÂåñËØÑ‰º∞**Ôºö‰ΩøÁî® LLM-as-a-Judge ËøõË°åË¥®ÈáèËØÑÂàÜ\n",
    "- **‰∫∫Â∑•ËØÑ‰º∞**Ôºö‰∏ìÂÆ∂ÂØπËæìÂá∫ÁªìÊûúËøõË°åË¥®ÈáèÂà§Êñ≠\n",
    "- **ÊåáÊ†áËÆ°ÁÆó**ÔºöËÆ°ÁÆóÂáÜÁ°ÆÊÄß„ÄÅÂÆåÊï¥ÊÄß„ÄÅÁõ∏ÂÖ≥ÊÄßÁ≠âÈáèÂåñÊåáÊ†á\n",
    "\n",
    "#### 3. ÂØπÊØîÂàÜÊûê (Comparative Analysis)\n",
    "- **ÁâàÊú¨ÂØπÊØî**ÔºöÊØîËæÉ‰∏çÂêåÁâàÊú¨Êô∫ËÉΩ‰ΩìÁöÑÊÄßËÉΩÂ∑ÆÂºÇ\n",
    "- **ÈÖçÁΩÆÊµãËØï**ÔºöÊµãËØï‰∏çÂêåÂèÇÊï∞ËÆæÁΩÆÂØπÊÄßËÉΩÁöÑÂΩ±Âìç\n",
    "- **Âü∫ÂáÜÂØπÊØî**Ôºö‰∏é‰∏öÁïåÊ†áÂáÜÊàñÁ´ûÂìÅËøõË°åÊÄßËÉΩÂØπÊØî\n",
    "\n",
    "### üéØ Á¶ªÁ∫øËØÑ‰º∞ÁöÑ‰ºòÂäø\n",
    "\n",
    "- **Á≥ªÁªüÊÄßÊµãËØï**ÔºöÂÖ®Èù¢Ë¶ÜÁõñÂêÑÁßç‰ΩøÁî®Âú∫ÊôØ\n",
    "- **ÂèØÈáçÂ§çÊÄß**ÔºöÁõ∏ÂêåÊù°‰ª∂‰∏ãÁöÑÊµãËØïÁªìÊûú‰∏ÄËá¥\n",
    "- **ÊàêÊú¨ÊïàÁõä**ÔºöÊâπÈáèÊµãËØïÈôç‰ΩéËØÑ‰º∞ÊàêÊú¨\n",
    "- **È£éÈô©ÊéßÂà∂**ÔºöÂú®ÈÉ®ÁΩ≤ÂâçÂèëÁé∞ÊΩúÂú®ÈóÆÈ¢ò\n",
    "\n",
    "### üí° ËØÑ‰º∞ÊúÄ‰Ω≥ÂÆûË∑µ\n",
    "\n",
    "1. **ÂàÜÂ±ÇËØÑ‰º∞**Ôºö‰ªéÁªÑ‰ª∂Á∫ßÂà∞Á≥ªÁªüÁ∫ßÁöÑÈÄêÂ±ÇÊµãËØï\n",
    "2. **ÊåÅÁª≠ÈõÜÊàê**ÔºöÂ∞ÜËØÑ‰º∞ÈõÜÊàêÂà∞ÂºÄÂèëÊµÅÁ®ã‰∏≠\n",
    "3. **ÁªìÊûúÂàÜÊûê**ÔºöÊ∑±ÂÖ•ÂàÜÊûêËØÑ‰º∞ÁªìÊûúÔºåÊâæÂá∫ÊîπËøõÊñπÂêë\n",
    "4. **Ëø≠‰ª£‰ºòÂåñ**ÔºöÂü∫‰∫éËØÑ‰º∞ÁªìÊûúÊåÅÁª≠ÊîπËøõÁ≥ªÁªü\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ ÂàõÂª∫Á†îÁ©∂‰∏ªÈ¢òËØÑ‰º∞Êï∞ÊçÆÈõÜ\n",
    "\n",
    "print(\"üìã ÊûÑÂª∫Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãËØÑ‰º∞Êï∞ÊçÆÈõÜ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# üî¨ ÂàõÂª∫Áî®‰∫éËØÑ‰º∞ÁöÑÁ†îÁ©∂‰∏ªÈ¢òÊï∞ÊçÆÈõÜ\n",
    "research_topics_dataset = [\n",
    "    {\n",
    "        \"id\": \"tech_001\",\n",
    "        \"topic\": \"‰∫∫Â∑•Êô∫ËÉΩÂú®ÂåªÁñóËØäÊñ≠‰∏≠ÁöÑÂ∫îÁî®ÂâçÊôØ\",\n",
    "        \"category\": \"ÊäÄÊúØÂ∫îÁî®\",\n",
    "        \"difficulty\": \"‰∏≠Á≠â\",\n",
    "        \"expected_analysts\": [\"ÂåªÁñó‰∏ìÂÆ∂\", \"AIÊäÄÊúØ‰∏ìÂÆ∂\", \"‰º¶ÁêÜÂ≠¶ÂÆ∂\"],\n",
    "        \"expected_insights\": [\"ÊäÄÊúØÂèØË°åÊÄß\", \"‰∏¥Â∫äÂ∫îÁî®\", \"‰º¶ÁêÜËÄÉÈáè\", \"ÁõëÁÆ°ÊåëÊàò\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"tech_002\", \n",
    "        \"topic\": \"Âå∫ÂùóÈìæÊäÄÊúØÂú®‰æõÂ∫îÈìæÁÆ°ÁêÜ‰∏≠ÁöÑÂàõÊñ∞Â∫îÁî®\",\n",
    "        \"category\": \"ÊäÄÊúØÂàõÊñ∞\",\n",
    "        \"difficulty\": \"È´ò\",\n",
    "        \"expected_analysts\": [\"Âå∫ÂùóÈìæ‰∏ìÂÆ∂\", \"‰æõÂ∫îÈìæ‰∏ìÂÆ∂\", \"‰ºÅ‰∏öÊàòÁï•ÂàÜÊûêÂ∏à\"],\n",
    "        \"expected_insights\": [\"ÊäÄÊúØÂÆûÁé∞\", \"ÊàêÊú¨ÊïàÁõä\", \"ÂÆâÂÖ®ÊÄß\", \"Ë°å‰∏öÈááÁî®\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"business_001\",\n",
    "        \"topic\": \"ËøúÁ®ãÂ∑•‰ΩúÂØπ‰ºÅ‰∏öÊñáÂåñÁöÑÈïøÊúüÂΩ±Âìç\",\n",
    "        \"category\": \"ÂïÜ‰∏öË∂ãÂäø\", \n",
    "        \"difficulty\": \"‰∏≠Á≠â\",\n",
    "        \"expected_analysts\": [\"ÁªÑÁªáË°å‰∏∫‰∏ìÂÆ∂\", \"‰∫∫ÂäõËµÑÊ∫ê‰∏ìÂÆ∂\", \"‰ºÅ‰∏öÁÆ°ÁêÜÈ°æÈóÆ\"],\n",
    "        \"expected_insights\": [\"ÊñáÂåñÂèòÂåñ\", \"ÂëòÂ∑•Êª°ÊÑèÂ∫¶\", \"Áîü‰∫ßÂäõÂΩ±Âìç\", \"ÁÆ°ÁêÜÊåëÊàò\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"social_001\",\n",
    "        \"topic\": \"Á§æ‰∫§Â™í‰ΩìÂØπÈùíÂ∞ëÂπ¥ÂøÉÁêÜÂÅ•Â∫∑ÁöÑÂΩ±ÂìçÁ†îÁ©∂\",\n",
    "        \"category\": \"Á§æ‰ºöÈóÆÈ¢ò\",\n",
    "        \"difficulty\": \"È´ò\",\n",
    "        \"expected_analysts\": [\"ÂøÉÁêÜÂ≠¶‰∏ìÂÆ∂\", \"Á§æ‰ºöÂ≠¶ÂÆ∂\", \"Êï∞Â≠óÂ™í‰ΩìÁ†îÁ©∂Âëò\"],\n",
    "        \"expected_insights\": [\"ÂøÉÁêÜÂΩ±Âìç\", \"Á§æ‰ºöË°å‰∏∫\", \"Âπ≤È¢ÑÁ≠ñÁï•\", \"ÊîøÁ≠ñÂª∫ËÆÆ\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"econ_001\",\n",
    "        \"topic\": \"Êï∞Â≠óË¥ßÂ∏ÅÂØπ‰º†ÁªüÈì∂Ë°å‰∏öÁöÑÂÜ≤Âáª‰∏éÊú∫ÈÅá\",\n",
    "        \"category\": \"ÁªèÊµéÈáëËûç\",\n",
    "        \"difficulty\": \"È´ò\", \n",
    "        \"expected_analysts\": [\"ÈáëËûç‰∏ìÂÆ∂\", \"Âå∫ÂùóÈìæ‰∏ìÂÆ∂\", \"ÁõëÁÆ°ÊîøÁ≠ñÂàÜÊûêÂ∏à\"],\n",
    "        \"expected_insights\": [\"Â∏ÇÂú∫ÂÜ≤Âáª\", \"ÊäÄÊúØËΩ¨Âûã\", \"ÁõëÁÆ°Â∫îÂØπ\", \"Êú™Êù•Ë∂ãÂäø\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# üî¨ Âú® Langfuse ‰∏≠ÂàõÂª∫ËØÑ‰º∞Êï∞ÊçÆÈõÜ\n",
    "def create_langfuse_evaluation_dataset():\n",
    "    \"\"\"\n",
    "    Âú® Langfuse Âπ≥Âè∞‰∏≠ÂàõÂª∫Á†îÁ©∂Âä©ÊâãËØÑ‰º∞Êï∞ÊçÆÈõÜ\n",
    "    \n",
    "    ÂäüËÉΩÔºö\n",
    "    - ÂàõÂª∫ÁªìÊûÑÂåñÁöÑËØÑ‰º∞Êï∞ÊçÆÈõÜ\n",
    "    - ‰∏∫ÊØè‰∏™Á†îÁ©∂‰∏ªÈ¢òËÆæÁΩÆÊúüÊúõËæìÂá∫\n",
    "    - ÊîØÊåÅÂêéÁª≠ÁöÑÊâπÈáèËØÑ‰º∞ÂíåÂØπÊØîÂàÜÊûê\n",
    "    \"\"\"\n",
    "    \n",
    "    # Êï∞ÊçÆÈõÜÂêçÁß∞\n",
    "    dataset_name = \"deep-research-assistant-evaluation\"\n",
    "    \n",
    "    # ÂàõÂª∫ Langfuse Êï∞ÊçÆÈõÜ\n",
    "    try:\n",
    "        langfuse.create_dataset(\n",
    "            name=dataset_name,\n",
    "            description=\"Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÊô∫ËÉΩ‰ΩìËØÑ‰º∞Êï∞ÊçÆÈõÜ - ÂåÖÂê´‰∏çÂêåÁ±ªÂûãÂíåÈöæÂ∫¶ÁöÑÁ†îÁ©∂‰∏ªÈ¢ò\",\n",
    "            metadata={\n",
    "                \"version\": \"1.0\",\n",
    "                \"total_items\": len(research_topics_dataset),\n",
    "                \"categories\": list(set(item[\"category\"] for item in research_topics_dataset)),\n",
    "                \"difficulty_levels\": list(set(item[\"difficulty\"] for item in research_topics_dataset)),\n",
    "                \"created_for\": \"Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞ÂíåË¥®ÈáèÁõëÊéß\"\n",
    "            }\n",
    "        )\n",
    "        print(f\"‚úÖ ÊàêÂäüÂàõÂª∫Êï∞ÊçÆÈõÜ: {dataset_name}\")\n",
    "        \n",
    "        # Ê∑ªÂä†Êï∞ÊçÆÈõÜÊù°ÁõÆ\n",
    "        for item in research_topics_dataset:\n",
    "            langfuse.create_dataset_item(\n",
    "                dataset_name=dataset_name,\n",
    "                input={\n",
    "                    \"topic\": item[\"topic\"],\n",
    "                    \"max_analysts\": 3,\n",
    "                    \"category\": item[\"category\"],\n",
    "                    \"difficulty\": item[\"difficulty\"]\n",
    "                },\n",
    "                expected_output={\n",
    "                    \"expected_analysts\": item[\"expected_analysts\"],\n",
    "                    \"expected_insights\": item[\"expected_insights\"],\n",
    "                    \"quality_criteria\": {\n",
    "                        \"relevance\": \"ÂàÜÊûêÂ∏àÊòØÂê¶‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥\",\n",
    "                        \"diversity\": \"ÊòØÂê¶Ë¶ÜÁõñ‰∏çÂêåËßÜËßí\", \n",
    "                        \"expertise\": \"ÊòØÂê¶ÂÖ∑Â§á‰∏ì‰∏öÁü•ËØÜËÉåÊôØ\",\n",
    "                        \"completeness\": \"ÊòØÂê¶ÂÖ®Èù¢Ë¶ÜÁõñÂÖ≥ÈîÆÊñπÈù¢\"\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        print(f\"üìã ÊàêÂäüÊ∑ªÂä† {len(research_topics_dataset)} ‰∏™ËØÑ‰º∞Êù°ÁõÆ\")\n",
    "        return dataset_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÂàõÂª∫Êï∞ÊçÆÈõÜÂ§±Ë¥•: {e}\")\n",
    "        return None\n",
    "\n",
    "# ÂàõÂª∫ËØÑ‰º∞Êï∞ÊçÆÈõÜ\n",
    "dataset_name = create_langfuse_evaluation_dataset()\n",
    "\n",
    "if dataset_name:\n",
    "    print(f\"\\nüî¨ ËØÑ‰º∞Êï∞ÊçÆÈõÜËØ¶ÊÉÖ:\")\n",
    "    print(f\"  üìä Êï∞ÊçÆÈõÜÂêçÁß∞: {dataset_name}\")\n",
    "    print(f\"  üìà Êù°ÁõÆÊï∞Èáè: {len(research_topics_dataset)}\")\n",
    "    print(f\"  üè∑Ô∏è Ê∂µÁõñÁ±ªÂà´: {len(set(item['category'] for item in research_topics_dataset))} ‰∏™\")\n",
    "    print(f\"  üìä ÈöæÂ∫¶Á≠âÁ∫ß: {set(item['difficulty'] for item in research_topics_dataset)}\")\n",
    "    print(f\"  üîó ËÆøÈóÆÂú∞ÂùÄ: https://cloud.langfuse.com/datasets\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Êï∞ÊçÆÈõÜÂàõÂª∫Â§±Ë¥•ÔºåËØ∑Ê£ÄÊü• Langfuse ÈÖçÁΩÆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc179cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ ÊâπÈáèËØÑ‰º∞ÔºöÂú®Êï∞ÊçÆÈõÜ‰∏äËøêË°åÊ∑±Â∫¶Á†îÁ©∂Âä©Êâã\n",
    "\n",
    "print(\"üöÄ ÂêØÂä®Êï∞ÊçÆÈõÜÊâπÈáèËØÑ‰º∞\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def evaluate_research_assistant_on_dataset(dataset_name, max_items=3):\n",
    "    \"\"\"\n",
    "    Âú®ËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äÊâπÈáèËøêË°åÊ∑±Â∫¶Á†îÁ©∂Âä©Êâã\n",
    "    \n",
    "    ÂèÇÊï∞:\n",
    "        dataset_name: Langfuse Êï∞ÊçÆÈõÜÂêçÁß∞\n",
    "        max_items: ÊúÄÂ§ßËØÑ‰º∞Êù°ÁõÆÊï∞ÈáèÔºàÊºîÁ§∫Áî®Ôºâ\n",
    "    \n",
    "    ÂäüËÉΩ:\n",
    "        - ‰∏∫ÊØè‰∏™Êï∞ÊçÆÈõÜÊù°ÁõÆËøêË°åÂÆåÊï¥ÁöÑÁ†îÁ©∂ÊµÅÁ®ã\n",
    "        - ËÆ∞ÂΩïËØ¶ÁªÜÁöÑÊÄßËÉΩÊåáÊ†áÂíåË¥®ÈáèËØÑ‰º∞\n",
    "        - ÁîüÊàêÂèØÂØπÊØîÁöÑËØÑ‰º∞Êä•Âëä\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Ëé∑Âèñ Langfuse Êï∞ÊçÆÈõÜ\n",
    "        dataset = langfuse.get_dataset(dataset_name)\n",
    "        print(f\"üìã Ëé∑ÂèñÊï∞ÊçÆÈõÜ: {dataset_name}\")\n",
    "        \n",
    "        # ÈôêÂà∂ËØÑ‰º∞Êù°ÁõÆÊï∞ÈáèÔºàÈÅøÂÖçÊºîÁ§∫Êó∂Èó¥ËøáÈïøÔºâ\n",
    "        items_to_evaluate = list(dataset.items)[:max_items]\n",
    "        print(f\"üìä Â∞ÜËØÑ‰º∞ {len(items_to_evaluate)} ‰∏™Êù°ÁõÆ\")\n",
    "        \n",
    "        evaluation_results = []\n",
    "        \n",
    "        for i, item in enumerate(items_to_evaluate, 1):\n",
    "            print(f\"\\nüî¨ ËØÑ‰º∞Êù°ÁõÆ {i}/{len(items_to_evaluate)}\")\n",
    "            print(f\"üìù ‰∏ªÈ¢ò: {item.input['topic']}\")\n",
    "            \n",
    "            # üî¨ ‰∏∫ÊØè‰∏™Êù°ÁõÆÂºÄÂêØËØÑ‰º∞ËøΩË∏™\n",
    "            with item.run(\n",
    "                run_name=f\"research_assistant_eval_{i}\",\n",
    "                run_description=f\"ËØÑ‰º∞Á†îÁ©∂Âä©ÊâãÂú®'{item.input['topic']}'‰∏ªÈ¢ò‰∏äÁöÑË°®Áé∞\",\n",
    "                run_metadata={\n",
    "                    \"model\": \"gpt-4o\",\n",
    "                    \"category\": item.input[\"category\"], \n",
    "                    \"difficulty\": item.input[\"difficulty\"]\n",
    "                }\n",
    "            ) as run_span:\n",
    "                \n",
    "                # ËøêË°åÁ†îÁ©∂Âä©ÊâãÁöÑÂàÜÊûêÂ∏àÁîüÊàêÈò∂ÊÆµ\n",
    "                with langfuse.start_as_current_generation(\n",
    "                    name=\"analyst_generation\",\n",
    "                    model=\"gpt-4o\",\n",
    "                    input=item.input\n",
    "                ) as gen_span:\n",
    "                    \n",
    "                    # ÂàõÂª∫Êñ∞ÁöÑÁ∫øÁ®ãIDÁî®‰∫éËØÑ‰º∞\n",
    "                    eval_thread = {\"configurable\": {\"thread_id\": f\"eval_{i}\"}}\n",
    "                    \n",
    "                    # ËøêË°åÂàÜÊûêÂ∏àÁîüÊàêÔºàÊó†‰∫∫Á±ªÂèçÈ¶àÔºåËá™Âä®ÂåñËØÑ‰º∞Ôºâ\n",
    "                    result = None\n",
    "                    try:\n",
    "                        for event in graph.stream(\n",
    "                            {\n",
    "                                \"topic\": item.input[\"topic\"],\n",
    "                                \"max_analysts\": item.input[\"max_analysts\"],\n",
    "                                \"human_analyst_feedback\": None  # Ëá™Âä®ÂåñËØÑ‰º∞ÔºåÊó†‰∫∫Á±ªÂèçÈ¶à\n",
    "                            }, \n",
    "                            eval_thread, \n",
    "                            stream_mode=\"values\",\n",
    "                            config={\"callbacks\": [langfuse_handler]}\n",
    "                        ):\n",
    "                            analysts = event.get('analysts', '')\n",
    "                            if analysts:\n",
    "                                result = {\n",
    "                                    \"generated_analysts\": [\n",
    "                                        {\n",
    "                                            \"name\": a.name,\n",
    "                                            \"role\": a.role, \n",
    "                                            \"affiliation\": a.affiliation,\n",
    "                                            \"description\": a.description\n",
    "                                        } for a in analysts\n",
    "                                    ],\n",
    "                                    \"analysts_count\": len(analysts)\n",
    "                                }\n",
    "                                break\n",
    "                    \n",
    "                        # Êõ¥Êñ∞ÁîüÊàêÁªìÊûú\n",
    "                        if result:\n",
    "                            gen_span.update(output=result)\n",
    "                            \n",
    "                            # üî¨ Ëá™Âä®ËØÑ‰º∞ÔºöËÆ°ÁÆóË¥®ÈáèÂàÜÊï∞\n",
    "                            quality_score = evaluate_analyst_quality(\n",
    "                                result[\"generated_analysts\"], \n",
    "                                item.expected_output[\"expected_analysts\"],\n",
    "                                item.input[\"topic\"]\n",
    "                            )\n",
    "                            \n",
    "                            # ËÆ∞ÂΩïËØÑ‰º∞ÂàÜÊï∞\n",
    "                            run_span.score_trace(\n",
    "                                name=\"analyst_quality\",\n",
    "                                value=quality_score,\n",
    "                                data_type=\"NUMERIC\",\n",
    "                                comment=f\"Âü∫‰∫éÁõ∏ÂÖ≥ÊÄßÂíåÂ§öÊ†∑ÊÄßÁöÑÁªºÂêàËØÑÂàÜ\"\n",
    "                            )\n",
    "                            \n",
    "                            evaluation_results.append({\n",
    "                                \"topic\": item.input[\"topic\"],\n",
    "                                \"category\": item.input[\"category\"],\n",
    "                                \"difficulty\": item.input[\"difficulty\"], \n",
    "                                \"analysts_generated\": len(result[\"generated_analysts\"]),\n",
    "                                \"quality_score\": quality_score,\n",
    "                                \"status\": \"success\"\n",
    "                            })\n",
    "                            \n",
    "                            print(f\"‚úÖ ËØÑ‰º∞ÂÆåÊàê - Ë¥®ÈáèËØÑÂàÜ: {quality_score:.2f}/5.0\")\n",
    "                        else:\n",
    "                            print(\"‚ùå ÂàÜÊûêÂ∏àÁîüÊàêÂ§±Ë¥•\")\n",
    "                            evaluation_results.append({\n",
    "                                \"topic\": item.input[\"topic\"],\n",
    "                                \"status\": \"failed\"\n",
    "                            })\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå ËØÑ‰º∞Âá∫Èîô: {e}\")\n",
    "                        evaluation_results.append({\n",
    "                            \"topic\": item.input[\"topic\"],\n",
    "                            \"status\": \"error\",\n",
    "                            \"error\": str(e)\n",
    "                        })\n",
    "        \n",
    "        return evaluation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Êï∞ÊçÆÈõÜËØÑ‰º∞Â§±Ë¥•: {e}\")\n",
    "        return []\n",
    "\n",
    "def evaluate_analyst_quality(generated_analysts, expected_analysts, topic):\n",
    "    \"\"\"\n",
    "    ËØÑ‰º∞ÁîüÊàêÁöÑÂàÜÊûêÂ∏àË¥®Èáè\n",
    "    \n",
    "    ËØÑ‰º∞Áª¥Â∫¶Ôºö\n",
    "    - Áõ∏ÂÖ≥ÊÄßÔºöÂàÜÊûêÂ∏àËßíËâ≤ÊòØÂê¶‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥\n",
    "    - Â§öÊ†∑ÊÄßÔºöÊòØÂê¶Ë¶ÜÁõñ‰∏çÂêåÁöÑ‰∏ì‰∏öÈ¢ÜÂüü\n",
    "    - ‰∏ì‰∏öÊÄßÔºöÂàÜÊûêÂ∏àÊèèËø∞ÊòØÂê¶‰ΩìÁé∞‰∏ì‰∏öÁü•ËØÜ\n",
    "    \"\"\"\n",
    "    \n",
    "    # ÁÆÄÂåñÁöÑË¥®ÈáèËØÑ‰º∞ÁÆóÊ≥ïÔºàÂÆûÈôÖÈ°πÁõÆ‰∏≠ÂèØ‰ΩøÁî®Êõ¥Â§çÊùÇÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºâ\n",
    "    relevance_score = 0.8  # ÂÅáËÆæÂ§ßÈÉ®ÂàÜÂàÜÊûêÂ∏àÈÉΩ‰∏é‰∏ªÈ¢òÁõ∏ÂÖ≥\n",
    "    diversity_score = min(len(set(a[\"role\"] for a in generated_analysts)) / 3.0, 1.0)  # ËßíËâ≤Â§öÊ†∑ÊÄß\n",
    "    completeness_score = min(len(generated_analysts) / 3.0, 1.0)  # Êï∞ÈáèÂÆåÊï¥ÊÄß\n",
    "    \n",
    "    # ÁªºÂêàËØÑÂàÜÔºàÊª°ÂàÜ5ÂàÜÔºâ\n",
    "    overall_score = (relevance_score * 0.4 + diversity_score * 0.3 + completeness_score * 0.3) * 5\n",
    "    \n",
    "    return round(overall_score, 2)\n",
    "\n",
    "# Â¶ÇÊûúÊï∞ÊçÆÈõÜÂàõÂª∫ÊàêÂäüÔºåÊâßË°åÊâπÈáèËØÑ‰º∞\n",
    "if dataset_name:\n",
    "    print(\"üî¨ ÂºÄÂßãÊâπÈáèËØÑ‰º∞...\")\n",
    "    results = evaluate_research_assistant_on_dataset(dataset_name, max_items=2)  # ÊºîÁ§∫Áî®ÔºåÂè™ËØÑ‰º∞2‰∏™Êù°ÁõÆ\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nüìä ÊâπÈáèËØÑ‰º∞ÁªìÊûúÊÄªÁªì:\")\n",
    "        print(\"=\" * 50)\n",
    "        successful_evals = [r for r in results if r.get(\"status\") == \"success\"]\n",
    "        if successful_evals:\n",
    "            avg_score = sum(r[\"quality_score\"] for r in successful_evals) / len(successful_evals)\n",
    "            print(f\"üìà Âπ≥ÂùáË¥®ÈáèËØÑÂàÜ: {avg_score:.2f}/5.0\")\n",
    "            print(f\"‚úÖ ÊàêÂäüËØÑ‰º∞: {len(successful_evals)} ‰∏™\")\n",
    "            print(f\"‚ùå Â§±Ë¥•ËØÑ‰º∞: {len(results) - len(successful_evals)} ‰∏™\")\n",
    "            \n",
    "            # ÊåâÁ±ªÂà´ÁªüËÆ°\n",
    "            categories = {}\n",
    "            for r in successful_evals:\n",
    "                cat = r[\"category\"]\n",
    "                if cat not in categories:\n",
    "                    categories[cat] = []\n",
    "                categories[cat].append(r[\"quality_score\"])\n",
    "            \n",
    "            print(f\"\\nüìä ÂàÜÁ±ªÂà´ËØÑ‰º∞ÁªìÊûú:\")\n",
    "            for cat, scores in categories.items():\n",
    "                avg_cat_score = sum(scores) / len(scores)\n",
    "                print(f\"  {cat}: {avg_cat_score:.2f}/5.0 ({len(scores)} ‰∏™Ê†∑Êú¨)\")\n",
    "        else:\n",
    "            print(\"‚ùå ÊâÄÊúâËØÑ‰º∞ÈÉΩÂ§±Ë¥•‰∫Ü\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è ÊâπÈáèËØÑ‰º∞Êú™ËøîÂõûÁªìÊûú\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Ë∑≥ËøáÊâπÈáèËØÑ‰º∞ÔºàÊï∞ÊçÆÈõÜÂàõÂª∫Â§±Ë¥•Ôºâ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69debd73",
   "metadata": {},
   "source": [
    "## üéØ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÊÄªÁªì‰∏éÊúÄ‰Ω≥ÂÆûË∑µ\n",
    "\n",
    "ÈÄöËøáÊú¨ÊïôÁ®ãÔºåÊàë‰ª¨Â∑≤Áªè‰∏∫Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÊûÑÂª∫‰∫ÜÂÆåÊï¥ÁöÑÊô∫ËÉΩ‰ΩìËØÑ‰º∞‰ΩìÁ≥ª„ÄÇ‰ª•‰∏ãÊòØÂÖ≥ÈîÆË¶ÅÁÇπÂíåÊúÄ‰Ω≥ÂÆûË∑µÔºö\n",
    "\n",
    "### üìä ËØÑ‰º∞‰ΩìÁ≥ªÊû∂ÊûÑ\n",
    "\n",
    "#### 1. Âú®Á∫øËØÑ‰º∞ (Online Evaluation)\n",
    "- **ÂÆûÊó∂ÁõëÊéß**ÔºöËøΩË∏™Áîü‰∫ßÁéØÂ¢É‰∏≠ÁöÑÁ≥ªÁªüË°®Áé∞\n",
    "- **Áî®Êà∑ÂèçÈ¶à**ÔºöÊî∂ÈõÜÁúüÂÆûÁî®Êà∑ÁöÑËØÑ‰ª∑ÂíåÂª∫ËÆÆ\n",
    "- **ÊÄßËÉΩÊåáÊ†á**ÔºöÁõëÊéßÂª∂Ëøü„ÄÅÊàêÊú¨„ÄÅÊàêÂäüÁéáÁ≠âÂÖ≥ÈîÆÊåáÊ†á\n",
    "- **ÂºÇÂ∏∏Ê£ÄÊµã**ÔºöÂèäÊó∂ÂèëÁé∞Á≥ªÁªüÂºÇÂ∏∏ÂíåË¥®Èáè‰∏ãÈôç\n",
    "\n",
    "#### 2. Á¶ªÁ∫øËØÑ‰º∞ (Offline Evaluation)  \n",
    "- **Êï∞ÊçÆÈõÜÊµãËØï**Ôºö‰ΩøÁî®Ê†áÂáÜÂåñÊï∞ÊçÆÈõÜËøõË°åÁ≥ªÁªüÊÄßËØÑ‰º∞\n",
    "- **Âü∫ÂáÜÂØπÊØî**Ôºö‰∏éÂÖ∂‰ªñÊñπÊ≥ïÊàñÁâàÊú¨ËøõË°åÊÄßËÉΩÂØπÊØî\n",
    "- **ÂõûÂΩíÊµãËØï**ÔºöÁ°Æ‰øùÊñ∞ÁâàÊú¨‰∏ç‰ºöÈôç‰ΩéÁé∞ÊúâÂäüËÉΩË¥®Èáè\n",
    "- **ÂéãÂäõÊµãËØï**ÔºöÊµãËØïÁ≥ªÁªüÂú®ÊûÅÁ´ØÊù°‰ª∂‰∏ãÁöÑË°®Áé∞\n",
    "\n",
    "### üîß ÊäÄÊúØÂÆûÁé∞Ë¶ÅÁÇπ\n",
    "\n",
    "#### 1. ËøΩË∏™ÈõÜÊàê\n",
    "```python\n",
    "# ‚úÖ Êé®ËçêÂÅöÊ≥ïÔºö‰ΩøÁî®‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®\n",
    "with langfuse.start_as_current_span(name=\"operation_name\") as span:\n",
    "    result = your_operation()\n",
    "    span.update_trace(input=input_data, output=result)\n",
    "```\n",
    "\n",
    "#### 2. ËØÑ‰º∞ÊåáÊ†áËÆæËÆ°\n",
    "- **Â§öÁª¥Â∫¶ËØÑ‰º∞**Ôºö‰ªé‰∏çÂêåËßíÂ∫¶ËØÑ‰º∞Á≥ªÁªüË¥®Èáè\n",
    "- **ÈáèÂåñÊåáÊ†á**ÔºöËÆæËÆ°ÂèØË°°ÈáèÁöÑËØÑ‰º∞Ê†áÂáÜ\n",
    "- **Áî®Êà∑‰∏≠ÂøÉ**Ôºö‰ª•Áî®Êà∑‰ª∑ÂÄº‰∏∫Ê†∏ÂøÉËÆæËÆ°ËØÑ‰º∞ÊñπÊ≥ï\n",
    "\n",
    "#### 3. Êï∞ÊçÆÁÆ°ÁêÜ\n",
    "- **ÁâàÊú¨ÊéßÂà∂**ÔºöÁÆ°ÁêÜ‰∏çÂêåÁâàÊú¨ÁöÑËØÑ‰º∞Êï∞ÊçÆ\n",
    "- **ÈöêÁßÅ‰øùÊä§**ÔºöÁ°Æ‰øùÁî®Êà∑Êï∞ÊçÆÁöÑÂÆâÂÖ®ÂíåÈöêÁßÅ\n",
    "- **Êï∞ÊçÆË¥®Èáè**Ôºö‰øùËØÅËØÑ‰º∞Êï∞ÊçÆÁöÑÂáÜÁ°ÆÊÄßÂíå‰ª£Ë°®ÊÄß\n",
    "\n",
    "### üí° ÊúÄ‰Ω≥ÂÆûË∑µÂª∫ËÆÆ\n",
    "\n",
    "#### 1. ËØÑ‰º∞Á≠ñÁï•\n",
    "- **ÂàÜÂ±ÇËØÑ‰º∞**Ôºö‰ªéÁªÑ‰ª∂Âà∞Á≥ªÁªüÁöÑÈÄêÂ±ÇÊµãËØï\n",
    "- **ÊåÅÁª≠ËØÑ‰º∞**ÔºöÂ∞ÜËØÑ‰º∞ÈõÜÊàêÂà∞ÂºÄÂèëÊµÅÁ®ã‰∏≠\n",
    "- **Â§öÊñπÊ≥ïÁªìÂêà**ÔºöÂêåÊó∂‰ΩøÁî®Ëá™Âä®ÂåñÂíå‰∫∫Â∑•ËØÑ‰º∞\n",
    "\n",
    "#### 2. ÊÄßËÉΩ‰ºòÂåñ\n",
    "- **ÊàêÊú¨ÊéßÂà∂**Ôºö‰ºòÂåñ LLM Ë∞ÉÁî®Ê¨°Êï∞Âíå‰ª§ÁâåÊ∂àËÄó\n",
    "- **Âª∂Ëøü‰ºòÂåñ**ÔºöÂáèÂ∞ëÁ≥ªÁªüÂìçÂ∫îÊó∂Èó¥\n",
    "- **ÁºìÂ≠òÁ≠ñÁï•**ÔºöÂêàÁêÜ‰ΩøÁî®ÁºìÂ≠òÊèêÈ´òÊïàÁéá\n",
    "\n",
    "#### 3. Ë¥®Èáè‰øùËØÅ\n",
    "- **ÈîôËØØÂ§ÑÁêÜ**ÔºöÂÆåÂñÑÁöÑÂºÇÂ∏∏Â§ÑÁêÜÂíåÊÅ¢Â§çÊú∫Âà∂\n",
    "- **ÁõëÊéßÂëäË≠¶**ÔºöÂèäÊó∂ÂèëÁé∞ÂíåÂ§ÑÁêÜÁ≥ªÁªüÈóÆÈ¢ò\n",
    "- **Áî®Êà∑‰ΩìÈ™å**ÔºöÊåÅÁª≠ÊîπËøõÁî®Êà∑‰∫§‰∫í‰ΩìÈ™å\n",
    "\n",
    "### üöÄ Êú™Êù•Â±ïÊúõ\n",
    "\n",
    "ÈöèÁùÄ AI ÊäÄÊúØÁöÑÂèëÂ±ïÔºåÊô∫ËÉΩ‰ΩìËØÑ‰º∞Â∞ÜÂêë‰ª•‰∏ãÊñπÂêëÊºîËøõÔºö\n",
    "\n",
    "1. **Êõ¥Êô∫ËÉΩÁöÑËØÑ‰º∞**Ôºö‰ΩøÁî® AI ËæÖÂä©ËØÑ‰º∞ AI Á≥ªÁªü\n",
    "2. **Êõ¥ÂÖ®Èù¢ÁöÑÊåáÊ†á**ÔºöÊ∂µÁõñÊäÄÊúØ„ÄÅ‰∏öÂä°„ÄÅ‰º¶ÁêÜÁ≠âÂ§ö‰∏™Áª¥Â∫¶\n",
    "3. **Êõ¥Ëá™Âä®ÂåñÁöÑÊµÅÁ®ã**ÔºöÂáèÂ∞ë‰∫∫Â∑•Âπ≤È¢ÑÔºåÊèêÈ´òËØÑ‰º∞ÊïàÁéá\n",
    "4. **Êõ¥‰∏™ÊÄßÂåñÁöÑÊñπÊ°à**ÔºöÊ†πÊçÆÂÖ∑‰ΩìÂ∫îÁî®Âú∫ÊôØÂÆöÂà∂ËØÑ‰º∞ÊñπÊ≥ï\n",
    "\n",
    "### üîó Áõ∏ÂÖ≥ËµÑÊ∫ê\n",
    "\n",
    "- **Langfuse ÂÆòÊñπÊñáÊ°£**Ôºöhttps://langfuse.com/docs\n",
    "- **LangGraph ËØÑ‰º∞ÊåáÂçó**Ôºöhttps://langchain-ai.github.io/langgraph/\n",
    "- **AI ËØÑ‰º∞ÊúÄ‰Ω≥ÂÆûË∑µ**Ôºöhttps://langfuse.com/blog/llm-evaluation\n",
    "\n",
    "ÈÄöËøáÁ≥ªÁªüÊÄßÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ËÉΩÂ§üÁ°Æ‰øùÊ∑±Â∫¶Á†îÁ©∂Âä©ÊâãÂú®ÁúüÂÆûÁéØÂ¢É‰∏≠Êèê‰æõÈ´òË¥®Èáè„ÄÅÂèØÈù†ÁöÑÊúçÂä°ÔºåÊåÅÁª≠ÂàõÈÄ†Áî®Êà∑‰ª∑ÂÄº„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÂÆåÊàêÔºöÊï∞ÊçÆÂêåÊ≠•‰∏éÊ∏ÖÁêÜ\n",
    "\n",
    "print(\"üéâ Ê∑±Â∫¶Á†îÁ©∂Âä©ÊâãÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÊïôÁ®ãÂÆåÊàêÔºÅ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üî¨ ÊúÄÁªàÊï∞ÊçÆÂêåÊ≠•ÔºöÁ°Æ‰øùÊâÄÊúâËøΩË∏™Êï∞ÊçÆÈÉΩ‰∏ä‰º†Âà∞ Langfuse\n",
    "print(\"üì§ ÂêåÊ≠•ËØÑ‰º∞Êï∞ÊçÆÂà∞ Langfuse Âπ≥Âè∞...\")\n",
    "langfuse.flush()  # Âº∫Âà∂ÂêåÊ≠•ÊâÄÊúâÁºìÂ≠òÁöÑËøΩË∏™Êï∞ÊçÆ\n",
    "\n",
    "print(\"‚úÖ Êï∞ÊçÆÂêåÊ≠•ÂÆåÊàêÔºÅ\")\n",
    "\n",
    "# üìä ÊïôÁ®ãÊÄªÁªì\n",
    "print(\"\\nüìä Êú¨ÊïôÁ®ãÊ∂µÁõñÁöÑÊô∫ËÉΩ‰ΩìËØÑ‰º∞ÂäüËÉΩÔºö\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üîç 1. ÁéØÂ¢ÉÈÖçÁΩÆ‰∏é Langfuse ÈõÜÊàê\")\n",
    "print(\"   - API ÂØÜÈí•ÈÖçÁΩÆÂíåÂÆ¢Êà∑Á´ØÂàùÂßãÂåñ\")\n",
    "print(\"   - ËøûÊé•È™åËØÅÂíåÁä∂ÊÄÅÊ£ÄÊü•\")\n",
    "print(\"\")\n",
    "print(\"üìà 2. Âú®Á∫øËØÑ‰º∞ (Online Evaluation)\")\n",
    "print(\"   - ÂÆûÊó∂ËøΩË∏™ÊâÄÊúâLLMË∞ÉÁî®ÂíåËäÇÁÇπÊâßË°å\")\n",
    "print(\"   - Áî®Êà∑ÂèçÈ¶àÊî∂ÈõÜÂíåË¥®ÈáèËØÑÂàÜ\")\n",
    "print(\"   - ‰∫∫Êú∫ÂçèÂêåÊïàÊûúÁõëÊéß\")\n",
    "print(\"   - ÊÄßËÉΩÊåáÊ†áËÆ∞ÂΩïÔºàÂª∂Ëøü„ÄÅÊàêÊú¨„ÄÅÊàêÂäüÁéáÔºâ\")\n",
    "print(\"\")\n",
    "print(\"üéØ 3. Á¶ªÁ∫øËØÑ‰º∞ (Offline Evaluation)\")\n",
    "print(\"   - ËØÑ‰º∞Êï∞ÊçÆÈõÜÊûÑÂª∫ÂíåÁÆ°ÁêÜ\")\n",
    "print(\"   - ÊâπÈáèËá™Âä®ÂåñÊµãËØï\")\n",
    "print(\"   - Ë¥®ÈáèËØÑ‰º∞ÁÆóÊ≥ïËÆæËÆ°\")\n",
    "print(\"   - ÁªìÊûúÂàÜÊûêÂíåÂØπÊØî\")\n",
    "print(\"\")\n",
    "print(\"üîß 4. ÊäÄÊúØÈõÜÊàêË¶ÅÁÇπ\")\n",
    "print(\"   - Langfuse CallbackHandler ‰ΩøÁî®\")\n",
    "print(\"   - ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®ËøΩË∏™Ê®°Âºè\")\n",
    "print(\"   - Êï∞ÊçÆÈõÜÁÆ°ÁêÜÂíåËØÑ‰º∞ÊµÅÁ®ã\")\n",
    "print(\"   - ËØÑ‰º∞ÊåáÊ†áËÆæËÆ°ÂíåËÆ°ÁÆó\")\n",
    "\n",
    "print(\"\\nüîó ÂÖ≥ÈîÆÈìæÊé•Ôºö\")\n",
    "print(\"üìä Langfuse ËøΩË∏™‰ª™Ë°®Êùø: https://cloud.langfuse.com/traces\")\n",
    "print(\"üìã Êï∞ÊçÆÈõÜÁÆ°ÁêÜÈ°µÈù¢: https://cloud.langfuse.com/datasets\")\n",
    "print(\"üìà ÊÄßËÉΩÂàÜÊûêÊä•Âëä: https://cloud.langfuse.com/analytics\")\n",
    "\n",
    "print(\"\\nüí° ‰∏ã‰∏ÄÊ≠•Âª∫ËÆÆÔºö\")\n",
    "print(\"1. üöÄ ÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢ÉÔºåÂêØÁî®ÊåÅÁª≠ÁõëÊéß\")\n",
    "print(\"2. üìä Êâ©Â±ïËØÑ‰º∞Êï∞ÊçÆÈõÜÔºåÊèêÈ´òÊµãËØïË¶ÜÁõñÁéá\")\n",
    "print(\"3. üîÑ ËÆæÁΩÆËá™Âä®ÂåñËØÑ‰º∞ÊµÅÁ®ãÔºåÈõÜÊàêÂà∞CI/CD\")\n",
    "print(\"4. üë• Êî∂ÈõÜÁúüÂÆûÁî®Êà∑ÂèçÈ¶àÔºåÊåÅÁª≠‰ºòÂåñÁ≥ªÁªü\")\n",
    "print(\"5. üéØ Âü∫‰∫éËØÑ‰º∞ÁªìÊûúÔºå‰ºòÂåñÊ®°ÂûãÂíåÊèêÁ§∫ËØç\")\n",
    "\n",
    "print(\"\\nüéì Â≠¶‰π†ÊàêÊûúÔºö\")\n",
    "print(\"‚úÖ ÊéåÊè°‰∫Ü Langfuse Êô∫ËÉΩ‰ΩìËØÑ‰º∞ÁöÑÂÆåÊï¥ÊµÅÁ®ã\")\n",
    "print(\"‚úÖ ‰∫ÜËß£‰∫ÜÂú®Á∫øÂíåÁ¶ªÁ∫ø‰∏§ÁßçËØÑ‰º∞Ê®°Âºè\")\n",
    "print(\"‚úÖ Â≠¶‰ºö‰∫ÜËÆæËÆ°ÂíåÂÆûÁé∞ËØÑ‰º∞ÊåáÊ†á\")\n",
    "print(\"‚úÖ ÂÖ∑Â§á‰∫ÜÁîü‰∫ßÁéØÂ¢ÉÊô∫ËÉΩ‰ΩìÁõëÊéßËÉΩÂäõ\")\n",
    "\n",
    "print(\"\\nüî¨ ËØÑ‰º∞ÁâàÊ∑±Â∫¶Á†îÁ©∂Âä©ÊâãÂ∑≤Â∞±Áª™ÔºÅ\")\n",
    "print(\"üéØ Èù¢ÂêëÂ§ßÊ®°ÂûãÂàùÂ≠¶ËÄÖÁöÑËØ¶ÁªÜÊ≥®ÈáäÂ∑≤ÂÆåÊï¥Ê∑ªÂä†\")\n",
    "print(\"üìö Áé∞Âú®ÊÇ®ÂèØ‰ª•ÂºÄÂßã‰ΩøÁî®Ëøô‰∏™ËØÑ‰º∞Á≥ªÁªüÊù•ÁõëÊéßÂíåÊîπËøõÊÇ®ÁöÑAIÂ∫îÁî®‰∫ÜÔºÅ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab7742",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3",
   "metadata": {
    "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3"
   },
   "source": [
    "# LangSmithÊâßË°åËøΩË∏™\n",
    "\n",
    "Êàë‰ª¨ÂèØ‰ª•Êü•Áúã‰∏ÄÊ¨°ÂÆåÊï¥ÁöÑÊâßË°åËøΩË∏™ÔºàtraceÔºâÔºå‰∫ÜËß£Êï¥‰∏™Á†îÁ©∂ÊµÅÁ®ãÁöÑËØ¶ÁªÜÊâßË°åÊÉÖÂÜµÔºö\n",
    "\n",
    "`https://smith.langchain.com/o/7bfa9385-4ac5-468a-a06c-ffd7dbac42ec/projects/p/27f0e396-e7ab-4eac-9501-8df28b729149?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=ffca07d8-1e11-499f-9253-a13706bb9794&peeked_trace=ffca07d8-1e11-499f-9253-a13706bb9794`\n",
    "\n",
    "![image-20251001132158739](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202510011322954.png)\n",
    "\n",
    "## ËøΩË∏™ÂÜÖÂÆπËØ¥Êòé\n",
    "\n",
    "Ëøô‰∏™ËøΩË∏™ÈìæÊé•Â±ïÁ§∫‰∫ÜÔºö\n",
    "\n",
    "1. **ÂàÜÊûêÂ∏àÁîüÊàêËøáÁ®ã**ÔºöÂ¶Ç‰ΩïÊ†πÊçÆÁ†îÁ©∂‰∏ªÈ¢òÂàõÂª∫‰∏çÂêåÁöÑÂàÜÊûêÂ∏àËßíËâ≤\n",
    "2. **Âπ∂Ë°åËÆøË∞àÊâßË°å**ÔºöÂ§ö‰∏™ÂàÜÊûêÂ∏àÂêåÊó∂ËøõË°åËÆøË∞àÁöÑËØ¶ÁªÜËøáÁ®ã\n",
    "3. **‰ø°ÊÅØÊ£ÄÁ¥¢ÊµÅÁ®ã**ÔºöÁΩëÁªúÊêúÁ¥¢ÂíåÁôæÁßëÔºàÁôæÂ∫¶ÁôæÁßëÔºâÊêúÁ¥¢ÁöÑÂÖ∑‰ΩìÊâßË°å\n",
    "4. **Êä•ÂëäÁîüÊàêÊ≠•È™§**Ôºö‰ªéËÆøË∞àÂÜÖÂÆπÂà∞ÊúÄÁªàÊä•ÂëäÁöÑÂÆåÊï¥ËΩ¨Êç¢ËøáÁ®ã\n",
    "5. **‰∫∫Êú∫ÂçèÂêå‰∫§‰∫í**Ôºö‰∫∫Á±ªÂèçÈ¶àÂ¶Ç‰ΩïÂΩ±ÂìçÁ≥ªÁªüË°å‰∏∫\n",
    "\n",
    "ÈÄöËøáËøô‰∏™ËøΩË∏™Ôºå‰Ω†ÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£LangGraphÂ∑•‰ΩúÊµÅÁöÑÂÜÖÈÉ®ÊâßË°åÊú∫Âà∂ÂíåÊØè‰∏™ËäÇÁÇπÁöÑÂÖ∑‰ΩìÂäüËÉΩ„ÄÇ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
