{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/01_langfuse_integration_openai_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki7E44X5ViQB"
      },
      "source": [
        "# OpenAI SDKé›†æˆLangfuseè·å¾—å®Œæ•´çš„å¯è§‚æµ‹æ€§\n",
        "---\n",
        "\n",
        "## ğŸ“š ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹å¯è§‚æµ‹æ€§ï¼Ÿ\n",
        "\n",
        "**å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰** æ˜¯ç›‘æ§å’Œè°ƒè¯•å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„å…³é”®æŠ€æœ¯ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå½“ä½ çš„AIåº”ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿è¡Œæ—¶ï¼Œä½ éœ€è¦çŸ¥é“ï¼š\n",
        "\n",
        "- ğŸ¤” **æ¨¡å‹å›ç­”äº†ä»€ä¹ˆï¼Ÿ** - æŸ¥çœ‹æ¯æ¬¡å¯¹è¯çš„å®Œæ•´å†…å®¹\n",
        "- â±ï¸ **å“åº”é€Ÿåº¦å¦‚ä½•ï¼Ÿ** - ç›‘æ§å»¶è¿Ÿå’Œæ€§èƒ½æŒ‡æ ‡  \n",
        "- ğŸ’° **èŠ±è´¹äº†å¤šå°‘ï¼Ÿ** - è·Ÿè¸ªTokenä½¿ç”¨å’Œæˆæœ¬\n",
        "- ğŸ› **å“ªé‡Œå‡ºé”™äº†ï¼Ÿ** - å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜\n",
        "- ğŸ“Š **æ•ˆæœæ€ä¹ˆæ ·ï¼Ÿ** - è¯„ä¼°æ¨¡å‹å›ç­”è´¨é‡\n",
        "\n",
        "**Langfuse** å°±æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºå¤§æ¨¡å‹åº”ç”¨è®¾è®¡çš„å¯è§‚æµ‹æ€§å¹³å°ï¼Œå®ƒèƒ½å¤Ÿï¼š\n",
        "- è‡ªåŠ¨è®°å½•æ‰€æœ‰APIè°ƒç”¨\n",
        "- æä¾›ç›´è§‚çš„å¯è§†åŒ–ç•Œé¢\n",
        "- æ”¯æŒè¯„åˆ†å’Œè¯„ä¼°\n",
        "- å¸®åŠ©ä¼˜åŒ–æ¨¡å‹æ€§èƒ½\n",
        "\n",
        "## ğŸ¯ æœ¬æ•™ç¨‹å°†æ•™ä¼šä½ ä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "1. **åŸºç¡€é›†æˆ** - å¦‚ä½•ç”¨å‡ è¡Œä»£ç é›†æˆLangfuse\n",
        "2. **å¤šç§è°ƒç”¨æ–¹å¼** - æ–‡æœ¬ã€å›¾åƒã€æµå¼ã€å¼‚æ­¥è°ƒç”¨\n",
        "3. **é«˜çº§åŠŸèƒ½** - å‡½æ•°è°ƒç”¨ã€è¯„åˆ†ç³»ç»Ÿã€é“¾è·¯è¿½è¸ª\n",
        "4. **æœ€ä½³å®è·µ** - ç”Ÿäº§ç¯å¢ƒä¸­çš„ä½¿ç”¨æŠ€å·§\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfMAzJYcirtK"
      },
      "source": [
        "# ğŸš€ ç¤ºä¾‹æ‰‹å†Œï¼šOpenAI é›†æˆï¼ˆPythonï¼‰\n",
        "\n",
        "## ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ•™ç¨‹ï¼Ÿ\n",
        "\n",
        "ä½œä¸ºå¤§æ¨¡å‹æŠ€æœ¯åˆå­¦è€…ï¼Œä½ å¯èƒ½é‡åˆ°è¿‡è¿™äº›é—®é¢˜ï¼š\n",
        "- ä¸çŸ¥é“æ¨¡å‹åˆ°åº•è¾“å‡ºäº†ä»€ä¹ˆ\n",
        "- æ— æ³•è¿½è¸ªAPIè°ƒç”¨çš„æˆæœ¬\n",
        "- è°ƒè¯•é—®é¢˜æ—¶æ‰¾ä¸åˆ°å†å²è®°å½•\n",
        "- ä¸çŸ¥é“å¦‚ä½•è¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
        "\n",
        "**è¿™ä¸ªæ•™ç¨‹å°†å½»åº•è§£å†³è¿™äº›é—®é¢˜ï¼** é€šè¿‡ç®€å•çš„ä»£ç ä¿®æ”¹ï¼Œä½ å°±èƒ½è·å¾—ä¼ä¸šçº§çš„å¯è§‚æµ‹æ€§èƒ½åŠ›ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0A389k2irtK"
      },
      "source": [
        "## ğŸ“– æ•™ç¨‹æ¦‚è¿°\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ª**é›¶åŸºç¡€å‹å¥½**çš„ç¤ºä¾‹æ‰‹å†Œï¼Œæ¼”ç¤ºå¦‚ä½•åœ¨ Python é¡¹ç›®ä¸­é›†æˆ Langfuse ä¸ OpenAIã€‚\n",
        "\n",
        "### ğŸ” Langfuse èƒ½ä¸ºä½ åšä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "**Langfuse ä¼šè®°å½•æ¯æ¬¡æ¨¡å‹è°ƒç”¨çš„è¾“å…¥è¾“å‡º**ï¼Œå°±åƒç»™ä½ çš„AIåº”ç”¨è£…ä¸Šäº†\"é»‘åŒ£å­\"ï¼š\n",
        "\n",
        "1. **ğŸ“ å®Œæ•´è®°å½•** - ä¿å­˜æ¯æ¬¡å¯¹è¯çš„å®Œæ•´ä¸Šä¸‹æ–‡\n",
        "2. **ğŸ” é—®é¢˜æ’æŸ¥** - å¿«é€Ÿå®šä½é”™è¯¯å’Œå¼‚å¸¸\n",
        "3. **ğŸ“Š è´¨é‡è¯„ä¼°** - é€šè¿‡è¯„åˆ†ç³»ç»Ÿè¯„ä¼°æ¨¡å‹æ•ˆæœ\n",
        "4. **ğŸ’° æˆæœ¬æ§åˆ¶** - ç›‘æ§Tokenä½¿ç”¨å’ŒAPIè´¹ç”¨\n",
        "5. **ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–** - åˆ†æå“åº”æ—¶é—´å’Œååé‡\n",
        "\n",
        "### ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "å®Œæˆæœ¬æ•™ç¨‹åï¼Œä½ å°†æŒæ¡ï¼š\n",
        "- âœ… å¦‚ä½•å®‰è£…å’Œé…ç½®Langfuse\n",
        "- âœ… å¦‚ä½•æ›¿æ¢OpenAI SDKå®ç°è‡ªåŠ¨è¿½è¸ª\n",
        "- âœ… å¦‚ä½•æŸ¥çœ‹å’Œåˆ†æè¿½è¸ªæ•°æ®\n",
        "- âœ… å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰å…ƒæ•°æ®å’Œè¯„åˆ†\n",
        "- âœ… å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨\n",
        "\n",
        "æŒ‰ç…§ [é›†æˆæŒ‡å—](https://langfuse.com/integrations/model-providers/openai-py) å°†æœ¬é›†æˆæ·»åŠ åˆ°ä½ çš„ OpenAI é¡¹ç›®ä¸­ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq04G_FSWjF-"
      },
      "source": [
        "## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡\n",
        "\n",
        "### å‰ç½®çŸ¥è¯†è¦æ±‚\n",
        "\n",
        "åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦äº†è§£ä¸€äº›åŸºç¡€æ¦‚å¿µï¼š\n",
        "\n",
        "- **PythonåŸºç¡€** - å˜é‡ã€å‡½æ•°ã€ç±»çš„åŸºæœ¬ä½¿ç”¨\n",
        "- **APIè°ƒç”¨** - äº†è§£HTTPè¯·æ±‚å’Œå“åº”\n",
        "- **ç¯å¢ƒå˜é‡** - å¦‚ä½•å®‰å…¨åœ°å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
        "- **Jupyter Notebook** - åŸºæœ¬çš„notebookæ“ä½œ\n",
        "\n",
        "### ç³»ç»Ÿè¦æ±‚\n",
        "\n",
        "- Python 3.10+\n",
        "- ç¨³å®šçš„ç½‘ç»œè¿æ¥\n",
        "- OpenAI APIå¯†é’¥\n",
        "- Langfuseè´¦æˆ·ï¼ˆå…è´¹æ³¨å†Œï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYoil3FcOIQt"
      },
      "source": [
        "### ğŸ“¦ ä¾èµ–åŒ…ç‰ˆæœ¬è¯´æ˜\n",
        "\n",
        "**é‡è¦ç‰ˆæœ¬è¦æ±‚ï¼š**\n",
        "- **OpenAI SDK** `>=0.27.8` - åŸºç¡€åŠŸèƒ½æ”¯æŒ\n",
        "- **OpenAI SDK** `>=1.0.0` - å¼‚æ­¥å‡½æ•°å’Œæµå¼è¾“å‡ºæ”¯æŒï¼ˆæ¨èï¼‰\n",
        "\n",
        "**ä¸ºä»€ä¹ˆéœ€è¦ç‰¹å®šç‰ˆæœ¬ï¼Ÿ**\n",
        "- æ—§ç‰ˆæœ¬å¯èƒ½ç¼ºå°‘æŸäº›åŠŸèƒ½\n",
        "- æ–°ç‰ˆæœ¬æœ‰æ›´å¥½çš„æ€§èƒ½å’Œç¨³å®šæ€§\n",
        "- æµå¼è¾“å‡ºéœ€è¦è¾ƒæ–°çš„SDKæ”¯æŒ\n",
        "\n",
        "**åˆå­¦è€…æç¤ºï¼š** å¦‚æœä½ ä¸ç¡®å®šå½“å‰ç‰ˆæœ¬ï¼Œç›´æ¥å®‰è£…æœ€æ–°ç‰ˆæœ¬å³å¯ï¼\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hVOOiBtUPtOO",
        "outputId": "2d9a4742-d70e-4cbf-c7fe-63a25dad2bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langfuse==3.3.0\n",
            "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
            "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opentelemetry-proto, backoff, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langfuse\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "Successfully installed backoff-2.2.1 langfuse-3.3.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¥ å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
        "# è¿™ä¸ªå‘½ä»¤ä¼šå®‰è£…ä¸¤ä¸ªæ ¸å¿ƒåŒ…ï¼š\n",
        "# 1. langfuse - å¯è§‚æµ‹æ€§å¹³å°çš„æ ¸å¿ƒåº“\n",
        "# 2. openai - OpenAIå®˜æ–¹SDK\n",
        "\n",
        "%pip install langfuse==3.3.0 openai==1.107.0\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
        "# - %pip æ˜¯Jupyter Notebookçš„é­”æ³•å‘½ä»¤ï¼Œç”¨äºå®‰è£…PythonåŒ…\n",
        "# - == æŒ‡å®šäº†ç¡®åˆ‡çš„ç‰ˆæœ¬å·ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§\n",
        "# - å¦‚æœå®‰è£…å¤±è´¥ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•ä½¿ç”¨å›½å†…é•œåƒæº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K72KpSE2OiJY",
        "outputId": "e137b755-2a4e-4db8-fc97-d8da6754b1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "OPENAI_BASE_URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_PUBLIC_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_SECRET_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "LANGFUSE_HOST: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
        "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„æœ€ä½³å®è·µ\n",
        "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
        "\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
        "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
        "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "# ğŸ¤– OpenAI API é…ç½®\n",
        "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
        "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# APIä»£ç†åœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ï¼ˆå¦‚å›½å†…ä»£ç†ï¼‰\n",
        "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
        "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
        "_set_env(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# ğŸŒ Langfuse é…ç½®\n",
        "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
        "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
        "\n",
        "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
        "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
        "\n",
        "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
        "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
        "\n",
        "# æœåŠ¡å™¨åœ°å€ï¼šé€‰æ‹©ç¦»ä½ æœ€è¿‘çš„åŒºåŸŸ\n",
        "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
        "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ https://us.cloud.langfuse.com\n",
        "_set_env(\"LANGFUSE_HOST\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
        "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
        "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
        "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldSEJ0bAP4sj"
      },
      "outputs": [],
      "source": [
        "# ğŸ¯ æ ¸å¿ƒé›†æˆï¼šæ›¿æ¢OpenAI SDK\n",
        "# è¿™æ˜¯æ•´ä¸ªæ•™ç¨‹çš„æ ¸å¿ƒï¼åªéœ€è¦ä¸€è¡Œä»£ç çš„ä¿®æ”¹\n",
        "# åªéœ€æ›¿æ¢ import è¯­å¥ï¼Œå°±èƒ½ç”¨ Langfuse ç‰ˆæœ¬çš„ OpenAI SDK è·å¾—å®Œæ•´çš„å¯è§‚æµ‹æ€§\n",
        "\n",
        "# åŸæ¥çš„å¯¼å…¥æ–¹å¼ï¼š\n",
        "# from openai import OpenAI\n",
        "\n",
        "# æ–°çš„å¯¼å…¥æ–¹å¼ï¼ˆè‡ªåŠ¨é›†æˆLangfuseï¼‰ï¼š\n",
        "from langfuse.openai import openai\n",
        "\n",
        "# ğŸš€ é­”æ³•å°±åœ¨è¿™é‡Œï¼\n",
        "# Langfuseæä¾›äº†å¯¹åŸç”ŸOpenAI SDKçš„å®Œå…¨å…¼å®¹å°è£…\n",
        "# è¿™æ„å‘³ç€ï¼š\n",
        "# 1. âœ… ä½ çš„ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹\n",
        "# 2. âœ… è‡ªåŠ¨è®°å½•æ‰€æœ‰APIè°ƒç”¨\n",
        "# 3. âœ… ä¿æŒå®Œå…¨ç›¸åŒçš„æ¥å£\n",
        "# 4. âœ… é›¶å­¦ä¹ æˆæœ¬\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# æƒ³è±¡ä¸€ä¸‹ï¼ŒLangfuseå°±åƒä¸€ä¸ª\"é€æ˜çš„ä¸­é—´å±‚\"\n",
        "# å®ƒæ‹¦æˆªä½ çš„OpenAIè°ƒç”¨ï¼Œè®°å½•æ•°æ®ï¼Œç„¶åè½¬å‘ç»™çœŸæ­£çš„OpenAI API\n",
        "# å¯¹ä½ æ¥è¯´ï¼Œä½¿ç”¨æ–¹å¼å®Œå…¨ä¸€æ ·ï¼Œä½†è·å¾—äº†å¼ºå¤§çš„å¯è§‚æµ‹æ€§èƒ½åŠ›\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ovnAAdbaLmD"
      },
      "source": [
        "## ğŸ¯ å®æˆ˜ç¤ºä¾‹\n",
        "\n",
        "ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡å…·ä½“çš„ä»£ç ç¤ºä¾‹æ¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨Langfuseï¼\n",
        "\n",
        "### ğŸ“ ç¤ºä¾‹1ï¼šæ–‡æœ¬èŠå¤©è¡¥å…¨\n",
        "\n",
        "**ä»€ä¹ˆæ˜¯èŠå¤©è¡¥å…¨ï¼Ÿ**\n",
        "èŠå¤©è¡¥å…¨æ˜¯GPTæ¨¡å‹çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå®ƒæ ¹æ®ä½ æä¾›çš„å¯¹è¯å†å²ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªå›å¤ã€‚å°±åƒå’ŒçœŸäººèŠå¤©ä¸€æ ·ï¼\n",
        "\n",
        "**åº”ç”¨åœºæ™¯ï¼š**\n",
        "- æ™ºèƒ½å®¢æœ\n",
        "- å†™ä½œåŠ©æ‰‹  \n",
        "- ä»£ç ç”Ÿæˆ\n",
        "- é—®ç­”ç³»ç»Ÿ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8RhokKUP9I0"
      },
      "outputs": [],
      "source": [
        "# ğŸ§® ç®€å•è®¡ç®—å™¨ç¤ºä¾‹\n",
        "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•è®©GPTæ‰®æ¼”ä¸€ä¸ªç²¾ç¡®çš„è®¡ç®—å™¨\n",
        "\n",
        "# å‘èµ·èŠå¤©è¡¥å…¨è¯·æ±‚\n",
        "completion = openai.chat.completions.create(\n",
        "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
        "  name=\"calculator-demo\",  # ç»™è¿™æ¬¡è°ƒç”¨èµ·ä¸ªåå­—ï¼Œæ–¹ä¾¿åœ¨Langfuseä¸­æŸ¥æ‰¾\n",
        "\n",
        "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
        "  model=\"gpt-4o\",  # ä½¿ç”¨GPT-4oæ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©gpt-3.5-turboç­‰\n",
        "\n",
        "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
        "  messages=[\n",
        "      # systemæ¶ˆæ¯ï¼šå®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º\n",
        "      {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚æ‚¨åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
        "\n",
        "      # useræ¶ˆæ¯ï¼šç”¨æˆ·çš„å®é™…é—®é¢˜\n",
        "      {\"role\": \"user\", \"content\": \"1 + 1 = \"}\n",
        "  ],\n",
        "\n",
        "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
        "  temperature=0,  # 0è¡¨ç¤ºæœ€ç¨³å®šï¼Œé€‚åˆæ•°å­¦è®¡ç®—ç­‰éœ€è¦å‡†ç¡®ç­”æ¡ˆçš„åœºæ™¯\n",
        "\n",
        "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
        "  metadata={\n",
        "      \"task_type\": \"calculator\",  # ä»»åŠ¡ç±»å‹\n",
        "      \"difficulty\": \"easy\",       # éš¾åº¦ç­‰çº§\n",
        "      \"user_id\": \"demo_user\"      # ç”¨æˆ·ID\n",
        "  }\n",
        ")\n",
        "\n",
        "# ğŸ“Š è·å–æ¨¡å‹å“åº”\n",
        "# completion.choices[0] è·å–ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸ä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰å›å¤\n",
        "# .message.content è·å–å›å¤çš„æ–‡æœ¬å†…å®¹\n",
        "result = completion.choices[0].message.content\n",
        "print(f\"è®¡ç®—ç»“æœ: {result}\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# 1. messagesæ˜¯ä¸€ä¸ªå¯¹è¯å†å²åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—\n",
        "# 2. systemæ¶ˆæ¯è®¾ç½®AIçš„è§’è‰²ï¼Œuseræ¶ˆæ¯æ˜¯ç”¨æˆ·è¾“å…¥\n",
        "# 3. temperatureæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼ˆ0-2ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰\n",
        "# 4. metadataå¯ä»¥å­˜å‚¨ä»»ä½•è‡ªå®šä¹‰ä¿¡æ¯ï¼Œç”¨äºåˆ†æå’Œè°ƒè¯•\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAqxBgOqKTzO"
      },
      "source": [
        "### ğŸ–¼ï¸ ç¤ºä¾‹2ï¼šå›¾åƒèŠå¤©è¡¥å…¨\n",
        "\n",
        "**ä»€ä¹ˆæ˜¯å›¾åƒèŠå¤©è¡¥å…¨ï¼Ÿ**\n",
        "GPT-4oç­‰æ¨¡å‹ä¸ä»…èƒ½ç†è§£æ–‡å­—ï¼Œè¿˜èƒ½\"çœ‹æ‡‚\"å›¾ç‰‡ï¼è¿™è®©AIå¯ä»¥ï¼š\n",
        "- æè¿°å›¾ç‰‡å†…å®¹\n",
        "- å›ç­”å…³äºå›¾ç‰‡çš„é—®é¢˜\n",
        "- åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯\n",
        "- è¿›è¡Œå›¾åƒç›¸å…³çš„åˆ›ä½œ\n",
        "\n",
        "**åº”ç”¨åœºæ™¯ï¼š**\n",
        "- å›¾åƒå†…å®¹å®¡æ ¸\n",
        "- è§†è§‰é—®ç­”ç³»ç»Ÿ\n",
        "- å›¾åƒæ ‡æ³¨å’Œæè¿°\n",
        "- å¤šæ¨¡æ€AIåŠ©æ‰‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sM_Pe0YIfTT"
      },
      "outputs": [],
      "source": [
        "# ğŸ–¼ï¸ å›¾åƒåˆ†æç¤ºä¾‹\n",
        "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•è®©GPTåˆ†æä¸€å¼ å›¾ç‰‡\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
        "  name=\"image-analysis-demo\",  # ç»™è¿™æ¬¡å›¾åƒåˆ†æèµ·ä¸ªåå­—\n",
        "\n",
        "  # ğŸ¤– æ¨¡å‹é€‰æ‹©ï¼ˆæ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼‰\n",
        "  model=\"gpt-4o-mini\",  # æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼šGPT-4oã€GPT-4o miniã€GPT-4 Turbo\n",
        "\n",
        "  # ğŸ’¬ å¤šæ¨¡æ€å¯¹è¯å†…å®¹\n",
        "  messages=[\n",
        "      # systemæ¶ˆæ¯ï¼šå®šä¹‰AIåœ¨å›¾åƒåˆ†æä¸­çš„è§’è‰²\n",
        "      {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä¸ªè¢«è®­ç»ƒæ¥æè¿°å’Œè§£é‡Šå›¾åƒçš„AIã€‚æè¿°å›¾åƒä¸­çš„ä¸»è¦ç‰©ä½“å’ŒåŠ¨ä½œã€‚\"},\n",
        "\n",
        "      # useræ¶ˆæ¯ï¼šåŒ…å«æ–‡å­—å’Œå›¾ç‰‡çš„å¤åˆå†…å®¹\n",
        "      {\"role\": \"user\", \"content\": [\n",
        "        # æ–‡å­—éƒ¨åˆ†ï¼šç»™AIçš„æŒ‡ä»¤\n",
        "        {\"type\": \"text\", \"text\": \"è¿™å¹…ç”»æç»˜äº†ä»€ä¹ˆï¼Ÿè¯·è¯¦ç»†æè¿°ã€‚\"},\n",
        "\n",
        "        # å›¾ç‰‡éƒ¨åˆ†ï¼šè¦åˆ†æçš„å›¾ç‰‡\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://static.langfuse.com/langfuse-dev/langfuse-example-image.jpeg\"\n",
        "          },\n",
        "        },\n",
        "      ]}\n",
        "  ],\n",
        "\n",
        "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
        "  temperature=0,  # å›¾åƒæè¿°éœ€è¦å‡†ç¡®æ€§ï¼Œä½¿ç”¨è¾ƒä½æ¸©åº¦\n",
        "\n",
        "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
        "  metadata={\n",
        "      \"task_type\": \"image_analysis\",\n",
        "      \"image_source\": \"langfuse_example\",\n",
        "      \"analysis_type\": \"description\"\n",
        "  }\n",
        ")\n",
        "\n",
        "# ğŸ“Š è·å–åˆ†æç»“æœ\n",
        "analysis_result = completion.choices[0].message.content\n",
        "print(f\"å›¾åƒåˆ†æç»“æœ: {analysis_result}\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# 1. å¤šæ¨¡æ€æ¶ˆæ¯ï¼šuseræ¶ˆæ¯å¯ä»¥åŒæ—¶åŒ…å«æ–‡å­—å’Œå›¾ç‰‡\n",
        "# 2. å›¾ç‰‡æ ¼å¼ï¼šæ”¯æŒURLé“¾æ¥æˆ–base64ç¼–ç \n",
        "# 3. è§†è§‰æ¨¡å‹ï¼šåªæœ‰ç‰¹å®šæ¨¡å‹æ”¯æŒå›¾åƒç†è§£\n",
        "# 4. Langfuseè®°å½•ï¼šä¼šè‡ªåŠ¨ä¿å­˜å›¾ç‰‡URLï¼Œæ–¹ä¾¿åç»­æŸ¥çœ‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4iJpqYQirtM"
      },
      "source": [
        "## ğŸ” æŸ¥çœ‹è¿½è¸ªç»“æœ\n",
        "\n",
        "ç°åœ¨ä½ å¯ä»¥å‰å¾€ [Langfuseæ§åˆ¶å°](https://cloud.langfuse.com) æŸ¥çœ‹åˆšæ‰çš„APIè°ƒç”¨è®°å½•ï¼\n",
        "\n",
        "**åœ¨Langfuseä¸­ä½ å¯ä»¥çœ‹åˆ°ï¼š**\n",
        "- ğŸ“Š **å®Œæ•´çš„å¯¹è¯å†å²** - åŒ…æ‹¬systemå’Œuseræ¶ˆæ¯\n",
        "- â±ï¸ **å“åº”æ—¶é—´** - äº†è§£APIæ€§èƒ½\n",
        "- ğŸ’° **Tokenä½¿ç”¨é‡** - ç›‘æ§æˆæœ¬\n",
        "- ğŸ·ï¸ **è‡ªå®šä¹‰å…ƒæ•°æ®** - ä½ æ·»åŠ çš„æ ‡ç­¾å’Œåˆ†ç±»\n",
        "- ğŸ–¼ï¸ **å›¾ç‰‡é“¾æ¥** - æ–¹ä¾¿å¤ç°å›¾åƒåˆ†æ\n",
        "\n",
        "![Langfuseè¿½è¸ªç•Œé¢ç¤ºä¾‹](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211139659.png)\n",
        "\n",
        "**ğŸ’¡ åˆå­¦è€…æç¤ºï¼š**\n",
        "- æ¯æ¬¡APIè°ƒç”¨éƒ½ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª\"Trace\"ï¼ˆè¿½è¸ªè®°å½•ï¼‰\n",
        "- ä½ å¯ä»¥é€šè¿‡nameå­—æ®µå¿«é€Ÿæ‰¾åˆ°ç‰¹å®šçš„è°ƒç”¨\n",
        "- å…ƒæ•°æ®å¸®åŠ©ä½ åˆ†ç±»å’Œç­›é€‰ä¸åŒçš„è°ƒç”¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFYWEbD6IfTU"
      },
      "source": [
        "### ğŸŒŠ ç¤ºä¾‹3ï¼šæµå¼èŠå¤©è¡¥å…¨\n",
        "\n",
        "**ä»€ä¹ˆæ˜¯æµå¼è¾“å‡ºï¼Ÿ**\n",
        "æµå¼è¾“å‡ºè®©AIå¯ä»¥\"è¾¹æƒ³è¾¹è¯´\"ï¼Œå°±åƒçœŸäººå¯¹è¯ä¸€æ ·é€å­—é€å¥åœ°å›å¤ï¼Œè€Œä¸æ˜¯ç­‰å¾…å®Œæ•´ç­”æ¡ˆã€‚\n",
        "\n",
        "**æµå¼è¾“å‡ºçš„ä¼˜åŠ¿ï¼š**\n",
        "- âš¡ **æ›´å¿«çš„å“åº”æ„ŸçŸ¥** - ç”¨æˆ·ç«‹å³çœ‹åˆ°AIå¼€å§‹å›å¤\n",
        "- ğŸ¯ **æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ** - é¿å…é•¿æ—¶é—´ç­‰å¾…\n",
        "- ğŸ”„ **å®æ—¶äº¤äº’** - å¯ä»¥ä¸­é€”åœæ­¢æˆ–ä¿®æ”¹\n",
        "- ğŸ“± **é€‚åˆç§»åŠ¨ç«¯** - å‡å°‘ç½‘ç»œè¶…æ—¶é£é™©\n",
        "\n",
        "**åº”ç”¨åœºæ™¯ï¼š**\n",
        "- èŠå¤©æœºå™¨äºº\n",
        "- é•¿æ–‡æœ¬ç”Ÿæˆ\n",
        "- å®æ—¶ç¿»è¯‘\n",
        "- ä»£ç ç”ŸæˆåŠ©æ‰‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9gRlb2rKTaA",
        "outputId": "12be69ba-0f5b-46c7-afa0-b6390a9671c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å½“ç„¶ï¼ä½ çŸ¥é“ä¸ºä»€ä¹ˆæ•°å­¦ä¹¦æ€»æ˜¯å¾ˆå¿§éƒå—ï¼Ÿå› ä¸ºå®ƒæœ‰å¤ªå¤šçš„é—®é¢˜ï¼None"
          ]
        }
      ],
      "source": [
        "# ğŸ­ æµå¼ç¬‘è¯ç”Ÿæˆç¤ºä¾‹\n",
        "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•å®æ—¶è·å–AIçš„å›å¤\n",
        "\n",
        "print(\"ğŸ¤– AIå¼€å§‹è®²ç¬‘è¯ï¼š\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# å‘èµ·æµå¼èŠå¤©è¡¥å…¨è¯·æ±‚\n",
        "completion = openai.chat.completions.create(\n",
        "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
        "  name=\"streaming-joke-demo\",  # ç»™è¿™æ¬¡æµå¼è°ƒç”¨èµ·ä¸ªåå­—\n",
        "\n",
        "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
        "  model=\"gpt-4o\",\n",
        "\n",
        "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„å–œå‰§æ¼”å‘˜ï¼Œæ“…é•¿è®²æœ‰è¶£çš„ç¬‘è¯ã€‚\"},\n",
        "      {\"role\": \"user\", \"content\": \"è®²ä¸€ä¸ªå…³äºç¼–ç¨‹çš„ç¬‘è¯ç»™æˆ‘å¬ã€‚\"}\n",
        "  ],\n",
        "\n",
        "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
        "  temperature=0.7,  # ç¨å¾®æé«˜æ¸©åº¦ï¼Œè®©ç¬‘è¯æ›´æœ‰åˆ›æ„\n",
        "\n",
        "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
        "  metadata={\n",
        "      \"task_type\": \"joke_generation\",\n",
        "      \"style\": \"programming_humor\",\n",
        "      \"streaming\": True\n",
        "  },\n",
        "\n",
        "  # ğŸŒŠ å¼€å¯æµå¼æ¨¡å¼\n",
        "  stream=True  # è¿™æ˜¯å…³é”®ï¼å¼€å¯åAPIä¼šè¾¹ç”Ÿæˆè¾¹è¿”å›\n",
        ")\n",
        "\n",
        "# ğŸ“Š å¤„ç†æµå¼å“åº”\n",
        "# completionç°åœ¨æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä¼šé€æ­¥è¿”å›å†…å®¹\n",
        "for chunk in completion:\n",
        "    # æ£€æŸ¥chunkä¸­æ˜¯å¦æœ‰æ–°å†…å®¹\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "        # å®æ—¶æ‰“å°å†…å®¹ï¼Œend=\"\"è¡¨ç¤ºä¸æ¢è¡Œ\n",
        "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 40)\n",
        "print(\"âœ… ç¬‘è¯è®²å®Œäº†ï¼\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# 1. stream=True å¼€å¯æµå¼æ¨¡å¼\n",
        "# 2. è¿”å›çš„æ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦ç”¨forå¾ªç¯å¤„ç†\n",
        "# 3. delta.content åŒ…å«æ–°å¢çš„å†…å®¹ç‰‡æ®µ\n",
        "# 4. flush=True ç¡®ä¿å†…å®¹ç«‹å³æ˜¾ç¤º\n",
        "# 5. Langfuseä¼šè‡ªåŠ¨è®°å½•æ•´ä¸ªæµå¼è¿‡ç¨‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2pvm0qLKg7Q"
      },
      "source": [
        "### âš¡ ç¤ºä¾‹4ï¼šå¼‚æ­¥èŠå¤©è¡¥å…¨\n",
        "\n",
        "**ä»€ä¹ˆæ˜¯å¼‚æ­¥è°ƒç”¨ï¼Ÿ**\n",
        "å¼‚æ­¥è°ƒç”¨å…è®¸ç¨‹åºåœ¨ç­‰å¾…APIå“åº”æ—¶ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡ï¼Œæé«˜ç¨‹åºçš„å¹¶å‘æ€§èƒ½ã€‚\n",
        "\n",
        "**å¼‚æ­¥çš„ä¼˜åŠ¿ï¼š**\n",
        "- ğŸš€ **æ›´é«˜çš„å¹¶å‘æ€§** - åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚\n",
        "- â±ï¸ **æ›´å¥½çš„èµ„æºåˆ©ç”¨** - é¿å…é˜»å¡ç­‰å¾…\n",
        "- ğŸ“ˆ **æ›´é«˜çš„ååé‡** - é€‚åˆé«˜å¹¶å‘åœºæ™¯\n",
        "- ğŸ”„ **éé˜»å¡æ“ä½œ** - ä¸ä¼šå¡ä½æ•´ä¸ªç¨‹åº\n",
        "\n",
        "**åº”ç”¨åœºæ™¯ï¼š**\n",
        "- æ‰¹é‡å¤„ç†å¤§é‡è¯·æ±‚\n",
        "- å¾®æœåŠ¡æ¶æ„\n",
        "- é«˜å¹¶å‘Webåº”ç”¨\n",
        "- å®æ—¶æ•°æ®å¤„ç†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hggwggv_MKpV"
      },
      "outputs": [],
      "source": [
        "# âš¡ å¼‚æ­¥å®¢æˆ·ç«¯åˆå§‹åŒ–\n",
        "# å¼‚æ­¥å®¢æˆ·ç«¯å…è®¸éé˜»å¡çš„APIè°ƒç”¨ï¼Œæé«˜ç¨‹åºæ€§èƒ½\n",
        "\n",
        "from langfuse.openai import AsyncOpenAI\n",
        "\n",
        "# åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯å®ä¾‹\n",
        "# è‡ªåŠ¨å¤ç”¨ç¯å¢ƒå˜é‡ä¸­çš„Langfuseé…ç½®\n",
        "async_client = AsyncOpenAI()\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# 1. AsyncOpenAI æ˜¯å¼‚æ­¥ç‰ˆæœ¬çš„OpenAIå®¢æˆ·ç«¯\n",
        "# 2. ä½¿ç”¨æ–¹å¼ä¸åŒæ­¥å®¢æˆ·ç«¯åŸºæœ¬ç›¸åŒ\n",
        "# 3. ä¸»è¦åŒºåˆ«æ˜¯éœ€è¦ä½¿ç”¨ await å…³é”®å­—\n",
        "# 4. é€‚åˆéœ€è¦å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚çš„åœºæ™¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIUKD8Z3KmvQ"
      },
      "outputs": [],
      "source": [
        "# ğŸ§® å¼‚æ­¥è®¡ç®—å™¨ç¤ºä¾‹\n",
        "# è¿™ä¸ªä¾‹å­å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è¿›è¡ŒAPIè°ƒç”¨\n",
        "\n",
        "# åœ¨å¼‚æ­¥å‡½æ•°å†…è°ƒç”¨èŠå¤©è¡¥å…¨æ¥å£\n",
        "completion = await async_client.chat.completions.create(\n",
        "  # ğŸ“ è¿½è¸ªä¿¡æ¯\n",
        "  name=\"async-calculator-demo\",  # ä¸ºæœ¬æ¬¡å¼‚æ­¥è°ƒç”¨å‘½å\n",
        "\n",
        "  # ğŸ¤– æ¨¡å‹é€‰æ‹©\n",
        "  model=\"gpt-4o\",\n",
        "\n",
        "  # ğŸ’¬ å¯¹è¯å†…å®¹\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚ä½ åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
        "      {\"role\": \"user\", \"content\": \"1 + 100 = \"}\n",
        "  ],\n",
        "\n",
        "  # ğŸŒ¡ï¸ æ¸©åº¦æ§åˆ¶\n",
        "  temperature=0,\n",
        "\n",
        "  # ğŸ·ï¸ è‡ªå®šä¹‰å…ƒæ•°æ®\n",
        "  metadata={\n",
        "      \"task_type\": \"async_calculator\",\n",
        "      \"concurrency\": \"high\",\n",
        "      \"user_id\": \"async_demo_user\"\n",
        "  }\n",
        ")\n",
        "\n",
        "# ğŸ“Š è·å–å¼‚æ­¥å“åº”ç»“æœ\n",
        "result = completion.choices[0].message.content\n",
        "print(f\"å¼‚æ­¥è®¡ç®—ç»“æœ: {result}\")\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# 1. await å…³é”®å­—ç”¨äºç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ\n",
        "# 2. å¼‚æ­¥è°ƒç”¨ä¸ä¼šé˜»å¡ç¨‹åºæ‰§è¡Œ\n",
        "# 3. Langfuseè‡ªåŠ¨å¤„ç†å¼‚æ­¥è°ƒç”¨çš„è¿½è¸ª\n",
        "# 4. é€‚åˆéœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚çš„åœºæ™¯\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVbKbya4IfTX"
      },
      "source": [
        "å‰å¾€ https://cloud.langfuse.com æˆ–ä½ è‡ªå»ºçš„å®ä¾‹ï¼Œå¯ä»¥åœ¨ Langfuse ä¸­æŸ¥çœ‹ç”Ÿæˆè®°å½•ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7CtCNzaSrn"
      },
      "source": [
        "### ğŸ”§ ç¤ºä¾‹5ï¼šå‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰\n",
        "\n",
        "**ä»€ä¹ˆæ˜¯å‡½æ•°è°ƒç”¨ï¼Ÿ**\n",
        "å‡½æ•°è°ƒç”¨è®©AIå¯ä»¥è°ƒç”¨ä½ å®šä¹‰çš„å‡½æ•°ï¼Œå®ç°æ›´å¤æ‚çš„äº¤äº’å’Œç»“æ„åŒ–è¾“å‡ºã€‚\n",
        "\n",
        "**å‡½æ•°è°ƒç”¨çš„ä¼˜åŠ¿ï¼š**\n",
        "- ğŸ¯ **ç»“æ„åŒ–è¾“å‡º** - è·å¾—æ ¼å¼åŒ–çš„JSONæ•°æ®\n",
        "- ğŸ”— **å¤–éƒ¨é›†æˆ** - è°ƒç”¨æ•°æ®åº“ã€APIç­‰å¤–éƒ¨æœåŠ¡\n",
        "- ğŸ“Š **æ•°æ®éªŒè¯** - ä½¿ç”¨Pydanticç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®\n",
        "- ğŸ¤– **æ™ºèƒ½å†³ç­–** - AIæ ¹æ®æƒ…å†µé€‰æ‹©è°ƒç”¨å“ªä¸ªå‡½æ•°\n",
        "\n",
        "**åº”ç”¨åœºæ™¯ï¼š**\n",
        "- æ™ºèƒ½åŠ©æ‰‹ï¼ˆæŸ¥è¯¢å¤©æ°”ã€å‘é€é‚®ä»¶ï¼‰\n",
        "- æ•°æ®æå–å’Œè½¬æ¢\n",
        "- å·¥ä½œæµè‡ªåŠ¨åŒ–\n",
        "- APIæ¥å£ç”Ÿæˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJfBdHowaRgs",
        "outputId": "cda9d41d-9a70-40a2-9625-93714c1f253c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic==2.11.9 in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.9) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¦ å®‰è£…Pydanticä¾èµ–\n",
        "# Pydanticæ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ•°æ®éªŒè¯åº“ï¼Œç”¨äºå®šä¹‰ç»“æ„åŒ–æ•°æ®æ¨¡å‹\n",
        "\n",
        "%pip install pydantic==2.11.9\n",
        "\n",
        "# ğŸ’¡ åˆå­¦è€…ç†è§£ï¼š\n",
        "# Pydanticå¸®åŠ©æˆ‘ä»¬ï¼š\n",
        "# 1. å®šä¹‰æ•°æ®ç»“æ„ï¼ˆç±»ä¼¼æ•°æ®åº“è¡¨ç»“æ„ï¼‰\n",
        "# 2. è‡ªåŠ¨éªŒè¯æ•°æ®æ ¼å¼\n",
        "# 3. ç”ŸæˆJSON Schemaä¾›AIä½¿ç”¨\n",
        "# 4. ç¡®ä¿AIè¿”å›çš„æ•°æ®ç¬¦åˆé¢„æœŸæ ¼å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gA-zGk7VYYp",
        "outputId": "10430c87-cf69-4679-ea68-0aabb687de75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-414262564.py:9: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  schema = StepByStepAIResponse.schema()  # è¿”å› JSON Schemaï¼Œä¾› OpenAI å‡½æ•°è°ƒç”¨ä½¿ç”¨\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# å®šä¹‰å‡½æ•°è°ƒç”¨è¿”å›å€¼çš„æ•°æ®ç»“æ„ï¼Œè®©æ¨¡å‹ç”Ÿæˆç»“æ„åŒ–çš„ JSON\n",
        "class StepByStepAIResponse(BaseModel):\n",
        "    title: str  # æ ‡é¢˜ï¼šä¾‹å¦‚â€œè£…æœºæ­¥éª¤â€\n",
        "    steps: List[str]  # æ­¥éª¤åˆ—è¡¨ï¼šæ¯ä¸ªå…ƒç´ æ˜¯ä¸€å¥æè¿°\n",
        "\n",
        "schema = StepByStepAIResponse.schema()  # è¿”å› JSON Schemaï¼Œä¾› OpenAI å‡½æ•°è°ƒç”¨ä½¿ç”¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORtNcN4-afDC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# ç¤ºä¾‹ï¼šå¼•å¯¼æ¨¡å‹è°ƒç”¨æˆ‘ä»¬å®šä¹‰çš„å‡½æ•°ï¼Œå¹¶è¿”å›ç»“æ„åŒ–ç»“æœ\n",
        "response = openai.chat.completions.create(\n",
        "    name=\"test-function\",\n",
        "    model=\"gpt-4o-0613\",  # æ”¯æŒå‡½æ•°è°ƒç”¨çš„æ¨¡å‹ç‰ˆæœ¬(æœ‰äº›OpenAIä»£ç†ä¸æ”¯æŒå‡½æ•°è°ƒç”¨ï¼Œè¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºDeepSeek)\n",
        "    messages=[\n",
        "       {\"role\": \"user\", \"content\": \"å¦‚ä½•ç»„è£…ä¸€å°ç”µè„‘\"}\n",
        "    ],\n",
        "    functions=[\n",
        "        {\n",
        "          \"name\": \"get_answer_for_user_query\",  # å‡½æ•°åç§°ï¼Œéœ€è¦ä¸ä¸šåŠ¡ä»£ç ä¿æŒä¸€è‡´\n",
        "          \"description\": \"åˆ†æ­¥éª¤ä¸ºç”¨æˆ·æä¾›ç­”æ¡ˆ\",  # å‘Šè¯‰æ¨¡å‹å‡½æ•°çš„ç”¨é€”\n",
        "          \"parameters\": StepByStepAIResponse.schema()  # Pydantic è‡ªåŠ¨ç”Ÿæˆçš„å‚æ•°å®šä¹‰\n",
        "        }\n",
        "    ],\n",
        "    function_call={\"name\": \"get_answer_for_user_query\"}  # å¼ºåˆ¶æ¨¡å‹è°ƒç”¨æŒ‡å®šå‡½æ•°\n",
        ")\n",
        "\n",
        "# Langfuse ä¼šè®°å½•å‡½æ•°è°ƒç”¨çš„å…¥å‚ä¸å‡ºå‚ï¼Œä¾¿äºè¿½è¸ª\n",
        "output = json.loads(response.choices[0].message.function_call.arguments)  # å°†å­—ç¬¦ä¸²ååºåˆ—åŒ–ä¸º Python å­—å…¸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qurrm-Ntp24O"
      },
      "source": [
        "å‰å¾€ https://cloud.langfuse.com æˆ–ä½ è‡ªå»ºçš„å®ä¾‹ï¼Œå¯ä»¥åœ¨ Langfuse ä¸­æŸ¥çœ‹ç”Ÿæˆè®°å½•ã€‚\n",
        "\n",
        "ç¤ºä¾‹ï¼šhttps://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces/8942d39f62095985bf891156bbd563b9?timestamp=2025-09-21T03:42:03.721Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hMsPXFDIfTZ"
      },
      "source": [
        "## Langfuse åŠŸèƒ½ï¼ˆç”¨æˆ·ã€æ ‡ç­¾ã€å…ƒæ•°æ®ã€ä¼šè¯ï¼‰\n",
        "\n",
        "ä½ å¯ä»¥åœ¨ OpenAI è¯·æ±‚ä¸­åŠ å…¥é¢å¤–å±æ€§ï¼Œä»¥å¯ç”¨æ›´å¤š Langfuse åŠŸèƒ½ã€‚Langfuse é›†æˆä¼šè‡ªåŠ¨è§£æè¿™äº›å­—æ®µã€‚å®Œæ•´åŠŸèƒ½åˆ—è¡¨è§ [æ–‡æ¡£](https://langfuse.com/integrations/model-providers/openai-py#custom-trace-properties)ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7srTKGjaIfTZ"
      },
      "outputs": [],
      "source": [
        "result = openai.chat.completions.create(\n",
        "    name=\"test-chat-with-attributes\",  # trace åç§°ï¼Œå¯¹åº” Langfuse ä¸­çš„ Trace.name\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä¸ªéå¸¸ç²¾ç¡®çš„è®¡ç®—å™¨ã€‚æ‚¨åªè¾“å‡ºè®¡ç®—ç»“æœã€‚\"},\n",
        "        {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
        "    temperature=0,\n",
        "    metadata={\n",
        "        \"langfuse_session_id\": \"session_123\", # ä¼šè¯ IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯/è¯·æ±‚\n",
        "        \"langfuse_user_id\": \"user_456\", # ä¸šåŠ¡ç”¨æˆ· IDï¼Œè®©ä½ åœ¨ Langfuse ä¸­æŒ‰ç”¨æˆ·èšåˆ\n",
        "        \"langfuse_tags\": [\"calculator\"], # trace æ ‡ç­¾ï¼Œå¯ç”¨äº Langfuse æ§åˆ¶å°ç­›é€‰\n",
        "        \"someMetadataKey\": \"someValue\"  # trace å…ƒæ•°æ®ï¼Œé€‚åˆè®°å½•ä¸šåŠ¡ä¸Šä¸‹æ–‡\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPfrmgbEIfTZ"
      },
      "source": [
        "ç¤ºä¾‹è¿½è¸ªï¼š\n",
        "\n",
        "\n",
        "![image-20250921115506459](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211155197.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su1OaQq3rPPh"
      },
      "source": [
        "## å°†å¤šæ¬¡ç”Ÿæˆå½’å¹¶ä¸ºå•ä¸ª Trace\n",
        "\n",
        "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾€å¾€éœ€è¦å¤šæ¬¡è°ƒç”¨ OpenAIã€‚å€ŸåŠ© `@observe()` è£…é¥°å™¨ï¼Œå¯ä»¥æŠŠä¸€æ¬¡ API è°ƒç”¨ä¸­çš„æ‰€æœ‰ LLM è¯·æ±‚å½’å…¥ Langfuse ä¸­åŒä¸€ä¸ª `trace`ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMDVxzS1ltWU",
        "outputId": "ce14c152-20f5-48f9-ffb4-60f934e8b85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åœ¨åå¤å¤§åœ°çš„åŒ—æ–¹ä¸€éš…ï¼Œ   \n",
            "é•¿åŸä»¥åŒ—ï¼Œé»„åœŸä»¥ä¸œï¼Œ   \n",
            "å¤è€ä¸ç°ä»£åœ¨æ­¤å…±èˆï¼Œ   \n",
            "åŒ—äº¬ï¼Œè¿™åº§åŸå¸‚çš„å¿ƒè·³å¦‚é’Ÿã€‚   \n",
            "\n",
            "ç´«ç¦åŸå·å³¨ï¼Œè¯‰è¯´ç€å¾€æ˜”çš„ä¼ å¥‡ï¼Œ   \n",
            "å¤©å®‰é—¨å¹¿åœºï¼Œè§è¯äº†å†å²çš„æ›´æ›¿ã€‚   \n",
            "åœ¨èƒ¡åŒæ·±å¤„ï¼Œå²æœˆçš„è¶³è¿¹ä¾ç¨€ï¼Œ   \n",
            "å››åˆé™¢é‡Œï¼Œå¤è€çš„éŸµå‘³é“­åˆ»å¿ƒåº•ã€‚   \n",
            "\n",
            "ç¹åçš„è¡—é“ï¼Œè½¦æµå¦‚æ°´ï¼Œ   \n",
            "éœ“è™¹ç¯ä¸‹ï¼ŒåŸå¸‚çš„æ¢¦å¢ƒæ— ç©·ã€‚   \n",
            "æ‘©å¤©å¤§æ¥¼ç›´æ’äº‘éœ„ï¼Œ   \n",
            "å­•è‚²æ–°çš„å¸Œæœ›ä¸å…‰è£ã€‚   \n",
            "\n",
            "æ–‡äººç¿°å¢¨ï¼Œåœ¨æ­¤æŒ¥æ´’åƒè½½ï¼Œ   \n",
            "åˆ›æ–°åˆ›ä¸šï¼Œå¹´è½»çš„çƒ­è¡€æ˜‚æ‰¬ã€‚   \n",
            "åŒ—äº¬ï¼Œä¸æ¯çš„è„‰åŠ¨ä¸­ï¼Œ   \n",
            "æ‰¿è½½ç€ä¸­åŸå„¿å¥³çš„\n"
          ]
        }
      ],
      "source": [
        "from langfuse.openai import openai\n",
        "from langfuse import observe\n",
        "\n",
        "# ã€@observe è£…é¥°å™¨ã€‘ä¼šè‡ªåŠ¨ï¼š\n",
        "# 1. ä¸º main å‡½æ•°åˆ›å»ºä¸€ä¸ªé¡¶å±‚ trace\n",
        "# 2. æ•è·å‡½æ•°å†…éƒ¨çš„æ‰€æœ‰ Langfuse/OpenAI è°ƒç”¨ï¼Œå¹¶å°†å®ƒä»¬ä¸²è”ä¸ºä¸€ä¸ªå®Œæ•´é“¾è·¯\n",
        "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
        "def main(country: str, user_id: str, **kwargs) -> str:\n",
        "    # åµŒå¥—è°ƒç”¨ 1ï¼šè¯¢é—®å›½å®¶é¦–éƒ½\n",
        "    capital = openai.chat.completions.create(\n",
        "      name=\"geography-teacher\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä½åœ°ç†è€å¸ˆï¼Œå¸®åŠ©å­¦ç”Ÿå­¦ä¹ å›½å®¶çš„é¦–éƒ½ã€‚å½“è¢«é—®åŠæ—¶ï¼Œåªè¾“å‡ºé¦–éƒ½ã€‚\"},\n",
        "          {\"role\": \"user\", \"content\": country}],\n",
        "      temperature=0,\n",
        "    ).choices[0].message.content  # è¯»å–æ¨¡å‹å›å¤\n",
        "\n",
        "    # åµŒå¥—è°ƒç”¨ 2ï¼šè¯·æ¨¡å‹å†™ä¸€é¦–å…³äºé¦–éƒ½çš„è¯—\n",
        "    poem = openai.chat.completions.create(\n",
        "      name=\"poet\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½è¯—äººã€‚åˆ›ä½œä¸€é¦–å…³äºåŸå¸‚çš„è¯—ã€‚\"},\n",
        "          {\"role\": \"user\", \"content\": capital}],\n",
        "      temperature=1,  # æé«˜æ¸©åº¦ï¼Œè®©è¯—æ­Œæ›´æœ‰åˆ›æ„\n",
        "      max_tokens=200,  # æ§åˆ¶è¾“å‡ºé•¿åº¦\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return poem\n",
        "\n",
        "# ç›´æ¥è°ƒç”¨ main å‡½æ•°ï¼ŒLangfuse ä¼šè‡ªåŠ¨ç”Ÿæˆ trace å¹¶å¯åœ¨æ§åˆ¶å°æŸ¥çœ‹é“¾è·¯\n",
        "print(main(\"åŒ—äº¬\", \"FLY\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehx2NZuIrPPh"
      },
      "source": [
        "å‰å¾€ https://cloud.langfuse.com æˆ–ä½ è‡ªå»ºçš„å®ä¾‹ï¼Œå¯ä»¥åœ¨ Langfuse ä¸­æŸ¥çœ‹å®Œæ•´é“¾è·¯ã€‚\n",
        "\n",
        "![å¤šæ¬¡ OpenAI è°ƒç”¨çš„è¿½è¸ªå›¾](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211159038.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HeMqTWgK4xL"
      },
      "source": [
        "## å®Œæ•´æ–¹æ¡ˆï¼šä¸ Langfuse SDK ååŒ\n",
        "\n",
        "`trace` æ˜¯ Langfuse çš„æ ¸å¿ƒå¯¹è±¡ï¼Œä½ å¯ä»¥ä¸ºå®ƒé™„åŠ ä¸°å¯Œçš„å…ƒæ•°æ®ã€‚è¯¦è§ [Python SDK æ–‡æ¡£](https://langfuse.com/docs/sdk/python#traces-1)ã€‚\n",
        "\n",
        "è‡ªå®šä¹‰ trace åå¯ä»¥å®ç°ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
        "- è‡ªå®šä¹‰åç§°ï¼Œç”¨æ¥åŒºåˆ†ä¸åŒç±»å‹çš„é“¾è·¯\n",
        "- ä»¥ç”¨æˆ·ä¸ºç²’åº¦çš„è¿½è¸ª\n",
        "- é€šè¿‡ç‰ˆæœ¬ä¸å‘å¸ƒä¿¡æ¯è¿›è¡Œå®éªŒç®¡ç†\n",
        "- ä¿å­˜è‡ªå®šä¹‰å…ƒæ•°æ®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28to65wpK4xL",
        "outputId": "6eec4e7c-b210-4690-a50d-ed9909f46e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åœ¨ä¸‡é‡Œé•¿åŸçš„è‡‚å¼¯é—´ï¼Œ  \n",
            "åŒ—å¹³å¤éƒ½ä»Šæ­£ç¹å¿™ã€‚  \n",
            "æ•…å®«ç‰ç’ƒè¾‰æ˜ æœéœï¼Œ  \n",
            "é•¿å®‰è¡—å¤´äººæ½®æ¶Œè¡ã€‚  \n",
            "\n",
            "æ›¾é—»èƒ­è„‚è½¦é©¬å–§é—¹ï¼Œ  \n",
            "å¦‚ä»Šé«˜æ¥¼æ¥å¤©å¦‚å½±ã€‚  \n",
            "èƒ¡åŒæ·±å··æ‰¿è½½æ—§æ¢¦ï¼Œ  \n",
            "CBDå†…éœ“è™¹äº¤æ˜ ã€‚  \n",
            "\n",
            "æ—¶å…‰åœ¨å››åˆé™¢ä¸­æµæ·Œï¼Œ  \n",
            "äº¬è…”èƒ¡åŒè¯‰è¯´å†å²ã€‚  \n",
            "é¦™å±±çº¢å¶å¿†å¾€äº‹ï¼Œ  \n",
            "ä¸œå•è¥¿å•å±•æ–°è²Œã€‚  \n",
            "\n",
            "è²èŠ±æ± ç•”å¯»ä¸€ä¸å®é™ï¼Œ  \n",
            "å¤©å›ç¥ˆç¦è¿æ¥æœæš®ã€‚  \n",
            "åœ¨è¿™å¤è€è€Œåˆç°ä»£çš„åŸï¼Œ  \n",
            "å²æœˆå¦‚æ­Œï¼Œé“­åˆ»æ°¸æ’ã€‚  \n"
          ]
        }
      ],
      "source": [
        "from langfuse.openai import openai\n",
        "from langfuse import observe, get_client\n",
        "\n",
        "langfuse = get_client()  # è·å–åº•å±‚ Langfuse å®¢æˆ·ç«¯ï¼Œå¯åœ¨è£…é¥°å™¨ä¹‹å¤–æ‰‹åŠ¨æ“ä½œ trace\n",
        "\n",
        "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
        "def main(country: str, user_id: str, **kwargs) -> str:\n",
        "    # åµŒå¥—è°ƒç”¨ 1ï¼šè·å–å›½å®¶é¦–éƒ½\n",
        "    capital = openai.chat.completions.create(\n",
        "      name=\"geography-teacher\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"æ‚¨æ˜¯ä¸€ä½åœ°ç†è€å¸ˆï¼Œå¸®åŠ©å­¦ç”Ÿå­¦ä¹ å›½å®¶çš„é¦–éƒ½ã€‚å½“è¢«é—®åŠæ—¶ï¼Œåªè¾“å‡ºé¦–éƒ½ã€‚\"},\n",
        "          {\"role\": \"user\", \"content\": country}],\n",
        "      temperature=0,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # åµŒå¥—è°ƒç”¨ 2ï¼šæ ¹æ®é¦–éƒ½ç”Ÿæˆè¯—æ­Œ\n",
        "    poem = openai.chat.completions.create(\n",
        "      name=\"poet\",\n",
        "      model=\"gpt-4o\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½è¯—äººã€‚åˆ›ä½œä¸€é¦–å…³äºåŸå¸‚çš„è¯—ã€‚\"},\n",
        "          {\"role\": \"user\", \"content\": capital}],\n",
        "      temperature=1,\n",
        "      max_tokens=200,\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # æ‰‹åŠ¨æ›´æ–°å½“å‰ trace çš„å±æ€§ï¼Œè®©ä»ªè¡¨ç›˜ä¿¡æ¯æ›´å®Œæ•´\n",
        "    langfuse.update_current_trace(\n",
        "        name=\"City poem generator\",  # è‡ªå®šä¹‰ trace åç§°\n",
        "        session_id=\"1234\",  # ä¸šåŠ¡ä¼šè¯ ID\n",
        "        user_id=user_id,  # ä¸šåŠ¡ç”¨æˆ· ID\n",
        "        tags=[\"tag1\", \"tag2\"],  # æ ‡ç­¾ï¼Œæ”¯æŒåœ¨ Langfuse ä¸­æœç´¢\n",
        "        public=True,  # æ˜¯å¦å…è®¸åˆ†äº« Trace é“¾æ¥\n",
        "        metadata = {\"env\": \"development\"}  # è‡ªå®šä¹‰å…ƒæ•°æ®ï¼Œä¾‹å¦‚ç¯å¢ƒæ ‡è®°\n",
        "    )\n",
        "\n",
        "    return poem\n",
        "\n",
        "# create_trace_id() ä¼šç”Ÿæˆä¸€ä¸ªå¯å¤ç”¨çš„è¿½è¸ª IDï¼Œä½ ä¹Ÿå¯ä»¥æ”¹ä¸ºè‡ªå·±çš„ä¸šåŠ¡ ID\n",
        "trace_id = langfuse.create_trace_id()\n",
        "\n",
        "# é€šè¿‡å…³é”®å­—å‚æ•° `langfuse_observation_id` å°† trace_id ä¼ é€’ç»™è£…é¥°å™¨ï¼Œæ–¹ä¾¿ä¸²è”ä¸Šä¸‹æ¸¸è°ƒç”¨\n",
        "print(main(\"åŒ—äº¬\", \"admin\", langfuse_observation_id=trace_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u5n_RUic4nb"
      },
      "source": [
        "ç¤ºä¾‹ï¼š\n",
        "![image-20250921120555385](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211205931.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3jxed-VrPPi"
      },
      "source": [
        "## ä»¥ç¼–ç¨‹æ–¹å¼æ·»åŠ è¯„åˆ†\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMO6tn53rPPi"
      },
      "source": [
        "ä½ å¯ä»¥å‘ trace æ·»åŠ  [è¯„åˆ†](https://langfuse.com/docs/scores)ï¼Œè®°å½•ç”¨æˆ·åé¦ˆæˆ–è‡ªåŠ¨åŒ–è¯„ä¼°ç»“æœã€‚è¯„åˆ†å¯ç”¨äºåœ¨ Langfuse ä¸­ç­›é€‰è¿½è¸ªï¼Œå¹¶ä¼šæ˜¾ç¤ºåœ¨æ§åˆ¶å°ä¸­ã€‚è¯¦è§è¯„åˆ†æ–‡æ¡£ã€‚\n",
        "\n",
        "è¯„åˆ†é€šè¿‡ `trace_id` ä¸å¯¹åº”çš„ trace å…³è”ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0argbJhrPPi"
      },
      "outputs": [],
      "source": [
        "from langfuse import observe, get_client\n",
        "\n",
        "langfuse = get_client()  # è·å–åº•å±‚å®¢æˆ·ç«¯ï¼Œç”¨äºä¸»æµç¨‹ä¹‹å¤–çš„æ“ä½œ\n",
        "\n",
        "@observe()  # è£…é¥°å™¨ä¼šè‡ªåŠ¨åˆ›å»º trace å¹¶åµŒå¥—å„æ¬¡ç”Ÿæˆ\n",
        "def main():\n",
        "    # åœ¨è£…é¥°å™¨å†…éƒ¨ï¼Œå¯éšæ—¶è·å–å½“å‰ trace çš„ ID\n",
        "    trace_id = langfuse.get_current_trace_id()\n",
        "\n",
        "    # TODO: åœ¨æ­¤å¤„ç¼–å†™ä½ çš„ä¸šåŠ¡é€»è¾‘ï¼Œä¾‹å¦‚ç»§ç»­è°ƒç”¨å…¶ä»– APIã€å¤„ç†ç”¨æˆ·è¾“å…¥ç­‰\n",
        "\n",
        "    return \"res\", trace_id\n",
        "\n",
        "# æ‰§è¡Œè¢«è£…é¥°çš„å‡½æ•°ï¼ŒLangfuse ä¼šç”Ÿæˆ trace\n",
        "_, trace_id = main()\n",
        "\n",
        "# åœ¨ trace ä¸Šä¸‹æ–‡å¤–éƒ¨ä¹Ÿå¯ä»¥ç»§ç»­æ“ä½œï¼Œä¾‹å¦‚å‘è¿™æ¬¡ trace æ·»åŠ è¯„åˆ†\n",
        "langfuse.create_score(\n",
        "    trace_id=trace_id,  # æŒ‡å®šè¦æ‰“åˆ†çš„ trace\n",
        "    name=\"my-score-name\",  # è¯„åˆ†åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒæŒ‡æ ‡\n",
        "    value=1  # åˆ†å€¼ï¼Œå¯ä»¥æ˜¯å¸ƒå°”ã€æ•´æ•°ã€æµ®ç‚¹æ•°ï¼Œè§†ä¸šåŠ¡åœºæ™¯è€Œå®š\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp899q3edni6"
      },
      "source": [
        "ç¤ºä¾‹ï¼š![image-20250921120901924](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509211209271.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz7LxE7-1XSK"
      },
      "source": [
        "## ğŸ”§ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
        "\n",
        "### é—®é¢˜1ï¼šæ— æ³•è¿æ¥åˆ°OpenAI API\n",
        "\n",
        "**ç—‡çŠ¶ï¼š**\n",
        "```\n",
        "openai.APIError: Connection error\n",
        "```\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n",
        "2. ç¡®è®¤APIå¯†é’¥æ­£ç¡®\n",
        "3. æ£€æŸ¥OPENAI_BASE_URLè®¾ç½®ï¼ˆå¦‚æœä½¿ç”¨ä»£ç†ï¼‰\n",
        "4. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®\n",
        "\n",
        "### é—®é¢˜2ï¼šLangfuseè¿æ¥å¤±è´¥\n",
        "\n",
        "**ç—‡çŠ¶ï¼š**\n",
        "```\n",
        "langfuse.LangfuseConnectionError\n",
        "```\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "1. ç¡®è®¤LANGFUSE_PUBLIC_KEYå’ŒLANGFUSE_SECRET_KEYæ­£ç¡®\n",
        "2. æ£€æŸ¥LANGFUSE_HOSTåœ°å€\n",
        "3. ç¡®è®¤ç½‘ç»œå¯ä»¥è®¿é—®LangfuseæœåŠ¡å™¨\n",
        "4. æ£€æŸ¥è´¦æˆ·æ˜¯å¦æœ‰æ•ˆ\n",
        "\n",
        "### é—®é¢˜3ï¼šTokenä½¿ç”¨é‡è¿‡é«˜\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "1. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚gpt-3.5-turboï¼‰\n",
        "2. å‡å°‘prompté•¿åº¦\n",
        "3. è®¾ç½®max_tokensé™åˆ¶è¾“å‡ºé•¿åº¦\n",
        "4. åœ¨Langfuseä¸­ç›‘æ§ä½¿ç”¨é‡\n",
        "\n",
        "### é—®é¢˜4ï¼šå“åº”é€Ÿåº¦æ…¢\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "1. ä½¿ç”¨å¼‚æ­¥è°ƒç”¨å¤„ç†å¤§é‡è¯·æ±‚\n",
        "2. é€‰æ‹©æ›´å¿«çš„æ¨¡å‹\n",
        "3. å‡å°‘promptå¤æ‚åº¦\n",
        "4. ä½¿ç”¨æµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ\n",
        "\n",
        "### é—®é¢˜5ï¼šæ‰¾ä¸åˆ°è¿½è¸ªè®°å½•\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼š**\n",
        "1. ç¡®è®¤APIè°ƒç”¨æˆåŠŸæ‰§è¡Œ\n",
        "2. æ£€æŸ¥Langfuseé…ç½®æ˜¯å¦æ­£ç¡®\n",
        "3. ç­‰å¾…å‡ åˆ†é’Ÿï¼ˆæ•°æ®åŒæ­¥å¯èƒ½æœ‰å»¶è¿Ÿï¼‰\n",
        "4. åœ¨Langfuseæ§åˆ¶å°ä½¿ç”¨nameå­—æ®µæœç´¢\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YckyL3hr1XSK"
      },
      "source": [
        "## ğŸŒŸ ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ\n",
        "\n",
        "### 1. å®‰å…¨æ€§\n",
        "\n",
        "**ä¿æŠ¤APIå¯†é’¥ï¼š**\n",
        "- âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨å¯†é’¥\n",
        "- âœ… ä½¿ç”¨.envæ–‡ä»¶ï¼ˆä¸è¦æäº¤åˆ°Gitï¼‰\n",
        "- âœ… å®šæœŸè½®æ¢APIå¯†é’¥\n",
        "- âŒ æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥\n",
        "\n",
        "**ç¤ºä¾‹.envæ–‡ä»¶ï¼š**\n",
        "```bash\n",
        "OPENAI_API_KEY=sk-your-openai-key\n",
        "LANGFUSE_PUBLIC_KEY=pk-your-langfuse-public-key\n",
        "LANGFUSE_SECRET_KEY=sk-your-langfuse-secret-key\n",
        "LANGFUSE_HOST=https://cloud.langfuse.com\n",
        "```\n",
        "\n",
        "### 2. æ€§èƒ½ä¼˜åŒ–\n",
        "\n",
        "**å‡å°‘æˆæœ¬ï¼š**\n",
        "- é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼ˆä¸æ€»æ˜¯æœ€å¤§çš„ï¼‰\n",
        "- è®¾ç½®max_tokensé™åˆ¶\n",
        "- ç¼“å­˜é‡å¤çš„è¯·æ±‚ç»“æœ\n",
        "- ä½¿ç”¨æ‰¹å¤„ç†å¤„ç†å¤§é‡æ•°æ®\n",
        "\n",
        "**æå‡é€Ÿåº¦ï¼š**\n",
        "- ä½¿ç”¨å¼‚æ­¥è°ƒç”¨\n",
        "- å¯ç”¨æµå¼è¾“å‡º\n",
        "- åˆç†è®¾ç½®timeoutå‚æ•°\n",
        "\n",
        "### 3. é”™è¯¯å¤„ç†\n",
        "\n",
        "```python\n",
        "import openai\n",
        "from langfuse.openai import openai as langfuse_openai\n",
        "import time\n",
        "\n",
        "def robust_api_call(messages, max_retries=3):\n",
        "    \"\"\"\n",
        "    å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨\n",
        "    \"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = langfuse_openai.chat.completions.create(\n",
        "                name=f\"robust-call-attempt-{attempt + 1}\",\n",
        "                model=\"gpt-4o\",\n",
        "                messages=messages,\n",
        "                timeout=30  # 30ç§’è¶…æ—¶\n",
        "            )\n",
        "            return response\n",
        "        except openai.RateLimitError:\n",
        "            # é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•\n",
        "            wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿\n",
        "            print(f\"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...\")\n",
        "            time.sleep(wait_time)\n",
        "        except openai.APIError as e:\n",
        "            print(f\"APIé”™è¯¯: {e}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                raise\n",
        "    \n",
        "    raise Exception(\"é‡è¯•æ¬¡æ•°ç”¨å°½\")\n",
        "```\n",
        "\n",
        "### 4. ç›‘æ§å’Œè¿½è¸ª\n",
        "\n",
        "**åœ¨Langfuseä¸­è®¾ç½®ï¼š**\n",
        "- ä½¿ç”¨æœ‰æ„ä¹‰çš„nameå­—æ®µ\n",
        "- æ·»åŠ è¯¦ç»†çš„metadata\n",
        "- è®¾ç½®ç”¨æˆ·IDå’Œä¼šè¯ID\n",
        "- ä½¿ç”¨æ ‡ç­¾åˆ†ç±»ä¸åŒç±»å‹çš„è¯·æ±‚\n",
        "\n",
        "**ç¤ºä¾‹ï¼š**\n",
        "```python\n",
        "response = openai.chat.completions.create(\n",
        "    name=\"production-chat-v1.0\",\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    metadata={\n",
        "        \"environment\": \"production\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"feature\": \"customer_support\",\n",
        "        \"user_type\": \"premium\"\n",
        "    }\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "### 5. æµ‹è¯•ç­–ç•¥\n",
        "\n",
        "**å•å…ƒæµ‹è¯•ï¼š**\n",
        "- Mock OpenAI APIè°ƒç”¨\n",
        "- æµ‹è¯•é”™è¯¯å¤„ç†é€»è¾‘\n",
        "- éªŒè¯è¾“å…¥è¾“å‡ºæ ¼å¼\n",
        "\n",
        "**é›†æˆæµ‹è¯•ï¼š**\n",
        "- ä½¿ç”¨æµ‹è¯•APIå¯†é’¥\n",
        "- éªŒè¯Langfuseè¿½è¸ª\n",
        "- æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHVuMzDl2RWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}