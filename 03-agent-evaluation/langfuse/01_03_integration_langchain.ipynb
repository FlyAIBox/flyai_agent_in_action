{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {},
   "source": [
    "# 🔧 环境配置和检查\n",
    "\n",
    "## 概述\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助您：\n",
    "- 使用统一的conda环境\n",
    "- 通过国内镜像源快速安装依赖\n",
    "- 加速模型下载\n",
    "- 检查系统配置\n",
    "\n",
    "## 配置步骤\n",
    "1. **Conda环境管理** - 激活统一的学习环境\n",
    "2. **包管理器优化** - 配置pip使用清华镜像源\n",
    "3. **模型下载加速** - 设置HuggingFace镜像代理\n",
    "4. **系统环境诊断** - 检查硬件和软件配置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 激活conda环境\n",
    "%%script bash\n",
    "# 初始化 conda\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "conda env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助您：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_integration_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlceIPalN3QR"
   },
   "source": [
    "# Langfuse集成LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pre-knowledge"
   },
   "source": [
    "## 📚 前置知识导读\n",
    "\n",
    "在开始学习 LangChain 与 Langfuse 的集成之前，让我们先了解一些基础概念：\n",
    "\n",
    "### 🤖 LangChain 是什么？\n",
    "- **定义**：LangChain 是一个用于构建大语言模型（LLM）应用的开发框架\n",
    "- **作用**：帮助开发者将 LLM 与外部数据源、工具、数据库等连接起来\n",
    "- **核心概念**：Chain（链）、Agent（智能体）、Tool（工具）、Memory（记忆）等\n",
    "\n",
    "### 📊 Langfuse 是什么？\n",
    "- **定义**：Langfuse 是一个专门为大语言模型应用设计的可观测性（Observability）平台\n",
    "- **作用**：帮助开发者监控、调试和优化 LLM 应用的性能\n",
    "- **核心功能**：追踪（Tracing）、评估（Evaluation）、监控（Monitoring）\n",
    "\n",
    "### 🔗 两者如何协同工作？\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[你的应用] --> B[LangChain]\n",
    "    B --> C[LLM/工具/数据]\n",
    "    B --> D[Langfuse]\n",
    "    D --> E[性能监控]\n",
    "    D --> F[调试分析]\n",
    "    D --> G[成本追踪]\n",
    "```\n",
    "\n",
    "### 🎯 学习目标\n",
    "通过本教程，你将学会：\n",
    "1. 如何在 LangChain 应用中集成 Langfuse\n",
    "2. 如何追踪和监控 LLM 调用链\n",
    "3. 如何分析应用性能和成本\n",
    "4. 如何调试和优化 LLM 应用\n",
    "\n",
    "---\n",
    "**💡 提示**：如果你对 LangChain 或 Langfuse 还不太熟悉，建议先阅读官方文档了解基础概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqBspBzuRk9C"
   },
   "source": [
    "# 示例：LangChain 集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1oaA7XYGOfX"
   },
   "source": [
    "请按照[集成指南](https://langfuse.com/integrations/frameworks/langchain)将该集成添加到你的 LangChain 项目中。该集成也支持 LangChain JS。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbSpd5EiZouE"
   },
   "source": [
    "## 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YNyU6IzCZouE",
    "outputId": "43cdd016-2e5d-4938-aa39-a6b1729a7e12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langfuse==3.3.0\n",
      "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Collecting langchain-openai==0.3.31\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain_community==0.3.27\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.27)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: opentelemetry-proto, mypy-extensions, marshmallow, backoff, typing-inspect, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langchain-openai, langfuse, langchain_community\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.36.0\n",
      "    Uninstalling opentelemetry-api-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.36.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.36.0\n",
      "    Uninstalling opentelemetry-sdk-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
      "Successfully installed backoff-2.2.1 dataclasses-json-0.6.7 langchain-openai-0.3.31 langchain_community-0.3.27 langfuse-3.3.0 marshmallow-3.26.1 mypy-extensions-1.1.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# 📦 安装必要的 Python 包\n",
    "#\n",
    "# 📚 包功能说明：\n",
    "# - langfuse: Langfuse 客户端库，专门用于大语言模型应用的监控、追踪和评估\n",
    "# - langchain: LangChain 核心框架，提供构建复杂 LLM 应用的基础组件\n",
    "# - langchain-openai: LangChain 的 OpenAI 官方集成包，支持 GPT 系列模型\n",
    "# - langchain_community: LangChain 社区维护的扩展组件，包含各种工具和集成\n",
    "\n",
    "#\n",
    "# 🔧 安装命令（根据需求选择）：\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpE57ujJZouE"
   },
   "source": [
    "在 Langfuse 控制台的项目设置页获取 API Key，初始化 Langfuse 客户端，并将其设置到环境变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dEdF-668ZouF",
    "outputId": "25252224-1bd7-45a9-f381-df623b9ebbfc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: ··········\n",
      "OPENAI_BASE_URL: ··········\n",
      "LANGFUSE_PUBLIC_KEY: ··········\n",
      "LANGFUSE_SECRET_KEY: ··········\n",
      "LANGFUSE_HOST: ··········\n"
     ]
    }
   ],
   "source": [
    "# 🔐 环境变量配置 - 安全存储敏感信息\n",
    "# 环境变量是存储API密钥等敏感信息的最佳实践\n",
    "# 避免在代码中硬编码密钥，防止泄露\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    安全地设置环境变量\n",
    "    如果环境变量不存在，会提示用户输入\n",
    "    使用getpass模块隐藏输入内容，防止密码泄露\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# 🤖 OpenAI API 配置\n",
    "# OpenAI API密钥：从 https://platform.openai.com/api-keys 获取\n",
    "# 这是调用GPT模型必需的认证信息\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API代理地址：如果你使用第三方代理服务（如国内代理）\n",
    "# 示例：https://api.apiyi.com/v1\n",
    "# 如果直接使用OpenAI官方API，可以留空\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 🌐 Langfuse 配置\n",
    "# Langfuse是一个可观测性平台，需要注册账户获取密钥\n",
    "# 注册地址：https://cloud.langfuse.com\n",
    "\n",
    "# 公开密钥：用于标识你的项目\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# 秘密密钥：用于认证，请妥善保管\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# 服务器地址：选择离你最近的区域\n",
    "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
    "# 🇺🇸 美国区域（不推荐） https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# 💡 初学者提示：\n",
    "# 1. 环境变量存储在操作系统中，重启后需要重新设置\n",
    "# 2. 生产环境中建议使用.env文件或云服务配置\n",
    "# 3. 永远不要在代码中硬编码API密钥！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "divRadPqZouF"
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 初始化 Langfuse 回调处理器\n",
    "# 这个处理器会自动捕获 LangChain 的执行过程，包括：\n",
    "# - LLM 调用的输入和输出\n",
    "# - 执行时间和延迟\n",
    "# - 错误信息（如果有）\n",
    "# - 成本信息（token 使用量）\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# 💡 提示：这个回调处理器将在后续的 LangChain 调用中使用\n",
    "# 通过 config={\"callbacks\": [langfuse_handler]} 参数传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZXRf2FZXEXV"
   },
   "source": [
    "## 示例\n",
    "### LangChain LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3-HEia6gNoAr"
   },
   "outputs": [],
   "source": [
    "# 🔧 导入 LangChain 核心组件\n",
    "from operator import itemgetter  # Python 内置函数，用于从字典中提取特定键值对\n",
    "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型接口，支持 GPT 系列模型\n",
    "from langchain.prompts import ChatPromptTemplate  # 聊天提示模板，用于格式化对话输入\n",
    "from langchain.schema import StrOutputParser  # 字符串输出解析器，将模型输出转换为字符串\n",
    "\n",
    "# 🔄 重新初始化 Langfuse 回调处理器\n",
    "# 确保追踪功能正常工作，记录整个链式执行过程\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# 📝 第一个提示模板：人物地理信息查询\n",
    "# 功能：根据人物姓名查询其来源城市\n",
    "# 输入变量：{person} - 人物姓名\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{person} 来自哪座城市？\")\n",
    "\n",
    "# 📝 第二个提示模板：城市国家映射查询\n",
    "# 功能：根据城市名称查询所属国家，并指定回答语言\n",
    "# 输入变量：{city} - 城市名称，{language} - 回答语言\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"城市 {city} 位于哪个国家？请用 {language} 回答\"\n",
    ")\n",
    "\n",
    "# 🤖 初始化 OpenAI 聊天模型\n",
    "# 默认使用 gpt-3.5-turbo 模型，可根据需要调整\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# ⛓️ 构建第一个处理链（简单链）\n",
    "# 数据流：人名 → 提示模板 → 模型推理 → 字符串输出\n",
    "# 作用：将人物姓名转换为城市名称\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "# ⛓️ 构建第二个处理链（复合链）\n",
    "# 数据流：\n",
    "# 1. 🔀 并行处理：通过 chain1 获取城市名，通过 itemgetter 提取语言参数\n",
    "# 2. 📋 数据整合：将城市和语言组合为字典格式\n",
    "# 3. 📝 提示生成：将数据传递给 prompt2 生成查询提示\n",
    "# 4. 🤖 模型推理：调用 OpenAI 模型进行推理\n",
    "# 5. 🔤 结果解析：将模型输出解析为最终字符串\n",
    "chain2 = (\n",
    "    {\"city\": chain1, \"language\": itemgetter(\"language\")}  # 🔀 并行数据准备\n",
    "    | prompt2    # 📝 第二阶段提示生成\n",
    "    | model      # 🤖 模型推理调用\n",
    "    | StrOutputParser()  # 🔤 输出格式化\n",
    ")\n",
    "\n",
    "# 🚀 执行链式调用并启用 Langfuse 追踪\n",
    "# 示例1：查询苏东坡的地理信息，要求用中文回答\n",
    "# 预期流程：苏东坡 → 眉山/杭州 → 中国，用中文回答\n",
    "result = chain2.invoke(\n",
    "    {\"person\": \"苏东坡\", \"language\": \"中文\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwFVrw-WVtY0"
   },
   "source": [
    "### LangChain LCEL 的追踪图\n",
    "\n",
    "![LangChain LCEL 的跟踪图](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508261521543.png)\n",
    "\n",
    "[Langfuse 中的示例追踪](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=9ec09bc81b4173edf6e3d11d24d0cf2f&timestamp=2025-08-26T07%3A11%3A54.389Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlBSpILFXEXV"
   },
   "source": [
    "#### LangChain Runnable 方法\n",
    "\n",
    "Runnable 是可以被调用、批处理、流式处理、转换并进行组合的工作单元。\n",
    "\n",
    "下面的示例展示了如何在 Langfuse 中使用这些方法：\n",
    "\n",
    "- invoke/ainvoke：将单个输入转换为输出。\n",
    "- batch/abatch：高效地将多个输入批量转换为输出。\n",
    "- stream/astream：在生成过程中以流式方式输出单个输入的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8N8pybGXEXV",
    "outputId": "b41d6ca3-b46f-4598-c021-ec21fcc3dbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流式分片: \n",
      "流式分片: The\n",
      "流式分片:  city\n",
      "流式分片:  of\n",
      "流式分片:  San\n",
      "流式分片:  Francisco\n",
      "流式分片: ,\n",
      "流式分片:  California\n",
      "流式分片: ,\n",
      "流式分片:  where\n",
      "流式分片:  Steve\n",
      "流式分片:  Jobs\n",
      "流式分片:  is\n",
      "流式分片:  from\n",
      "流式分片: ,\n",
      "流式分片:  is\n",
      "流式分片:  located\n",
      "流式分片:  in\n",
      "流式分片:  the\n",
      "流式分片:  United\n",
      "流式分片:  States\n",
      "流式分片: .\n",
      "流式分片: \n",
      "流式分片: \n",
      "异步流式分片: \n",
      "异步流式分片: The\n",
      "异步流式分片:  city\n",
      "异步流式分片:  Seattle\n",
      "异步流式分片: ,\n",
      "异步流式分片:  where\n",
      "异步流式分片:  Bill\n",
      "异步流式分片:  Gates\n",
      "异步流式分片:  comes\n",
      "异步流式分片:  from\n",
      "异步流式分片: ,\n",
      "异步流式分片:  is\n",
      "异步流式分片:  located\n",
      "异步流式分片:  in\n",
      "异步流式分片:  the\n",
      "异步流式分片:  United\n",
      "异步流式分片:  States\n",
      "异步流式分片: .\n",
      "异步流式分片: \n",
      "异步流式分片: \n"
     ]
    }
   ],
   "source": [
    "# 🔄 异步调用（Async Invoke）\n",
    "# 🎯 适用场景：\n",
    "#   - 需要在异步环境（如 FastAPI、Django Async）中执行单个请求\n",
    "#   - 与其他异步操作（数据库查询、API调用）并行执行\n",
    "# 💡 技术优势：\n",
    "#   - 不会阻塞其他异步操作，提高整体应用吞吐量\n",
    "#   - 支持 asyncio 事件循环，适合现代异步 Web 应用\n",
    "await chain2.ainvoke(\n",
    "    {\"person\": \"biden\", \"language\": \"german\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "# 📦 批处理（Batch）\n",
    "# 🎯 适用场景：\n",
    "#   - 需要同时处理多个相似的请求（如批量数据处理）\n",
    "#   - 数据分析、报告生成等需要并行处理的任务\n",
    "# 💡 技术优势：\n",
    "#   - 比逐个调用更高效，可以并行处理多个请求\n",
    "#   - 减少网络开销，优化资源利用率\n",
    "batch_results = chain2.batch([\n",
    "    {\"person\": \"elon musk\", \"language\": \"english\"},\n",
    "    {\"person\": \"mark zuckerberg\", \"language\": \"english\"}\n",
    "], config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# 🔄📦 异步批处理（Async Batch）\n",
    "# 🎯 适用场景：\n",
    "#   - 在异步环境中批量处理请求\n",
    "#   - 高并发场景下的批量数据处理\n",
    "# 💡 技术优势：\n",
    "#   - 结合了异步和批处理的优点\n",
    "#   - 支持更高的并发量，不阻塞主线程\n",
    "batch_async_results = await chain2.abatch([\n",
    "    {\"person\": \"jeff bezos\", \"language\": \"english\"},\n",
    "    {\"person\": \"tim cook\", \"language\": \"english\"}\n",
    "], config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# 🌊 流式处理（Stream）\n",
    "# 🎯 适用场景：\n",
    "#   - 需要实时显示生成过程的聊天应用\n",
    "#   - 长文本生成，提升用户体验\n",
    "#   - 实时翻译、摘要等需要逐步展示结果的应用\n",
    "# 💡 技术优势：\n",
    "#   - 用户可以立即看到部分结果，无需等待完整响应\n",
    "#   - 降低感知延迟，提升用户体验\n",
    "#   - 支持实时取消和中断操作\n",
    "print(\"🌊 流式处理示例：\")\n",
    "for chunk in chain2.stream(\n",
    "    {\"person\": \"steve jobs\", \"language\": \"english\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"📤 流式分片: {chunk}\")  # 每个分片会实时输出\n",
    "    # 在实际应用中，这里可以将 chunk 发送到前端实时显示\n",
    "\n",
    "# 🔄🌊 异步流式处理（Async Stream）\n",
    "# 🎯 适用场景：\n",
    "#   - 在异步 Web 应用中提供流式响应\n",
    "#   - WebSocket 实时通信\n",
    "#   - 服务器发送事件（Server-Sent Events）\n",
    "# 💡 技术优势：\n",
    "#   - 不阻塞其他异步操作，同时提供实时反馈\n",
    "#   - 支持异步上下文管理，资源利用更高效\n",
    "print(\"\\n🔄🌊 异步流式处理示例：\")\n",
    "async for chunk in chain2.astream(\n",
    "    {\"person\": \"bill gates\", \"language\": \"english\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"📤 异步流式分片: {chunk}\")  # 异步接收每个分片\n",
    "    # 在实际应用中，可以通过 WebSocket 或 SSE 发送到客户端\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvRWPsZ-NoAr"
   },
   "source": [
    "### LangChain LCEL 的跟踪图\n",
    "\n",
    "![LangChain LCEL 的跟踪图](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508261521543.png)\n",
    "\n",
    "[Langfuse 中的示例追踪](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=9ec09bc81b4173edf6e3d11d24d0cf2f&timestamp=2025-08-26T07%3A11%3A54.389Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP5avhNb3TBH"
   },
   "source": [
    "### Langfuse中的LangChain检索式问答跟踪（RetrievalQA）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wjiWEkRUFzCf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 设置 SerpAPI 密钥（用于网络搜索功能）\n",
    "# 💡 提示：如果不使用搜索功能，可以跳过这个设置\n",
    "# 获取免费 API 密钥：https://serpapi.com/\n",
    "_set_env(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "p0CgEPSlEpkC",
    "outputId": "bf5e0b36-6d2e-4df2-e220-7db3bbad10a1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting unstructured==0.18.13\n",
      "  Downloading unstructured-0.18.13-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting selenium==4.35.0\n",
      "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain-chroma==0.2.5\n",
      "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (3.4.3)\n",
      "Collecting filetype (from unstructured==0.18.13)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured==0.18.13)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (5.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (3.9.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.13.5)\n",
      "Collecting emoji (from unstructured==0.18.13)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured==0.18.13)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured==0.18.13)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.0.2)\n",
      "Collecting rapidfuzz (from unstructured==0.18.13)\n",
      "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.15.0)\n",
      "Collecting unstructured-client (from unstructured==0.18.13)\n",
      "  Downloading unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (1.17.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (5.9.5)\n",
      "Collecting python-oxmsg (from unstructured==0.18.13)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (1.1)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium==4.35.0) (2.5.0)\n",
      "Collecting trio~=0.30.0 (from selenium==4.35.0)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium==4.35.0)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium==4.35.0) (2025.8.3)\n",
      "Collecting typing-extensions (from unstructured==0.18.13)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium==4.35.0) (1.8.0)\n",
      "Requirement already satisfied: langchain-core>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma==0.2.5) (0.3.75)\n",
      "Collecting chromadb>=1.0.9 (from langchain-chroma==0.2.5)\n",
      "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.22.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.17.4)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (4.25.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (0.4.27)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (25.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (3.10)\n",
      "Collecting outcome (from trio~=0.30.0->selenium==4.35.0)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium==4.35.0)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium==4.35.0) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->unstructured==0.18.13) (2.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured==0.18.13) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured==0.18.13) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured==0.18.13) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured==0.18.13) (0.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured==0.18.13)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (43.0.3)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (1.0.9)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured==0.18.13)\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (1.0.0)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.1->unstructured-client->unstructured==0.18.13) (2.0.0)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client->unstructured==0.18.13) (0.16.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.10.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.70->langchain-chroma==0.2.5) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.38.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma==0.2.5) (0.24.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.58b0)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.34.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured==0.18.13) (1.1.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (15.0.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured==0.18.13) (2.23)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.1.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.6.1)\n",
      "Downloading unstructured-0.18.13-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
      "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m651.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect, pypika\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=8caff184c0eb14a8abeca03862001f30107f96e21b9a2b0ad693a9fd94202111\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=44052dc57bf038c3e7db15b7ef97b17daf2347da3633a4fe08d1d5d2541cf0cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built langdetect pypika\n",
      "Installing collected packages: pypika, filetype, durationpy, wsproto, uvloop, typing-extensions, rapidfuzz, python-magic, python-iso639, pypdf, pybase64, outcome, olefile, mmh3, langdetect, humanfriendly, httptools, emoji, bcrypt, trio, python-oxmsg, posthog, coloredlogs, watchfiles, trio-websocket, onnxruntime, kubernetes, unstructured-client, selenium, unstructured, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 emoji-2.15.0 filetype-1.2.0 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.2.5 langdetect-1.0.9 mmh3-5.2.0 olefile-0.47 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-grpc-1.37.0 outcome-1.3.0.post0 posthog-5.4.0 pybase64-1.4.2 pypdf-6.1.0 pypika-0.48.9 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.14.1 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing-extensions-4.14.1 unstructured-0.18.13 unstructured-client-0.42.3 uvloop-0.21.0 watchfiles-1.1.0 wsproto-1.2.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "opentelemetry"
        ]
       },
       "id": "389c66c14f0f458cb86e92b8cb43d019"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 安装检索式问答所需的额外依赖包\n",
    "# unstructured: 用于处理各种文档格式（PDF、Word、HTML等）\n",
    "# selenium: 用于网页内容抓取和动态页面处理\n",
    "# langchain-chroma: 向量数据库，用于存储和检索文档嵌入\n",
    "%pip install unstructured==0.18.13 selenium==4.35.0 langchain-chroma==0.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHDVa-Ssb-KT",
    "outputId": "8d6ee6ef-a534-4a59-8829-7e44decf37bc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📊 成功加载 1 个文档\n",
      "📋 文档分割完成，共生成 41 个文本块\n",
      "🔍 【文档分割预览】\n",
      "  块 1: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and th...\n",
      "  块 2: Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers tur...\n",
      "🔄 正在构建向量数据库...\n",
      "✅ 向量数据库构建完成，包含 41 个向量\n",
      "🔍 开始执行检索式问答...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "💡 问题：美国国情咨文演讲稿的核心主题是什么？请总结主要观点。\n",
      "🎯 答案：美国国情咨文演讲稿的核心主题是美国人民的强大。演讲中强调了美国人民的坚定意志和团结一致，强调了自由和民主的重要性。演讲还提到了面对挑战时的乐观态度和对未来的信心，以及美国人民在历史上始终将危机转化为机遇的能力。总的来说，演讲强调了美国人民的力量和团结，以及他们在面对挑战时的决心和勇气。\n",
      "\n",
      "📚 参考来源（共 3 个文档块）：\n",
      "  📄 来源 1: And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "Now is the hour. \n",
      "Our moment of responsibility. \n",
      "Our test of re...\n",
      "  📄 来源 2: And my report is this: the State of the Union is strong—because you, the American people, are strong. \n",
      "We are stronger today than we were a year ago. ...\n",
      "  📄 来源 3: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fello...\n"
     ]
    }
   ],
   "source": [
    "# 🧩 导入检索式问答（RAG）所需的核心模块\n",
    "from langchain_community.document_loaders import SeleniumURLLoader  # 🌐 网页文档加载器，支持 JavaScript 渲染\n",
    "from langchain_chroma import Chroma  # 🗄️ Chroma 向量数据库，用于存储和检索嵌入向量\n",
    "from langchain_text_splitters import CharacterTextSplitter  # ✂️ 文本分割器，将长文档切分为小块\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # 🤖 OpenAI 嵌入模型和聊天模型\n",
    "from langchain.chains import RetrievalQA  # 🔗 检索式问答链，实现 RAG 功能\n",
    "\n",
    "# 🔄 初始化 Langfuse 回调处理器\n",
    "# 用于追踪整个 RAG 流程，包括文档检索和答案生成\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# 📄 定义要加载的文档 URL 列表\n",
    "# 💡 示例：美国国情咨文演讲稿（包含丰富的政治、经济、社会话题）\n",
    "# 这个文档非常适合展示 RAG 系统的检索和问答能力\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
    "]\n",
    "\n",
    "# 📥 步骤1：文档加载\n",
    "# SeleniumURLLoader 的优势：\n",
    "# - 能够处理需要 JavaScript 渲染的动态网页\n",
    "# - 支持复杂的页面结构和异步内容加载\n",
    "# - 比简单的 HTTP 请求更强大\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "\n",
    "# 🤖 步骤2：初始化语言模型\n",
    "# 选择 ChatOpenAI 的原因：\n",
    "# - 支持对话格式，更适合问答任务\n",
    "# - 与现代 OpenAI API 完全兼容\n",
    "# - 支持系统消息和角色设定\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)  # 低温度确保答案稳定性\n",
    "\n",
    "# 📖 步骤3：文档内容加载\n",
    "# 从指定 URL 获取文档内容并解析为 Document 对象\n",
    "documents = loader.load()\n",
    "print(f\"📊 成功加载 {len(documents)} 个文档\")\n",
    "\n",
    "# ✂️ 步骤4：文档分割策略\n",
    "# 🎯 分割参数说明：\n",
    "# - chunk_size=1000: 每个文本块包含约1000个字符（平衡检索精度和上下文完整性）\n",
    "# - chunk_overlap=0: 文本块间无重叠（避免重复信息，但可能丢失跨块语义）\n",
    "# 💡 优化建议：在生产环境中，可以设置 chunk_overlap=100-200 以保持语义连续性\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    separator=\"\\n\"  # 按段落分割，保持语义完整性\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"📋 文档分割完成，共生成 {len(texts)} 个文本块\")\n",
    "print(\"🔍 【文档分割预览】\")\n",
    "for i, text in enumerate(texts[:2]):  # 只显示前两个块作为示例\n",
    "    print(f\"  块 {i+1}: {text.page_content[:100]}...\")\n",
    "\n",
    "# 🔢 步骤5：创建文本嵌入向量\n",
    "# OpenAIEmbeddings 将文本转换为高维向量，用于语义相似性搜索\n",
    "# 💰 成本提示：嵌入生成会产生 API 调用费用，但通常比 GPT 调用便宜得多\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 使用较新的嵌入模型\n",
    "\n",
    "# 🗄️ 步骤6：构建向量数据库\n",
    "# Chroma 数据库的优势：\n",
    "# - 轻量级，适合快速原型开发\n",
    "# - 内存存储，启动快速\n",
    "# - 支持多种相似性搜索算法\n",
    "print(\"🔄 正在构建向量数据库...\")\n",
    "docsearch = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"state_of_union\"  # 指定集合名称便于管理\n",
    ")\n",
    "print(f\"✅ 向量数据库构建完成，包含 {docsearch._collection.count()} 个向量\")\n",
    "\n",
    "# ❓ 步骤7：定义查询问题\n",
    "# 设计一个开放性问题来测试 RAG 系统的理解和综合能力\n",
    "query = \"美国国情咨文演讲稿的核心主题是什么？请总结主要观点。\"\n",
    "\n",
    "# 🔗 步骤8：构建检索式问答链\n",
    "# RetrievalQA 工作流程：\n",
    "# 1. 将用户问题转换为嵌入向量\n",
    "# 2. 在向量数据库中检索最相关的文档块\n",
    "# 3. 将检索到的文档作为上下文，结合用户问题生成提示\n",
    "# 4. 调用语言模型生成最终答案\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" 模式：将所有检索到的文档拼接为一个提示\n",
    "    retriever=docsearch.as_retriever(\n",
    "        search_type=\"similarity\",  # 使用语义相似性搜索\n",
    "        search_kwargs={\"k\": 3}     # 检索最相关的 3 个文档块\n",
    "    ),\n",
    "    return_source_documents=True,  # 返回源文档，便于验证答案来源\n",
    "    verbose=True  # 显示详细的执行过程\n",
    ")\n",
    "\n",
    "# 🚀 步骤9：执行 RAG 问答并启用 Langfuse 追踪\n",
    "# 这将在 Langfuse 控制台中记录：\n",
    "# - 文档检索过程和结果\n",
    "# - 提示词生成\n",
    "# - 模型推理过程\n",
    "# - 最终答案生成\n",
    "print(\"🔍 开始执行检索式问答...\")\n",
    "result = chain.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "print(f\"\\n💡 问题：{query}\")\n",
    "print(f\"🎯 答案：{result['result']}\")\n",
    "print(f\"\\n📚 参考来源（共 {len(result['source_documents'])} 个文档块）：\")\n",
    "for i, doc in enumerate(result['source_documents']):\n",
    "    print(f\"  📄 来源 {i+1}: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "RetrievalQA 追踪图\n",
    "![image-20250922113340738](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221133205.png)\n",
    "[Langfuse 中的示例追踪](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=c1a402f423a8b848f07461edba960bfa&timestamp=2025-09-22T03%3A26%3A02.600Z)"
   ],
   "metadata": {
    "id": "Cz2tu3EAev-V"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-next-steps"
   },
   "source": [
    "## 🎉 总结与下一步学习\n",
    "\n",
    "恭喜！你已经完成了 LangChain 与 Langfuse 集成的基础学习。让我们回顾一下学到的内容：\n",
    "\n",
    "### 📋 本教程涵盖的内容\n",
    "- ✅ **环境准备**：安装依赖、配置 API 密钥、初始化回调处理器\n",
    "- ✅ **基础集成**：在 LangChain 应用中使用 Langfuse 进行追踪\n",
    "- ✅ **LCEL 示例**：顺序链的构建与执行\n",
    "- ✅ **Runnable 方法**：同步/异步、批处理、流式处理\n",
    "- ✅ **检索式问答**：文档加载、向量化、问答链构建\n",
    "\n",
    "### 🚀 下一步学习建议\n",
    "\n",
    "#### 1. 深入 LangChain 核心概念\n",
    "- 学习 [LangChain 官方教程](https://python.langchain.com/docs/tutorials/)\n",
    "- 掌握 Agent（智能体）和 Tool（工具）的使用\n",
    "- 了解 Memory（记忆）和 Chain（链）的高级用法\n",
    "\n",
    "#### 2. 探索 Langfuse 高级功能\n",
    "- 学习如何创建自定义评估指标\n",
    "- 掌握成本分析和性能优化\n",
    "- 了解团队协作和项目管理功能\n",
    "\n",
    "#### 3. 实战项目练习\n",
    "- 构建一个带有多步骤推理的聊天机器人\n",
    "- 创建一个支持文档检索的问答系统\n",
    "- 开发一个多模态（文本+图像）应用\n",
    "\n",
    "#### 4. 生产环境部署\n",
    "- 学习 Docker 容器化部署\n",
    "- 了解 Kubernetes 集群管理\n",
    "- 掌握监控和日志管理最佳实践\n",
    "\n",
    "### 🔗 有用的资源链接\n",
    "\n",
    "#### 📚 官方文档\n",
    "- [LangChain 官方文档](https://python.langchain.com/) - 全面的 LangChain 使用指南\n",
    "- [Langfuse 官方文档](https://langfuse.com/docs) - 详细的 Langfuse 功能说明\n",
    "- [OpenAI API 文档](https://platform.openai.com/docs) - OpenAI API 使用指南\n",
    "\n",
    "#### 🛠️ 开源社区\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain) - 源码和问题讨论\n",
    "- [Langfuse GitHub](https://github.com/langfuse/langfuse) - 开源版本和贡献指南\n",
    "- [LangChain 模板库](https://github.com/langchain-ai/langchain/tree/master/templates) - 实用模板集合\n",
    "\n",
    "#### 🎓 学习资源\n",
    "- [LangChain 官方教程](https://python.langchain.com/docs/tutorials/) - 从入门到进阶\n",
    "- [Langfuse 示例库](https://langfuse.com/docs/integrations) - 各种集成示例\n",
    "- [大模型应用开发最佳实践](https://platform.openai.com/docs/guides/prompt-engineering) - 提示工程指南\n",
    "\n",
    "### 💡 实践建议\n",
    "\n",
    "#### 🏗️ 开发阶段\n",
    "1. **从简单开始**：先构建基础的问答链，验证核心功能后再增加复杂度\n",
    "2. **模块化设计**：将复杂的应用拆分为独立的组件，便于测试和维护\n",
    "3. **版本控制**：使用 Git 管理代码，记录每次重要的功能变更\n",
    "4. **环境隔离**：使用虚拟环境管理依赖，避免版本冲突\n",
    "\n",
    "#### 📊 监控与优化\n",
    "1. **全程追踪**：始终使用 Langfuse 追踪应用执行，建立完整的可观测性\n",
    "2. **性能分析**：定期查看 Langfuse 控制台，分析响应时间和成功率\n",
    "3. **成本监控**：密切关注 token 使用量和 API 调用成本，优化模型选择\n",
    "4. **错误处理**：建立完善的错误处理机制，提高应用的稳定性\n",
    "\n",
    "#### 🔄 迭代改进\n",
    "1. **数据驱动**：基于 Langfuse 的分析数据，持续优化提示词和参数\n",
    "2. **A/B 测试**：对比不同版本的性能，选择最优方案\n",
    "3. **用户反馈**：收集真实用户的使用反馈，指导产品改进方向\n",
    "4. **定期评估**：建立定期的性能评估机制，确保应用质量\n",
    "\n",
    "### 🚨 常见问题与解决方案\n",
    "\n",
    "#### ❓ API 密钥问题\n",
    "- **问题**：API 调用失败或认证错误\n",
    "- **解决**：检查环境变量设置，确保密钥正确且有效\n",
    "\n",
    "#### ❓ 依赖包冲突\n",
    "- **问题**：安装包时出现版本冲突\n",
    "- **解决**：使用虚拟环境，或指定具体的包版本\n",
    "\n",
    "#### ❓ 追踪数据缺失\n",
    "- **问题**：Langfuse 控制台看不到追踪数据\n",
    "- **解决**：确保回调处理器正确配置，检查网络连接\n",
    "\n",
    "#### ❓ 性能问题\n",
    "- **问题**：应用响应速度慢\n",
    "- **解决**：优化提示词长度，选择合适的模型，使用缓存机制\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 最后的话\n",
    "\n",
    "大模型应用开发是一个充满挑战和机遇的领域。通过本教程，你已经掌握了：\n",
    "\n",
    "- ✅ **基础技能**：LangChain 与 Langfuse 的集成使用\n",
    "- ✅ **实践经验**：从简单链到复杂应用的构建过程\n",
    "- ✅ **监控能力**：使用 Langfuse 进行全面的应用监控\n",
    "- ✅ **优化思路**：基于数据驱动的持续改进方法\n",
    "\n",
    "记住，**实践是最好的老师**。建议你：\n",
    "1. 🔨 **动手实践**：基于本教程的示例，构建自己的应用\n",
    "2. 📖 **持续学习**：关注 LangChain 和 Langfuse 的最新发展\n",
    "3. 🤝 **社区参与**：加入开发者社区，分享经验和学习心得\n",
    "4. 🚀 **勇于创新**：探索大模型在你所在领域的应用可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dZKzDHsakrG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}