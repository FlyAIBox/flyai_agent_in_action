{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {},
   "source": [
    "# ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "## æ¦‚è¿°\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®\n",
    "\n",
    "## é…ç½®æ­¥éª¤\n",
    "1. **Condaç¯å¢ƒç®¡ç†** - æ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "2. **åŒ…ç®¡ç†å™¨ä¼˜åŒ–** - é…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "3. **æ¨¡å‹ä¸‹è½½åŠ é€Ÿ** - è®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "4. **ç³»ç»Ÿç¯å¢ƒè¯Šæ–­** - æ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æ¿€æ´»condaç¯å¢ƒ\n",
    "%%script bash\n",
    "# åˆå§‹åŒ– conda\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "conda env list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_integration_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlceIPalN3QR"
   },
   "source": [
    "# Langfuseé›†æˆLangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pre-knowledge"
   },
   "source": [
    "## ğŸ“š å‰ç½®çŸ¥è¯†å¯¼è¯»\n",
    "\n",
    "åœ¨å¼€å§‹å­¦ä¹  LangChain ä¸ Langfuse çš„é›†æˆä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ä¸€äº›åŸºç¡€æ¦‚å¿µï¼š\n",
    "\n",
    "### ğŸ¤– LangChain æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "- **å®šä¹‰**ï¼šLangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„å¼€å‘æ¡†æ¶\n",
    "- **ä½œç”¨**ï¼šå¸®åŠ©å¼€å‘è€…å°† LLM ä¸å¤–éƒ¨æ•°æ®æºã€å·¥å…·ã€æ•°æ®åº“ç­‰è¿æ¥èµ·æ¥\n",
    "- **æ ¸å¿ƒæ¦‚å¿µ**ï¼šChainï¼ˆé“¾ï¼‰ã€Agentï¼ˆæ™ºèƒ½ä½“ï¼‰ã€Toolï¼ˆå·¥å…·ï¼‰ã€Memoryï¼ˆè®°å¿†ï¼‰ç­‰\n",
    "\n",
    "### ğŸ“Š Langfuse æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "- **å®šä¹‰**ï¼šLangfuse æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨è®¾è®¡çš„å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰å¹³å°\n",
    "- **ä½œç”¨**ï¼šå¸®åŠ©å¼€å‘è€…ç›‘æ§ã€è°ƒè¯•å’Œä¼˜åŒ– LLM åº”ç”¨çš„æ€§èƒ½\n",
    "- **æ ¸å¿ƒåŠŸèƒ½**ï¼šè¿½è¸ªï¼ˆTracingï¼‰ã€è¯„ä¼°ï¼ˆEvaluationï¼‰ã€ç›‘æ§ï¼ˆMonitoringï¼‰\n",
    "\n",
    "### ğŸ”— ä¸¤è€…å¦‚ä½•ååŒå·¥ä½œï¼Ÿ\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[ä½ çš„åº”ç”¨] --> B[LangChain]\n",
    "    B --> C[LLM/å·¥å…·/æ•°æ®]\n",
    "    B --> D[Langfuse]\n",
    "    D --> E[æ€§èƒ½ç›‘æ§]\n",
    "    D --> F[è°ƒè¯•åˆ†æ]\n",
    "    D --> G[æˆæœ¬è¿½è¸ª]\n",
    "```\n",
    "\n",
    "### ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å°†å­¦ä¼šï¼š\n",
    "1. å¦‚ä½•åœ¨ LangChain åº”ç”¨ä¸­é›†æˆ Langfuse\n",
    "2. å¦‚ä½•è¿½è¸ªå’Œç›‘æ§ LLM è°ƒç”¨é“¾\n",
    "3. å¦‚ä½•åˆ†æåº”ç”¨æ€§èƒ½å’Œæˆæœ¬\n",
    "4. å¦‚ä½•è°ƒè¯•å’Œä¼˜åŒ– LLM åº”ç”¨\n",
    "\n",
    "---\n",
    "**ğŸ’¡ æç¤º**ï¼šå¦‚æœä½ å¯¹ LangChain æˆ– Langfuse è¿˜ä¸å¤ªç†Ÿæ‚‰ï¼Œå»ºè®®å…ˆé˜…è¯»å®˜æ–¹æ–‡æ¡£äº†è§£åŸºç¡€æ¦‚å¿µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqBspBzuRk9C"
   },
   "source": [
    "# ç¤ºä¾‹ï¼šLangChain é›†æˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1oaA7XYGOfX"
   },
   "source": [
    "è¯·æŒ‰ç…§[é›†æˆæŒ‡å—](https://langfuse.com/integrations/frameworks/langchain)å°†è¯¥é›†æˆæ·»åŠ åˆ°ä½ çš„ LangChain é¡¹ç›®ä¸­ã€‚è¯¥é›†æˆä¹Ÿæ”¯æŒ LangChain JSã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbSpd5EiZouE"
   },
   "source": [
    "## ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YNyU6IzCZouE",
    "outputId": "43cdd016-2e5d-4938-aa39-a6b1729a7e12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langfuse==3.3.0\n",
      "  Downloading langfuse-3.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Collecting langchain-openai==0.3.31\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain_community==0.3.27\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting backoff>=1.10.0 (from langfuse==3.3.0)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.36.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.12/dist-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.27)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community==0.3.27) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.15.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse==3.3.0)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langfuse-3.3.0-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: opentelemetry-proto, mypy-extensions, marshmallow, backoff, typing-inspect, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, langchain-openai, langfuse, langchain_community\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.36.0\n",
      "    Uninstalling opentelemetry-api-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.36.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.36.0\n",
      "    Uninstalling opentelemetry-sdk-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
      "Successfully installed backoff-2.2.1 dataclasses-json-0.6.7 langchain-openai-0.3.31 langchain_community-0.3.27 langfuse-3.3.0 marshmallow-3.26.1 mypy-extensions-1.1.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å®‰è£…å¿…è¦çš„ Python åŒ…\n",
    "#\n",
    "# ğŸ“š åŒ…åŠŸèƒ½è¯´æ˜ï¼š\n",
    "# - langfuse: Langfuse å®¢æˆ·ç«¯åº“ï¼Œä¸“é—¨ç”¨äºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„ç›‘æ§ã€è¿½è¸ªå’Œè¯„ä¼°\n",
    "# - langchain: LangChain æ ¸å¿ƒæ¡†æ¶ï¼Œæä¾›æ„å»ºå¤æ‚ LLM åº”ç”¨çš„åŸºç¡€ç»„ä»¶\n",
    "# - langchain-openai: LangChain çš„ OpenAI å®˜æ–¹é›†æˆåŒ…ï¼Œæ”¯æŒ GPT ç³»åˆ—æ¨¡å‹\n",
    "# - langchain_community: LangChain ç¤¾åŒºç»´æŠ¤çš„æ‰©å±•ç»„ä»¶ï¼ŒåŒ…å«å„ç§å·¥å…·å’Œé›†æˆ\n",
    "\n",
    "#\n",
    "# ğŸ”§ å®‰è£…å‘½ä»¤ï¼ˆæ ¹æ®éœ€æ±‚é€‰æ‹©ï¼‰ï¼š\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpE57ujJZouE"
   },
   "source": [
    "åœ¨ Langfuse æ§åˆ¶å°çš„é¡¹ç›®è®¾ç½®é¡µè·å– API Keyï¼Œåˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯ï¼Œå¹¶å°†å…¶è®¾ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dEdF-668ZouF",
    "outputId": "25252224-1bd7-45a9-f381-df623b9ebbfc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_PUBLIC_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_SECRET_KEY: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_HOST: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„æœ€ä½³å®è·µ\n",
    "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
    "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ğŸ¤– OpenAI API é…ç½®\n",
    "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
    "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# APIä»£ç†åœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ï¼ˆå¦‚å›½å†…ä»£ç†ï¼‰\n",
    "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
    "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# ğŸŒ Langfuse é…ç½®\n",
    "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
    "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
    "\n",
    "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# æœåŠ¡å™¨åœ°å€ï¼šé€‰æ‹©ç¦»ä½ æœ€è¿‘çš„åŒºåŸŸ\n",
    "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
    "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸï¼ˆä¸æ¨èï¼‰ https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
    "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
    "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
    "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "divRadPqZouF"
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨\n",
    "# è¿™ä¸ªå¤„ç†å™¨ä¼šè‡ªåŠ¨æ•è· LangChain çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "# - LLM è°ƒç”¨çš„è¾“å…¥å’Œè¾“å‡º\n",
    "# - æ‰§è¡Œæ—¶é—´å’Œå»¶è¿Ÿ\n",
    "# - é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "# - æˆæœ¬ä¿¡æ¯ï¼ˆtoken ä½¿ç”¨é‡ï¼‰\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸ’¡ æç¤ºï¼šè¿™ä¸ªå›è°ƒå¤„ç†å™¨å°†åœ¨åç»­çš„ LangChain è°ƒç”¨ä¸­ä½¿ç”¨\n",
    "# é€šè¿‡ config={\"callbacks\": [langfuse_handler]} å‚æ•°ä¼ é€’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZXRf2FZXEXV"
   },
   "source": [
    "## ç¤ºä¾‹\n",
    "### LangChain LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3-HEia6gNoAr"
   },
   "outputs": [],
   "source": [
    "# ğŸ”§ å¯¼å…¥ LangChain æ ¸å¿ƒç»„ä»¶\n",
    "from operator import itemgetter  # Python å†…ç½®å‡½æ•°ï¼Œç”¨äºä»å­—å…¸ä¸­æå–ç‰¹å®šé”®å€¼å¯¹\n",
    "from langchain_openai import ChatOpenAI  # OpenAI èŠå¤©æ¨¡å‹æ¥å£ï¼Œæ”¯æŒ GPT ç³»åˆ—æ¨¡å‹\n",
    "from langchain.prompts import ChatPromptTemplate  # èŠå¤©æç¤ºæ¨¡æ¿ï¼Œç”¨äºæ ¼å¼åŒ–å¯¹è¯è¾“å…¥\n",
    "from langchain.schema import StrOutputParser  # å­—ç¬¦ä¸²è¾“å‡ºè§£æå™¨ï¼Œå°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "\n",
    "# ğŸ”„ é‡æ–°åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨\n",
    "# ç¡®ä¿è¿½è¸ªåŠŸèƒ½æ­£å¸¸å·¥ä½œï¼Œè®°å½•æ•´ä¸ªé“¾å¼æ‰§è¡Œè¿‡ç¨‹\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸ“ ç¬¬ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼šäººç‰©åœ°ç†ä¿¡æ¯æŸ¥è¯¢\n",
    "# åŠŸèƒ½ï¼šæ ¹æ®äººç‰©å§“åæŸ¥è¯¢å…¶æ¥æºåŸå¸‚\n",
    "# è¾“å…¥å˜é‡ï¼š{person} - äººç‰©å§“å\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{person} æ¥è‡ªå“ªåº§åŸå¸‚ï¼Ÿ\")\n",
    "\n",
    "# ğŸ“ ç¬¬äºŒä¸ªæç¤ºæ¨¡æ¿ï¼šåŸå¸‚å›½å®¶æ˜ å°„æŸ¥è¯¢\n",
    "# åŠŸèƒ½ï¼šæ ¹æ®åŸå¸‚åç§°æŸ¥è¯¢æ‰€å±å›½å®¶ï¼Œå¹¶æŒ‡å®šå›ç­”è¯­è¨€\n",
    "# è¾“å…¥å˜é‡ï¼š{city} - åŸå¸‚åç§°ï¼Œ{language} - å›ç­”è¯­è¨€\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"åŸå¸‚ {city} ä½äºå“ªä¸ªå›½å®¶ï¼Ÿè¯·ç”¨ {language} å›ç­”\"\n",
    ")\n",
    "\n",
    "# ğŸ¤– åˆå§‹åŒ– OpenAI èŠå¤©æ¨¡å‹\n",
    "# é»˜è®¤ä½¿ç”¨ gpt-3.5-turbo æ¨¡å‹ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# â›“ï¸ æ„å»ºç¬¬ä¸€ä¸ªå¤„ç†é“¾ï¼ˆç®€å•é“¾ï¼‰\n",
    "# æ•°æ®æµï¼šäººå â†’ æç¤ºæ¨¡æ¿ â†’ æ¨¡å‹æ¨ç† â†’ å­—ç¬¦ä¸²è¾“å‡º\n",
    "# ä½œç”¨ï¼šå°†äººç‰©å§“åè½¬æ¢ä¸ºåŸå¸‚åç§°\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "# â›“ï¸ æ„å»ºç¬¬äºŒä¸ªå¤„ç†é“¾ï¼ˆå¤åˆé“¾ï¼‰\n",
    "# æ•°æ®æµï¼š\n",
    "# 1. ğŸ”€ å¹¶è¡Œå¤„ç†ï¼šé€šè¿‡ chain1 è·å–åŸå¸‚åï¼Œé€šè¿‡ itemgetter æå–è¯­è¨€å‚æ•°\n",
    "# 2. ğŸ“‹ æ•°æ®æ•´åˆï¼šå°†åŸå¸‚å’Œè¯­è¨€ç»„åˆä¸ºå­—å…¸æ ¼å¼\n",
    "# 3. ğŸ“ æç¤ºç”Ÿæˆï¼šå°†æ•°æ®ä¼ é€’ç»™ prompt2 ç”ŸæˆæŸ¥è¯¢æç¤º\n",
    "# 4. ğŸ¤– æ¨¡å‹æ¨ç†ï¼šè°ƒç”¨ OpenAI æ¨¡å‹è¿›è¡Œæ¨ç†\n",
    "# 5. ğŸ”¤ ç»“æœè§£æï¼šå°†æ¨¡å‹è¾“å‡ºè§£æä¸ºæœ€ç»ˆå­—ç¬¦ä¸²\n",
    "chain2 = (\n",
    "    {\"city\": chain1, \"language\": itemgetter(\"language\")}  # ğŸ”€ å¹¶è¡Œæ•°æ®å‡†å¤‡\n",
    "    | prompt2    # ğŸ“ ç¬¬äºŒé˜¶æ®µæç¤ºç”Ÿæˆ\n",
    "    | model      # ğŸ¤– æ¨¡å‹æ¨ç†è°ƒç”¨\n",
    "    | StrOutputParser()  # ğŸ”¤ è¾“å‡ºæ ¼å¼åŒ–\n",
    ")\n",
    "\n",
    "# ğŸš€ æ‰§è¡Œé“¾å¼è°ƒç”¨å¹¶å¯ç”¨ Langfuse è¿½è¸ª\n",
    "# ç¤ºä¾‹1ï¼šæŸ¥è¯¢è‹ä¸œå¡çš„åœ°ç†ä¿¡æ¯ï¼Œè¦æ±‚ç”¨ä¸­æ–‡å›ç­”\n",
    "# é¢„æœŸæµç¨‹ï¼šè‹ä¸œå¡ â†’ çœ‰å±±/æ­å· â†’ ä¸­å›½ï¼Œç”¨ä¸­æ–‡å›ç­”\n",
    "result = chain2.invoke(\n",
    "    {\"person\": \"è‹ä¸œå¡\", \"language\": \"ä¸­æ–‡\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwFVrw-WVtY0"
   },
   "source": [
    "### LangChain LCEL çš„è¿½è¸ªå›¾\n",
    "\n",
    "![LangChain LCEL çš„è·Ÿè¸ªå›¾](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508261521543.png)\n",
    "\n",
    "[Langfuse ä¸­çš„ç¤ºä¾‹è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=9ec09bc81b4173edf6e3d11d24d0cf2f&timestamp=2025-08-26T07%3A11%3A54.389Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlBSpILFXEXV"
   },
   "source": [
    "#### LangChain Runnable æ–¹æ³•\n",
    "\n",
    "Runnable æ˜¯å¯ä»¥è¢«è°ƒç”¨ã€æ‰¹å¤„ç†ã€æµå¼å¤„ç†ã€è½¬æ¢å¹¶è¿›è¡Œç»„åˆçš„å·¥ä½œå•å…ƒã€‚\n",
    "\n",
    "ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨ Langfuse ä¸­ä½¿ç”¨è¿™äº›æ–¹æ³•ï¼š\n",
    "\n",
    "- invoke/ainvokeï¼šå°†å•ä¸ªè¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºã€‚\n",
    "- batch/abatchï¼šé«˜æ•ˆåœ°å°†å¤šä¸ªè¾“å…¥æ‰¹é‡è½¬æ¢ä¸ºè¾“å‡ºã€‚\n",
    "- stream/astreamï¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä»¥æµå¼æ–¹å¼è¾“å‡ºå•ä¸ªè¾“å…¥çš„ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8N8pybGXEXV",
    "outputId": "b41d6ca3-b46f-4598-c021-ec21fcc3dbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµå¼åˆ†ç‰‡: \n",
      "æµå¼åˆ†ç‰‡: The\n",
      "æµå¼åˆ†ç‰‡:  city\n",
      "æµå¼åˆ†ç‰‡:  of\n",
      "æµå¼åˆ†ç‰‡:  San\n",
      "æµå¼åˆ†ç‰‡:  Francisco\n",
      "æµå¼åˆ†ç‰‡: ,\n",
      "æµå¼åˆ†ç‰‡:  California\n",
      "æµå¼åˆ†ç‰‡: ,\n",
      "æµå¼åˆ†ç‰‡:  where\n",
      "æµå¼åˆ†ç‰‡:  Steve\n",
      "æµå¼åˆ†ç‰‡:  Jobs\n",
      "æµå¼åˆ†ç‰‡:  is\n",
      "æµå¼åˆ†ç‰‡:  from\n",
      "æµå¼åˆ†ç‰‡: ,\n",
      "æµå¼åˆ†ç‰‡:  is\n",
      "æµå¼åˆ†ç‰‡:  located\n",
      "æµå¼åˆ†ç‰‡:  in\n",
      "æµå¼åˆ†ç‰‡:  the\n",
      "æµå¼åˆ†ç‰‡:  United\n",
      "æµå¼åˆ†ç‰‡:  States\n",
      "æµå¼åˆ†ç‰‡: .\n",
      "æµå¼åˆ†ç‰‡: \n",
      "æµå¼åˆ†ç‰‡: \n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: \n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: The\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  city\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  Seattle\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: ,\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  where\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  Bill\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  Gates\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  comes\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  from\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: ,\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  is\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  located\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  in\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  the\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  United\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡:  States\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: .\n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: \n",
      "å¼‚æ­¥æµå¼åˆ†ç‰‡: \n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ å¼‚æ­¥è°ƒç”¨ï¼ˆAsync Invokeï¼‰\n",
    "# ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š\n",
    "#   - éœ€è¦åœ¨å¼‚æ­¥ç¯å¢ƒï¼ˆå¦‚ FastAPIã€Django Asyncï¼‰ä¸­æ‰§è¡Œå•ä¸ªè¯·æ±‚\n",
    "#   - ä¸å…¶ä»–å¼‚æ­¥æ“ä½œï¼ˆæ•°æ®åº“æŸ¥è¯¢ã€APIè°ƒç”¨ï¼‰å¹¶è¡Œæ‰§è¡Œ\n",
    "# ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š\n",
    "#   - ä¸ä¼šé˜»å¡å…¶ä»–å¼‚æ­¥æ“ä½œï¼Œæé«˜æ•´ä½“åº”ç”¨ååé‡\n",
    "#   - æ”¯æŒ asyncio äº‹ä»¶å¾ªç¯ï¼Œé€‚åˆç°ä»£å¼‚æ­¥ Web åº”ç”¨\n",
    "await chain2.ainvoke(\n",
    "    {\"person\": \"biden\", \"language\": \"german\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "# ğŸ“¦ æ‰¹å¤„ç†ï¼ˆBatchï¼‰\n",
    "# ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š\n",
    "#   - éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªç›¸ä¼¼çš„è¯·æ±‚ï¼ˆå¦‚æ‰¹é‡æ•°æ®å¤„ç†ï¼‰\n",
    "#   - æ•°æ®åˆ†æã€æŠ¥å‘Šç”Ÿæˆç­‰éœ€è¦å¹¶è¡Œå¤„ç†çš„ä»»åŠ¡\n",
    "# ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š\n",
    "#   - æ¯”é€ä¸ªè°ƒç”¨æ›´é«˜æ•ˆï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªè¯·æ±‚\n",
    "#   - å‡å°‘ç½‘ç»œå¼€é”€ï¼Œä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡\n",
    "batch_results = chain2.batch([\n",
    "    {\"person\": \"elon musk\", \"language\": \"english\"},\n",
    "    {\"person\": \"mark zuckerberg\", \"language\": \"english\"}\n",
    "], config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# ğŸ”„ğŸ“¦ å¼‚æ­¥æ‰¹å¤„ç†ï¼ˆAsync Batchï¼‰\n",
    "# ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š\n",
    "#   - åœ¨å¼‚æ­¥ç¯å¢ƒä¸­æ‰¹é‡å¤„ç†è¯·æ±‚\n",
    "#   - é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ‰¹é‡æ•°æ®å¤„ç†\n",
    "# ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š\n",
    "#   - ç»“åˆäº†å¼‚æ­¥å’Œæ‰¹å¤„ç†çš„ä¼˜ç‚¹\n",
    "#   - æ”¯æŒæ›´é«˜çš„å¹¶å‘é‡ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹\n",
    "batch_async_results = await chain2.abatch([\n",
    "    {\"person\": \"jeff bezos\", \"language\": \"english\"},\n",
    "    {\"person\": \"tim cook\", \"language\": \"english\"}\n",
    "], config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# ğŸŒŠ æµå¼å¤„ç†ï¼ˆStreamï¼‰\n",
    "# ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š\n",
    "#   - éœ€è¦å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹çš„èŠå¤©åº”ç”¨\n",
    "#   - é•¿æ–‡æœ¬ç”Ÿæˆï¼Œæå‡ç”¨æˆ·ä½“éªŒ\n",
    "#   - å®æ—¶ç¿»è¯‘ã€æ‘˜è¦ç­‰éœ€è¦é€æ­¥å±•ç¤ºç»“æœçš„åº”ç”¨\n",
    "# ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š\n",
    "#   - ç”¨æˆ·å¯ä»¥ç«‹å³çœ‹åˆ°éƒ¨åˆ†ç»“æœï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å“åº”\n",
    "#   - é™ä½æ„ŸçŸ¥å»¶è¿Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒ\n",
    "#   - æ”¯æŒå®æ—¶å–æ¶ˆå’Œä¸­æ–­æ“ä½œ\n",
    "print(\"ğŸŒŠ æµå¼å¤„ç†ç¤ºä¾‹ï¼š\")\n",
    "for chunk in chain2.stream(\n",
    "    {\"person\": \"steve jobs\", \"language\": \"english\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"ğŸ“¤ æµå¼åˆ†ç‰‡: {chunk}\")  # æ¯ä¸ªåˆ†ç‰‡ä¼šå®æ—¶è¾“å‡º\n",
    "    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥å°† chunk å‘é€åˆ°å‰ç«¯å®æ—¶æ˜¾ç¤º\n",
    "\n",
    "# ğŸ”„ğŸŒŠ å¼‚æ­¥æµå¼å¤„ç†ï¼ˆAsync Streamï¼‰\n",
    "# ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š\n",
    "#   - åœ¨å¼‚æ­¥ Web åº”ç”¨ä¸­æä¾›æµå¼å“åº”\n",
    "#   - WebSocket å®æ—¶é€šä¿¡\n",
    "#   - æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆServer-Sent Eventsï¼‰\n",
    "# ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š\n",
    "#   - ä¸é˜»å¡å…¶ä»–å¼‚æ­¥æ“ä½œï¼ŒåŒæ—¶æä¾›å®æ—¶åé¦ˆ\n",
    "#   - æ”¯æŒå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œèµ„æºåˆ©ç”¨æ›´é«˜æ•ˆ\n",
    "print(\"\\nğŸ”„ğŸŒŠ å¼‚æ­¥æµå¼å¤„ç†ç¤ºä¾‹ï¼š\")\n",
    "async for chunk in chain2.astream(\n",
    "    {\"person\": \"bill gates\", \"language\": \"english\"},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"ğŸ“¤ å¼‚æ­¥æµå¼åˆ†ç‰‡: {chunk}\")  # å¼‚æ­¥æ¥æ”¶æ¯ä¸ªåˆ†ç‰‡\n",
    "    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥é€šè¿‡ WebSocket æˆ– SSE å‘é€åˆ°å®¢æˆ·ç«¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvRWPsZ-NoAr"
   },
   "source": [
    "### LangChain LCEL çš„è·Ÿè¸ªå›¾\n",
    "\n",
    "![LangChain LCEL çš„è·Ÿè¸ªå›¾](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508261521543.png)\n",
    "\n",
    "[Langfuse ä¸­çš„ç¤ºä¾‹è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=9ec09bc81b4173edf6e3d11d24d0cf2f&timestamp=2025-08-26T07%3A11%3A54.389Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP5avhNb3TBH"
   },
   "source": [
    "### Langfuseä¸­çš„LangChainæ£€ç´¢å¼é—®ç­”è·Ÿè¸ªï¼ˆRetrievalQAï¼‰\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wjiWEkRUFzCf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# è®¾ç½® SerpAPI å¯†é’¥ï¼ˆç”¨äºç½‘ç»œæœç´¢åŠŸèƒ½ï¼‰\n",
    "# ğŸ’¡ æç¤ºï¼šå¦‚æœä¸ä½¿ç”¨æœç´¢åŠŸèƒ½ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸ªè®¾ç½®\n",
    "# è·å–å…è´¹ API å¯†é’¥ï¼šhttps://serpapi.com/\n",
    "_set_env(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "p0CgEPSlEpkC",
    "outputId": "bf5e0b36-6d2e-4df2-e220-7db3bbad10a1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting unstructured==0.18.13\n",
      "  Downloading unstructured-0.18.13-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting selenium==4.35.0\n",
      "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain-chroma==0.2.5\n",
      "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (3.4.3)\n",
      "Collecting filetype (from unstructured==0.18.13)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured==0.18.13)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (5.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (3.9.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.13.5)\n",
      "Collecting emoji (from unstructured==0.18.13)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured==0.18.13)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured==0.18.13)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.0.2)\n",
      "Collecting rapidfuzz (from unstructured==0.18.13)\n",
      "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.15.0)\n",
      "Collecting unstructured-client (from unstructured==0.18.13)\n",
      "  Downloading unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (1.17.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (5.9.5)\n",
      "Collecting python-oxmsg (from unstructured==0.18.13)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (from unstructured==0.18.13) (1.1)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium==4.35.0) (2.5.0)\n",
      "Collecting trio~=0.30.0 (from selenium==4.35.0)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium==4.35.0)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium==4.35.0) (2025.8.3)\n",
      "Collecting typing-extensions (from unstructured==0.18.13)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium==4.35.0) (1.8.0)\n",
      "Requirement already satisfied: langchain-core>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma==0.2.5) (0.3.75)\n",
      "Collecting chromadb>=1.0.9 (from langchain-chroma==0.2.5)\n",
      "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.22.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.17.4)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma==0.2.5) (4.25.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (0.4.27)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain-chroma==0.2.5) (25.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (3.10)\n",
      "Collecting outcome (from trio~=0.30.0->selenium==4.35.0)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium==4.35.0) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium==4.35.0)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium==4.35.0) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->unstructured==0.18.13) (2.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured==0.18.13) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured==0.18.13) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured==0.18.13) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured==0.18.13) (0.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured==0.18.13) (2024.11.6)\n",
      "Collecting olefile (from python-oxmsg->unstructured==0.18.13)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (43.0.3)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (1.0.9)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured==0.18.13)\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured==0.18.13) (1.0.0)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.1->unstructured-client->unstructured==0.18.13) (2.0.0)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client->unstructured==0.18.13) (0.16.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.10.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.70->langchain-chroma==0.2.5) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.38.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.70->langchain-chroma==0.2.5) (0.24.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.58b0)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.34.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured==0.18.13) (1.1.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma==0.2.5) (15.0.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured==0.18.13) (2.23)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.1.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma==0.2.5) (0.6.1)\n",
      "Downloading unstructured-0.18.13-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
      "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m651.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect, pypika\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=8caff184c0eb14a8abeca03862001f30107f96e21b9a2b0ad693a9fd94202111\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=44052dc57bf038c3e7db15b7ef97b17daf2347da3633a4fe08d1d5d2541cf0cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built langdetect pypika\n",
      "Installing collected packages: pypika, filetype, durationpy, wsproto, uvloop, typing-extensions, rapidfuzz, python-magic, python-iso639, pypdf, pybase64, outcome, olefile, mmh3, langdetect, humanfriendly, httptools, emoji, bcrypt, trio, python-oxmsg, posthog, coloredlogs, watchfiles, trio-websocket, onnxruntime, kubernetes, unstructured-client, selenium, unstructured, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 emoji-2.15.0 filetype-1.2.0 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.2.5 langdetect-1.0.9 mmh3-5.2.0 olefile-0.47 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-grpc-1.37.0 outcome-1.3.0.post0 posthog-5.4.0 pybase64-1.4.2 pypdf-6.1.0 pypika-0.48.9 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.14.1 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing-extensions-4.14.1 unstructured-0.18.13 unstructured-client-0.42.3 uvloop-0.21.0 watchfiles-1.1.0 wsproto-1.2.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "opentelemetry"
        ]
       },
       "id": "389c66c14f0f458cb86e92b8cb43d019"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# å®‰è£…æ£€ç´¢å¼é—®ç­”æ‰€éœ€çš„é¢å¤–ä¾èµ–åŒ…\n",
    "# unstructured: ç”¨äºå¤„ç†å„ç§æ–‡æ¡£æ ¼å¼ï¼ˆPDFã€Wordã€HTMLç­‰ï¼‰\n",
    "# selenium: ç”¨äºç½‘é¡µå†…å®¹æŠ“å–å’ŒåŠ¨æ€é¡µé¢å¤„ç†\n",
    "# langchain-chroma: å‘é‡æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£åµŒå…¥\n",
    "%pip install unstructured==0.18.13 selenium==4.35.0 langchain-chroma==0.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHDVa-Ssb-KT",
    "outputId": "8d6ee6ef-a534-4a59-8829-7e44decf37bc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“Š æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£\n",
      "ğŸ“‹ æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ 41 ä¸ªæ–‡æœ¬å—\n",
      "ğŸ” ã€æ–‡æ¡£åˆ†å‰²é¢„è§ˆã€‘\n",
      "  å— 1: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and th...\n",
      "  å— 2: Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers tur...\n",
      "ğŸ”„ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...\n",
      "âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼ŒåŒ…å« 41 ä¸ªå‘é‡\n",
      "ğŸ” å¼€å§‹æ‰§è¡Œæ£€ç´¢å¼é—®ç­”...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ğŸ’¡ é—®é¢˜ï¼šç¾å›½å›½æƒ…å’¨æ–‡æ¼”è®²ç¨¿çš„æ ¸å¿ƒä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿè¯·æ€»ç»“ä¸»è¦è§‚ç‚¹ã€‚\n",
      "ğŸ¯ ç­”æ¡ˆï¼šç¾å›½å›½æƒ…å’¨æ–‡æ¼”è®²ç¨¿çš„æ ¸å¿ƒä¸»é¢˜æ˜¯ç¾å›½äººæ°‘çš„å¼ºå¤§ã€‚æ¼”è®²ä¸­å¼ºè°ƒäº†ç¾å›½äººæ°‘çš„åšå®šæ„å¿—å’Œå›¢ç»“ä¸€è‡´ï¼Œå¼ºè°ƒäº†è‡ªç”±å’Œæ°‘ä¸»çš„é‡è¦æ€§ã€‚æ¼”è®²è¿˜æåˆ°äº†é¢å¯¹æŒ‘æˆ˜æ—¶çš„ä¹è§‚æ€åº¦å’Œå¯¹æœªæ¥çš„ä¿¡å¿ƒï¼Œä»¥åŠç¾å›½äººæ°‘åœ¨å†å²ä¸Šå§‹ç»ˆå°†å±æœºè½¬åŒ–ä¸ºæœºé‡çš„èƒ½åŠ›ã€‚æ€»çš„æ¥è¯´ï¼Œæ¼”è®²å¼ºè°ƒäº†ç¾å›½äººæ°‘çš„åŠ›é‡å’Œå›¢ç»“ï¼Œä»¥åŠä»–ä»¬åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶çš„å†³å¿ƒå’Œå‹‡æ°”ã€‚\n",
      "\n",
      "ğŸ“š å‚è€ƒæ¥æºï¼ˆå…± 3 ä¸ªæ–‡æ¡£å—ï¼‰ï¼š\n",
      "  ğŸ“„ æ¥æº 1: And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "Now is the hour. \n",
      "Our moment of responsibility. \n",
      "Our test of re...\n",
      "  ğŸ“„ æ¥æº 2: And my report is this: the State of the Union is strongâ€”because you, the American people, are strong. \n",
      "We are stronger today than we were a year ago. ...\n",
      "  ğŸ“„ æ¥æº 3: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fello...\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§© å¯¼å…¥æ£€ç´¢å¼é—®ç­”ï¼ˆRAGï¼‰æ‰€éœ€çš„æ ¸å¿ƒæ¨¡å—\n",
    "from langchain_community.document_loaders import SeleniumURLLoader  # ğŸŒ ç½‘é¡µæ–‡æ¡£åŠ è½½å™¨ï¼Œæ”¯æŒ JavaScript æ¸²æŸ“\n",
    "from langchain_chroma import Chroma  # ğŸ—„ï¸ Chroma å‘é‡æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡\n",
    "from langchain_text_splitters import CharacterTextSplitter  # âœ‚ï¸ æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºå°å—\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # ğŸ¤– OpenAI åµŒå…¥æ¨¡å‹å’ŒèŠå¤©æ¨¡å‹\n",
    "from langchain.chains import RetrievalQA  # ğŸ”— æ£€ç´¢å¼é—®ç­”é“¾ï¼Œå®ç° RAG åŠŸèƒ½\n",
    "\n",
    "# ğŸ”„ åˆå§‹åŒ– Langfuse å›è°ƒå¤„ç†å™¨\n",
    "# ç”¨äºè¿½è¸ªæ•´ä¸ª RAG æµç¨‹ï¼ŒåŒ…æ‹¬æ–‡æ¡£æ£€ç´¢å’Œç­”æ¡ˆç”Ÿæˆ\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ğŸ“„ å®šä¹‰è¦åŠ è½½çš„æ–‡æ¡£ URL åˆ—è¡¨\n",
    "# ğŸ’¡ ç¤ºä¾‹ï¼šç¾å›½å›½æƒ…å’¨æ–‡æ¼”è®²ç¨¿ï¼ˆåŒ…å«ä¸°å¯Œçš„æ”¿æ²»ã€ç»æµã€ç¤¾ä¼šè¯é¢˜ï¼‰\n",
    "# è¿™ä¸ªæ–‡æ¡£éå¸¸é€‚åˆå±•ç¤º RAG ç³»ç»Ÿçš„æ£€ç´¢å’Œé—®ç­”èƒ½åŠ›\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
    "]\n",
    "\n",
    "# ğŸ“¥ æ­¥éª¤1ï¼šæ–‡æ¡£åŠ è½½\n",
    "# SeleniumURLLoader çš„ä¼˜åŠ¿ï¼š\n",
    "# - èƒ½å¤Ÿå¤„ç†éœ€è¦ JavaScript æ¸²æŸ“çš„åŠ¨æ€ç½‘é¡µ\n",
    "# - æ”¯æŒå¤æ‚çš„é¡µé¢ç»“æ„å’Œå¼‚æ­¥å†…å®¹åŠ è½½\n",
    "# - æ¯”ç®€å•çš„ HTTP è¯·æ±‚æ›´å¼ºå¤§\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "\n",
    "# ğŸ¤– æ­¥éª¤2ï¼šåˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
    "# é€‰æ‹© ChatOpenAI çš„åŸå› ï¼š\n",
    "# - æ”¯æŒå¯¹è¯æ ¼å¼ï¼Œæ›´é€‚åˆé—®ç­”ä»»åŠ¡\n",
    "# - ä¸ç°ä»£ OpenAI API å®Œå…¨å…¼å®¹\n",
    "# - æ”¯æŒç³»ç»Ÿæ¶ˆæ¯å’Œè§’è‰²è®¾å®š\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)  # ä½æ¸©åº¦ç¡®ä¿ç­”æ¡ˆç¨³å®šæ€§\n",
    "\n",
    "# ğŸ“– æ­¥éª¤3ï¼šæ–‡æ¡£å†…å®¹åŠ è½½\n",
    "# ä»æŒ‡å®š URL è·å–æ–‡æ¡£å†…å®¹å¹¶è§£æä¸º Document å¯¹è±¡\n",
    "documents = loader.load()\n",
    "print(f\"ğŸ“Š æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# âœ‚ï¸ æ­¥éª¤4ï¼šæ–‡æ¡£åˆ†å‰²ç­–ç•¥\n",
    "# ğŸ¯ åˆ†å‰²å‚æ•°è¯´æ˜ï¼š\n",
    "# - chunk_size=1000: æ¯ä¸ªæ–‡æœ¬å—åŒ…å«çº¦1000ä¸ªå­—ç¬¦ï¼ˆå¹³è¡¡æ£€ç´¢ç²¾åº¦å’Œä¸Šä¸‹æ–‡å®Œæ•´æ€§ï¼‰\n",
    "# - chunk_overlap=0: æ–‡æœ¬å—é—´æ— é‡å ï¼ˆé¿å…é‡å¤ä¿¡æ¯ï¼Œä½†å¯èƒ½ä¸¢å¤±è·¨å—è¯­ä¹‰ï¼‰\n",
    "# ğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¯ä»¥è®¾ç½® chunk_overlap=100-200 ä»¥ä¿æŒè¯­ä¹‰è¿ç»­æ€§\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    separator=\"\\n\"  # æŒ‰æ®µè½åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"ğŸ“‹ æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(texts)} ä¸ªæ–‡æœ¬å—\")\n",
    "print(\"ğŸ” ã€æ–‡æ¡£åˆ†å‰²é¢„è§ˆã€‘\")\n",
    "for i, text in enumerate(texts[:2]):  # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªå—ä½œä¸ºç¤ºä¾‹\n",
    "    print(f\"  å— {i+1}: {text.page_content[:100]}...\")\n",
    "\n",
    "# ğŸ”¢ æ­¥éª¤5ï¼šåˆ›å»ºæ–‡æœ¬åµŒå…¥å‘é‡\n",
    "# OpenAIEmbeddings å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œç”¨äºè¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢\n",
    "# ğŸ’° æˆæœ¬æç¤ºï¼šåµŒå…¥ç”Ÿæˆä¼šäº§ç”Ÿ API è°ƒç”¨è´¹ç”¨ï¼Œä½†é€šå¸¸æ¯” GPT è°ƒç”¨ä¾¿å®œå¾—å¤š\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # ä½¿ç”¨è¾ƒæ–°çš„åµŒå…¥æ¨¡å‹\n",
    "\n",
    "# ğŸ—„ï¸ æ­¥éª¤6ï¼šæ„å»ºå‘é‡æ•°æ®åº“\n",
    "# Chroma æ•°æ®åº“çš„ä¼˜åŠ¿ï¼š\n",
    "# - è½»é‡çº§ï¼Œé€‚åˆå¿«é€ŸåŸå‹å¼€å‘\n",
    "# - å†…å­˜å­˜å‚¨ï¼Œå¯åŠ¨å¿«é€Ÿ\n",
    "# - æ”¯æŒå¤šç§ç›¸ä¼¼æ€§æœç´¢ç®—æ³•\n",
    "print(\"ğŸ”„ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...\")\n",
    "docsearch = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"state_of_union\"  # æŒ‡å®šé›†åˆåç§°ä¾¿äºç®¡ç†\n",
    ")\n",
    "print(f\"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼ŒåŒ…å« {docsearch._collection.count()} ä¸ªå‘é‡\")\n",
    "\n",
    "# â“ æ­¥éª¤7ï¼šå®šä¹‰æŸ¥è¯¢é—®é¢˜\n",
    "# è®¾è®¡ä¸€ä¸ªå¼€æ”¾æ€§é—®é¢˜æ¥æµ‹è¯• RAG ç³»ç»Ÿçš„ç†è§£å’Œç»¼åˆèƒ½åŠ›\n",
    "query = \"ç¾å›½å›½æƒ…å’¨æ–‡æ¼”è®²ç¨¿çš„æ ¸å¿ƒä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿè¯·æ€»ç»“ä¸»è¦è§‚ç‚¹ã€‚\"\n",
    "\n",
    "# ğŸ”— æ­¥éª¤8ï¼šæ„å»ºæ£€ç´¢å¼é—®ç­”é“¾\n",
    "# RetrievalQA å·¥ä½œæµç¨‹ï¼š\n",
    "# 1. å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºåµŒå…¥å‘é‡\n",
    "# 2. åœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£å—\n",
    "# 3. å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œç»“åˆç”¨æˆ·é—®é¢˜ç”Ÿæˆæç¤º\n",
    "# 4. è°ƒç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" æ¨¡å¼ï¼šå°†æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£æ‹¼æ¥ä¸ºä¸€ä¸ªæç¤º\n",
    "    retriever=docsearch.as_retriever(\n",
    "        search_type=\"similarity\",  # ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢\n",
    "        search_kwargs={\"k\": 3}     # æ£€ç´¢æœ€ç›¸å…³çš„ 3 ä¸ªæ–‡æ¡£å—\n",
    "    ),\n",
    "    return_source_documents=True,  # è¿”å›æºæ–‡æ¡£ï¼Œä¾¿äºéªŒè¯ç­”æ¡ˆæ¥æº\n",
    "    verbose=True  # æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œè¿‡ç¨‹\n",
    ")\n",
    "\n",
    "# ğŸš€ æ­¥éª¤9ï¼šæ‰§è¡Œ RAG é—®ç­”å¹¶å¯ç”¨ Langfuse è¿½è¸ª\n",
    "# è¿™å°†åœ¨ Langfuse æ§åˆ¶å°ä¸­è®°å½•ï¼š\n",
    "# - æ–‡æ¡£æ£€ç´¢è¿‡ç¨‹å’Œç»“æœ\n",
    "# - æç¤ºè¯ç”Ÿæˆ\n",
    "# - æ¨¡å‹æ¨ç†è¿‡ç¨‹\n",
    "# - æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ\n",
    "print(\"ğŸ” å¼€å§‹æ‰§è¡Œæ£€ç´¢å¼é—®ç­”...\")\n",
    "result = chain.invoke(query, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "print(f\"\\nğŸ’¡ é—®é¢˜ï¼š{query}\")\n",
    "print(f\"ğŸ¯ ç­”æ¡ˆï¼š{result['result']}\")\n",
    "print(f\"\\nğŸ“š å‚è€ƒæ¥æºï¼ˆå…± {len(result['source_documents'])} ä¸ªæ–‡æ¡£å—ï¼‰ï¼š\")\n",
    "for i, doc in enumerate(result['source_documents']):\n",
    "    print(f\"  ğŸ“„ æ¥æº {i+1}: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "RetrievalQA è¿½è¸ªå›¾\n",
    "![image-20250922113340738](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221133205.png)\n",
    "[Langfuse ä¸­çš„ç¤ºä¾‹è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=c1a402f423a8b848f07461edba960bfa&timestamp=2025-09-22T03%3A26%3A02.600Z)"
   ],
   "metadata": {
    "id": "Cz2tu3EAev-V"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-next-steps"
   },
   "source": [
    "## ğŸ‰ æ€»ç»“ä¸ä¸‹ä¸€æ­¥å­¦ä¹ \n",
    "\n",
    "æ­å–œï¼ä½ å·²ç»å®Œæˆäº† LangChain ä¸ Langfuse é›†æˆçš„åŸºç¡€å­¦ä¹ ã€‚è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹å­¦åˆ°çš„å†…å®¹ï¼š\n",
    "\n",
    "### ğŸ“‹ æœ¬æ•™ç¨‹æ¶µç›–çš„å†…å®¹\n",
    "- âœ… **ç¯å¢ƒå‡†å¤‡**ï¼šå®‰è£…ä¾èµ–ã€é…ç½® API å¯†é’¥ã€åˆå§‹åŒ–å›è°ƒå¤„ç†å™¨\n",
    "- âœ… **åŸºç¡€é›†æˆ**ï¼šåœ¨ LangChain åº”ç”¨ä¸­ä½¿ç”¨ Langfuse è¿›è¡Œè¿½è¸ª\n",
    "- âœ… **LCEL ç¤ºä¾‹**ï¼šé¡ºåºé“¾çš„æ„å»ºä¸æ‰§è¡Œ\n",
    "- âœ… **Runnable æ–¹æ³•**ï¼šåŒæ­¥/å¼‚æ­¥ã€æ‰¹å¤„ç†ã€æµå¼å¤„ç†\n",
    "- âœ… **æ£€ç´¢å¼é—®ç­”**ï¼šæ–‡æ¡£åŠ è½½ã€å‘é‡åŒ–ã€é—®ç­”é“¾æ„å»º\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®\n",
    "\n",
    "#### 1. æ·±å…¥ LangChain æ ¸å¿ƒæ¦‚å¿µ\n",
    "- å­¦ä¹  [LangChain å®˜æ–¹æ•™ç¨‹](https://python.langchain.com/docs/tutorials/)\n",
    "- æŒæ¡ Agentï¼ˆæ™ºèƒ½ä½“ï¼‰å’Œ Toolï¼ˆå·¥å…·ï¼‰çš„ä½¿ç”¨\n",
    "- äº†è§£ Memoryï¼ˆè®°å¿†ï¼‰å’Œ Chainï¼ˆé“¾ï¼‰çš„é«˜çº§ç”¨æ³•\n",
    "\n",
    "#### 2. æ¢ç´¢ Langfuse é«˜çº§åŠŸèƒ½\n",
    "- å­¦ä¹ å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡\n",
    "- æŒæ¡æˆæœ¬åˆ†æå’Œæ€§èƒ½ä¼˜åŒ–\n",
    "- äº†è§£å›¢é˜Ÿåä½œå’Œé¡¹ç›®ç®¡ç†åŠŸèƒ½\n",
    "\n",
    "#### 3. å®æˆ˜é¡¹ç›®ç»ƒä¹ \n",
    "- æ„å»ºä¸€ä¸ªå¸¦æœ‰å¤šæ­¥éª¤æ¨ç†çš„èŠå¤©æœºå™¨äºº\n",
    "- åˆ›å»ºä¸€ä¸ªæ”¯æŒæ–‡æ¡£æ£€ç´¢çš„é—®ç­”ç³»ç»Ÿ\n",
    "- å¼€å‘ä¸€ä¸ªå¤šæ¨¡æ€ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰åº”ç”¨\n",
    "\n",
    "#### 4. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²\n",
    "- å­¦ä¹  Docker å®¹å™¨åŒ–éƒ¨ç½²\n",
    "- äº†è§£ Kubernetes é›†ç¾¤ç®¡ç†\n",
    "- æŒæ¡ç›‘æ§å’Œæ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ\n",
    "\n",
    "### ğŸ”— æœ‰ç”¨çš„èµ„æºé“¾æ¥\n",
    "\n",
    "#### ğŸ“š å®˜æ–¹æ–‡æ¡£\n",
    "- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/) - å…¨é¢çš„ LangChain ä½¿ç”¨æŒ‡å—\n",
    "- [Langfuse å®˜æ–¹æ–‡æ¡£](https://langfuse.com/docs) - è¯¦ç»†çš„ Langfuse åŠŸèƒ½è¯´æ˜\n",
    "- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs) - OpenAI API ä½¿ç”¨æŒ‡å—\n",
    "\n",
    "#### ğŸ› ï¸ å¼€æºç¤¾åŒº\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain) - æºç å’Œé—®é¢˜è®¨è®º\n",
    "- [Langfuse GitHub](https://github.com/langfuse/langfuse) - å¼€æºç‰ˆæœ¬å’Œè´¡çŒ®æŒ‡å—\n",
    "- [LangChain æ¨¡æ¿åº“](https://github.com/langchain-ai/langchain/tree/master/templates) - å®ç”¨æ¨¡æ¿é›†åˆ\n",
    "\n",
    "#### ğŸ“ å­¦ä¹ èµ„æº\n",
    "- [LangChain å®˜æ–¹æ•™ç¨‹](https://python.langchain.com/docs/tutorials/) - ä»å…¥é—¨åˆ°è¿›é˜¶\n",
    "- [Langfuse ç¤ºä¾‹åº“](https://langfuse.com/docs/integrations) - å„ç§é›†æˆç¤ºä¾‹\n",
    "- [å¤§æ¨¡å‹åº”ç”¨å¼€å‘æœ€ä½³å®è·µ](https://platform.openai.com/docs/guides/prompt-engineering) - æç¤ºå·¥ç¨‹æŒ‡å—\n",
    "\n",
    "### ğŸ’¡ å®è·µå»ºè®®\n",
    "\n",
    "#### ğŸ—ï¸ å¼€å‘é˜¶æ®µ\n",
    "1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆæ„å»ºåŸºç¡€çš„é—®ç­”é“¾ï¼ŒéªŒè¯æ ¸å¿ƒåŠŸèƒ½åå†å¢åŠ å¤æ‚åº¦\n",
    "2. **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†å¤æ‚çš„åº”ç”¨æ‹†åˆ†ä¸ºç‹¬ç«‹çš„ç»„ä»¶ï¼Œä¾¿äºæµ‹è¯•å’Œç»´æŠ¤\n",
    "3. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ Git ç®¡ç†ä»£ç ï¼Œè®°å½•æ¯æ¬¡é‡è¦çš„åŠŸèƒ½å˜æ›´\n",
    "4. **ç¯å¢ƒéš”ç¦»**ï¼šä½¿ç”¨è™šæ‹Ÿç¯å¢ƒç®¡ç†ä¾èµ–ï¼Œé¿å…ç‰ˆæœ¬å†²çª\n",
    "\n",
    "#### ğŸ“Š ç›‘æ§ä¸ä¼˜åŒ–\n",
    "1. **å…¨ç¨‹è¿½è¸ª**ï¼šå§‹ç»ˆä½¿ç”¨ Langfuse è¿½è¸ªåº”ç”¨æ‰§è¡Œï¼Œå»ºç«‹å®Œæ•´çš„å¯è§‚æµ‹æ€§\n",
    "2. **æ€§èƒ½åˆ†æ**ï¼šå®šæœŸæŸ¥çœ‹ Langfuse æ§åˆ¶å°ï¼Œåˆ†æå“åº”æ—¶é—´å’ŒæˆåŠŸç‡\n",
    "3. **æˆæœ¬ç›‘æ§**ï¼šå¯†åˆ‡å…³æ³¨ token ä½¿ç”¨é‡å’Œ API è°ƒç”¨æˆæœ¬ï¼Œä¼˜åŒ–æ¨¡å‹é€‰æ‹©\n",
    "4. **é”™è¯¯å¤„ç†**ï¼šå»ºç«‹å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œæé«˜åº”ç”¨çš„ç¨³å®šæ€§\n",
    "\n",
    "#### ğŸ”„ è¿­ä»£æ”¹è¿›\n",
    "1. **æ•°æ®é©±åŠ¨**ï¼šåŸºäº Langfuse çš„åˆ†ææ•°æ®ï¼ŒæŒç»­ä¼˜åŒ–æç¤ºè¯å’Œå‚æ•°\n",
    "2. **A/B æµ‹è¯•**ï¼šå¯¹æ¯”ä¸åŒç‰ˆæœ¬çš„æ€§èƒ½ï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ\n",
    "3. **ç”¨æˆ·åé¦ˆ**ï¼šæ”¶é›†çœŸå®ç”¨æˆ·çš„ä½¿ç”¨åé¦ˆï¼ŒæŒ‡å¯¼äº§å“æ”¹è¿›æ–¹å‘\n",
    "4. **å®šæœŸè¯„ä¼°**ï¼šå»ºç«‹å®šæœŸçš„æ€§èƒ½è¯„ä¼°æœºåˆ¶ï¼Œç¡®ä¿åº”ç”¨è´¨é‡\n",
    "\n",
    "### ğŸš¨ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "#### â“ API å¯†é’¥é—®é¢˜\n",
    "- **é—®é¢˜**ï¼šAPI è°ƒç”¨å¤±è´¥æˆ–è®¤è¯é”™è¯¯\n",
    "- **è§£å†³**ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®ï¼Œç¡®ä¿å¯†é’¥æ­£ç¡®ä¸”æœ‰æ•ˆ\n",
    "\n",
    "#### â“ ä¾èµ–åŒ…å†²çª\n",
    "- **é—®é¢˜**ï¼šå®‰è£…åŒ…æ—¶å‡ºç°ç‰ˆæœ¬å†²çª\n",
    "- **è§£å†³**ï¼šä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œæˆ–æŒ‡å®šå…·ä½“çš„åŒ…ç‰ˆæœ¬\n",
    "\n",
    "#### â“ è¿½è¸ªæ•°æ®ç¼ºå¤±\n",
    "- **é—®é¢˜**ï¼šLangfuse æ§åˆ¶å°çœ‹ä¸åˆ°è¿½è¸ªæ•°æ®\n",
    "- **è§£å†³**ï¼šç¡®ä¿å›è°ƒå¤„ç†å™¨æ­£ç¡®é…ç½®ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥\n",
    "\n",
    "#### â“ æ€§èƒ½é—®é¢˜\n",
    "- **é—®é¢˜**ï¼šåº”ç”¨å“åº”é€Ÿåº¦æ…¢\n",
    "- **è§£å†³**ï¼šä¼˜åŒ–æç¤ºè¯é•¿åº¦ï¼Œé€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œä½¿ç”¨ç¼“å­˜æœºåˆ¶\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ æœ€åçš„è¯\n",
    "\n",
    "å¤§æ¨¡å‹åº”ç”¨å¼€å‘æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜å’Œæœºé‡çš„é¢†åŸŸã€‚é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "\n",
    "- âœ… **åŸºç¡€æŠ€èƒ½**ï¼šLangChain ä¸ Langfuse çš„é›†æˆä½¿ç”¨\n",
    "- âœ… **å®è·µç»éªŒ**ï¼šä»ç®€å•é“¾åˆ°å¤æ‚åº”ç”¨çš„æ„å»ºè¿‡ç¨‹\n",
    "- âœ… **ç›‘æ§èƒ½åŠ›**ï¼šä½¿ç”¨ Langfuse è¿›è¡Œå…¨é¢çš„åº”ç”¨ç›‘æ§\n",
    "- âœ… **ä¼˜åŒ–æ€è·¯**ï¼šåŸºäºæ•°æ®é©±åŠ¨çš„æŒç»­æ”¹è¿›æ–¹æ³•\n",
    "\n",
    "è®°ä½ï¼Œ**å®è·µæ˜¯æœ€å¥½çš„è€å¸ˆ**ã€‚å»ºè®®ä½ ï¼š\n",
    "1. ğŸ”¨ **åŠ¨æ‰‹å®è·µ**ï¼šåŸºäºæœ¬æ•™ç¨‹çš„ç¤ºä¾‹ï¼Œæ„å»ºè‡ªå·±çš„åº”ç”¨\n",
    "2. ğŸ“– **æŒç»­å­¦ä¹ **ï¼šå…³æ³¨ LangChain å’Œ Langfuse çš„æœ€æ–°å‘å±•\n",
    "3. ğŸ¤ **ç¤¾åŒºå‚ä¸**ï¼šåŠ å…¥å¼€å‘è€…ç¤¾åŒºï¼Œåˆ†äº«ç»éªŒå’Œå­¦ä¹ å¿ƒå¾—\n",
    "4. ğŸš€ **å‹‡äºåˆ›æ–°**ï¼šæ¢ç´¢å¤§æ¨¡å‹åœ¨ä½ æ‰€åœ¨é¢†åŸŸçš„åº”ç”¨å¯èƒ½æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dZKzDHsakrG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}