{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔧 环境配置和检查\n",
    "\n",
    "#### 概述\n",
    "\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助您：\n",
    "\n",
    "- 使用统一的conda环境：激活统一的学习环境\n",
    "- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n",
    "- 加速模型下载：设置HuggingFace镜像代理\n",
    "- 检查系统配置：检查硬件和软件配置\n",
    "\n",
    "#### 配置\n",
    "\n",
    "- **所需环境及其依赖已经部署好**\n",
    "- 在`Notebook`右上角选择`jupyter内核`为`python(flyai_agent_in_action)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\n",
      "=========================================\n",
      "✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\n",
      "✅ 正在使用的环境路径: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\n",
      "   如果需要后续单元格也使用此环境，请执行以下操作:\n",
      "   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. 激活 conda 环境 (仅对当前单元格有效)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. 检查当前激活的环境\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"✅ 当前单元格已成功激活到 flyai_agent_in_action 环境。\"\n",
    "    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"💡 提示: 后续的 Python 单元格将使用 Notebook 当前选择的 Jupyter 内核。\"\n",
    "    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n",
    "    echo \"   1. 检查 Notebook 右上角是否已选择 'python(flyai_agent_in_action)'。\"\n",
    "else\n",
    "    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(flyai_agent_in_action)'。\"\n",
    "    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n",
    "    echo \"\"\n",
    "    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# 必须在每个单元格都执行\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### 环境信息\n",
      "| 项目         | 信息                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| 操作系统     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU 信息     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| 内存信息     | 2015.36 GB (Available: 1860.71 GB)                                    |\n",
      "| GPU 信息     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA 信息    | 12.6                                                                  |\n",
      "| Python 版本  | 3.12.11                                                               |\n",
      "| Conda 版本   | conda 25.7.0                                                          |\n",
      "| 物理磁盘空间 | Total: 2014.78 GB, Used: 652.01 GB, Free: 1260.35 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助您：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_04_integration_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlCI9KeX4Zn4"
   },
   "source": [
    "## 什么是 LangGraph？\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/) 是由 LangChain 团队开源的框架，用于基于大语言模型（LLM）构建复杂、有状态的多智能体应用。LangGraph 内置了持久化能力，可保存与恢复状态，从而支持错误恢复与包含“人机交互”（Human-in-the-loop, HITL）的工作流。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o8L1qPcaZeC"
   },
   "source": [
    "## 本实践手册的目标\n",
    "\n",
    "本手册演示如何借助 [Langfuse](https://langfuse.com/docs)，通过其与 [LangChain 的集成](https://langfuse.com/integrations/frameworks/langchain)，对你的 LangGraph 应用进行调试、分析与迭代优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPTaMtxH4eHV"
   },
   "source": [
    "**完成本手册后，你将能够：**\n",
    "\n",
    "- 自动通过 Langfuse 集成对 LangGraph 应用进行追踪（tracing）\n",
    "- 监控复杂的多智能体（multi-agent）方案\n",
    "- 添加评分（例如用户反馈）\n",
    "- 使用 Langfuse 管理 LangGraph 中使用的提示词（prompt）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sSIS88y9Ewm"
   },
   "source": [
    "## 初始化 Langfuse\n",
    "\n",
    "在 Langfuse 控制台项目设置页获取你的 [API 密钥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)，并将其加入到运行环境变量中以初始化 Langfuse 客户端。\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"⚠️\" -->\n",
    "_**注意：** 本笔记使用 Langfuse Python SDK v3。_\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"ℹ️\" -->\n",
    "_**注意：** 需要至少 Python 3.11（参见 [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)）。_\n",
    "<!-- CALLOUT_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C85BK1vJ5yD3",
    "outputId": "806323f8-3c9c-4bd1-d558-e474a2078baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langfuse==3.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain_community==0.3.27 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph==0.6.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.6.7)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.4.31)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (2.3.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (0.2.6)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (0.9.0)\n",
      "Requirement already satisfied: anyio in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (6.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27 langgraph==0.6.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUbRmJ-Kh0rq"
   },
   "source": [
    "在 Langfuse 控制台的项目设置页获取 API Key，初始化 Langfuse 客户端，并将其设置到环境变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vku6l5CLhwdC",
    "outputId": "604ff78f-65af-4fc1-8d81-a1a998a4c345"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n",
      "OPENAI_BASE_URL:  ········\n",
      "LANGFUSE_PUBLIC_KEY:  ········\n",
      "LANGFUSE_SECRET_KEY:  ········\n",
      "LANGFUSE_HOST:  ········\n"
     ]
    }
   ],
   "source": [
    "# 🔐 环境变量配置 - 安全存储敏感信息\n",
    "# 环境变量是存储API密钥等敏感信息的最佳实践\n",
    "# 避免在代码中硬编码密钥，防止泄露\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    安全地设置环境变量\n",
    "    如果环境变量不存在，会提示用户输入\n",
    "    使用getpass模块隐藏输入内容，防止密码泄露\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# 🤖 OpenAI API 配置\n",
    "# OpenAI API密钥：从 https://platform.openai.com/api-keys 获取\n",
    "# 这是调用GPT模型必需的认证信息\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API代理地址：如果你使用第三方代理服务（如国内代理）\n",
    "# 示例：https://api.apiyi.com/v1\n",
    "# 如果直接使用OpenAI官方API，可以留空\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 🌐 Langfuse 配置\n",
    "# Langfuse是一个可观测性平台，需要注册账户获取密钥\n",
    "# 注册地址：https://cloud.langfuse.com\n",
    "\n",
    "# 公开密钥：用于标识你的项目\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# 秘密密钥：用于认证，请妥善保管\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# 服务器地址：选择离你最近的区域\n",
    "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
    "# 🇺🇸 美国区域（不推荐） https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# 💡 初学者提示：\n",
    "# 1. 环境变量存储在操作系统中，重启后需要重新设置\n",
    "# 2. 生产环境中建议使用.env文件或云服务配置\n",
    "# 3. 永远不要在代码中硬编码API密钥！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agy0r3Byg-Aw"
   },
   "source": [
    "在环境变量设置完成后，我们即可初始化 Langfuse 客户端。`get_client()` 会使用环境变量中提供的凭据来初始化 Langfuse 客户端。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LVLs2A8g-Ax",
    "outputId": "44ce9dd7-1ada-4a05-bb0b-ca3281833dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Langfuse 客户端已通过身份验证，准备就绪！\n",
      "🔧 现在可以开始使用追踪功能了\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "# 🚀 初始化 Langfuse 客户端\n",
    "# get_client() 会自动读取环境变量中的配置信息\n",
    "langfuse = get_client()\n",
    "\n",
    "# 🔍 验证客户端连接状态\n",
    "# 这个步骤非常重要，确保后续的追踪功能能够正常工作\n",
    "if langfuse.auth_check():\n",
    "    print(\"✅ Langfuse 客户端已通过身份验证，准备就绪！\")\n",
    "    print(\"🔧 现在可以开始使用追踪功能了\")\n",
    "else:\n",
    "    print(\"❌ 身份验证失败！\")\n",
    "    print(\"🔍 请检查以下配置项：\")\n",
    "    print(\"   - LANGFUSE_PUBLIC_KEY 是否正确\")\n",
    "    print(\"   - LANGFUSE_SECRET_KEY 是否正确\")\n",
    "    print(\"   - LANGFUSE_HOST 是否可访问\")\n",
    "    print(\"   - 网络连接是否正常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqYMmi6n9Nh1"
   },
   "source": [
    "## 示例 1：使用 LangGraph 构建简单聊天应用\n",
    "\n",
    "**本节将完成：**\n",
    "\n",
    "- 在 LangGraph 中构建一个可回答常见问题的客服聊天机器人\n",
    "- 使用 Langfuse 对机器人的输入与输出进行追踪（tracing）\n",
    "\n",
    "我们先从一个基础机器人入手，随后在下一节扩展为更高级的多智能体（multi-agent）设置，并在过程中介绍关键的 LangGraph 概念。\n",
    "\n",
    "### 创建智能体（Agent）\n",
    "\n",
    "首先创建一个 `StateGraph`。`StateGraph` 定义了聊天机器人的状态机结构。我们会添加节点来表示 LLM 以及机器人可调用的函数，并通过边（edge）定义机器人在这些函数之间的状态流转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aGIxgPww6VX6"
   },
   "outputs": [],
   "source": [
    "# 🔧 导入 LangGraph 构建智能体所需的核心模块\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
    "from langchain_core.messages import HumanMessage  # 人类消息类型\n",
    "from typing_extensions import TypedDict  # 类型化字典\n",
    "from langgraph.graph import StateGraph  # LangGraph 状态图\n",
    "from langgraph.graph.message import add_messages  # 消息添加函数\n",
    "\n",
    "# 📋 定义智能体的状态结构\n",
    "# State 是一个类型化字典，定义了智能体在执行过程中需要维护的状态信息\n",
    "class State(TypedDict):\n",
    "    # 💬 消息列表：存储对话历史\n",
    "    # Annotated[list, add_messages] 的含义：\n",
    "    # - list: 消息的数据类型是列表\n",
    "    # - add_messages: 指定状态更新策略，新消息会追加到列表末尾而不是覆盖整个列表\n",
    "    # 这种设计确保了对话历史的完整保存\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 创建状态图构建器\n",
    "# StateGraph 是 LangGraph 的核心组件，用于定义智能体的工作流程\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 初始化语言模型\n",
    "# 选择 GPT-4o 模型，temperature=0.2 确保输出相对稳定但仍有一定创造性\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# 🔄 定义聊天机器人节点函数\n",
    "# 这是 LangGraph 节点函数的基本模式：接收当前状态，返回更新后的状态\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    聊天机器人节点的核心逻辑\n",
    "\n",
    "    参数:\n",
    "        state (State): 当前的智能体状态，包含消息历史\n",
    "\n",
    "    返回:\n",
    "        dict: 包含新生成消息的状态更新\n",
    "\n",
    "    工作流程:\n",
    "    1. 获取当前的消息历史\n",
    "    2. 将消息历史发送给语言模型\n",
    "    3. 接收模型生成的回复\n",
    "    4. 将回复包装成状态更新返回\n",
    "    \"\"\"\n",
    "    # 调用语言模型处理当前对话历史，生成回复\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 返回状态更新：将模型的回复添加到消息列表中\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 🔗 向图中添加\"chatbot\"节点\n",
    "# 节点代表工作单元，通常是普通的 Python 函数\n",
    "# 每个节点负责特定的处理逻辑，如调用 LLM、处理工具、数据转换等\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 🚀 设置图的入口点\n",
    "# 告诉图每次运行时从哪个节点开始执行\n",
    "# 在这个简单示例中，我们直接从 chatbot 节点开始\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# 🏁 设置图的结束点\n",
    "# 指示图\"当这个节点运行完成后，可以退出执行\"\n",
    "# 对于简单的单轮对话，chatbot 节点执行完就可以结束\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# ⚙️ 编译图形为可执行对象\n",
    "# compile() 方法将图构建器转换为 CompiledGraph\n",
    "# CompiledGraph 是可以实际运行的图形对象，支持 invoke、stream 等方法\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# 💡 理解 LangGraph 的核心概念：\n",
    "# 🏗️ StateGraph: 定义智能体的状态和工作流程\n",
    "# 🔄 Node: 执行具体任务的函数，如调用 LLM、使用工具等\n",
    "# 🔗 Edge: 连接节点，定义执行顺序和条件跳转\n",
    "# 📊 State: 智能体运行过程中维护的数据结构\n",
    "# ⚙️ CompiledGraph: 编译后的可执行图形对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW2SJcRgh7Xo"
   },
   "source": [
    "### 在调用时添加 Langfuse 回调\n",
    "\n",
    "现在，为了追踪应用执行过程，我们将添加 [面向 LangChain 的 Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PxEc455-KYM",
    "outputId": "f7564588-e640-49a9-d36c-bbd3955eef94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 智能体开始运行，正在处理问题……\n",
      "❓ 用户提问：什么是 Langfuse？\n",
      "📋 执行过程:\n",
      "📤 节点执行结果：{'chatbot': {'messages': [AIMessage(content='Langfuse 是一个专门用于监控和调试生成式 AI 应用程序的工具。它提供了一系列功能，帮助开发者更好地理解和优化他们的 AI 模型和应用程序。以下是 Langfuse 的主要功能和典型应用场景：\\n\\n### 主要功能\\n\\n1. **请求跟踪和监控**：\\n   - Langfuse 可以跟踪每一个请求的详细信息，包括输入、输出、响应时间等。这使得开发者能够深入了解每个请求的处理过程。\\n   \\n2. **错误检测和调试**：\\n   - 通过详细的日志和错误报告，Langfuse 帮助开发者快速识别和修复生成式 AI 应用中的错误和异常情况。\\n   \\n3. **性能分析**：\\n   - Langfuse 提供性能分析工具，帮助开发者识别性能瓶颈，并优化模型和应用程序的响应时间。\\n   \\n4. **用户行为分析**：\\n   - 通过分析用户交互数据，Langfuse 可以帮助开发者理解用户行为和偏好，从而优化用户体验。\\n   \\n5. **可视化工具**：\\n   - Langfuse 提供可视化界面，帮助开发者以图形化方式查看数据和分析结果，便于快速做出决策。\\n\\n### 典型应用场景\\n\\n1. **生成式 AI 应用开发**：\\n   - 在开发生成式 AI 应用时，Langfuse 可以帮助开发者监控模型的表现，确保其输出符合预期，并快速迭代改进。\\n\\n2. **实时应用监控**：\\n   - 对于需要实时监控的应用，如聊天机器人或实时翻译工具，Langfuse 能够提供实时数据和分析，帮助开发者及时响应问题。\\n\\n3. **用户体验优化**：\\n   - 通过分析用户与 AI 应用的交互数据，开发者可以使用 Langfuse 来优化应用的界面和功能，提高用户满意度。\\n\\n4. **性能优化**：\\n   - 在需要高效处理大量请求的应用中，Langfuse 的性能分析功能可以帮助识别和解决性能问题，确保应用能够稳定运行。\\n\\n5. **错误调试和修复**：\\n   - 对于复杂的生成式 AI 应用，Langfuse 的错误检测和调试功能可以帮助开发者快速定位问题并进行修复，减少停机时间。\\n\\nLangfuse 是一个强大的工具，适用于任何需要深入监控和优化生成式 AI 应用的开发者和团队。通过其全面的功能，开发者可以更好地管理和提升 AI 应用的质量和性能。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 573, 'prompt_tokens': 26, 'total_tokens': 599, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_8458c98457', 'id': 'chatcmpl-CLQOL8THUCQF10Q4S92W5K13WyxJb', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--865c0419-0705-4ba9-a31a-0be69b882629-0', usage_metadata={'input_tokens': 26, 'output_tokens': 573, 'total_tokens': 599, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "✅ 智能体执行完成！\n",
      "🔍 请前往 Langfuse 控制台查看完整的追踪记录。\n"
     ]
    }
   ],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 🛎️ 初始化 Langfuse 回调处理器\n",
    "# 该处理器会自动捕获 LangChain/LangGraph 的执行细节，用于：\n",
    "# - 🕒 记录每个节点的耗时与延迟\n",
    "# - 📝 保存输入、输出及中间状态\n",
    "# - 💰 统计 token 消耗和 API 调用成本\n",
    "# - 🐞 收集异常信息，便于排错\n",
    "# - 📈 在 Langfuse 中生成可视化调用链\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# 🚀 运行智能体并启用 Langfuse 追踪\n",
    "print(\"🤖 智能体开始运行，正在处理问题……\")\n",
    "print(\"❓ 用户提问：什么是 Langfuse？\")\n",
    "print(\"📋 执行过程:\")\n",
    "\n",
    "# 使用 stream 方法可以实时查看智能体的执行步骤：\n",
    "# - graph.stream(...) 会在每个节点完成后产生一次增量输出（生成器）\n",
    "# - config={\"callbacks\": [langfuse_handler]} 确保每一步都写入 Langfuse\n",
    "# - 适合本地调试/教学演示，清晰观察逐步推理过程与耗时\n",
    "for step_result in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"什么是 Langfuse？请详细介绍其主要功能和典型应用场景。\")]},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    # 提示：step_result 的结构类似 {\"chatbot\": {\"messages\": [...]}}，\n",
    "    # 你可以在此对中间结果执行断言/日志上报，构建更稳健的测试与可观测性\n",
    "    print(f\"📤 节点执行结果：{step_result}\")\n",
    "\n",
    "# 结束提示：在 Langfuse 控制台可查看完整调用链、耗时、token 成本等\n",
    "print(\"✅ 智能体执行完成！\")\n",
    "print(\"🔍 请前往 Langfuse 控制台查看完整的追踪记录。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fdf3ZRnWGZ0N"
   },
   "source": [
    "### 在 Langfuse 中查看追踪结果\n",
    "\n",
    "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=cbc8503a9a111fc5eadb5e914be3fa7a&timestamp=2025-09-22T03%3A48%3A16.647Z&observation=47245ec86916a5d1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17Aq7u6_LBR6"
   },
   "source": [
    "![在 Langfuse 中查看聊天应用的追踪](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221150147.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3yyVtGKhMPU"
   },
   "source": [
    "### 可视化聊天应用\n",
    "\n",
    "你可以使用 `get_graph` 方法配合相应的 “draw” 方法对图进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "MKkM6mw47kIy",
    "outputId": "66a35e42-b0bd-4163-eeaa-9946473ff849"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "# 可视化当前图（graph）：有助于直观理解节点与执行顺序\n",
    "# 若图较大，可改用 draw_mermaid_file() 输出到文件或 draw_mermaid_svg() 生成矢量图\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0HW5xISntw"
   },
   "source": [
    "```mermaid\n",
    "graph TD;\n",
    "\t__start__([__start__]):::first\n",
    "\tchatbot(chatbot)\n",
    "\t__end__([__end__]):::last\n",
    "\t__start__ --> chatbot;\n",
    "\tchatbot --> __end__;\n",
    "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
    "\tclassDef first fill-opacity:0\n",
    "\tclassDef last fill:#bfb6fc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F4Tt_E4g-A0"
   },
   "source": [
    "### 在 LangGraph Server 中使用 Langfuse\n",
    "\n",
    "#### 🖥️ LangGraph Server 简介\n",
    "\n",
    "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) 是 LangGraph 提供的服务器部署方案，用于将本地构建的图工作流发布为可扩展的在线服务，具备以下能力：\n",
    "\n",
    "- 🌐 **HTTP API 接口**：将 LangGraph 智能体封装为 REST API，便于与业务系统集成\n",
    "- 🚀 **生产级运行**：支持高并发、负载均衡与容器化交付\n",
    "- 🔧 **运维友好**：自动处理请求路由、状态恢复与错误重试\n",
    "- 📊 **监控集成**：兼容主流监控与追踪体系，便于观测运行状况\n",
    "- 🔒 **安全管控**：内置身份认证与授权机制，满足企业安全需求\n",
    "\n",
    "#### 💡 为什么要在 Server 环境接入 Langfuse？\n",
    "\n",
    "- 🏭 **生产可观测性**：实时查看线上请求的调用链与状态\n",
    "- 🐛 **远程调试**：无需复现场景即可还原问题细节\n",
    "- 📈 **性能洞察**：量化每个节点的耗时与成本\n",
    "- 💰 **费用治理**：准确统计第三方 API 的调用量与费用\n",
    "- 👥 **团队协作**：共享追踪记录，支持跨职能协同排查\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTW_X4rFg-A0"
   },
   "source": [
    "#### 🔧 配置方法说明\n",
    "\n",
    "使用 LangGraph Server 时，智能体图的调用由服务器自动处理，用户无法在每次请求时手动指定回调处理器。\n",
    "\n",
    "**关键差异：**\n",
    "- 🏠 **本地开发**：可以在每次调用时添加 `config={\"callbacks\": [langfuse_handler]}`\n",
    "- 🖥️ **服务器部署**：需要在图编译时预先配置回调处理器\n",
    "\n",
    "**解决方案：**\n",
    "在声明和编译图时就添加 Langfuse 回调，这样服务器上的所有请求都会自动启用追踪功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J5UKXzbUg-A0"
   },
   "outputs": [],
   "source": [
    "# 🔧 导入服务器部署所需的模块\n",
    "# 初学者须知：本节示例面向“部署到 LangGraph Server（或任何持久化服务端）”场景，\n",
    "# 重点在于将追踪回调“静态注入”到图对象中，确保线上每个请求都被自动追踪。\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 📋 定义与前文一致的智能体状态结构\n",
    "# - State 是图的“共享黑板”，所有节点通过它传递数据\n",
    "# - messages 字段使用 add_messages 策略：新消息在运行中会被“追加”，而不是覆盖\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 构建图形结构\n",
    "# 小贴士：将最小可用功能先装成一张图，有利于后续扩展、观测与运维\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 初始化语言模型\n",
    "# 说明：temperature 控制随机性。生产环境若追求稳定复现，可适当降低至 0~0.2。\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# 🔄 定义聊天机器人节点\n",
    "# 约定：节点函数签名 (state) -> partial_state\n",
    "# 返回值是“增量状态”（partial update），LangGraph 会据此合并到全局状态\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"处理用户消息并生成回复。\"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"]) ]}\n",
    "\n",
    "# 🔗 组装图形结构\n",
    "# entry_point / finish_point 分别指定起点与终点，便于 Server 判定一次执行的生命周期\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# 🔄 初始化 Langfuse 回调处理器（服务器模式）\n",
    "# 注意：在 Server 场景无法逐次在调用处传入 callbacks，需在图对象层面预配置\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ⚙️ 编译图形并预配置回调处理器\n",
    "# 🎯 核心方法：with_config()\n",
    "# - compile()：编译图形，生成可执行的 CompiledGraph\n",
    "# - with_config()：为编译后的图形设置默认配置（如回调处理器）\n",
    "#\n",
    "# 💡 工作流程：\n",
    "# 1. 编译图形得到 CompiledGraph 对象\n",
    "# 2. 调用 with_config() 注入 Langfuse 回调\n",
    "# 3. 得到一个“默认启用追踪”的图对象，Server 直接引用即可\n",
    "#\n",
    "# ✅ 常见误区：\n",
    "# - 在 API Handler 内再临时创建 CallbackHandler → 会导致追踪分散、不易聚合\n",
    "# - 只在本地调试时传 callbacks，忘记在 Server 端注入 → 线上无追踪\n",
    "#\n",
    "# 🚀 优势：\n",
    "# - 无需在每次请求时手动添加回调配置\n",
    "# - 所有 API 请求都会自动写入 Langfuse 追踪\n",
    "# - 简化生产环境的部署与运维\n",
    "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# 💡 部署提示：\n",
    "# - 在 LangGraph Server 中直接引用此 graph，即可立即获得完整的追踪数据\n",
    "# - 如需区分环境（dev/staging/prod），可在环境变量中切换 Langfuse Host/Key；\n",
    "#   但“图对象注入回调”的做法保持一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvKULkc6g-BE"
   },
   "source": [
    "## 多个 LangGraph 智能体的协同\n",
    "\n",
    "在某些架构中，一个 LangGraph 智能体会调用一个或多个其他 LangGraph 智能体。若想让整套执行链在 Langfuse 中聚合为同一条追踪，可显式传入自定义的 `trace_id`。\n",
    "\n",
    "首先生成一个共享的 `trace_id`，供主智能体与子智能体共用，以便在 Langfuse 中合并为同一条记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TS8hQBHVg-BE"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client, Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ✅ 初学者要点：\n",
    "# - get_client() 会自动读取环境变量（LANGFUSE_PUBLIC_KEY/SECRET_KEY/HOST）进行认证\n",
    "# - Langfuse.create_trace_id() 生成可跨服务复用的 trace_id，用于将多段执行“串成一条”\n",
    "langfuse = get_client()\n",
    "\n",
    "# 🔐 生成一个稳定的 trace_id（也可由上游网关/业务系统传入，实现全链路同一 Trace）\n",
    "predefined_trace_id = Langfuse.create_trace_id()\n",
    "\n",
    "# 📡 初始化 Langfuse 回调处理器，用于采集 LangChain/LangGraph 的执行数据\n",
    "# 小贴士：该 handler 可复用，避免在每个请求内重复创建，减少开销\n",
    "langfuse_handler = CallbackHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73necyiUg-BE"
   },
   "source": [
    "接下来，构建子智能体的逻辑。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LWS82VWsg-BE"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 子智能体（Sub Agent）的最小实现：仅负责根据 messages 生成一次回复\n",
    "# 这样可把“研究/检索”等专项逻辑与主流程解耦，便于复用与独立观测\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 说明：与主智能体可使用相同或不同模型；按需求选择\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    # LangGraph 约定：返回增量状态（只包含需要更新的键）\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 仅单节点的直通图，适合封装为工具被主流程调用\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "sub_agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIcpIMEPg-BF"
   },
   "source": [
    "随后，将该子智能体封装成工具，供主流程调用并复用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R0KC8Gvzg-BF"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def langgraph_research(question):\n",
    "  \"\"\"Conducts research for various topics.\"\"\"\n",
    "\n",
    "  # 关键思路：\n",
    "  # - 使用 start_as_current_span 创建一个子跨度（span），并注入共享 trace_id，\n",
    "  #   确保该工具内的执行与主流程聚合到同一条追踪\n",
    "  with langfuse.start_as_current_span(\n",
    "      name=\"🤖-sub-research-agent\",\n",
    "      trace_context={\"trace_id\": predefined_trace_id}\n",
    "  ) as span:\n",
    "      # 在进入子智能体前，将用户问题写入 trace，便于还原现场\n",
    "      span.update_trace(input=question)\n",
    "\n",
    "      # 调用子智能体；通过 callbacks 将 LangChain 级别的细节采集到 Langfuse\n",
    "      response = sub_agent.invoke(\n",
    "          {\"messages\": [HumanMessage(content = question)]},\n",
    "          config={\"callbacks\": [langfuse_handler]}\n",
    "      )\n",
    "\n",
    "      # 返回结构是增量状态；此处取模型输出的 AI 消息作为工具答案\n",
    "      # 注意：索引 1 对应追加后的第二条消息（0 为 Human，1 为 AI）\n",
    "      span.update_trace(output= response[\"messages\"][1].content)\n",
    "\n",
    "  return response[\"messages\"][1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PpMQXiEg-BF"
   },
   "source": [
    "最后，创建第二个 LangGraph 智能体，通过前面新增的 `langgraph_research` 工具完成协作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lhNPp4pmg-BF"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 主智能体：采用内置 ReAct 模式（推理-行动-反思），可自动选择工具\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "# 将子智能体封装的工具注入，主智能体即可在需要时调用\n",
    "main_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[langgraph_research]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyeGvSf3g-BF",
    "outputId": "14edd5b7-f48c-48e2-9187-6aee8ad6b582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace ID: ccc330b1b0866a247f6678453786b2cf\n"
     ]
    }
   ],
   "source": [
    "user_question = \"什么是 Langfuse？\"\n",
    "\n",
    "# 🧭 使用预生成的 trace_id（通过 trace_context 注入）\n",
    "# 作用：让主/子智能体在 Langfuse 界面中聚合到同一条调用链上\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"🤖-main-agent\",\n",
    "    trace_context={\"trace_id\": predefined_trace_id}\n",
    ") as span:\n",
    "    # 记录入口输入，方便运维人员复盘\n",
    "    span.update_trace(input=user_question)\n",
    "\n",
    "    # 此处的 LangChain 执行都会归属于同一条追踪\n",
    "    response = main_agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "\n",
    "    # 记录最终输出，可配合评分（Score）进行质量分析\n",
    "    span.update_trace(output=response[\"messages\"][1].content)\n",
    "\n",
    "print(f\"Trace ID: {predefined_trace_id}\")  # 可在后续评分或排查时使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "alDFf_8RVG7X",
    "outputId": "823add00-dd87-4d46-a47e-9bbd8e4449ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 可以使用 get_graph 方法配合相应的 “draw” 方法对图进行可视化。\n",
    "# 初学者提示：可视化有助于理解 ReAct 智能体内部的节点与边，\n",
    "# 快速定位执行瓶颈与错误发生位置。\n",
    "from IPython.display import Image, display\n",
    "display(Image(main_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzPZIqUWg-BF"
   },
   "source": [
    "### 在 Langfuse 中查看多智能体追踪\n",
    "\n",
    "![多智能体追踪示例](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509231446631.png)\n",
    "\n",
    "示例追踪链接：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=a7d9c0badaccd67fccf2045c68fb01ec&timestamp=2025-09-23T06%3A37%3A08.963Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uybP4h8wGvWw"
   },
   "source": [
    "## 为追踪添加评分\n",
    "\n",
    "[评分（Score）](https://langfuse.com/docs/scores/overview) 用于评价单个观测（observation）或整条追踪（trace），可帮助你在运行时执行自定义质量检查，或配合人工审核流程。\n",
    "\n",
    "下面的示例演示如何：\n",
    "\n",
    "- 为某个 span 记录一个数值型评分（如 `relevance`）\n",
    "- 为整条追踪记录一个分类型评分（如 `feedback`）\n",
    "\n",
    "这有助于系统化地评估与改进应用质量。\n",
    "\n",
    "**→ 想深入了解？请参阅 [Langfuse 自定义评分指南](https://langfuse.com/docs/scores/custom)。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pgAqYnQuGwCL"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "# 评分（Score）适用场景：\n",
    "# - 在线反馈：例如“用户是否满意/是否有帮助”等\n",
    "# - 质量度量：如准确性/相关性/安全性等离线指标\n",
    "# - A/B 实验：以 trace 为单位聚合对比\n",
    "langfuse = get_client()\n",
    "\n",
    "# 方案一：使用上下文管理器返回的 span 对象进行评分（推荐，最直观）\n",
    "with langfuse.start_as_current_span(name=\"🤖-sub-research-agent\") as span:\n",
    "    # ... 此处执行 LangGraph 逻辑 ...\n",
    "\n",
    "    # 直接通过 span.score_trace 记录评分\n",
    "    # name：评分项名称；value：数值；data_type：NUMERIC/TEXT/CATEGORICAL\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\",\n",
    "        comment=\"This was correct, thank you\"\n",
    "    )\n",
    "\n",
    "# 方案二：仍在上下文中，但不直接持有 span 对象时，可用 score_current_trace()\n",
    "with langfuse.start_as_current_span(name=\"🤖-sub-research-agent\") as span:\n",
    "    # ... LangGraph execution ...\n",
    "\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "\n",
    "# 方案三：已离开上下文，用 trace_id 直接创建评分（适合异步/后台批处理）\n",
    "langfuse.create_score(\n",
    "    trace_id=predefined_trace_id,\n",
    "    name=\"user-feedback\",\n",
    "    value=1,\n",
    "    data_type=\"NUMERIC\",\n",
    "    comment=\"This was correct, thank you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq_DeCcXSxwq"
   },
   "source": [
    "### 在 Langfuse 中查看带评分的追踪\n",
    "\n",
    "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=a7d9c0badaccd67fccf2045c68fb01ec&timestamp=2025-09-23T06%3A37%3A08.963Z\n",
    "\n",
    "![包含评分的追踪展示](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509231502415.png)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
