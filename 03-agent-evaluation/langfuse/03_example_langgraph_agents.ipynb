{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸ”§ ç¯å¢ƒé…ç½®å’Œæ£€æŸ¥\n",
    "\n",
    "#### æ¦‚è¿°\n",
    "\n",
    "æœ¬æ•™ç¨‹éœ€è¦ç‰¹å®šçš„ç¯å¢ƒé…ç½®ä»¥ç¡®ä¿æœ€ä½³å­¦ä¹ ä½“éªŒã€‚ä»¥ä¸‹é…ç½®å°†å¸®åŠ©æ‚¨ï¼š\n",
    "\n",
    "- ä½¿ç”¨ç»Ÿä¸€çš„condaç¯å¢ƒï¼šæ¿€æ´»ç»Ÿä¸€çš„å­¦ä¹ ç¯å¢ƒ\n",
    "- é€šè¿‡å›½å†…é•œåƒæºå¿«é€Ÿå®‰è£…ä¾èµ–ï¼šé…ç½®pipä½¿ç”¨æ¸…åé•œåƒæº\n",
    "- åŠ é€Ÿæ¨¡å‹ä¸‹è½½ï¼šè®¾ç½®HuggingFaceé•œåƒä»£ç†\n",
    "- æ£€æŸ¥ç³»ç»Ÿé…ç½®ï¼šæ£€æŸ¥ç¡¬ä»¶å’Œè½¯ä»¶é…ç½®\n",
    "\n",
    "#### é…ç½®\n",
    "\n",
    "- **æ‰€éœ€ç¯å¢ƒåŠå…¶ä¾èµ–å·²ç»éƒ¨ç½²å¥½**\n",
    "- åœ¨`Notebook`å³ä¸Šè§’é€‰æ‹©`jupyterå†…æ ¸`ä¸º`python(flyai_agent_in_action)`ï¼Œå³å¯æ‰§è¡Œä¸‹æ–¹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /workspace/envs/flyai_agent_in_action\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate flyai_agent_in_action\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"flyai_agent_in_action\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° flyai_agent_in_action ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„ Python å•å…ƒæ ¼å°†ä½¿ç”¨ Notebook å½“å‰é€‰æ‹©çš„ Jupyter å†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(flyai_agent_in_action)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(flyai_agent_in_action)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate flyai_agent_in_action\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "global.index-url='https://pypi.tuna.tsinghua.edu.cn/simple'\n",
      ":env:.target=''\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                  |\n",
      "|:-------------|:----------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux 5.15.0-126-generic                                              |\n",
      "| CPU ä¿¡æ¯     | Intel(R) Xeon(R) Platinum 8468 (48 physical cores, 192 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 2015.36 GB (Available: 1848.40 GB)                                    |\n",
      "| GPU ä¿¡æ¯     | No GPU found (checked nvidia-smi, lshw not found)                     |\n",
      "| CUDA ä¿¡æ¯    | 12.6                                                                  |\n",
      "| Python ç‰ˆæœ¬  | 3.12.11                                                               |\n",
      "| Conda ç‰ˆæœ¬   | conda 25.7.0                                                          |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 2014.78 GB, Used: 787.65 GB, Free: 1124.71 GB                  |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©æ‚¨ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2_SkHQMwIsZ"
   },
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Trace and Evaluate LangGraph Agents\" description: \"This guide shows how to evaluate LangGraph Agents with Langfuse using online and offline evaluation methods.\" category: \"Integrations\" -->\n",
    "\n",
    "# LangGraph ä»£ç†è¿½è¸ªä¸è¯„ä¼°å®Œæ•´æŒ‡å—\n",
    "\n",
    "## ğŸ“– æ•™ç¨‹æ¦‚è¿°\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ å¦‚ä½•ä½¿ç”¨ [Langfuse](https://langfuse.com)ï¼ˆä¸€ä¸ªå¼ºå¤§çš„å¤§æ¨¡å‹å¯è§‚æµ‹æ€§å¹³å°ï¼‰ä¸ [Hugging Face Datasets](https://huggingface.co/datasets)ï¼Œæ¥**å…¨é¢ç›‘æ§ [LangGraph ä»£ç†](https://github.com/langchain-ai/langgraph) çš„æ‰§è¡Œè¿‡ç¨‹ï¼ˆtracesï¼‰**å¹¶**ç§‘å­¦è¯„ä¼°å…¶æ€§èƒ½è¡¨ç°**ã€‚\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨æŒæ¡å°† AI Agentå¿«é€Ÿä¸”å¯é åœ°éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒæ‰€éœ€çš„æ ¸å¿ƒæŠ€èƒ½ï¼š\n",
    "- **åœ¨çº¿è¯„ä¼°**ï¼šå®æ—¶ç›‘æ§ç”Ÿäº§ç¯å¢ƒä¸­çš„ä»£ç†è¡¨ç°\n",
    "- **ç¦»çº¿è¯„ä¼°**ï¼šä½¿ç”¨åŸºå‡†æ•°æ®é›†è¿›è¡Œç³»ç»Ÿæ€§æµ‹è¯•\n",
    "\n",
    "\n",
    "## ğŸ” ä¸ºä»€ä¹ˆ AI Agentè¯„ä¼°å¦‚æ­¤é‡è¦ï¼Ÿ\n",
    "\n",
    "åœ¨ AI Agentå¼€å‘è¿‡ç¨‹ä¸­ï¼Œè¯„ä¼°æ˜¯ç¡®ä¿ç³»ç»Ÿè´¨é‡çš„å…³é”®ç¯èŠ‚ï¼š\n",
    "\n",
    "- **ğŸ› é—®é¢˜è¯Šæ–­**ï¼šå½“ä»£ç†ä»»åŠ¡æ‰§è¡Œå¤±è´¥æˆ–ç»“æœä¸ç†æƒ³æ—¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®šä½é—®é¢˜æ ¹æº\n",
    "- **ğŸ“Š æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶è¿½è¸ªç³»ç»Ÿçš„æˆæœ¬æ¶ˆè€—ã€å“åº”å»¶è¿Ÿç­‰å…³é”®æŒ‡æ ‡\n",
    "- **ğŸ”„ æŒç»­æ”¹è¿›**ï¼šé€šè¿‡ç”¨æˆ·åé¦ˆå’Œè¯„ä¼°æ•°æ®ï¼Œä¸æ–­æå‡ä»£ç†çš„å¯é æ€§ä¸å®‰å…¨æ€§\n",
    "- **ğŸš€ ç”Ÿäº§å°±ç»ª**ï¼šç¡®ä¿ä»£ç†åœ¨çœŸå®ç¯å¢ƒä¸­èƒ½å¤Ÿç¨³å®šè¿è¡Œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzPbsmLrfoSN"
   },
   "source": [
    "## ğŸ› ï¸ æ­¥éª¤ 0ï¼šç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–å®‰è£…\n",
    "\n",
    "### ğŸ“¦ å®‰è£…æ ¸å¿ƒä¾èµ–åº“\n",
    "\n",
    "åœ¨å¼€å§‹æœ¬æ•™ç¨‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹æ ¸å¿ƒåº“ï¼š\n",
    "\n",
    "- **`langgraph`**ï¼šç”¨äºæ„å»ºå¤šèŠ‚ç‚¹ã€çŠ¶æ€é©±åŠ¨çš„ AI Agentå·¥ä½œæµ\n",
    "- **`langfuse`**ï¼šæä¾›å¤§æ¨¡å‹åº”ç”¨çš„å¯è§‚æµ‹æ€§å’Œè¯„ä¼°åŠŸèƒ½  \n",
    "- **`langchain`** ç³»åˆ—ï¼šç”¨äº LLM åº”ç”¨å¼€å‘çš„æ ¸å¿ƒæ¡†æ¶\n",
    "- **`datasets`**ï¼šHugging Face çš„æ•°æ®é›†å¤„ç†åº“\n",
    "\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"âš ï¸\" -->\n",
    "**ğŸ“Œ é‡è¦æç¤ºï¼š**\n",
    "- æœ¬æ•™ç¨‹ä½¿ç”¨ **Langfuse Python SDK v3**ï¼Œå®ƒæä¾›äº†æ›´å¥½çš„æ€§èƒ½å’Œæ–°ç‰¹æ€§\n",
    "- å»ºè®®åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œæœ¬æ•™ç¨‹ä»¥é¿å…ä¾èµ–å†²çª\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "### ğŸ”§ ç¯å¢ƒè¦æ±‚\n",
    "\n",
    "- **Python ç‰ˆæœ¬**ï¼š3.8 æˆ–æ›´é«˜ç‰ˆæœ¬\n",
    "- **æ“ä½œç³»ç»Ÿ**ï¼šæ”¯æŒ Windowsã€macOSã€Linux\n",
    "- **ç½‘ç»œ**ï¼šéœ€è¦è®¿é—® OpenAI API å’Œ Langfuse æœåŠ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqXWStafwIsd"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EI_0ZfzfoSO",
    "outputId": "d4418732-c65a-41cd-a7b3-931838ea85d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langfuse==3.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph==0.6.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.6.7)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain_community==0.3.27 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_huggingface==0.3.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (0.4.31)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (0.2.6)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph==0.6.7) (3.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_community==0.3.27) (2.3.3)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_huggingface==0.3.1) (0.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain_huggingface==0.3.1) (0.35.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (0.9.0)\n",
      "Requirement already satisfied: anyio in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (6.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (1.1.0)\n",
      "Requirement already satisfied: filelock in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain_huggingface==0.3.1) (1.1.10)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /workspace/envs/flyai_agent_in_action/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å®‰è£…æ‰€éœ€çš„PythonåŒ…\n",
    "# ä½¿ç”¨é­”æ³•å‘½ä»¤ %pip åœ¨Jupyterç¯å¢ƒä¸­å®‰è£…ä¾èµ–åº“\n",
    "%pip install langfuse==3.3.0 langchain==0.3.27 langgraph==0.6.7 langchain-openai==0.3.31 langchain_community==0.3.27 langchain_huggingface==0.3.1\n",
    "\n",
    "# å„åº“åŠŸèƒ½è¯´æ˜ï¼š\n",
    "# - langfuse: LLMåº”ç”¨çš„å¯è§‚æµ‹æ€§å’Œè¯„ä¼°å¹³å°\n",
    "# - langchain: å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶\n",
    "# - langgraph: åŸºäºlangchainçš„å›¾å½¢åŒ–å·¥ä½œæµæ„å»ºå·¥å…·\n",
    "# - langchain_openai: OpenAIæ¨¡å‹çš„langchainé›†æˆ\n",
    "# - langchain_community: ç¤¾åŒºè´¡çŒ®çš„langchainæ‰©å±•\n",
    "# - langchain_huggingface: Hugging Faceæ¨¡å‹çš„langchainé›†æˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHRsxz1VfoSP"
   },
   "source": [
    "## ğŸ”‘ æ­¥éª¤ 1ï¼šé…ç½® API å¯†é’¥å’Œç¯å¢ƒå˜é‡\n",
    "\n",
    "### è·å– Langfuse API å¯†é’¥\n",
    "\n",
    "åœ¨å¼€å§‹ä½¿ç”¨ Langfuse ä¹‹å‰ï¼Œæ‚¨éœ€è¦è·å– API è®¿é—®å‡­è¯ï¼š\n",
    "\n",
    "#### æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ Langfuse Cloudï¼ˆæ¨èï¼‰\n",
    "1. è®¿é—® [Langfuse Cloud](https://cloud.langfuse.com) å¹¶æ³¨å†Œè´¦æˆ·\n",
    "2. åˆ›å»ºæ–°é¡¹ç›®æˆ–é€‰æ‹©ç°æœ‰é¡¹ç›®\n",
    "3. åœ¨é¡¹ç›®è®¾ç½®é¡µé¢è·å–ä»¥ä¸‹å¯†é’¥ï¼š\n",
    "   - `LANGFUSE_PUBLIC_KEY`ï¼šä»¥ `pk-lf-` å¼€å¤´çš„å…¬é’¥\n",
    "   - `LANGFUSE_SECRET_KEY`ï¼šä»¥ `sk-lf-` å¼€å¤´çš„ç§é’¥\n",
    "\n",
    "#### æ–¹æ¡ˆäºŒï¼šè‡ªæ‰˜ç®¡ Langfuse\n",
    "å¦‚æœæ‚¨é€‰æ‹©è‡ªæ‰˜ç®¡éƒ¨ç½²ï¼Œè¯·æŒ‰ç…§ [Langfuse è‡ªæ‰˜ç®¡æ–‡æ¡£](https://langfuse.com/docs/deployment/self-host) è¿›è¡Œé…ç½®ã€‚\n",
    "\n",
    "### è·å– OpenAI API å¯†é’¥\n",
    "\n",
    "1. è®¿é—® [OpenAI å¹³å°](https://platform.openai.com/)\n",
    "2. æ³¨å†Œè´¦æˆ·å¹¶å®Œæˆèº«ä»½éªŒè¯\n",
    "3. åœ¨ API å¯†é’¥é¡µé¢åˆ›å»ºæ–°çš„ API å¯†é’¥\n",
    "4. ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿçš„ä½™é¢ç”¨äº API è°ƒç”¨\n",
    "\n",
    "### ğŸ” å®‰å…¨æé†’\n",
    "\n",
    "- **è¯·å‹¿å°† API å¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­**\n",
    "- **ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†ç³»ç»Ÿ**\n",
    "- **å®šæœŸè½®æ¢å¯†é’¥ä»¥æé«˜å®‰å…¨æ€§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZnxtWx9foSP",
    "outputId": "cbabe0f0-49e2-4500-8b9a-b43baaa5cc17"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "OPENAI_BASE_URL:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_PUBLIC_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_SECRET_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "LANGFUSE_HOST:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒå˜é‡é…ç½® - å®‰å…¨å­˜å‚¨æ•æ„Ÿä¿¡æ¯\n",
    "# ç¯å¢ƒå˜é‡æ˜¯å­˜å‚¨APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯çš„æœ€ä½³å®è·µ\n",
    "# é¿å…åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥ï¼Œé˜²æ­¢æ³„éœ²\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    å®‰å…¨åœ°è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥\n",
    "    ä½¿ç”¨getpassæ¨¡å—éšè—è¾“å…¥å†…å®¹ï¼Œé˜²æ­¢å¯†ç æ³„éœ²\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ğŸ¤– OpenAI API é…ç½®\n",
    "# OpenAI APIå¯†é’¥ï¼šä» https://platform.openai.com/api-keys è·å–\n",
    "# è¿™æ˜¯è°ƒç”¨GPTæ¨¡å‹å¿…éœ€çš„è®¤è¯ä¿¡æ¯\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# APIä»£ç†åœ°å€ï¼šå¦‚æœä½ ä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ï¼ˆå¦‚å›½å†…ä»£ç†ï¼‰\n",
    "# ç¤ºä¾‹ï¼šhttps://api.apiyi.com/v1\n",
    "# å¦‚æœç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹APIï¼Œå¯ä»¥ç•™ç©º\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# ğŸŒ Langfuse é…ç½®\n",
    "# Langfuseæ˜¯ä¸€ä¸ªå¯è§‚æµ‹æ€§å¹³å°ï¼Œéœ€è¦æ³¨å†Œè´¦æˆ·è·å–å¯†é’¥\n",
    "# æ³¨å†Œåœ°å€ï¼šhttps://cloud.langfuse.com\n",
    "\n",
    "# å…¬å¼€å¯†é’¥ï¼šç”¨äºæ ‡è¯†ä½ çš„é¡¹ç›®\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# ç§˜å¯†å¯†é’¥ï¼šç”¨äºè®¤è¯ï¼Œè¯·å¦¥å–„ä¿ç®¡\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# æœåŠ¡å™¨åœ°å€ï¼šé€‰æ‹©ç¦»ä½ æœ€è¿‘çš„åŒºåŸŸ\n",
    "# ğŸ‡ªğŸ‡º æ¬§ç›ŸåŒºåŸŸ(æ¨è) https://cloud.langfuse.com\n",
    "# ğŸ‡ºğŸ‡¸ ç¾å›½åŒºåŸŸ https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# ğŸ’¡ åˆå­¦è€…æç¤ºï¼š\n",
    "# 1. ç¯å¢ƒå˜é‡å­˜å‚¨åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œé‡å¯åéœ€è¦é‡æ–°è®¾ç½®\n",
    "# 2. ç”Ÿäº§ç¯å¢ƒä¸­å»ºè®®ä½¿ç”¨.envæ–‡ä»¶æˆ–äº‘æœåŠ¡é…ç½®\n",
    "# 3. æ°¸è¿œä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJjyA41_wIsi"
   },
   "source": [
    "### ğŸ”— è¿æ¥éªŒè¯ä¸å®¢æˆ·ç«¯åˆå§‹åŒ–\n",
    "\n",
    "è®¾ç½®å®Œç¯å¢ƒå˜é‡åï¼Œæˆ‘ä»¬éœ€è¦åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯å¹¶éªŒè¯è¿æ¥ã€‚\n",
    "\n",
    "**æ ¸å¿ƒæ¦‚å¿µè§£é‡Šï¼š**\n",
    "- **`get_client()`**ï¼šLangfuse æä¾›çš„ä¾¿æ·å‡½æ•°ï¼Œä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„å‡­è¯\n",
    "- **å®¢æˆ·ç«¯å®ä¾‹**ï¼šç”¨äºä¸ Langfuse æœåŠ¡å™¨é€šä¿¡çš„å¯¹è±¡\n",
    "- **è¿æ¥éªŒè¯**ï¼šç¡®ä¿ API å¯†é’¥æ­£ç¡®ä¸”ç½‘ç»œè¿æ¥æ­£å¸¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvQRomm-wIsi",
    "outputId": "0fb60071-bc52-4d90-a487-5cb0bf3ff3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Langfuse å®¢æˆ·ç«¯è¿æ¥æˆåŠŸï¼API è®¤è¯é€šè¿‡\n",
      "ğŸ¯ ç°åœ¨å¯ä»¥å¼€å§‹è¿½è¸ªå’Œè¯„ä¼° LLM åº”ç”¨äº†\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¡ å¯¼å…¥ Langfuse å®¢æˆ·ç«¯å¹¶å»ºç«‹è¿æ¥\n",
    "from langfuse import get_client\n",
    "\n",
    "# ğŸ”§ åˆå§‹åŒ– Langfuse å®¢æˆ·ç«¯\n",
    "# get_client() ä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API å‡­è¯\n",
    "langfuse = get_client()\n",
    "\n",
    "# âœ… éªŒè¯ API è¿æ¥å’Œèº«ä»½è®¤è¯\n",
    "# auth_check() æ–¹æ³•ä¼šæµ‹è¯•ä¸ Langfuse æœåŠ¡å™¨çš„è¿æ¥\n",
    "if langfuse.auth_check():\n",
    "    print(\"âœ… Langfuse å®¢æˆ·ç«¯è¿æ¥æˆåŠŸï¼API è®¤è¯é€šè¿‡\")\n",
    "    print(\"ğŸ¯ ç°åœ¨å¯ä»¥å¼€å§‹è¿½è¸ªå’Œè¯„ä¼° LLM åº”ç”¨äº†\")\n",
    "else:\n",
    "    print(\"âŒ è®¤è¯å¤±è´¥ï¼è¯·æ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š\")\n",
    "    print(\"   1. API å¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®\")\n",
    "    print(\"   2. æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®\")\n",
    "    print(\"   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uulS5iGHfoSP"
   },
   "source": [
    "## ğŸ§ª æ­¥éª¤ 2ï¼šæ„å»ºç¬¬ä¸€ä¸ª LangGraph ä»£ç†å¹¶éªŒè¯è¿½è¸ªåŠŸèƒ½\n",
    "\n",
    "### ğŸ’¡ ä»€ä¹ˆæ˜¯è¿½è¸ªï¼ˆTracingï¼‰ï¼Ÿ\n",
    "\n",
    "åœ¨ LLM åº”ç”¨å¼€å‘ä¸­ï¼Œ**è¿½è¸ªï¼ˆTracingï¼‰** æ˜¯æŒ‡è®°å½•åº”ç”¨ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯ï¼š\n",
    "- **æ‰§è¡Œè·¯å¾„**ï¼šä»£ç†æ‰§è¡Œäº†å“ªäº›æ­¥éª¤\n",
    "- **æ€§èƒ½æŒ‡æ ‡**ï¼šæ¯ä¸ªæ­¥éª¤çš„è€—æ—¶ã€ä»¤ç‰Œæ¶ˆè€—ç­‰\n",
    "- **è¾“å…¥è¾“å‡º**ï¼šæ¯ä¸ªç¯èŠ‚çš„è¾“å…¥å’Œè¾“å‡ºå†…å®¹\n",
    "- **é”™è¯¯ä¿¡æ¯**ï¼šå‡ºç°é—®é¢˜æ—¶çš„è¯¦ç»†é”™è¯¯æ—¥å¿—\n",
    "\n",
    "### ğŸ¯ æœ¬èŠ‚ç›®æ ‡\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„é—®ç­”ä»£ç†æ¥éªŒè¯ Langfuse è¿½è¸ªåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚\n",
    "\n",
    "**æŠ€æœ¯è¦ç‚¹ï¼š**\n",
    "- ä½¿ç”¨ **LangGraph** æ„å»ºçŠ¶æ€é©±åŠ¨çš„ä»£ç†å·¥ä½œæµ\n",
    "- é€šè¿‡ **CallbackHandler** å®ç°è‡ªåŠ¨è¿½è¸ª\n",
    "- åœ¨ Langfuse ä»ªè¡¨æ¿ä¸­æŸ¥çœ‹æ‰§è¡Œè®°å½•\n",
    "\n",
    "ğŸ” **è¿è¡ŒæˆåŠŸæ ‡å¿—**ï¼šå¦‚æœé…ç½®æ­£ç¡®ï¼Œæ‚¨å°†åœ¨ [Langfuse è¿½è¸ªä»ªè¡¨æ¿](https://cloud.langfuse.com/traces) ä¸­çœ‹åˆ°è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcyynS9CfoSP",
    "outputId": "9092ae17-ff79-442e-d274-2de3e921fd41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç®€å•é—®ç­”ä»£ç†æ„å»ºå®Œæˆï¼\n",
      "ğŸ”§ ä»£ç†æ¶æ„ï¼šè¾“å…¥ â†’ ChatBotèŠ‚ç‚¹ â†’ è¾“å‡º\n",
      "ğŸ“ æ”¯æŒåŠŸèƒ½ï¼šåŸºæœ¬é—®ç­”ã€ä¸Šä¸‹æ–‡ç†è§£\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ æ„å»ºç®€å•çš„ LangGraph é—®ç­”ä»£ç†\n",
    "\n",
    "# ğŸ“¦ å¯¼å…¥å¿…è¦çš„ç±»å‹å’Œå·¥å…·\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ğŸ”§ å®šä¹‰ä»£ç†çš„çŠ¶æ€ç»“æ„\n",
    "class State(TypedDict):\n",
    "    # messages å­—æ®µå­˜å‚¨å¯¹è¯å†å²ï¼Œç±»å‹ä¸ºåˆ—è¡¨\n",
    "    # Annotated[list, add_messages] å®šä¹‰äº†çŠ¶æ€æ›´æ–°çš„æ–¹å¼ï¼š\n",
    "    # - list: æ•°æ®ç±»å‹ä¸ºåˆ—è¡¨\n",
    "    # - add_messages: æ›´æ–°æ—¶è¿½åŠ æ¶ˆæ¯è€Œä¸æ˜¯è¦†ç›–ï¼ˆä¿æŒå¯¹è¯å†å²ï¼‰\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ åˆ›å»ºçŠ¶æ€å›¾æ„å»ºå™¨\n",
    "# StateGraph æ˜¯ LangGraph çš„æ ¸å¿ƒç±»ï¼Œç”¨äºæ„å»ºçŠ¶æ€é©±åŠ¨çš„å·¥ä½œæµ\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ğŸ¤– åˆå§‹åŒ– OpenAI è¯­è¨€æ¨¡å‹\n",
    "# - model: ä½¿ç”¨ GPT-4o æ¨¡å‹ï¼ˆæ€§èƒ½å¼ºå¤§ä¸”æˆæœ¬é€‚ä¸­ï¼‰\n",
    "# - temperature: è®¾ç½®ä¸º 0.2ï¼Œè¾“å‡ºç›¸å¯¹ç¨³å®šä½†ä¿æŒä¸€å®šåˆ›é€ æ€§\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# ğŸ’¬ å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹å‡½æ•°\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    èŠå¤©æœºå™¨äººçš„æ ¸å¿ƒé€»è¾‘\n",
    "\n",
    "    å‚æ•°:\n",
    "        state: å½“å‰çš„å¯¹è¯çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²\n",
    "\n",
    "    è¿”å›:\n",
    "        åŒ…å«æ–°æ¶ˆæ¯çš„å­—å…¸ï¼Œä¼šè¢«è‡ªåŠ¨åˆå¹¶åˆ°çŠ¶æ€ä¸­\n",
    "    \"\"\"\n",
    "    # è°ƒç”¨ LLM å¤„ç†å½“å‰æ‰€æœ‰æ¶ˆæ¯ï¼Œå¹¶è¿”å›å›å¤\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ğŸ”— æ„å»ºå·¥ä½œæµå›¾ç»“æ„\n",
    "# 1. æ·»åŠ èŠ‚ç‚¹ï¼šæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªå·¥ä½œå•å…ƒï¼ˆé€šå¸¸æ˜¯ Python å‡½æ•°ï¼‰\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 2. è®¾ç½®å…¥å£ç‚¹ï¼šå‘Šè¯‰å›¾ä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# 3. è®¾ç½®ç»“æŸç‚¹ï¼šå®šä¹‰å·¥ä½œæµçš„ç»ˆæ­¢æ¡ä»¶\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# âš™ï¸ ç¼–è¯‘å›¾ä»¥è·å¾—å¯æ‰§è¡Œçš„ä»£ç†\n",
    "# compile() æ–¹æ³•å°†å›¾å®šä¹‰è½¬æ¢ä¸ºå¯è¿è¡Œçš„ CompiledGraph å¯¹è±¡\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ… ç®€å•é—®ç­”ä»£ç†æ„å»ºå®Œæˆï¼\")\n",
    "print(\"ğŸ”§ ä»£ç†æ¶æ„ï¼šè¾“å…¥ â†’ ChatBotèŠ‚ç‚¹ â†’ è¾“å‡º\")\n",
    "print(\"ğŸ“ æ”¯æŒåŠŸèƒ½ï¼šåŸºæœ¬é—®ç­”ã€ä¸Šä¸‹æ–‡ç†è§£\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLXIdYuwwIsi",
    "outputId": "38e19edf-0627-4974-88b2-5ec7fa350611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹è¿è¡Œä»£ç†å¹¶å¯ç”¨ Langfuse è¿½è¸ª...\n",
      "â“ ç”¨æˆ·é—®é¢˜ï¼šLangfuseæ˜¯ä»€ä¹ˆï¼Œåº”ç”¨åœºæ™¯æ˜¯?\n",
      "ğŸ“Š è¿½è¸ªä¿¡æ¯å°†å‘é€åˆ° Langfuse å¹³å°\n",
      "--------------------------------------------------\n",
      "ğŸ“¥ ä»£ç†æ‰§è¡Œæ­¥éª¤: {'chatbot': {'messages': [AIMessage(content='Langfuse æ˜¯ä¸€ä¸ªç”¨äºç›‘æ§å’Œè°ƒè¯•ç”Ÿæˆå¼ AI åº”ç”¨ç¨‹åºçš„å·¥å…·ã€‚å®ƒå¯ä»¥å¸®åŠ©å¼€å‘è€…è·Ÿè¸ªå’Œåˆ†æä¸ç”Ÿæˆå¼ AI æ¨¡å‹ï¼ˆå¦‚ OpenAI çš„ GPT-3 æˆ–å…¶ä»–ç±»ä¼¼æ¨¡å‹ï¼‰çš„äº¤äº’ã€‚Langfuse æä¾›äº†å¯è§†åŒ–ç•Œé¢ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æ¨¡å‹çš„è¡Œä¸ºã€æ€§èƒ½ä»¥åŠç”¨æˆ·ä¸æ¨¡å‹çš„äº¤äº’æƒ…å†µã€‚\\n\\nåº”ç”¨åœºæ™¯åŒ…æ‹¬ï¼š\\n\\n1. **è°ƒè¯•ç”Ÿæˆå¼ AI åº”ç”¨**ï¼šå¼€å‘è€…å¯ä»¥ä½¿ç”¨ Langfuse æ¥ç›‘æ§æ¨¡å‹çš„è¾“å‡ºï¼Œè¯†åˆ«æ½œåœ¨çš„é—®é¢˜ï¼Œå¹¶è¿›è¡Œè°ƒè¯•å’Œä¼˜åŒ–ã€‚\\n\\n2. **æ€§èƒ½åˆ†æ**ï¼šé€šè¿‡åˆ†ææ¨¡å‹çš„å“åº”æ—¶é—´å’Œå‡†ç¡®æ€§ï¼Œå¼€å‘è€…å¯ä»¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚\\n\\n3. **ç”¨æˆ·äº¤äº’åˆ†æ**ï¼šLangfuse å¯ä»¥å¸®åŠ©å¼€å‘è€…äº†è§£ç”¨æˆ·å¦‚ä½•ä¸ AI åº”ç”¨äº¤äº’ï¼Œä»è€Œæ”¹è¿›åº”ç”¨çš„è®¾è®¡å’ŒåŠŸèƒ½ã€‚\\n\\n4. **å®‰å…¨å’Œåˆè§„æ€§**ï¼šé€šè¿‡ç›‘æ§å’Œè®°å½•æ¨¡å‹çš„è¾“å‡ºï¼Œå¼€å‘è€…å¯ä»¥ç¡®ä¿åº”ç”¨ç¬¦åˆç›¸å…³çš„å®‰å…¨å’Œåˆè§„æ€§è¦æ±‚ã€‚\\n\\næ€»ä¹‹ï¼ŒLangfuse æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œé€‚ç”¨äºä»»ä½•éœ€è¦ç›‘æ§å’Œä¼˜åŒ–ç”Ÿæˆå¼ AI åº”ç”¨çš„åœºæ™¯ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 251, 'prompt_tokens': 17, 'total_tokens': 268, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_8458c98457', 'id': 'chatcmpl-CLQquIiGcpreLADevFjhJ0sX4Ou5M', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--df3efe01-6bcf-4f03-9a73-8975d4ebf095-0', usage_metadata={'input_tokens': 17, 'output_tokens': 251, 'total_tokens': 268, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "--------------------------------------------------\n",
      "âœ… ä»£ç†æ‰§è¡Œå®Œæˆï¼\n",
      "ğŸ”— è¯·è®¿é—® Langfuse ä»ªè¡¨æ¿æŸ¥çœ‹è¯¦ç»†è¿½è¸ªä¿¡æ¯\n",
      "ğŸ“ é“¾æ¥: https://cloud.langfuse.com/traces\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” å¯ç”¨ Langfuse è¿½è¸ªå¹¶è¿è¡Œä»£ç†\n",
    "\n",
    "# ğŸ“¡ å¯¼å…¥ Langfuse çš„ LangChain å›è°ƒå¤„ç†å™¨\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ¯ åˆå§‹åŒ– Langfuse è¿½è¸ªå¤„ç†å™¨\n",
    "# CallbackHandler ä¼šè‡ªåŠ¨æ•è· LangChain/LangGraph çš„æ‰§è¡Œä¿¡æ¯\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹è¿è¡Œä»£ç†å¹¶å¯ç”¨ Langfuse è¿½è¸ª...\")\n",
    "print(\"â“ ç”¨æˆ·é—®é¢˜ï¼šLangfuseæ˜¯ä»€ä¹ˆï¼Œåº”ç”¨åœºæ™¯æ˜¯?\")\n",
    "print(\"ğŸ“Š è¿½è¸ªä¿¡æ¯å°†å‘é€åˆ° Langfuse å¹³å°\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ğŸƒ è¿è¡Œä»£ç†å¹¶å¯ç”¨è¿½è¸ª\n",
    "# stream() æ–¹æ³•å…è®¸å®æ—¶æ¥æ”¶ä»£ç†çš„æ‰§è¡Œç»“æœ\n",
    "for step_result in graph.stream(\n",
    "    # è¾“å…¥ï¼šåŒ…å«ç”¨æˆ·æ¶ˆæ¯çš„çŠ¶æ€\n",
    "    {\"messages\": [HumanMessage(content=\"Langfuseæ˜¯ä»€ä¹ˆï¼Œåº”ç”¨åœºæ™¯æ˜¯?\")]},\n",
    "    # é…ç½®ï¼šå¯ç”¨ Langfuse å›è°ƒå¤„ç†å™¨è¿›è¡Œè¿½è¸ª\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    print(f\"ğŸ“¥ ä»£ç†æ‰§è¡Œæ­¥éª¤: {step_result}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"âœ… ä»£ç†æ‰§è¡Œå®Œæˆï¼\")\n",
    "print(\"ğŸ”— è¯·è®¿é—® Langfuse ä»ªè¡¨æ¿æŸ¥çœ‹è¯¦ç»†è¿½è¸ªä¿¡æ¯\")\n",
    "print(\"ğŸ“ é“¾æ¥: https://cloud.langfuse.com/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPLt1hRkfoSQ"
   },
   "source": [
    "### ğŸ” éªŒè¯è¿½è¸ªåŠŸèƒ½ï¼šæŸ¥çœ‹ Langfuse ä»ªè¡¨æ¿\n",
    "\n",
    "#### ğŸ“Š å¦‚ä½•æ£€æŸ¥è¿½è¸ªè®°å½•\n",
    "\n",
    "è¿è¡Œä¸Šè¿°ä»£ç åï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤éªŒè¯è¿½è¸ªåŠŸèƒ½ï¼š\n",
    "\n",
    "1. **è®¿é—®ä»ªè¡¨æ¿**ï¼šæ‰“å¼€ [Langfuse è¿½è¸ªä»ªè¡¨æ¿](https://cloud.langfuse.com/traces)\n",
    "2. **æŸ¥æ‰¾è®°å½•**ï¼šåœ¨è¿½è¸ªåˆ—è¡¨ä¸­æ‰¾åˆ°åˆšæ‰çš„æ‰§è¡Œè®°å½•\n",
    "3. **åˆ†ææ•°æ®**ï¼šç‚¹å‡»è®°å½•æŸ¥çœ‹è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯\n",
    "\n",
    "#### ğŸ”¬ è¿½è¸ªè®°å½•åŒ…å«ä»€ä¹ˆä¿¡æ¯ï¼Ÿ\n",
    "\n",
    "åœ¨ Langfuse ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹é‡è¦ä¿¡æ¯ï¼š\n",
    "\n",
    "- **ğŸ“ Spansï¼ˆè·¨åº¦ï¼‰**ï¼šæ¯ä¸ªæ‰§è¡Œæ­¥éª¤çš„è¯¦ç»†è®°å½•\n",
    "- **ğŸ“‹ Logsï¼ˆæ—¥å¿—ï¼‰**ï¼šæ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ—¥å¿—ä¿¡æ¯  \n",
    "- **â±ï¸ æ—¶é—´æˆ³**ï¼šæ¯ä¸ªæ­¥éª¤çš„ç²¾ç¡®æ‰§è¡Œæ—¶é—´\n",
    "- **ğŸ’° æˆæœ¬ä¿¡æ¯**ï¼šAPI è°ƒç”¨çš„ä»¤ç‰Œæ¶ˆè€—å’Œè´¹ç”¨\n",
    "- **ğŸ“Š æ€§èƒ½æŒ‡æ ‡**ï¼šå»¶è¿Ÿã€ååé‡ç­‰å…³é”®æŒ‡æ ‡\n",
    "\n",
    "#### ğŸ“¸ Langfuse ä¸­çš„ç¤ºä¾‹è¿½è¸ªæˆªå›¾\n",
    "\n",
    "![Langfuse ä¸­çš„ç¤ºä¾‹è¿½è¸ª](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251551391.png)\n",
    "\n",
    "ğŸ’¡ **å°æç¤º**ï¼šè¿½è¸ªè®°å½•å¯èƒ½éœ€è¦å‡ ç§’é’Ÿæ‰èƒ½åœ¨ä»ªè¡¨æ¿ä¸­æ˜¾ç¤ºï¼Œè¯·ç¨ä½œç­‰å¾…ã€‚\n",
    "\n",
    "ğŸ”— _[æŸ¥çœ‹ç¤ºä¾‹è¿½è¸ªè®°å½•](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=6efb8472addcad81fa932915e6a5eff2&timestamp=2025-09-25T07%3A48%3A04.647Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onjMD-ZJfoSQ"
   },
   "source": [
    "## ğŸ”¬ æ­¥éª¤ 3ï¼šæ„å»ºå¹¶è§‚æµ‹å¤æ‚çš„é‚®ä»¶å¤„ç†ä»£ç†\n",
    "\n",
    "### ğŸ¯ è¿›é˜¶å®æˆ˜ï¼šçœŸå®ä¸šåŠ¡åœºæ™¯æ¨¡æ‹Ÿ\n",
    "\n",
    "æ—¢ç„¶å·²ç¡®è®¤åŸºç¡€è¿½è¸ªåŠŸèƒ½æœ‰æ•ˆï¼Œç°åœ¨æˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ªæ›´åŠ å¤æ‚ä¸”è´´è¿‘å®é™…ä¸šåŠ¡åœºæ™¯çš„ä»£ç†ç³»ç»Ÿã€‚\n",
    "\n",
    "### ğŸ“§ ä¸šåŠ¡åœºæ™¯ï¼šæ™ºèƒ½é‚®ä»¶ç®¡ç†åŠ©æ‰‹\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª**é‚®ä»¶å¤„ç†ä»£ç†**ï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "\n",
    "#### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—\n",
    "- **ğŸ“¬ é‚®ä»¶æ¥æ”¶**ï¼šè¯»å–å’Œè§£æé‚®ä»¶å†…å®¹\n",
    "- **ğŸ” åƒåœ¾é‚®ä»¶è¯†åˆ«**ï¼šæ™ºèƒ½åˆ¤æ–­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶\n",
    "- **ğŸ—‚ï¸ è‡ªåŠ¨åˆ†ç±»**ï¼šå¯¹åˆæ³•é‚®ä»¶è¿›è¡Œåˆ†ç±»å¤„ç†\n",
    "- **âœï¸ å›å¤èµ·è‰**ï¼šä¸ºé‡è¦é‚®ä»¶ç”Ÿæˆå›å¤è‰ç¨¿\n",
    "- **ğŸ“¢ é€šçŸ¥ä¸»äºº**ï¼šå‘éŸ¦æ©å…ˆç”Ÿæ±‡æŠ¥é‡è¦é‚®ä»¶\n",
    "\n",
    "#### ğŸ“Š è¿½è¸ªçš„é«˜çº§æŒ‡æ ‡\n",
    "\n",
    "é€šè¿‡è¿™ä¸ªå¤æ‚ä»£ç†ï¼Œæˆ‘ä»¬å°†è§‚å¯Ÿä»¥ä¸‹å…³é”®æŒ‡æ ‡ï¼š\n",
    "- **ğŸ’° æˆæœ¬è¿½è¸ª**ï¼šè¯¦ç»†çš„ä»¤ç‰Œæ¶ˆè€—å’Œ API è´¹ç”¨\n",
    "- **â±ï¸ æ€§èƒ½åˆ†æ**ï¼šæ¯ä¸ªå¤„ç†æ­¥éª¤çš„è€—æ—¶åˆ†å¸ƒ\n",
    "- **ğŸ”„ å·¥ä½œæµè·¯å¾„**ï¼šä»£ç†çš„å†³ç­–é€»è¾‘å’Œæ‰§è¡Œè·¯å¾„\n",
    "- **âŒ é”™è¯¯ç›‘æ§**ï¼šå¼‚å¸¸æƒ…å†µçš„æ•è·å’Œåˆ†æ\n",
    "\n",
    "### ğŸ—ï¸ æŠ€æœ¯æ¶æ„ç‰¹ç‚¹\n",
    "\n",
    "- **çŠ¶æ€é©±åŠ¨**ï¼šä½¿ç”¨ LangGraph çš„çŠ¶æ€ç®¡ç†æœºåˆ¶\n",
    "- **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®é‚®ä»¶ç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘\n",
    "- **å¤šèŠ‚ç‚¹åä½œ**ï¼šæ¨¡æ‹ŸçœŸå®çš„ä¸šåŠ¡å¤„ç†æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhZyuiZNwIsj",
    "outputId": "66f2befe-309e-4f09-d675-405a64dcebbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š åº“å¯¼å…¥å®Œæˆï¼Œå‡†å¤‡æ„å»ºé‚®ä»¶å¤„ç†ä»£ç†...\n",
      "ğŸ”§ å³å°†ä½¿ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼š\n",
      "   - StateGraph: æ„å»ºçŠ¶æ€é©±åŠ¨çš„å·¥ä½œæµ\n",
      "   - ChatOpenAI: è°ƒç”¨ GPT æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¤„ç†\n",
      "   - TypedDict: å®šä¹‰ä¸¥æ ¼çš„æ•°æ®ç»“æ„\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ å¯¼å…¥æ„å»ºå¤æ‚ä»£ç†æ‰€éœ€çš„åº“\n",
    "\n",
    "import os  # æ“ä½œç³»ç»Ÿæ¥å£ï¼Œç”¨äºç¯å¢ƒå˜é‡ç®¡ç†\n",
    "from typing import TypedDict, List, Dict, Any, Optional  # ç±»å‹æ³¨è§£ï¼Œæé«˜ä»£ç å¯è¯»æ€§å’ŒIDEæ”¯æŒ\n",
    "from langgraph.graph import StateGraph, START, END  # LangGraphæ ¸å¿ƒç»„ä»¶ï¼šçŠ¶æ€å›¾ã€å¼€å§‹èŠ‚ç‚¹ã€ç»“æŸèŠ‚ç‚¹\n",
    "from langchain_openai import ChatOpenAI  # OpenAIæ¨¡å‹çš„LangChainé›†æˆ\n",
    "from langchain_core.messages import HumanMessage  # LangChainæ¶ˆæ¯ç±»å‹\n",
    "\n",
    "print(\"ğŸ“š åº“å¯¼å…¥å®Œæˆï¼Œå‡†å¤‡æ„å»ºé‚®ä»¶å¤„ç†ä»£ç†...\")\n",
    "print(\"ğŸ”§ å³å°†ä½¿ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼š\")\n",
    "print(\"   - StateGraph: æ„å»ºçŠ¶æ€é©±åŠ¨çš„å·¥ä½œæµ\")\n",
    "print(\"   - ChatOpenAI: è°ƒç”¨ GPT æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¤„ç†\")\n",
    "print(\"   - TypedDict: å®šä¹‰ä¸¥æ ¼çš„æ•°æ®ç»“æ„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbdEGxUQwIsj",
    "outputId": "f37e46ee-8c8e-467e-8fe9-7953eeb071b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é‚®ä»¶çŠ¶æ€ç»“æ„å®šä¹‰å®Œæˆ\n",
      "ğŸ“‹ çŠ¶æ€å­—æ®µè¯´æ˜ï¼š\n",
      "   - email: åŸå§‹é‚®ä»¶æ•°æ®\n",
      "   - is_spam: åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœ\n",
      "   - draft_response: å›å¤è‰ç¨¿\n",
      "   - messages: LLMå¯¹è¯å†å²\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ï¸ å®šä¹‰é‚®ä»¶å¤„ç†ä»£ç†çš„çŠ¶æ€ç»“æ„\n",
    "\n",
    "class EmailState(TypedDict):\n",
    "    \"\"\"\n",
    "    é‚®ä»¶å¤„ç†ä»£ç†çš„çŠ¶æ€æ•°æ®ç»“æ„\n",
    "\n",
    "    è¿™ä¸ªç±»å®šä¹‰äº†ä»£ç†åœ¨å¤„ç†é‚®ä»¶è¿‡ç¨‹ä¸­éœ€è¦ç»´æŠ¤çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # ğŸ“§ åŸå§‹é‚®ä»¶ä¿¡æ¯\n",
    "    email: Dict[str, Any]  # åŒ…å«å‘ä»¶äººã€ä¸»é¢˜ã€æ­£æ–‡ç­‰é‚®ä»¶å®Œæ•´ä¿¡æ¯\n",
    "\n",
    "    # ğŸ” åƒåœ¾é‚®ä»¶æ£€æµ‹ç»“æœ\n",
    "    is_spam: Optional[bool]  # æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ï¼ˆTrue/False/Noneï¼‰\n",
    "    spam_reason: Optional[str]  # åˆ¤å®šä¸ºåƒåœ¾é‚®ä»¶çš„åŸå› è¯´æ˜\n",
    "\n",
    "    # ğŸ—‚ï¸ é‚®ä»¶åˆ†ç±»ä¿¡æ¯\n",
    "    email_category: Optional[str]  # é‚®ä»¶ç±»åˆ«ï¼ˆå¦‚ï¼šå•†åŠ¡ã€ä¸ªäººã€ç´§æ€¥ç­‰ï¼‰\n",
    "\n",
    "    # âœï¸ å›å¤è‰ç¨¿\n",
    "    draft_response: Optional[str]  # ä¸ºä¸»äººå‡†å¤‡çš„å›å¤è‰ç¨¿\n",
    "\n",
    "    # ğŸ’¬ å¯¹è¯å†å²è®°å½•\n",
    "    messages: List[Dict[str, Any]]  # å­˜å‚¨å¤„ç†è¿‡ç¨‹ä¸­çš„LLMå¯¹è¯è®°å½•\n",
    "\n",
    "print(\"âœ… é‚®ä»¶çŠ¶æ€ç»“æ„å®šä¹‰å®Œæˆ\")\n",
    "print(\"ğŸ“‹ çŠ¶æ€å­—æ®µè¯´æ˜ï¼š\")\n",
    "print(\"   - email: åŸå§‹é‚®ä»¶æ•°æ®\")\n",
    "print(\"   - is_spam: åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœ\")\n",
    "print(\"   - draft_response: å›å¤è‰ç¨¿\")\n",
    "print(\"   - messages: LLMå¯¹è¯å†å²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdo7y_0mwIsj",
    "outputId": "08199035-52cb-4553-cbbb-738aa5b2e4c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f2fd464f860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œåç»­æ‰€æœ‰èŠ‚ç‚¹éƒ½ä¼šå¤ç”¨å®ƒè¿›è¡Œæ¨ç†\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ğŸ§± åœ¨è¿è¡Œå®é™…å›¾ä¹‹å‰å†æ¬¡å®šä¹‰çŠ¶æ€ç»“æ„ï¼Œç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹èƒ½æ‹¿åˆ°è‡ªå·±éœ€è¦çš„æ•°æ®\n",
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]            # ğŸ“¬ å½“å‰å¾…å¤„ç†çš„åŸå§‹é‚®ä»¶å†…å®¹ï¼ˆå‘ä»¶äººã€ä¸»é¢˜ã€æ­£æ–‡ï¼‰\n",
    "    is_spam: Optional[bool]          # ğŸš¨ åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœï¼ŒNone è¡¨ç¤ºå°šæœªåˆ¤å®š\n",
    "    draft_response: Optional[str]    # âœï¸ Alfred èµ·è‰çš„å›å¤å†…å®¹\n",
    "    messages: List[Dict[str, Any]]   # ğŸ—’ï¸ LangChain å¯¹è¯å†å²ï¼Œç”¨æ¥è®°å½•æ¨¡å‹è°ƒç”¨\n",
    "\n",
    "# ğŸ” å®šä¹‰å·¥ä½œæµä¸­çš„æ¯ä¸ªèŠ‚ç‚¹å‡½æ•°\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    å…¥å£èŠ‚ç‚¹ï¼šå±•ç¤ºé‚®ä»¶åŸºç¡€ä¿¡æ¯ï¼Œå¸®åŠ©æˆ‘ä»¬åœ¨å‘½ä»¤è¡Œä¸­è§‚å¯Ÿæµç¨‹ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]  # ä»çŠ¶æ€ä¸­å–å‡ºå½“å‰é‚®ä»¶\n",
    "    print(f\"é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª {email['sender']} çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼š{email['subject']}\")\n",
    "    return {}  # èŠ‚ç‚¹åªåšå±•ç¤ºï¼Œä¸ä¿®æ”¹çŠ¶æ€\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ LLM åˆ¤æ–­å½“å‰é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
    "    å¦‚æœæ˜¯åƒåœ¾é‚®ä»¶å°±ä¸è®°å½•æ¨¡å‹å¯¹è¯ï¼Œé¿å…æ±¡æŸ“å†å²ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # æ„é€ æç¤ºè¯ï¼Œå‘ LLM ä¼ å…¥é‚®ä»¶çš„æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼ˆä¸­æ–‡åˆå­¦è€…å‹å¥½ç‰ˆæœ¬ï¼‰\n",
    "    prompt = f\"\"\"\n",
    "è¯·ä»¥é˜¿å°”å¼—é›·å¾·ï¼ˆAlfredï¼ŒéŸ¦æ©å…ˆç”Ÿçš„ç®¡å®¶ï¼ŒåŒæ—¶çŸ¥æ™“å…¶â€œè™è ä¾ â€èº«ä»½ï¼‰çš„è§†è§’ï¼Œåˆ†æä¸‹é¢è¿™å°é‚®ä»¶ï¼Œåˆ¤æ–­å…¶æ˜¯åƒåœ¾é‚®ä»¶ï¼ˆSPAMï¼‰è¿˜æ˜¯æ­£å¸¸é‚®ä»¶ï¼ˆHAMï¼‰ï¼Œå¹¶è¯´æ˜æ˜¯å¦éœ€è¦æé†’éŸ¦æ©å…ˆç”Ÿæ³¨æ„ã€‚\n",
    "\n",
    "é‚®ä»¶å†…å®¹ï¼š\n",
    "å‘ä»¶äººï¼ˆFromï¼‰ï¼š{email['sender']}\n",
    "ä¸»é¢˜ï¼ˆSubjectï¼‰ï¼š{email['subject']}\n",
    "æ­£æ–‡ï¼ˆBodyï¼‰ï¼š{email['body']}\n",
    "\n",
    "è¯·å…ˆåˆ¤æ–­è¿™å°é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
    "åªè¿”å›ä¸€ä¸ªè‹±æ–‡å•è¯ä½œä¸ºæœ€ç»ˆç­”æ¡ˆï¼šè‹¥æ˜¯åƒåœ¾é‚®ä»¶ï¼Œè¿”å›â€œSPAMâ€ï¼›è‹¥æ˜¯æ­£å¸¸é‚®ä»¶ï¼Œè¿”å›â€œHAMâ€ã€‚ä¸è¦è¾“å‡ºå¤šä½™æ–‡å­—ã€‚\n",
    "ç­”æ¡ˆï¼š\n",
    "    \"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]  # LangChain è¦æ±‚ä¼ å…¥ HumanMessage å¯¹è±¡\n",
    "    response = model.invoke(messages)  # è°ƒç”¨ LLM è·å¾—åˆ¤å®šç»“æœ\n",
    "\n",
    "    response_text = response.content.lower()  # ç»Ÿä¸€è½¬å°å†™ï¼Œä¾¿äºå…³é”®è¯åŒ¹é…\n",
    "    print(response_text)  # åœ¨æ§åˆ¶å°è¾“å‡ºï¼Œæ–¹ä¾¿æˆ‘ä»¬è°ƒè¯•å’Œè§‚å¯Ÿ\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text  # åŒæ—¶æ’é™¤åŒæ—¶å‡ºç° spam/ham çš„æƒ…å†µ\n",
    "\n",
    "    if not is_spam:\n",
    "        # å¦‚æœä¸æ˜¯åƒåœ¾é‚®ä»¶ï¼Œå°±å°†æœ¬æ¬¡é—®ç­”è¿½åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else:\n",
    "        # åƒåœ¾é‚®ä»¶æ— éœ€è®°å½•ä¸Šä¸‹æ–‡ï¼Œä¿æŒåŸæœ‰çš„æ¶ˆæ¯è®°å½•\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,       # æŠŠåƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœå†™å›çŠ¶æ€\n",
    "        \"messages\": new_messages  # åŒæ­¥å¯¹è¯å†å²\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"\n",
    "    åƒåœ¾é‚®ä»¶åˆ†æ”¯ï¼šè¿™é‡Œåªæ¼”ç¤ºæ‰“å°æç¤ºè¯­ï¼ŒçœŸå®é¡¹ç›®å¯ä»¥å†™å…¥æ•°æ®åº“æˆ–æŠ¥è­¦ã€‚\n",
    "    \"\"\"\n",
    "    print(\"é˜¿å°”å¼—é›·å¾·å·²ç»å°†é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶ã€‚\")\n",
    "    print(\"è¯¥ç”µå­é‚®ä»¶å·²è¢«ç§»è‡³åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\")\n",
    "    return {}  # è¿”å›ç©ºå­—å…¸è¡¨ç¤ºä¸ä¿®æ”¹çŠ¶æ€å­—æ®µ\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    \"\"\"\n",
    "    åˆæ³•é‚®ä»¶åˆ†æ”¯ï¼šè®© LLM å¸®å¿™æ’°å†™ä¸€ä»½ç¤¼è²Œçš„å›å¤è‰ç¨¿ã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # ç»´æŒæç¤ºè¯ï¼Œæ˜ç¡®è¾“å‡ºè¯­æ°”å’Œéœ€è¦è¦†ç›–çš„å…³é”®å†…å®¹ï¼ˆä¸­æ–‡åˆå­¦è€…å‹å¥½ç‰ˆæœ¬ï¼‰\n",
    "    prompt = f\"\"\"\n",
    "è¯·ä»¥é˜¿å°”å¼—é›·å¾·ï¼ˆAlfredï¼ŒéŸ¦æ©å…ˆç”Ÿçš„ç®¡å®¶ï¼‰çš„å£å»ï¼Œä¸ºä¸‹é¢è¿™å°é‚®ä»¶èµ·è‰ä¸€ä»½ç¤¼è²Œã€ç®€æ´ä¸”ä¸“ä¸šçš„åˆç¨¿å›å¤ã€‚\n",
    "\n",
    "é‚®ä»¶å†…å®¹ï¼š\n",
    "å‘ä»¶äººï¼ˆFromï¼‰ï¼š{email['sender']}\n",
    "ä¸»é¢˜ï¼ˆSubjectï¼‰ï¼š{email['subject']}\n",
    "æ­£æ–‡ï¼ˆBodyï¼‰ï¼š{email['body']}\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€æ®µç®€çŸ­ã€ä¸“ä¸šã€è¯­æ°”å‹å–„çš„ä¸­æ–‡å›å¤è‰ç¨¿ï¼Œä¾›éŸ¦æ©å…ˆç”Ÿå®¡é˜…å¹¶åœ¨å‘é€å‰ä¸ªæ€§åŒ–æ¶¦è‰²ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # å°†æœ€æ–°çš„é—®ç­”è¿½åŠ åˆ°å¯¹è¯å†å²é‡Œï¼Œä¿æŒä¸Šä¸‹æ–‡å®Œæ•´\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"draft_response\": response.content,  # ä¿å­˜ç”Ÿæˆçš„é‚®ä»¶è‰ç¨¿\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    \"\"\"\n",
    "    æ”¶å°¾èŠ‚ç‚¹ï¼šæ¨¡æ‹Ÿå‘å¸ƒé²æ–¯Â·éŸ¦æ©æ±‡æŠ¥é‚®ä»¶å¤„ç†ç»“æœã€‚\n",
    "    \"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    print(\"\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"I've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\")\n",
    "\n",
    "    return {}\n",
    "\n",
    "# ğŸ§­ è·¯ç”±é€»è¾‘ï¼šæ ¹æ®åƒåœ¾é‚®ä»¶åˆ¤å®šé€‰æ‹©ä¸‹ä¸€æ­¥çš„åˆ†æ”¯\n",
    "def route_email(state: EmailState) -> str:\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "# ğŸ› ï¸ åˆ›å»ºçŠ¶æ€å›¾ï¼Œå°†ä¸Šé¢å®šä¹‰çš„èŠ‚ç‚¹ä¸²è”æˆä¸€ä¸ª LangGraph å·¥ä½œæµ\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# ğŸ“Œ æ³¨å†ŒèŠ‚ç‚¹â€”â€”æ¯ä¸€è¡Œéƒ½ä¼šæŠŠå‡½æ•°å˜æˆå›¾é‡Œçš„ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹\n",
    "email_graph.add_node(\"read_email\", read_email)  # é¦–å…ˆè¯»å–å¹¶å±•ç¤ºé‚®ä»¶ä¿¡æ¯\n",
    "email_graph.add_node(\"classify_email\", classify_email)  # ç„¶åè¯· LLM åˆ¤å®šåƒåœ¾é‚®ä»¶\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)  # åƒåœ¾é‚®ä»¶èµ°å•ç‹¬çš„å¤„ç†åˆ†æ”¯\n",
    "email_graph.add_node(\"drafting_response\", drafting_response)  # åˆæ³•é‚®ä»¶ç”Ÿæˆå›å¤è‰ç¨¿\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne)  # æœ€åå‘ä¸»äººæ±‡æŠ¥ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I6C2-0jwIsj",
    "outputId": "abd06b5b-3165-4cf7-996b-6fc9864059ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f2fd464f860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â• é…ç½®èŠ‚ç‚¹ä¹‹é—´çš„æµè½¬é¡ºåº\n",
    "email_graph.add_edge(START, \"read_email\")  # å›¾çš„èµ·ç‚¹å…ˆè¿›å…¥ read_email èŠ‚ç‚¹\n",
    "\n",
    "# ğŸ§  åˆ¤å®šä¹‹åæ ¹æ®ç»“æœæµå‘ä¸åŒåˆ†æ”¯\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")  # å±•ç¤ºå®Œé‚®ä»¶åè°ƒç”¨åˆ†ç±»é€»è¾‘\n",
    "\n",
    "# ğŸ”€ æ·»åŠ æ¡ä»¶åˆ†æ”¯ï¼šroute_email è¿”å›å­—ç¬¦ä¸²å†³å®šä¸‹ä¸€æ¡è¾¹\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",  # æ ¹æ®åƒåœ¾é‚®ä»¶åˆ¤å®šç»“æœæ¥å†³å®šå»å‘\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",          # åˆ¤å®šä¸ºåƒåœ¾é‚®ä»¶åˆ™ç›´æ¥èµ° handle_spam èŠ‚ç‚¹\n",
    "        \"legitimate\": \"drafting_response\"  # åˆæ³•é‚®ä»¶åˆ™ç»§ç»­æ’°å†™å›å¤\n",
    "    }\n",
    ")\n",
    "\n",
    "# âœ… æ”¶å°¾ï¼šæ— è®ºå“ªä¸ªåˆ†æ”¯èµ°å®Œéƒ½å›åˆ° END èŠ‚ç‚¹\n",
    "email_graph.add_edge(\"handle_spam\", END)  # åƒåœ¾é‚®ä»¶å¤„ç†å®Œæ¯•å³ç»“æŸ\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")  # å›å¤è‰ç¨¿åé€šçŸ¥ä¸»äºº\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END)  # æ±‡æŠ¥ç»“æŸåæ•´ä¸ªæµç¨‹æ”¶å°¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "haTVi7UmwIsj"
   },
   "outputs": [],
   "source": [
    "# ğŸ§® å°†å›¾ç»“æ„ç¼–è¯‘æˆå¯æ‰§è¡Œçš„ LangGraph ä»£ç†å¯¹è±¡\n",
    "compiled_graph = email_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GlJYoVUbwIsj"
   },
   "outputs": [],
   "source": [
    "# ğŸ“¨ å‡†å¤‡ä¸¤å°ç¤ºä¾‹é‚®ä»¶ï¼Œå¸®åŠ©æˆ‘ä»¬è§‚å¯Ÿä¸åŒåˆ†æ”¯çš„æ‰§è¡Œæ•ˆæœ\n",
    "legitimate_email = {\n",
    "    \"sender\": \"äº¬ä¸œå®¢æœ\",  # å‘ä»¶äºº\n",
    "    \"subject\": \"å…³äºæ‚¨è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\",  # é‚®ä»¶ä¸»é¢˜\n",
    "    \"body\": \"å°Šæ•¬çš„éŸ¦æ©å…ˆç”Ÿï¼Œæ‚¨å¥½ï¼å…³äºæ‚¨åœ¨äº¬ä¸œçš„è¿‘æœŸè®¢å•ï¼Œå¢å€¼ç¨ç”µå­æ™®é€šå‘ç¥¨å·²å¼€å…·å¹¶æ¨é€è‡³æ‚¨çš„é‚®ç®±ã€‚å¦‚éœ€çº¸è´¨å‘ç¥¨æˆ–æŠ¬å¤´å˜æ›´ï¼Œè¯·åœ¨7æ—¥å†…é€šè¿‡â€œæˆ‘çš„è®¢å•-ç”³è¯·å¼€ç¥¨â€å‘èµ·ï¼Œæˆ‘ä»¬å°†å°½å¿«å¤„ç†ã€‚ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œæ•¬è¯·è°…è§£ã€‚\"  # é‚®ä»¶æ­£æ–‡\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"æŸæ•°å­—è´§å¸é¡¹ç›®æ–¹\",  # åƒåœ¾é‚®ä»¶å¸¸è§çš„æ¨é”€è€…\n",
    "    \"subject\": \"é™æ—¶æš´æ¶¨100å€ï¼Œç«‹å³ä¸Šè½¦ï¼\",  # è¯±å¯¼æ€§æ ‡é¢˜\n",
    "    \"body\": \"éŸ¦æ©å…ˆç”Ÿï¼Œæˆ‘ä»¬æ–°ä¸Šçº¿äº†ä¸€æ¬¾æ•°å­—è´§å¸ï¼Œæ‰¿è¯ºç¨³ç¨³èµšã€ç¨³èµšä¸èµ”ï¼æ‰«ç åŠ ç¾¤ï¼Œå‰100åèµ é€ç©ºæŠ•åé¢ï¼Œé”™è¿‡ä»Šå¤©å†ç­‰ä¸€å¹´ï¼\"  # æ˜æ˜¾çš„åƒåœ¾æ¨å¹¿/è¯ˆéª—æ–‡æ¡ˆ\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwnC2JXXwIsj",
    "outputId": "9aa7dc2d-908f-447c-a7ce-b47f36dae81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing legitimate email...\n",
      "é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª äº¬ä¸œå®¢æœ çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼šå…³äºæ‚¨è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\n",
      "ham\n",
      "==================================================\n",
      "Sir, you've received an email from äº¬ä¸œå®¢æœ.\n",
      "Subject: å…³äºæ‚¨è¿‘æœŸè®¢å•çš„å‘ç¥¨å¼€å…·è¯´æ˜\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "å°Šæ•¬çš„äº¬ä¸œå®¢æœå›¢é˜Ÿï¼Œ\n",
      "\n",
      "æ„Ÿè°¢æ‚¨åŠæ—¶å‘é€å…³äºæˆ‘è¿‘æœŸè®¢å•çš„å‘ç¥¨ä¿¡æ¯ã€‚æˆ‘å·²æ”¶åˆ°ç”µå­å‘ç¥¨ï¼Œå¹¶ç¡®è®¤å…¶å†…å®¹æ— è¯¯ã€‚ç›®å‰æ— éœ€çº¸è´¨å‘ç¥¨æˆ–æŠ¬å¤´å˜æ›´ã€‚å¦‚æœ‰è¿›ä¸€æ­¥éœ€æ±‚ï¼Œæˆ‘ä¼šåœ¨è§„å®šæ—¶é—´å†…é€šè¿‡ç›¸å…³æ¸ é“è”ç³»æ‚¨ã€‚\n",
      "\n",
      "æ„Ÿè°¢æ‚¨çš„ååŠ©ä¸æ”¯æŒã€‚\n",
      "\n",
      "ç¥å¥½ï¼Œ\n",
      "\n",
      "é˜¿å°”å¼—é›·å¾·  \n",
      "éŸ¦æ©å…ˆç”Ÿçš„ç®¡å®¶\n",
      "==================================================\n",
      "Processing spam email...\n",
      "é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª æŸæ•°å­—è´§å¸é¡¹ç›®æ–¹ çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼šé™æ—¶æš´æ¶¨100å€ï¼Œç«‹å³ä¸Šè½¦ï¼\n",
      "spam\n",
      "é˜¿å°”å¼—é›·å¾·å·²ç»å°†é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
      "è¯¥ç”µå­é‚®ä»¶å·²è¢«ç§»è‡³åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ§© åˆå§‹åŒ– Langfuse çš„å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºè‡ªåŠ¨è®°å½•æ‰§è¡Œè½¨è¿¹\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# âœ… è¿è¡Œåˆæ³•é‚®ä»¶ç¤ºä¾‹ï¼Œæ¼”ç¤ºå®Œæ•´å·¥ä½œæµ\n",
    "print(\"Processing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": legitimate_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # å°†å›è°ƒæŒ‚åˆ°å›¾çš„æ‰§è¡Œé…ç½®ä¸Š\n",
    ")\n",
    "\n",
    "# ğŸš¨ å†è¿è¡Œåƒåœ¾é‚®ä»¶ç¤ºä¾‹ï¼Œè§‚å¯Ÿåˆ†æ”¯å·®å¼‚\n",
    "print(\"Processing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjkhTgLWfoSQ"
   },
   "source": [
    "### è¿½è¸ªç»“æ„\n",
    "\n",
    "Langfuse ä¼šè®°å½•åŒ…å«è‹¥å¹² **spanï¼ˆè·¨åº¦ï¼‰** çš„**traceï¼ˆè¿½è¸ªï¼‰**ï¼Œæ¯ä¸ª span ä»£è¡¨ä»£ç†é€»è¾‘ä¸­çš„ä¸€ä¸ªæ­¥éª¤ã€‚æœ¬ä¾‹ä¸­çš„è¿½è¸ªåŒ…å«æ•´ä½“è¿è¡Œä»¥åŠå¦‚ä¸‹å­è·¨åº¦ï¼š\n",
    "- å·¥å…·è°ƒç”¨ï¼ˆ\n",
    "- LLM è°ƒç”¨ï¼ˆä½¿ç”¨ 'gpt-4o' çš„ Responses APIï¼‰\n",
    "\n",
    "ä½ å¯ä»¥æ£€æŸ¥è¿™äº›è®°å½•ä»¥ç²¾ç¡®äº†è§£æ—¶é—´æ¶ˆè€—ã€ä»¤ç‰Œä½¿ç”¨é‡ç­‰ï¼š\n",
    "\n",
    "![Langfuse ä¸­çš„è¿½è¸ªæ ‘](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251730026.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHZAkQuefoSQ"
   },
   "source": [
    "## åœ¨çº¿è¯„ä¼°\n",
    "\n",
    "åœ¨çº¿è¯„ä¼°æŒ‡åœ¨çœŸå®çº¿ä¸Šç¯å¢ƒï¼ˆç”Ÿäº§ç¯å¢ƒçš„å®é™…ä½¿ç”¨ä¸­ï¼‰å¯¹ä»£ç†è¿›è¡Œè¯„ä¼°ã€‚è¿™éœ€è¦å¯¹çœŸå®ç”¨æˆ·äº¤äº’è¿›è¡ŒæŒç»­ç›‘æ§ä¸ç»“æœåˆ†æã€‚\n",
    "\n",
    "æˆ‘ä»¬åœ¨æ­¤æ€»ç»“äº†å¤šç§è¯„ä¼°æŠ€æœ¯çš„æŒ‡å—ï¼š[é“¾æ¥](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)ã€‚\n",
    "\n",
    "### ç”Ÿäº§ç¯å¢ƒå¸¸è§ç›‘æ§æŒ‡æ ‡\n",
    "\n",
    "1. **æˆæœ¬ï¼ˆCostsï¼‰**ï¼šåŸ‹ç‚¹ä¼šè®°å½•ä»¤ç‰Œç”¨é‡ï¼Œä½ å¯æŒ‰æ¯ä¸ªä»¤ç‰Œçš„ä»·æ ¼ä¼°ç®—æˆæœ¬ã€‚\n",
    "2. **å»¶è¿Ÿï¼ˆLatencyï¼‰**ï¼šè§‚å¯Ÿå®Œæˆæ¯ä¸ªæ­¥éª¤æˆ–æ•´æ¬¡è¿è¡Œæ‰€éœ€çš„æ—¶é—´ã€‚\n",
    "3. **ç”¨æˆ·åé¦ˆï¼ˆUser Feedbackï¼‰**ï¼šç”¨æˆ·å¯ç›´æ¥æä¾›åé¦ˆï¼ˆå¦‚ç‚¹èµ/ç‚¹è¸©ï¼‰ä»¥å¸®åŠ©è¿­ä»£ä¸ä¿®æ­£ä»£ç†ã€‚\n",
    "4. **LLM è¯„å®¡ï¼ˆLLM-as-a-Judgeï¼‰**ï¼šä½¿ç”¨é¢å¤–çš„ LLM è¿‘å®æ—¶è¯„ä¼°ä»£ç†è¾“å‡ºï¼ˆå¦‚æ£€æµ‹æ¯’æ€§æˆ–æ­£ç¡®æ€§ï¼‰ã€‚\n",
    "\n",
    "ä¸‹é¢å±•ç¤ºè¿™äº›æŒ‡æ ‡çš„ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHMvJ1QlfoSQ"
   },
   "source": [
    "#### 1. æˆæœ¬ï¼ˆCostsï¼‰\n",
    "\n",
    "ä¸‹å›¾å±•ç¤ºäº† `gpt-4o` è°ƒç”¨çš„ç”¨é‡ï¼Œå¯æ®æ­¤è¯†åˆ«é«˜æˆæœ¬æ­¥éª¤å¹¶ä¼˜åŒ–ä»£ç†ã€‚\n",
    "\n",
    "![æˆæœ¬](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251732570.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz0y9mn7foSQ"
   },
   "source": [
    "#### 2. å»¶è¿Ÿï¼ˆLatencyï¼‰\n",
    "\n",
    "è¿˜å¯ä»¥æŸ¥çœ‹å®Œæˆæ¯ä¸ªæ­¥éª¤æ‰€éœ€çš„æ—¶é—´ã€‚å¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼Œæ•´ä¸ªè¿è¡Œçº¦ 3 ç§’ï¼Œä½ å¯ä»¥ç»†åˆ†åˆ°å„æ­¥éª¤ã€‚æ­¤ä¸¾æœ‰åŠ©äºè¯†åˆ«ç“¶é¢ˆå¹¶ä¼˜åŒ–ä»£ç†ã€‚\n",
    "\n",
    "![å»¶è¿Ÿ](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251735069.png)\n",
    "\n",
    "_[å‰å¾€è¯¥è¿½è¸ª](https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=2d1f23b960fb1ff0bdaf7623fda4936c&timestamp=2025-09-25T09%3A06%3A06.476Z&display=timeline)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtKiK62HfoSR"
   },
   "source": [
    "#### 3. ç”¨æˆ·åé¦ˆï¼ˆUser Feedbackï¼‰\n",
    "\n",
    "å¦‚æœä½ çš„ä»£ç†åµŒå…¥åœ¨ç”¨æˆ·ç•Œé¢ä¸­ï¼Œå¯ä»¥é‡‡é›†ç”¨æˆ·çš„ç›´æ¥åé¦ˆï¼ˆä¾‹å¦‚åœ¨èŠå¤©ç•Œé¢ä¸­çš„ç‚¹èµ/ç‚¹è¸©ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YI9siKKKfoSR"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# âœ… æ–¹å¼ä¸€ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿”å›çš„ span å¯¹è±¡ç»™å½“å‰è¿½è¸ªæ‰“åˆ†\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"LangGraph\") as span:\n",
    "    # ... åœ¨è¿™é‡Œæ‰§è¡Œå…·ä½“çš„ LangGraph é€»è¾‘ ...\n",
    "\n",
    "    # ç›´æ¥å¯¹ span è°ƒç”¨ score_trace å¹¶é™„åŠ è¡¥å……ä¿¡æ¯\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\",\n",
    "        comment=\"This was correct, thank you\"\n",
    "    )\n",
    "\n",
    "# âœ… æ–¹å¼äºŒï¼šä»åœ¨ä¸Šä¸‹æ–‡ä¸­æ—¶ï¼Œå¯ä½¿ç”¨ score_current_trace ç®€åŒ–è°ƒç”¨\n",
    "with langfuse.start_as_current_span(name=\"langgraph-request\") as span:\n",
    "    # ... LangGraph execution ...\n",
    "\n",
    "    # ä½¿ç”¨å½“å‰ä¸Šä¸‹æ–‡çš„ traceï¼Œè€Œæ— éœ€æŒæœ‰ span å¯¹è±¡\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "\n",
    "# âœ… æ–¹å¼ä¸‰ï¼šå¦‚æœå·²ç»ç¦»å¼€ä¸Šä¸‹æ–‡ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ trace_id è¿›è¡Œè¡¥å½•\n",
    "langfuse.create_score(\n",
    "    trace_id=\"predefined-trace-id\",  # âš ï¸ è¿™é‡Œéœ€è¦æ›¿æ¢æˆçœŸå®çš„ trace_id\n",
    "    name=\"user-feedback\",\n",
    "    value=1,\n",
    "    data_type=\"NUMERIC\",\n",
    "    comment=\"This was correct, thank you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiemuS7YfoSR"
   },
   "source": [
    "ç”¨æˆ·åé¦ˆéšåä¼šè¢« Langfuse æ•è·ï¼š\n",
    "\n",
    "![Langfuse ä¸­æ•è·çš„ç”¨æˆ·åé¦ˆ](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509251746651.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29KsI9xcfoSR"
   },
   "source": [
    "#### 4. è‡ªåŠ¨åŒ–çš„ LLM è¯„å®¡æ‰“åˆ†ï¼ˆLLM-as-a-Judgeï¼‰\n",
    "\n",
    "LLM-as-a-Judge æä¾›äº†ä¸€ç§è‡ªåŠ¨è¯„ä¼°ä»£ç†è¾“å‡ºçš„æ–¹æ³•ã€‚ä½ å¯ä»¥**é…ç½®ä¸€ä¸ªç‹¬ç«‹çš„ LLM è°ƒç”¨**ï¼Œç”¨äºè¯„ä¼°è¾“å‡ºçš„æ­£ç¡®æ€§ã€æ¯’æ€§ã€é£æ ¼æˆ–å…¶ä»–ä½ å…³å¿ƒçš„æŒ‡æ ‡ã€‚\n",
    "\n",
    "**å·¥ä½œæµç¨‹ï¼š**\n",
    "1. å®šä¹‰ä¸€ä¸ª**è¯„ä¼°æ¨¡æ¿**ï¼Œä¾‹å¦‚â€œæ£€æŸ¥æ–‡æœ¬æ˜¯å¦å«æœ‰æ¯’æ€§â€ã€‚\n",
    "2. æŒ‡å®šç”¨äºè¯„å®¡çš„æ¨¡å‹ï¼ˆjudge-modelï¼‰ï¼Œä¾‹å¦‚ `gpt-4o-mini`ã€‚\n",
    "2. æ¯å½“ä»£ç†ç”Ÿæˆè¾“å‡ºæ—¶ï¼Œå°†å…¶ä¸æ¨¡æ¿ä¸€èµ·ä¼ ç»™â€œè¯„å®¡â€LLMã€‚\n",
    "3. è¯„å®¡ LLM ç»™å‡ºè¯„åˆ†æˆ–æ ‡ç­¾ï¼Œå¹¶å°†ç»“æœè®°å½•åˆ°å¯è§‚æµ‹æ€§å¹³å°ã€‚\n",
    "\n",
    "Langfuse ç¤ºä¾‹ï¼š\n",
    "\n",
    "![LLM è¯„å®¡æ¨¡æ¿](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator-template.png)\n",
    "![LLM è¯„å®¡å™¨](https://langfuse.com/images/cookbook/integration_openai-agents/evaluator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UGGlYrB7foSR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spam email...\n",
      "é˜¿å°”å¼—é›·å¾·æ­£åœ¨å¤„ç†æ¥è‡ª æŸæ•°å­—è´§å¸é¡¹ç›®æ–¹ çš„é‚®ä»¶ï¼Œä¸»é¢˜ä¸ºï¼šé™æ—¶æš´æ¶¨100å€ï¼Œç«‹å³ä¸Šè½¦ï¼\n",
      "spam\n",
      "é˜¿å°”å¼—é›·å¾·å·²ç»å°†é‚®ä»¶æ ‡è®°ä¸ºåƒåœ¾é‚®ä»¶ã€‚\n",
      "è¯¥ç”µå­é‚®ä»¶å·²è¢«ç§»è‡³åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” å¦‚æœéœ€è¦å•ç‹¬å†æ¬¡éªŒè¯åƒåœ¾é‚®ä»¶è·¯å¾„ï¼Œå¯ä»¥å¤ç”¨ä¸‹é¢çš„è°ƒç”¨ä»£ç \n",
    "print(\"Processing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "        },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izr-3LiQfoSR"
   },
   "source": [
    "å¯ä»¥çœ‹åˆ°ï¼Œè¯¥ç¤ºä¾‹çš„ç­”æ¡ˆè¢«è¯„å®¡ä¸ºâ€œæ— æ¯’æ€§ï¼ˆnot toxicï¼‰â€ã€‚\n",
    "\n",
    "![LLM è¯„å®¡å¾—åˆ†ç¤ºä¾‹](https://langfuse.com/images/cookbook/example-langgraph-evaluation/llm-as-a-judge-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7fN0UTkfoSR"
   },
   "source": [
    "#### 5. å¯è§‚æµ‹æ€§æŒ‡æ ‡æ€»è§ˆ\n",
    "\n",
    "æ‰€æœ‰ä¸Šè¿°æŒ‡æ ‡éƒ½å¯ä»¥åœ¨ç»Ÿä¸€çš„ä»ªè¡¨ç›˜ä¸­å¯è§†åŒ–ã€‚è¿™æ ·ä½ å¯ä»¥å¿«é€ŸæŸ¥çœ‹ä»£ç†åœ¨å¤šæ¬¡ä¼šè¯ä¸­çš„è¡¨ç°ï¼Œå¹¶éšæ—¶é—´è·Ÿè¸ªè´¨é‡æŒ‡æ ‡ã€‚\n",
    "\n",
    "![å¯è§‚æµ‹æ€§æŒ‡æ ‡æ€»è§ˆ](https://langfuse.com/images/cookbook/integration_openai-agents/dashboard-dark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlwltgEkfoSR"
   },
   "source": [
    "## ç¦»çº¿è¯„ä¼°ï¼ˆOffline Evaluationï¼‰\n",
    "\n",
    "åœ¨çº¿è¯„ä¼°å¯ç”¨äºè·å–å®æ—¶åé¦ˆï¼Œä½†åŒæ ·éœ€è¦è¿›è¡Œ**ç¦»çº¿è¯„ä¼°ï¼ˆoffline evaluationï¼‰**â€”â€”å³åœ¨å¼€å‘å‰æˆ–å¼€å‘è¿‡ç¨‹ä¸­è¿›è¡Œç³»ç»Ÿæ€§çš„æ£€æŸ¥ã€‚è¿™æ ·å¯ä»¥åœ¨å‘å¸ƒå˜æ›´åˆ°ç”Ÿäº§ç¯å¢ƒä¹‹å‰ï¼Œä¿éšœè´¨é‡ä¸å¯é æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5R8eNQxfoSR"
   },
   "source": [
    "### æ•°æ®é›†è¯„ä¼°ï¼ˆDataset Evaluationï¼‰\n",
    "\n",
    "åœ¨ç¦»çº¿è¯„ä¼°ä¸­ï¼Œé€šå¸¸ä¼šï¼š\n",
    "1. å‡†å¤‡ä¸€ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆåŒ…å«æç¤ºè¯ä¸æœŸæœ›è¾“å‡ºçš„æˆå¯¹æ ·æœ¬ï¼‰\n",
    "2. ä½¿ç”¨è¯¥æ•°æ®é›†æ‰¹é‡è¿è¡Œä½ çš„ Agent\n",
    "3. å°†æ¨¡å‹è¾“å‡ºä¸æœŸæœ›ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œæˆ–é‡‡ç”¨é¢å¤–çš„è‡ªåŠ¨æ‰“åˆ†æœºåˆ¶\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé—®ç­”æ•°æ®é›†ç¤ºä¾‹ï¼š[q&a-dataset](https://huggingface.co/datasets/junzhang1207/search-dataset)ï¼Œå…¶ä¸­åŒ…å«é—®é¢˜ä¸æœŸæœ›ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOAP8e45wIsp",
    "outputId": "b2807d06-e184-43b7-cb94-e2e2ef8e40af"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# è®¾ç½®HuggingFaceä»£ç†\u001b[39;00m\n\u001b[32m      5\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33menv\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHF_ENDPOINT=https://hf-mirror.com\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "\n",
    "# ğŸ“¥ ä» Hugging Face ä¸‹è½½ç¤ºä¾‹æ•°æ®é›†ï¼Œè¿™é‡ŒåŒ…å«é—®ç­”å½¢å¼çš„æ¡ç›®\n",
    "dataset = load_dataset(\"junzhang1207/search-dataset\", split=\"train\")\n",
    "df = pd.DataFrame(dataset)  # è½¬æˆ DataFrame æ–¹ä¾¿ç­›é€‰ä¸éå†\n",
    "print(\"First few rows of search-dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æœ¬åœ° JSONL æ–‡ä»¶: dataset/data.jsonl\n",
      "\n",
      "æ•°æ®é›†å‰5è¡Œ:\n",
      "                                     id  \\\n",
      "0  20caf138-0c81-4ef9-be60-fe919e0d68d4   \n",
      "1  1f37d9fd-1bcc-4f79-b004-bc0e1e944033   \n",
      "2  76173a7f-d645-4e3e-8e0d-cca139e00ebe   \n",
      "3  5f5ef4ca-91fe-4610-a8a9-e15b12e3c803   \n",
      "4  64dbed0d-d91b-4acd-9a9c-0a7aa83115ec   \n",
      "\n",
      "                                            question  \\\n",
      "0                 steve jobs statue location budapst   \n",
      "1  Why is the Battle of Stalingrad considered a t...   \n",
      "2  In what year did 'The Birth of a Nation' surpa...   \n",
      "3  How many Russian soldiers surrendered to AFU i...   \n",
      "4   What event led to the creation of Google Images?   \n",
      "\n",
      "                                     expected_answer       category       area  \n",
      "0  The Steve Jobs statue is located in Budapest, ...           Arts  Knowledge  \n",
      "1  The Battle of Stalingrad is considered a turni...   General News       News  \n",
      "2  This question is based on a false premise. 'Th...  Entertainment       News  \n",
      "3  About 300 Russian soldiers surrendered to the ...   General News       News  \n",
      "4  Jennifer Lopez's appearance in a green Versace...     Technology       News  \n",
      "\n",
      "æ•°æ®é›†å½¢çŠ¶: (929, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ğŸ“Œ æ›¿æ¢ä¸ºä½ æœ¬åœ°æ–‡ä»¶çš„å®é™…è·¯å¾„ï¼Œä¾‹å¦‚ï¼š'dataset/data.jsonl '\n",
    "local_jsonl_path = 'dataset/data.jsonl'\n",
    "\n",
    "if os.path.exists(local_jsonl_path):\n",
    "    try:\n",
    "        # ä½¿ç”¨ pd.read_json å¹¶æŒ‡å®š lines=True æ¥è¯»å– JSON Lines æ ¼å¼\n",
    "        local_df = pd.read_json(local_jsonl_path, lines=True)\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸè¯»å–æœ¬åœ° JSONL æ–‡ä»¶: {local_jsonl_path}\")\n",
    "        print(\"\\næ•°æ®é›†å‰5è¡Œ:\")\n",
    "        print(local_df.head())\n",
    "        print(f\"\\næ•°æ®é›†å½¢çŠ¶: {local_df.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "else:\n",
    "    print(f\"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®: {local_jsonl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlgYY3VmwIsp"
   },
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åœ¨ Langfuse ä¸­åˆ›å»ºä¸€ä¸ªæ•°æ®é›†å®ä½“ä»¥è¿½è¸ªè¿è¡Œï¼›éšåå°†æ•°æ®é›†ä¸­çš„æ¯æ¡è®°å½•æ·»åŠ åˆ°ç³»ç»Ÿä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdn2qSCwwIsp",
    "outputId": "ef3bb5d3-21bc-416a-aef3-5dccfedd2b05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='cmg0ap0r900z9ad07gwjr3y2r', name='qa-dataset_langgraph-agent', description='ä»Hugging Faceä¸Šä¼ çš„é—®ç­”æ•°æ®é›†', metadata={'date': '2025-09-21', 'type': 'benchmark'}, project_id='cmequpe0j00euad07w6wrvkzg', created_at=datetime.datetime(2025, 9, 26, 3, 41, 31, 29000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 9, 30, 9, 31, 49, 357000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse_dataset_name = \"qa-dataset_langgraph-agent\"\n",
    "\n",
    "# ğŸ—‚ï¸ åœ¨ Langfuse ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œç”¨äºå­˜å‚¨è¯„æµ‹æ ·æœ¬\n",
    "langfuse.create_dataset(\n",
    "    name=langfuse_dataset_name,\n",
    "    description=\"ä»Hugging Faceä¸Šä¼ çš„é—®ç­”æ•°æ®é›†\",\n",
    "    metadata={\n",
    "        \"date\": \"2025-09-21\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_BkN1d1QwIsq"
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ ä»…é€‰å– 30 æ¡ç¤ºä¾‹æ•°æ®ä¸Šä¼ ï¼Œå®é™…é¡¹ç›®å¯æ ¹æ®éœ€æ±‚è°ƒæ•´\n",
    "df_30 = local_df.sample(30)\n",
    "\n",
    "for idx, row in df_30.iterrows():\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=langfuse_dataset_name,\n",
    "        input={\"text\": row[\"question\"]},            # Langfuse éœ€è¦æ˜ç¡®çš„è¾“å…¥å­—æ®µ\n",
    "        expected_output={\"text\": row[\"expected_answer\"]}  # æä¾›æ ‡å‡†ç­”æ¡ˆä¾¿äºåç»­è¯„ä¼°\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3yJVaBnwIsq"
   },
   "source": [
    "![Langfuse ä¸­çš„æ•°æ®é›†æ¡ç›®](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509261143566.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7NHQ4XowIsq"
   },
   "source": [
    "#### åœ¨æ•°æ®é›†ä¸Šè¿è¡Œä»£ç†\n",
    "\n",
    "é¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªä½¿ç”¨ OpenAI æ¨¡å‹å›ç­”é—®é¢˜çš„ç®€æ˜“ LangGraph ä»£ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ACoBDVzbwIsq"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage  # å¦‚éœ€è‡ªå®šä¹‰è¾“å…¥æ¶ˆæ¯å¯ä»¥ä½¿ç”¨è¯¥ç±»å‹\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ğŸ§± å®šä¹‰çŠ¶æ€ç»“æ„ï¼šmessages å­—æ®µä¼šè‡ªåŠ¨ç´¯ç§¯å¯¹è¯å†å²\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„çŠ¶æ€å›¾æ„å»ºå™¨\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ğŸ¤– å‡†å¤‡è¦è°ƒç”¨çš„ OpenAI èŠå¤©æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"gpt-4.5-preview\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    å•èŠ‚ç‚¹èŠå¤©æœºå™¨äººï¼š\n",
    "    - å°†å½“å‰æ‰€æœ‰æ¶ˆæ¯ä¼ ç»™ LLM\n",
    "    - è¿”å›æ¨¡å‹çš„å›å¤ï¼ŒLangGraph ä¼šè‡ªåŠ¨æŠŠå®ƒè¿½åŠ åˆ°çŠ¶æ€é‡Œ\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# ğŸ”— æ³¨å†ŒèŠ‚ç‚¹ä¸å…¥å£ã€å‡ºå£\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# âš™ï¸ compile() ä¼šè¿”å›å¯ç›´æ¥è°ƒç”¨çš„å›¾å®ä¾‹\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXSe2ScIwIsq"
   },
   "source": [
    "æ¥ç€ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•° `my_agent()`ï¼Œå…¶èŒè´£æ˜¯ï¼š\n",
    "1. åˆ›å»ºä¸€ä¸ª Langfuse è¿½è¸ªï¼ˆtraceï¼‰\n",
    "2. è·å– `langfuse_handler_trace`ï¼Œç”¨äºä¸º LangGraph çš„æ‰§è¡Œè¿‡ç¨‹æ‰“ç‚¹\n",
    "3. è¿è¡Œæˆ‘ä»¬çš„ Agentï¼Œå¹¶åœ¨è°ƒç”¨æ—¶ä¼ å…¥ `langfuse_handler_trace` ä»¥è®°å½•æ‰§è¡Œç»†èŠ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZQTQKusMwIsq"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate  # å¯ç”¨äºè‡ªå®šä¹‰æç¤ºæ¨¡æ¿ï¼ˆæœ¬ç¤ºä¾‹æš‚æœªä½¿ç”¨ï¼‰\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ğŸ—ï¸ æ„å»ºä¸€ä¸ªå¸¦ Langfuse è¿½è¸ªèƒ½åŠ›çš„ LangGraph ä»£ç†\n",
    "graph_builder = StateGraph(State)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")  # é€‰æ‹©å¯¹è¯æ¨¡å‹\n",
    "langfuse = get_client()  # å¤ç”¨å‰é¢é…ç½®å¥½çš„ Langfuse å®¢æˆ·ç«¯\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    æ ¸å¿ƒèŠ‚ç‚¹ï¼šå°†å¯¹è¯å†å²äº¤ç»™ LLMï¼Œå¹¶æŠŠç”Ÿæˆç»“æœåŒ…è£…æˆ LangGraph éœ€è¦çš„æ ¼å¼ã€‚\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "def my_agent(question, langfuse_handler):\n",
    "    \"\"\"\n",
    "    å¯¹å¤–æš´éœ²çš„ä¾¿æ·å‡½æ•°ï¼š\n",
    "    1. æ‰“å¼€ä¸€ä¸ª Langfuse span ä»¥ä¾¿è§‚æµ‹è¿™æ¬¡è¯·æ±‚ï¼›\n",
    "    2. è°ƒç”¨ LangGraph ä»£ç†è·å–å›ç­”ï¼›\n",
    "    3. å°†è¾“å…¥è¾“å‡ºå†™å› Langfuseï¼Œæ–¹ä¾¿åç»­è¯„ä¼°ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # åˆ›å»ºä¸€ä¸ªé¡¶å±‚è¿½è¸ª spanï¼Œæ‰€æœ‰ä¸Šä¸‹æ–‡éƒ½ä¼šè®°å½•åœ¨è¿™é‡Œ\n",
    "    with langfuse.start_as_current_span(name=\"my-langgraph-agent\") as root_span:\n",
    "\n",
    "        # Step 2: LangChain processing\n",
    "        response = graph.invoke(\n",
    "            input={\"messages\": [HumanMessage(content=question)]},\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        )\n",
    "\n",
    "        # å°†åŸå§‹é—®é¢˜å’Œæ¨¡å‹å›ç­”åŒæ­¥åˆ° Langfuse ä»ªè¡¨ç›˜\n",
    "        root_span.update_trace(\n",
    "            input=question,\n",
    "            output=response[\"messages\"][1].content)\n",
    "\n",
    "        print(question)\n",
    "        print(response[\"messages\"][1].content)\n",
    "\n",
    "    return response[\"messages\"][1].content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iri3PYQwIsq"
   },
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬éå†æ•°æ®é›†ä¸­çš„æ¯ä¸€æ¡æ ·æœ¬ï¼Œè¿è¡Œä»£ç†ï¼Œå¹¶å°†ç”Ÿæˆçš„è¿½è¸ªä¸è¯¥æ•°æ®é›†æ¡ç›®è¿›è¡Œå…³è”ã€‚å¦‚æœ‰éœ€è¦ï¼Œè¿˜å¯ä»¥é™„åŠ ä¸€ä¸ªå¿«é€Ÿçš„è¯„ä¼°åˆ†æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJyw6m61wIsq",
    "outputId": "7115f780-5ce4-49c2-c281-40cd7bcd76bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'first edition of how to win friends and influence people published in 1932'}\n",
      "The first edition of \"How to Win Friends and Influence People,\" written by Dale Carnegie, was actually published in 1936, not 1932. This seminal self-help book provides practical advice on interpersonal skills and effective communication to improve one's ability to connect with others and enhance personal and professional relationships.\n",
      "{'text': 'kamala harris 2024 vp pick'}\n",
      "As of now, Vice President Kamala Harris is the incumbent Vice President serving under President Joe Biden. For the 2024 presidential election, it is expected that she would continue to be the Vice Presidential candidate if President Biden runs for re-election. However, it's important to note that political landscapes can change, and official announcements or decisions regarding the 2024 election have not been made publicly. For the most up-to-date information, you should follow news sources or official announcements from the political parties involved.\n",
      "{'text': 'what is the karman line definition?'}\n",
      "The KÃ¡rmÃ¡n line is traditionally defined as the boundary between Earth's atmosphere and outer space. It is situated at an altitude of 100 kilometers (about 62 miles) above sea level. The line is named after Theodore von KÃ¡rmÃ¡n, a Hungarian-American engineer and physicist, who calculated that above this altitude, the atmosphere becomes too thin to support conventional aircraft flight because the necessary orbital speed would exceed the capabilities of these aircraft. As such, the KÃ¡rmÃ¡n line is often used to distinguish between aeronautics and astronautics and is recognized by various organizations, including the FÃ©dÃ©ration AÃ©ronautique Internationale (FAI), which sets standards for air sports and aeronautical records.\n",
      "{'text': 'What is the goal of the Quagga Project?'}\n",
      "The goal of the Quagga Project is to bring back animals that closely resemble the extinct quagga, a subspecies of the plains zebra. Quaggas once lived in South Africa but were driven to extinction in the late 19th century due to excessive hunting. The project involves selective breeding of plains zebras that have similar striping patterns to the historical quagga, aiming to recreate the appearance and certain behaviors of the original subspecies. While the animals produced by the project are not genetically identical to the extinct quagga, they represent an effort to restore a similar ecological niche in the region.\n",
      "{'text': \"In Amy Millan's third solo album 'Whiskey Lullabies', released between 'Honey from the Tombs' and 'Masters of the Burial', how did her experiences with Stars and Broken Social Scene influence the album's sound compared to her previous solo work?\"}\n",
      "Amy Millan's third solo album, \"Whiskey Lullabies,\" if it were to exist, would likely draw on her extensive experiences with Stars and Broken Social Scene. In her previous solo albums, \"Honey from the Tombs\" and \"Masters of the Burial,\" Millan showcased her ability to blend folk, country, and indie rock elements, crafting a distinct sound that differs from her work with those bands.\n",
      "\n",
      "Stars are known for their lush, orchestral pop sound, while Broken Social Scene is celebrated for its experimental and collaborative approach. These influences could have led \"Whiskey Lullabies\" to feature richer instrumentation and more complex arrangements compared to her earlier solo work. The album might exhibit a balance of introspective lyrics and expansive soundscapes, incorporating elements such as layered vocals, diverse instrumentation, and a blend of electronic and acoustic sounds, reflecting the collaborative spirit of Broken Social Scene.\n",
      "\n",
      "Compared to her previous solo efforts, \"Whiskey Lullabies\" would likely reflect a matured sound, integrating Millan's growth as an artist through her experiences with these bands. The album may display a nuanced emotional depth, drawing from her journey with Stars' romanticism and Broken Social Scene's raw energy and eclecticism, resulting in a compelling fusion of introspective songwriting and expansive sonic exploration.\n",
      "{'text': 'zuffa antitrust lawsuit ninth circut court decision'}\n",
      "As of my last update in October 2023, there hasn't been a decision from the Ninth Circuit Court regarding the Zuffa antitrust lawsuit. Zuffa, LLC, the parent company of the UFC, had been involved in an antitrust lawsuit where plaintiffs accused the company of engaging in anti-competitive practices to dominate the MMA market. The case was a major point of interest in the sports and legal communities, but for the most current information, you may want to look into the latest court documents or news updates.\n",
      "{'text': \"Given that Earth's rotation period relative to the fixed stars is approximately 86,164.0989 seconds, and the main apparent motion of celestial bodies in Earth's sky is to the west at a rate of 15Ã‚Â°/h, how many apparent diameters of the Sun would an observer on Earth's equator see pass overhead in exactly 24 hours?\"}\n",
      "To solve this problem, we need to determine how many apparent diameters of the Sun would pass overhead as observed from Earth's equator in a 24-hour period, given the Sun's apparent motion across the sky.\n",
      "\n",
      "First, let's start with the details we have:\n",
      "\n",
      "1. The Earth's rotation period relative to the fixed stars, known as the sidereal day, is approximately 86,164.0989 seconds, or about 23 hours, 56 minutes, and 4.0989 seconds. This period represents the time it takes for the Earth to rotate 360Â° relative to the fixed stars.\n",
      "\n",
      "2. The main apparent motion of celestial bodies (including the Sun) in Earth's sky is to the west at a rate of 15Â° per hour. This is due to the Earth's rotation.\n",
      "\n",
      "3. We are considering a period of exactly 24 hours.\n",
      "\n",
      "To find how many apparent diameters of the Sun pass overhead, we also need to know the apparent angular diameter of the Sun. The average apparent angular diameter of the Sun is about 0.53 degrees.\n",
      "\n",
      "Now, we calculate the total apparent westward motion of the Sun in 24 hours:\n",
      "\n",
      "- In 24 hours, the Earth rotates 360Â° relative to the Sun.\n",
      "- Therefore, the apparent motion of the Sun relative to an observer on Earthâ€™s surface is also 360Â° in 24 hours.\n",
      "\n",
      "Next, we calculate the number of apparent Sun diameters that fit into this 360Â° rotation:\n",
      "\n",
      "- We divide the total apparent motion (360Â°) by the angular diameter of the Sun (0.53Â°):\n",
      "\n",
      "  \\[\n",
      "  \\text{Number of Sun diameters} = \\frac{360Â°}{0.53Â°} \\approx 679.25\n",
      "  \\]\n",
      "\n",
      "Thus, an observer on Earth's equator would see approximately 679 apparent diameters of the Sun pass overhead in exactly 24 hours.\n",
      "{'text': 'Who awarded Steve Jobs a posthumous Medal of Freedom?'}\n",
      "Steve Jobs was posthumously awarded the Presidential Medal of Freedom by President Joe Biden.\n",
      "{'text': 'When did Abraham Lincoln arrive in Washington, D.C. as President-elect?'}\n",
      "Abraham Lincoln arrived in Washington, D.C. as President-elect on February 23, 1861.\n",
      "{'text': 'which year did simone biles win olympic gold on uneven bars'}\n",
      "Simone Biles has never won an Olympic gold medal on the uneven bars. Her strengths are typically in other events, such as floor exercise, vault, and all-around. At the 2016 Rio Olympics, she won gold in the all-around, vault, and floor exercise, but not on the uneven bars.\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ğŸ“¡ åˆå§‹åŒ–è¿½è¸ªç»„ä»¶ï¼šCallbackHandler ä¼šæŠŠ LangChain çš„æ¯ä¸€æ­¥åŒæ­¥åˆ° Langfuse\n",
    "langfuse_handler = CallbackHandler()\n",
    "langfuse = get_client()\n",
    "\n",
    "dataset = langfuse.get_dataset('qa-dataset_langgraph-agent')  # è·å–ä¸Šä¸€æ­¥åˆ›å»ºçš„æ•°æ®é›†\n",
    "\n",
    "for item in dataset.items:\n",
    "    # âœ… item.run() ä¼šä¸ºæ¯ä¸ªæ ·æœ¬å¼€å¯ä¸€ä¸ªå­è¿½è¸ªï¼Œæ–¹ä¾¿æŸ¥çœ‹å•æ¡æ ·æœ¬çš„æ‰§è¡Œæƒ…å†µ\n",
    "    with item.run(\n",
    "        run_name=\"run_gpt-4o\",\n",
    "        run_description=\"My first run\",\n",
    "        run_metadata={\"model\": \"gpt-4o\"},\n",
    "    ) as root_span:\n",
    "        # è¿›å…¥æ­¤ä¸Šä¸‹æ–‡çš„æ‰€æœ‰è°ƒç”¨éƒ½ä¼šè‡ªåŠ¨å…³è”åˆ°å½“å‰ dataset item\n",
    "\n",
    "        # ğŸ¯ è¿è¡Œæ ¸å¿ƒä¸šåŠ¡é€»è¾‘æ—¶ï¼Œå†å¼€ä¸€ä¸ª generation ä¸Šä¸‹æ–‡è®°å½•å•æ¬¡æ¨¡å‹è°ƒç”¨\n",
    "        with langfuse.start_as_current_generation(\n",
    "            name=\"llm-call\",\n",
    "            model=\"gpt-4o\",\n",
    "            input=item.input\n",
    "        ) as generation:\n",
    "            # ç”¨æˆ‘ä»¬åˆšæ‰å°è£…çš„ my_agent å®Œæˆå®é™…é—®ç­”\n",
    "            output = my_agent(str(item.input), langfuse_handler)\n",
    "            generation.update(output=output)\n",
    "\n",
    "        # ğŸ“ å¯é€‰æ‹©å¯¹ç»“æœæ‰“åˆ†ï¼ˆä¾‹å¦‚äººå·¥ç‚¹è¯„æˆ–è‡ªåŠ¨æŒ‡æ ‡ï¼‰\n",
    "        root_span.score_trace(\n",
    "            name=\"user-feedback\",\n",
    "            value=1,\n",
    "            comment=\"This is a comment\",  # å¯è®°å½•è¯„åˆ†åŸå› ï¼Œä¾¿äºå›æº¯\n",
    "        )\n",
    "\n",
    "# ğŸ”š æ‰€æœ‰è°ƒç”¨ç»“æŸååˆ·æ–°å®¢æˆ·ç«¯ï¼Œç¡®ä¿ç¼“å†²åŒºé‡Œçš„æ•°æ®éƒ½è¢«å‘é€\n",
    "langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rofi0MnywIsq"
   },
   "source": [
    "ä½ å¯ä»¥åœ¨ä¸åŒçš„ Agent é…ç½®ä¹‹é—´é‡å¤è¿™ä¸€æµç¨‹ï¼Œä¾‹å¦‚ï¼š\n",
    "- æ¨¡å‹ï¼ˆå¦‚ gpt-4o-miniã€o1 ç­‰ï¼‰\n",
    "- æç¤ºè¯ï¼ˆPromptsï¼‰\n",
    "- å·¥å…·ï¼ˆå¦‚æ˜¯å¦å¯ç”¨æœç´¢èƒ½åŠ›ï¼‰\n",
    "- Agent å¤æ‚åº¦ï¼ˆå¤šä»£ç† vs å•ä»£ç†ï¼‰\n",
    "\n",
    "éšåå¯åœ¨ Langfuse ä¸­è¿›è¡Œå¹¶æ’å¯¹æ¯”ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ 30 æ¡æ•°æ®é›†é—®é¢˜ä¸Šåˆ†åˆ«è¿è¡Œäº† 3 æ¬¡ä»£ç†ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„ OpenAI æ¨¡å‹ã€‚å¯ä»¥çœ‹åˆ°ï¼Œéšç€æ¨¡å‹èƒ½åŠ›å¢å¤§ï¼Œæ­£ç¡®å›ç­”çš„æ•°é‡æŒ‰é¢„æœŸæå‡ã€‚`correct_answer` åˆ†æ•°ç”±ä¸€ä¸ª[â€œæ¨¡å‹å……å½“è¯„å®¡â€ï¼ˆLLM-as-a-Judgeï¼‰è¯„ä¼°å™¨](https://langfuse.com/docs/scores/model-based-evals)ç”Ÿæˆï¼Œå®ƒä¼šåŸºäºæ•°æ®é›†ä¸­ç»™å‡ºçš„å‚è€ƒç­”æ¡ˆæ¥è¯„ä¼°è¾“å‡ºæ˜¯å¦æ­£ç¡®ã€‚\n",
    "\n",
    "![æ•°æ®é›†è¿è¡Œæ¦‚è§ˆ](https://langfuse.com/images/cookbook/example-langgraph-evaluation/dataset_runs.png)\n",
    "![æ•°æ®é›†è¿è¡Œå¯¹æ¯”](https://langfuse.com/images/cookbook/example-langgraph-evaluation/dataset-run-comparison.png)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python(flyai_agent_in_action)",
   "language": "python",
   "name": "flyai_agent_in_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
